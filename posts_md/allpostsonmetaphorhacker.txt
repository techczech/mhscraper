./2010-07-18-hacking-a-metaphor-in-five-steps.md
```
---
title: "Hacking a metaphor in five steps"
date: 2010-07-18
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/07/hacking-a-metaphor-in-five-steps
---

### **Preliminaries**

**1.** Before you start [metaphor](http://en.wikipedia.org/wiki/Metaphor "Metaphor") hacking you must first accept that you don’t have a choice but to speak in some sort of a figurative fashion. Almost nothing worth saying is entirely literal and there are many things whose “literalness” is rooted in metaphor. Look at “I sat in a chair the whole day.” Looks very literal at first glance but it depends on our understanding of a chair as a container (e.g. he was spilling out of his chair) and the day as an object (e.g. she was counting the days, cutting the day short, a long day, etc.)

**2.** You must also learn to recognize how metaphors are constructed through mappings from one domain to another. Sometimes these mappings are explicit, sometimes they are hidden, sometimes they are clear cut one-on-one connections and sometimes they are fuzzy and cross levels of categorization. But they’re there. If you say, “life is a journey” you can also say “I’ve reached a fork in the road” or “I’ve hit a rough patch” because you map elements of the “road/journey domain” such as intersections, rocky surfaces, hills, etc. to elements of the “life domain” such as decisions and difficult time periods. This way of thinking about metaphor was popularized by [Lakoff](http://en.wikipedia.org/wiki/George_Lakoff "George Lakoff") and Johnson in their 1980 book “Metaphors we live by” which is a great weekend read. However, do read the 2003 edition which contains an important additional chapter.

### **Metaphor hacking**

Once you’ve done the above, you can start hacking (or really do them at the same time).

**1.** Find an example of a metaphor being used in a way that limits your ability to achieve something or one that constrains your thinking or actions. For example, “education is a marketplace.”

**2.** Identify the domains involved in the metaphor. The source domain is the domain of knowledge or experience which is being used to structure our understanding of the target domain. This is frequently being confused with concrete/abstract or known/unknown but very often the source domain is just as abstract or well/little known as the target domain. For example: The source domain of marketplace and business is no more concrete or better known than the target domain of education. But it can still be used to structure our understanding  of the domain education.

**3.** Identity the most common mappings between the source and target domains. These generally have the form of “X is (like) Y” and carry with them the assumption that if X is like Y, it should have a similar relationship to Z or perform similar activities. The “is like” function relies on a fuzzy concept of identity, a sort of [family resemblance](http://en.wikipedia.org/wiki/Family_resemblance "Family resemblance"). For example, in the “education is a marketplace” metaphor, some common mappings are “students are customers” and “schools are companies providing a service”. Don’t make any judgements at this stage. Simply list as many mappings as you can find.

**4.** See which of the existing mappings are problematic in some way. Some mappings may lead us to others which we didn’t set out to create. This could be good or bad.  For instance, if we think of students as the clients of schools, it’s a very short step to thinking of  teachers as service staff and performance pay. This may be good or bad. But it also leads to students saying “I’ve paid you money for my education” so I deserve to pass. Which is a consequence very few would describe as good. You can also find some one-to-many mappings to see where the metaphor may get you into trouble. For example, if schools are businesses who is their customer? Students, parents, government or society? What is the currency? Knowledge, career prospects, etc. There’s nothing intrinsically wrong with one-to-many mappings but they can underscore a possible problem area in the way the metaphor is being used to generate new understandings.

**5.** Finally, find other possible mappings and try to imagine what the consequences would be. For this, you must strive to learn as much as possible about both of the domains involved and keep an open mind about the mappings. Anything goes. This can be done in a negative manner to bring into question the premise of the metaphor. For instance, Jeffrey Henig pointed out in his book on the Market Metaphor in education that one of the key prerequisites to the functioning of the market is a failure of business entities but none of the market reformers in education have provided a sufficient alternative to failure in their market model of schools.  This should certainly give the market advocates a pause. It doesn’t automatically mean that the marketplace metaphor cannot help us understand education in a useful way but it points to a possible limit to its utility. This process is similar to the rhetorical technique known as [reductio ad absurdum](http://en.wikipedia.org/wiki/Reductio_ad_absurdum "Reductio ad absurdum") but it has a different purpose. Also the metaphor hacker will approach this process with an open mind and will rule nothing out as a priori absurd but will also understand that all these mappings as just options not necessary consequences.

But driving a metaphor forward is most often a positive experience. Donald A Schön called this kind of metaphor use the “generative metaphor”. He gives a great example from engineering. When trying to design a new type of synthetic bristle for a paintbrush, a group of engineers was stuck because they were trying to figure out how to make the paint stick to the threads. This led to blobs of paint rather than nice smooth surfaces. Until one engineer said “You know what, a paintbrush is really a pump”. And immediately the research shifted from the surface of the bristles to their flexibility to create a pump like environment between the bristles rather than trying to make the paint stick to them. Anywhere else the “paintbrush is a pump” metaphor would have seemed ridiculous but in this context it didn’t even need an explanation. The engineers just got on with their work.

This process never stops. You can always find alternative mappings or alternative domains to help you understand the world. You can even have more than one source domain in a process called blending (or [conceptual integration](http://en.wikipedia.org/wiki/Conceptual_blending "Conceptual blending")) that generates new domains Fauconnier and Turner give the example of a [computer virus](http://en.wikipedia.org/wiki/Computer_virus "Computer virus") which blended the domain of software with the domain of medicine to generate a domain of computer viruses that has some properties of both and some [emergent properties](http://en.wikipedia.org/wiki/Emergence "Emergence") of its own. But this is for another time.

### **Conclusion**

All good hackers, engineers, journalists or even just members of a school or pub debate club have been hacking **at** metaphors ever since the phrase “is like” appeared in human language (and possibly even before). But this post urges a transition from hacking **at** metaphors to hacking metaphors in the best sense of the word. This requires some work at understanding how metaphors work and also getting rid of quite a few prejudices. We’re all used to dismissing others’ arguments as just metaphors and “literalness” is seen as virtue. Once we accept metaphors for what they are, we can start using them to improve how we think and what we do. Not through a wholesale transformation but through little tweaks and a bit of conceptual duct tape. And that’s what the hacker spirit is all about.

**Readings**
------------

1. George Lakoff and Mark Johnson, Metaphors we live by (Chicago: University of Chicago Press, 1980).
2. Jeffrey R. Henig, Rethinking school choice: limits of the market metaphor (Princeton, N.J.: Princeton University Press, 1994).
3. Donald Alan Schön, Displacement of concepts (London: Tavistock Publications, 1963).
4. Donald A. Schön, “Generative metaphor: A perspective on problem-setting in social policy,” in Metaphor (Cambridge: Cambridge University Press, 1979), 254-283.
5. Gilles Fauconnier and Mark Turner, The way we think: conceptual blending and the mind’s hidden complexities (New York: Basic Books, 2002).

### *Related*
```
./2010-07-18-what-its-all-about.md
```
---
title: "What it’s all About"
date: 2010-07-18
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/07/what-its-all-about
---

[Metaphors](http://en.wikipedia.org/wiki/Metaphor "Metaphor") are not just something extra we use when we’re feeling poetic or at a loss for le mot juste, they are all over our minds, texts and conversations. Just like conjunctions, tenses or word. And just like anything else, they can be used for good or ill, on purpose or without conscious regard. Their meanings can be exposed, explored and exorcised. They can be brought from the dead by fresh perspectives or trodden into the ground by frequent use. They may bring us into the very heights of ecstasy or they may pass by unnoticed. They elluminate and obscure, lead and mislead, bring life and death. They can be too constrained or they can taken too far. They can be wrong and they can be right. And they can be hacked.

[Hacking](http://en.wikipedia.org/wiki/Hacker_%28computer_security%29 "Hacker (computer security)") metaphors means taking them apart seeing how they work and putting them back together in a creative and useful way. People hack metaphors all the time without realizing what they’re doing and often getting into trouble by not recognizing that this is what they’re doing.  Paying a bit more attention to how metaphors work and how they can made work differently can make their hacking an easier process.

**Oh, and …**

Metaphor doesn’t really exist as a separate clearly delineated concept. It is really only one expression of a more general [cognitive](http://en.wikipedia.org/wiki/Cognition "Cognition") faculty I call [conceptual framing](http://en.wikipedia.org/wiki/Framing_(social_sciences)). Depending on who you ask, it is different from or the same as [simile](http://en.wikipedia.org/wiki/Simile "Simile"), [analogy](http://en.wikipedia.org/wiki/Analogy "Analogy"), [allegory](http://en.wikipedia.org/wiki/Allegory "Allegory") and closely related or in opposition to [metonymy](http://en.wikipedia.org/wiki/Metonymy "Metonymy"), [synechdoche](http://en.wikipedia.org/wiki/Synechdoche), irony, and a host of other [tropes](http://en.wikipedia.org/wiki/Figure_of_speech#Tropes). On this site, these distinctions don’t matter. All of the above rely on the same conceptual structures and metaphor is just as good a label as any for them.

[![Enhanced by Zemanta](http://img.zemanta.com/zemified_a.png?x-id=addb0a45-5640-4a8f-807a-485f99e7ba61)](http://www.zemanta.com/ "Enhanced by Zemanta")

### *Related*
```
./2010-07-21-what-its-not-about-so-much-about.md
```
---
title: "What it’s not about so much about"
date: 2010-07-21
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/07/what-its-not-about-so-much
---

Enter your email address to subscribe to this blog and receive notifications of new posts by email.
```
./2010-07-22-i-write-like-a-new-more-sophisticated-stripper-name.md
```
---
title: "I write like… a new more sophisticated stripper name?"
date: 2010-07-22
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/07/i-write-like-a-new-more-sophisticated-stripper-name
---

Making connections between ourselves and other people no matter how arbitrary, is an incredibly popular communal as well as private activity. The many algorithms for generating one’s stripper, mobster or some other kind of name have graduated from napkins in bars to Facebook apps and now proper quantitative analysis of text samples. But deep down they’re still the same. Is there a space here for hacking? Can we take this natural tendency, take it apart and put it back together again? Use it for good or for ill? I suppose most social engineering is the hacking of propositional frames, but are there explicit hacks of figurative language and thought? It’s certainly powerful enough when you find out that based on the About page here:

Just like with horoscopes, jumping on the connection gravy train is not easy to avoid. Mappings immediately started forming in my head: like with Nabokov, English isn’t my first language; like with Nabokov, I occasionally find my writing a bit tedious. But of course, taking [a piece of writing from another blog](http://hermeneuticheretic.net/2008/06/07/blending-and-framing-by-paradox/), I find I also

Drat, I was kind of getting used to the Nabokov simile. Ok, maybe I have a certain feel for the macabre and a book of the 12 different Czech translations of the Raven was one of my favorites… But just when I ought to quit while proverbially ahead, I paste a few paragraphs from my academic writing and find…

And I had to look this guy up! Simile fail!

NB: I wonder if they occasionally put up comparisons like Dr Seuss or complete nimrod.

### *Related*
```
./2010-07-30-why-ideas-arent-enough-to-solve-the-palestine-israeli-conflict.md
```
---
title: "Why ideas aren’t enough to solve the Palestine-Israeli conflict"
date: 2010-07-30
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/07/why-ideas-arent-enough-to-solve-the-palestine-israeli-conflict
---

An [advertising agency is trying to solve a bloody conflict](http://www.wired.co.uk/news/archive/2010-07/23/crowdsource-israeli-palestinian-conflict). This is presumptuous on such as scale that it could be called idiotic. Quoth [http://www.theimpossiblebrief.com](http://www.theimpossiblebrief.com/):

> “Rather than ‘out of date’ policies, we need ‘out of the box’ solutions. Let’s show the world that creative minds at their best can inspire even political leaders.”

Assuming that there’s an idea out there about resolving this conflict that noone’s ever thought of is nonsense. We should call this assumption that simple ideas can solve difficult problems the “TED Syndrome” (btw: I love TED talks, even if I share [Stephen Downes’ misgivings](http://halfanhour.blogspot.com/2010/02/ted-is-political.html) about the TED ‘elite’). Simple solutions to complex problems exist but they are very rare and when we hear about them, we are seldom told the whole story. Generally, it should be safe to assume that a solution should be of proportional complexity to the problem.

What Saatchi and Saatchi are so ineptly asking for could be thought of as a kind of metaphor hacking. But could metaphor hacking done right find a solution to the Palestine-Israeli conflict?

Short answer: No.

And now for the long answer. Metaphor hacking can’t solve anything. There are never any magical conceptual ways out of configurationally difficult situations. Metaphor hacking can provide insight and direction for individuals or groups (see the [paintbrush example](http://metaphorhacker.net/2010/07/hacking-a-metaphor-in-five-steps/)) but it has to be followed by hard work (both real and conceptual – I would call simplistically this ‘propositional’ work). On its own insight (whatever its source) achieves nothing.

Let’s try a few small hacks and see how far we get.

Although it can certainly be helpful to be aware of the conceptualizations that are involved, this awareness doesn’t necessarily give us power over them (I know a stick half-immersed in water is not broken but no power on Earth will make me see it so, I know that there is no up and down for the Globe, yet seeing a map with Africa on top will seem strange). First, metaphor is not the only conceptual structure involved in how people understand this situation. Metaphor (and its brethren) are mental structures relying on similarity. We also need to look at structures of contiguity (metonymy) and add other conceptual structuring devices that are propositional, imagistic and textual.

Let’s start at the end. I purposely entitled the problem Palestine-Israeli conflict. Logically, it shouldn’t matter, conflict is a commutative relationship – if I’m in conflict with you, you are in conflict with me. But we have textual iconicity. The thing that is first in real life is more important, and therefore we tend to put the more important things first in language first. That’s why we are instructed to say politely “Ladies and gentlemen” which only underscores the hidden sexism behind “boys and girls”, “men and women”, etc. So a small hack for all involved. Make sure you always describe the conflict with an iconicity that goes against your natural inclinations. This is not going to solve anything but it might keep you more attuned to your own possible prejudices.

We can also hack the “we were here first” trope. Now remember, there’s no hidden metaphorical solution. But if we can accept that our understanding of “claim by primacy” is structured by a number of source domains from which no perfect mappings exist, we can perhaps invest the claims with a bit less weight. The only way to settle this argument would be to close off or designate as illegitimate some of these source domains. But since such closing off is always the result of the application of power and not some disembodied logic, this is not the right way to go about it. So a useful hack would be to list all the possible source domains for understanding the domain of “we were here first, therefore we have a claim to this X”, draw all the mappings from the obvious to the ridiculous and see how easily challenged any such claim must always be (or maybe we’ll find that one side has many more favorable mappings than the other but I don’t think that’s very likely).

Can we hack our way out of the holy place and holy war controversies? Again, mostly no. A lot of religion is based on similarity and contiguity: from sympathetic magic or Anglican liturgy to free market capitalism or theory of evolution. These are bolstered by textual constructions that normally don’t carry a particularly heavy semantic load but will discharge their potential meanings in times of conflict. The same formulas that are mindlessly droned by the faithful during their rituals (be they Sunday worship or a Wall Street Journal editorial) can be brought into full conceptual battle readiness when necessary. This conceptual mobilization is always selective. All liturgical systems are internally contradictory (they might tell you to love your mom and dad one day and to ditch them the next) and it is necessary that some formulas remain just that while others are brought out in their full semantic splendor. This is what makes ecumenicalism possible. But from there we can perform a useful hack. Not all ideas potentially contained in a text have to come to fruition. Ours and theirs. If we can just keep them as part of the liturgy and not get too incensed over them. If we can accept that while the others may recite verses that would have us die, they may not necessarily mean “really” die, then we can go have a cautious conversation to make sure of that.

Growing up in communist Czechoslovakia, I remember my largely pacifist and moderately Christian family and friends singing to the tune of John Brown’s Body (unaware of the gruesome irony) “when all the communists are swinging from a tree, when all the communists are swinging from a tree, when all the communists are swinging from a tree, then there will be paradise.” Few of them would have probably even supported the death penalty let alone be part of a lynch mob. But in the right circumstances…who knows? A similar case is made for the traditional song “Shoot the Boer” sung in South Africa [in this On The Media feature](http://www.onthemedia.org/transcripts/2010/05/07/04). (Cf. also the fluctuating militarism of [Onward Christian Soldiers](http://en.wikipedia.org/wiki/Onward_Christian_Soldiers).)

In the case of Israel-Palestine, of course, we know that some of the people involved would be and have been involved in the carrying out of the underlying meanings of their phrases. However, the thing to remember is that they don’t have to be. We just have to keep in mind that words and actions aren’t always in sync and that is usually to the good. So in other words, we can’t solve the idea problem with more ideas but we can temper the ideas and divorce them from actions. Not easy and not instantaneous but historically inevitable.

So the hacks might be interesting but we come back to the original assumption that difficult situations are difficult to resolve. There are many ways in which you can hack somebody else’s mind, magicians, con artists and advertisers do it all the time. But these hacks are very straightforward, build on frame-based expectations and rarely have a lasting effect. Propaganda and brain washing are a kind of a mind hack but they only work predictably in conjunction with real power closing off other sources of cross-domain mappings. Mostly, when it comes to metaphor, we can’t hack somebody else’s, we can present a few alternative mappings, we can offer a more detailed analysis of the source domain or even reject or replace a source domain altogether. But whether this will carry weight is dependent on factors outside of the metaphor itself (although perhaps relying on the same sort of principles) such as social prestige, context, material resources, political clout, etc. Ideas always come with the people who espouse them and I doubt ideas coming with Saatchi and Saatchi will have enough internal coherence to carry them over the disadvantages flowing from their carrier. Let’s hope, I’m wrong.

### *Related*
```
./2010-08-01-why-chomsky-doesnt-count-as-a-gifted-linguist.md
```
---
title: "Why Chomsky doesn’t count as a gifted linguist"
date: 2010-08-01
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/08/why-chomsky-doesnt-count-as-a-gifted-linguist
---

Somebody commented on the Language Log saying “of course […] Chomsky was a massively gifted linguist” <http://j.mp/9Q98Bx> and for some reason, to use a Czech idiom, the handle of the jar repeatedly used to fetch water just fell off. Meaning, I’ve had enough.

I think we should stop thinking of Chomsky as a gifted linguist. He was certainly a gifted mathematician and logician still is a gifted orator and analyst of political discourse (sometimes putting professionals in this area to shame). But I honestly cannot think of a single insight he’s had about how language works as language. His main contribution to the study of language (his only one really) was a description of how certain combinatorial properties of English syntax can be modeled using a particular formal system.  This was a valuable insight but as has been repeatedly documented (e.g. Newmeyer 1986) its runaway success was due to a particular historical context and was later fed by the political prominence of its originator. Unfortunately, everything that followed was predicated on the model being isomorphic with the thing modeled. Meaning all subsequent insights of Chomsky and his followers were confined to refining the model in response to what other people knew about language and not once that I can think of using it to elucidate an actual linguistic phenomenon. (Well, I tell lie here, James MacCawley who worked with GB – and there must have been others – was probably an exception.) Chomsky’s followers who actually continued to have real insights about language – Ross,  Langacker, Lakoff, Fillmore – simply ceased to work within that field – their frustration given voice here by Robin Tolmach Lakoff:

> [Generative approaches to the ‘science’ of language meant] “accepting the impossibility of saying almost everything that might be interesting, anything normal people might want or need to know about language.“ (Robin Tolmach Lakoff, 2000, Language War)

So who deserves the label “gifted linguist” defined as somebody who repeatedly elucidates legitimate language phenomena in a way that is relevant across areas of inquiry? (And I don’t mean the fake relevance followers of the Universal Grammar hypothesis seem to be finding in more and more places.)

Well, I’d start with MAK Halliday who has contributed genuine insights into concepts like function, cohesion, written/spoken language, etc. Students on “linguistics for teachers” courses are always surprised when I tell them that pretty much all of the English as first or second language curriculum used in schools today was influenced by Halliday and none by Chomsky – despite valiant efforts to pretend otherwise.

But there are many others whose fingerprints are all over our thinking about language today. The two giants of 20th century linguistics who influenced probably everyone were Roman Jakobson and Charles Fillmore – neither of whom established a single-idea school (although Jakobson was part of two) but both were literal and metaphorical teachers to pretty much everybody. Then there’s William Labov who continues to help shift the “language decline” hypothesis on which much of 19th century philology was predicated. And, of course, there are countless practicing linguists who have interesting things to say about language every day – one needs to look no further than the contributors to the [excellent Language Log](http://languagelog.ldc.upenn.edu). I don’t want to list any others of the top of my head lest I forget someone important, but here some of my favorites:

My personal favorite linguist has long been Michael Hoey whose “lexical priming” hypothesis deserves more discussion and a lot more following than it has received. I got a real chill of excitement reading William Croft’s “Radical Construction Grammar”. It is probably the most interesting and innovative view of language that has come about since de Saussure.

Most of my thinking about language has been influenced by George Lakoff (so much I translated his thickest book into Czech – <http://cogling.info>) and Ronald Langacker who could both be said to be ‘single-theory’ thinkers but are actually using this theory to say interesting things about language rather than using language to say interesting things about their theory.

I have said to people at one point or another, you should read one of these linguists to understand this point about language better. I have never said that about Chomsky. Not once. I have said, however, you should read this thing by Chomsky to understand Chomsky better. (Not that it always helps, I’ve come across a book called [Structure of Language](http://www.amazon.co.uk/Structure-Spoken-Written-Language-English/dp/1861564295) whose authors’ sparse reference list includes all of Chomsky’s books but who refer to his work twice and get it wrong both times.) There is no denying Chomsky’s multi-disciplinary brilliance but a particularly gifted linguist he is not. He is just the only one most people can think of.

BTW: Here’s why I think Chomsky’s wrong. But that wasn’t really the point. Whether he’s right or wrong, he’s largely irrelevant to most people interested in language, and the sooner they realize they’re wasting their time, the better.

### *Related*
```
./2010-08-04-the-tortoise-and-the-hare-analogy-for-academia-in-the-digital-world.md
```
---
title: "The Tortoise and the Hare: Analogy for Academia in the Digital World?"
date: 2010-08-04
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/08/the-tortoise-and-the-hare-analogy-for-academia-in-the-digital-world
---

[Dan Cohen](http://www.dancohen.org "Dan Cohen") has decided to “[crowdsource](http://en.wikipedia.org/wiki/Crowdsourcing "Crowdsourcing")” (a fascinating blend, by the way) the title of his next book with the following instructions.

> The title should be a couplet like “The X and the Y” where X can be “Highbrow Humanities” “Elite Academia” “The Ivory Tower” “Deep/High Thought” [insert your idea] and Y can be “Lowbrow Web” “Common Web” “Vernacular Technology/Web” “Public Web” [insert your idea]. so possible titles are “The Highbrow Humanities and the Lowbrow Web” or “The Ivory Tower and the Wild Web” etc.
>
> via [Dan Cohen’s Digital Humanities Blog » Blog Archive » Crowdsourcing the Title of My Next Book](http://www.dancohen.org/2010/08/04/crowdsourcing-the-title-of-my-next-book/).

Before I offer my suggestion, let me pause and wonder how do we know what the book is to be about? Well, we know exactly what it is to be about because what he has in fact done was describe its contents in the form of two cross domain mappings that are then mapped onto each other (a sort of a double-barrel metaphor). And the title, it goes without saying (in a culture that agrees on what titles should be) should as eloquently and entertainingly point to the complex mapping through yet more mappings (if this was a post on blending theory, I’d elaborate on this some more).

We (I mean us the digitized or unanalog) can also roughly guess what Dan Cohen’s stance will be and if he were to be writing it just for us, we’d much rather just get it as a series of blog posts, or perhaps not at all. The paragraph quoted above is enough for us. We know what’s going on.

So aware of the ease with which meaning was co-constructed, I would recommend a more circumspect and ambiguous title. **[The Tortoise and the Hare](http://www.amazon.com/Tortoise-Hare-Janet-Stevens/dp/0590336770%3FSubscriptionId%3D0G81C5DAZ03ZR9WH9X82%26tag%3Dbohemicaco%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D0590336770 "The Tortoise and the Hare")** with a subtitle:  **Who’s Chasing Whom in Digital Scholarship** or possibly **The Winners and Losers of Digital Academia**. Why this title? Well, I believe in challenging preconceptions, starting with our own. The tale of the Tortoise and the Hare (as the [excellent Wikipedia entry documents](http://en.wikipedia.org/w/index.php?title=The_Tortoise_and_the_Hare&oldid=375942493)) offers no easy answer. Or rather it offers too many easy answers for comfort. The first comes from the title and a vague awareness of the fact that this is a story about a speed contest between two animals who are stereotypes for the polar opposites of speed. So the first impression is “of course, the hare is the winner” and this is a book about the benefits of digital scholarship, so the digital scholars must be the hare. Also, and also digital equals fast so that means the book is about how the hare of digital scholarship is leaving the tortoise of ivory-tower academia in the dust. And we could come up with a dozen stories illustrating how this is the case.

Then we pause and remember, ah, but didn’t the tortoise win the race because of the hasty overconfidence and carelessness of the hare? So that means that perhaps the traditional academics, moving slowly but deliberately, are the favored ones, after all? Can’t we all also think of too many errors made on blogs, crowdsourced encyclopedic entries and easily make the case that the deliberate approach is superior to moving at breakneck speed? Aren’t hares known for their short and precarious life spans as well as speed while the tortoise is almost proverbial in its longevity?

But the moral of the story is even more complex and less determinate. If we continue further in our deliberations, we might be able to get a few more hints of this. In particular, we must ask, what does this story tell us about speed and wisdom? And the answer must be: absolutely nothing. We knew coming into it that hares were faster than tortoises over any distance that can be traveled by both animals. We’re not exactly clear why the tortoise challenged the hare. Unless it had secret knowledge of its narcolepsy, it couldn’t have possibly known that the hare would take a nap or get distracted (depending on the version of the story) in the middle of the race? So equating the tortoise with wisdom would seem foolish. At best we can see the tortoise as an inveterate gambler whose one-in-a-million bet paid off. We would certainly be foolish (as was noticed by [Lord Dunsany](http://en.wikipedia.org/wiki/Edward_Plunkett,_18th_Baron_of_Dunsany "Edward Plunkett, 18th Baron of Dunsany") cited in the Wikipedia entry) to assume that the hare’s loss makes the tortoise more suitable for a job delivering a swift message over the same journey the following day. So the only possible learning could be that taking nap in the middle of a race and not waking up in time can lead to loosing the race. Conceivably, there could be something about the dangers of overconfidence. But again didn’t we know this already through many much less ambiguous stories?

What does that mean for the digital and traditional scholarship? Very tentatively, I would suggest it is that we cannot predict the results of a single race (i.e. any single academic enterprise) based purely on the known (or inferred) qualities of one approach. There are too many variables. But neither can we discount what we know about the capabilities of one approach in favor of another simply because it proved to be a failure where we would have expected success. In a way, just like with the fable, we already know everything about the situation. For some things hares are better than tortoises and vice versa. Most of the time, our expectations are borne out and sometimes they are not. Sometimes the differences are insignificant, sometimes they matter a lot. In short, life is pretty damn complicated, and hoping a simple contrast of two prejudice-laden images will help us understand it better is perhaps the silliest thing of all. But often it is also the thing without which understanding would be impossible. So perhaps the moral of this story, this blog, and of Dan Cohen’s book really should be: beware of easy understandings.

[![Enhanced by Zemanta](http://img.zemanta.com/zemified_a.png?x-id=538459b7-02e8-49f2-ac64-06386022bc16)](http://www.zemanta.com/ "Enhanced by Zemanta")

### *Related*
```
./2010-08-06-metaphor-is-my-co-pilot-how-the-literal-and-metaphorical-rely-on-the-same-type-of-knowledge.md
```
---
title: "Metaphor is my co-pilot: How the literal and metaphorical rely on the same type of knowledge"
date: 2010-08-06
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/08/metaphor-is-my-co-pilot-how-the-literal-and-metaphorical-rely-on-the-same-type-of-knowledge
---

“Thanks” to experimental philosophy, we have a bit more evidence confirming, that what many people think about the special [epistemological](http://en.wikipedia.org/wiki/Epistemology "Epistemology") status of [metaphor](http://en.wikipedia.org/wiki/Metaphor "Metaphor") is bunk. We should also note that Gibbs’ and Glucksberg’s teams have been doing a lot of similar research with the same results since the late 1980s.

This is how [Joshua Knobe](http://en.wikipedia.org/wiki/Joshua_Knobe "Joshua Knobe") on the [Experimental Philosophy](http://experimentalphilosophy.typepad.com/experimental_philosophy/2010/08/what-metaphors-mean.html) blog summarized a forthcoming paper by Mark Phelan (<http://pantheon.yale.edu/~mp622/inadequacy.pdf>):

In short, it looks like it really is pretty impossible to explain what a metaphor means. But that is not because of anything special about metaphors. It is merely a reflection of the fact that we can’t explain what any sentence means.  [Experimental Philosophy: What Metaphors Mean](http://experimentalphilosophy.typepad.com/experimental_philosophy/2010/08/what-metaphors-mean.html)

Phelan went and asked people to paraphrase metaphorical and non-metaphorical statements only to find that the resulting paraphrases were judged equally inadequate for metaphors and literal statements. In fact, paraphrases of metaphorical statements like “Music is the universal language” or “Never give your heart away” were judged as more acceptable than paraphrases of their “literal” counterparts “French is the language Quebec” and “Always count your change”. The result shows something that any good translator will know intuitively – paraphrases are always hard.

So the conclusion (one to which I’m repeatedly drawn) is that there’s nothing special about metaphors when it comes to meaning, understanding and associated activities like paraphrasing. The availability of paraphrase (and understanding in general) is broadly dependent to two factors knowledge and usage. We have to know a lot about the world and how language is used to navigate it. So while we might consider “there’s a chair in the office”, “a chair is in the office” or “how about that chair in the office” as adequate descriptions of a particular configuration of objects in space, the same does not apply to usage. And things get even trickier when we substitute “a cobra” or “an elephant” for “a chair” and then start playing around with definiteness.  We know that chairs in offices are normal and desirable, cobras unlikely and undesirable and elephants impossible and most likely metaphorical. Thinking that we can understand both “there’s an elephant in the office” and “there’s a chair in the office” as simply a combination of the words and the construction “there’s X in Y” is a bad idea. And the same goes for metaphors. We need to know a lot about the world and language to understand them.

One of the pairs of sentences Phelan compared was “God is my co-pilot” and “Bill Thomson is my co-pilot”. Intuitively, we’d say that the “literal” one would be easier to paraphrase and we’d be right but not as radically: 47% of respondents chose “God is helping me get where I want to go” as a good paraphrase and mere 58% went with “I have a copilot named Bill Thomson”. And that goes slightly against intuition. But not if we think about it a bit more carefully. All the same questions we can ask about the meaning of these two sentences demonstrate a significant dependence on knowledge and usage. “In what way is God your co-pilot” makes sense where “In what way is Bill Thomson your co-pilot” doesn’t. But we can certainly ask “What exactly does Bill do when he’s your copilots”, “What do co-pilots do anyway”. And armed with that knowledge and knowledge of the situation we can challenge either statement “no God isn’t really your co-pilot” or “no Bill isn’t really your co-pilot”. Metaphoricity really had no impact – it was knowledge. Most people know relatively little about what co-pilots do so we might even suspect that their understanding of “God is my co-pilot” is greater than of “Bill is my co-pilot”.

This is because the two utterances are not even that different conceptually. They both depend on our ability to create mental mappings between two domains of understanding: the present situation and what we know about co-pilots. We might argue that in the “literal” case, there are fewer more determinate mappings but that is only the case if we have precise and extensive knowledge. If we hear the captain say “Bill is my co-pilot” and we know that “co-pilots sit next to pilots and twiddle with instruments”, we can then conclude “the guy sitting next to the captain and switching toggles is Bill”. If the person sitting next to us said “God is my co-pilot”, we can draw conclusions from our knowledge of usage e.g. “people who say this are also likely to talk to me about God”. It seems a very simple mapping. This would get a lot more complex if the captain said “God is my co-pilot” and the person sitting next to us on the plane would say “Bill is my co-pilot” but it would still be a case of reconciling our knowledge of the world and language usage with the present situation through mappings. So the seeming simplicity of the literal is really just an illusion when it comes to statements of any consequence.

–7 Aug – Edited slightly for coherence and typos

### *Related*
```
./2010-08-17-philosophers-songbook-philbitescomp.md
```
---
title: "Philosophers’ songbook #philbitescomp"
date: 2010-08-17
author: Dominik Lukeš
source: https://metaphorhacker.net/2010/08/philosophers-songbook-philbitescomp
---

I was so inspired by the [#philbitescomp](http://twitter.com/#search?q=%23philbitescomp) twitter contest that I wrote a short history of philosophy in tweetable fragments of songs.

*Parmenides’ lament:*I guess it will make a change  
when things stop changing

*Heracleitus’ blues:*  
I cried you the same river  
thrice

*Plato’s polka:*  
two steps out of the cave  
and look at what you’re doing

*Descartes’ swan song:*  
unbidden unwelcome it counts  
yet for a penny I perish

*Bishop Berkeley’s soccer fan chant:*  
Hey Samuel Johnson  
You’re kicking that rock in my mind

*Locke’s lullaby:*  
You’ve licked your plate clean  
And now what do you know?

*Kant’s shanty:*  
it’s a long way  
from first principles

*Voltaire’s spiritual:*  
Think low sweet chariot  
Believe in Him and don’t cheat me

*Hegel’s Carroll:*  
Give up the ghosts of times past  
Master and slave, together at last

*Marx’s revolutionary song:*  
I saw you coming Ford, a mile away  
But Lenin came out of left field

*Heidegger’s Rap:*  
With all my sein, I’ll do my zeit  
Those sons of canines might not bite

*Derrida and Wittgenstein’s duet:*Brick by brick move by move  
you say circuses I say no more

*High school philosophy teacher’s tattoo:*Be rational  
you scabs

### *Related*
```
./2011-02-20-the-most-ridiculous-metaphor-of-education-courtesy-of-an-economics-professor.md
```
---
title: "The most ridiculous metaphor of education courtesy of an economics professor"
date: 2011-02-20
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/02/the-most-ridiculous-metaphor-of-education
---

Acclaimed academics have policy agendas just like anybody else. And often they let them interfere with a straightforward critical analysis of their output. The monumental capacity for blindness of highly intelligent people  is sometimes staggering. **Metaphors and analogies** (same thing for metaphor hacking) **make thinkers particularly prone to mis-projection blindness**. [Edward Glaeser](http://www.economics.harvard.edu/faculty/glaeser), a Harvard economics prof, is just the latest in the long line of economists and blowhards, who think they have the education system licked by comparing it to some -free market gimmick. They generally reveal that they know or care precious little about the full extent of the processes involved in the market and Glaeser is a shining example of this. His analogy is so preposterous and only needs so little thought to break down, I can’t believe he didn’t take a few minutes to to do it himself. Well, actually, I can believe it. It’s pretty,  neat and seductive. So who cares that it is pure non-sense. Here’s what he said:

> [Why Cities Rock | Freakonomics Radio](http://freakonomicsradio.com/why-cities-rock.html): I want you to just imagine if for example, instead of having a New York restaurant scene that was dominated by private entrepreneurs who competed wildly with each other trying to come up with new, new things. The bad restaurants collapse; the good restaurants go on to cooking show fame. You have these powerful forces of competition and innovation working. Imagine instead if there was a food superintendent who operated a system of canteens where the menus were decided at the local level, and every New Yorker had to eat in these canteens. Well, the food would be awful. And that’s kind of what we decided to do with schooling. Instead of harnessing the urban ability to provide innovation, competition, new entry, we’ve put together a system where we’ve turn all that stuff off, and we’ve allowed only a huge advantage for a local, public monopoly. It’s very, very difficult to fix this. I think the most hopeful signs, and there’s been as you know a steady stream of economics papers on this, the most hopeful signs I think are coming from charter schools, which are particularly effective in urban areas. And it’s not so much that the average charter school is so much better than the average public school, but rather that in charter schools, because they can go bankrupt, because the can fail, the good ones will succeed, and the bad ones will drop out of the market. And certainly we’ve seen lots of great randomized studies that have shown the ability of charters to deliver great test score results.

As we know, metaphors (and their ilk) rely on projections from one domain to another. Generative metaphor (of which this is one) then try to base a solution on a new domain which is the result of the blending of the source domain.

So this is how Glaser envisions the domain of New York restaurants: there is competition, which drives up the quality of the food (note that he didn’t mention driving down prices, lowering expense per unit, and other tricks used by ‘wildly competing entrepreneurs’). Restaurateurs and chefs must strive to provide better food than others because there is so much choice, people will flock to their competitors for the better food.

This is how he wants to project it into schooling: give people more choice (and means to exercise that choice by using the intra city’s short commutes) and this will result in competition, the competition will increase experimentation and as a result the quality of education goes up. He also mentions test scores at the end but these have little to do with education (but why should somebody at Harvard know that?).

Of course, he makes most of the argument through a reverse projection, where he asks us to imagine what the New York restaurants would look like if they were run like a centralized public school system. He envisions the end process as similar to Apple’s 1984 commercial: a sea of bland canteens with awful food. But this is just so much elitist blather. Glaeser should be ashamed of himself for not thinking this through.

First, what he describes is only true of the top tier of New York restaurants. The sort of places the upper-middle glass go to because of a review on Yelp. The majority of places where New Yorkers (and people everywhere) eat their lunches and the occasional dinner are either real canteens, some local greasy spoon, or a chain that makes its consistent prices and dining experiences possible through resolute mediocrity. The Zagat guide is for special occasions, not daily nutrition.

Second, Glaser never asks how this maps onto schooling or education, in general. Probably because the answer would be that it doesn’t. Glaeser certainly refused to say anything useful about his analogy. He went far enough to promote his shallow ideology and stopped while the stopping was good. Let’s look at a few possible mappings and see how we fare.

So first we have the quality of the food. This would seem to map quite nicely onto quality of education. But it doesn’t. Or at least not in the way Gleaeser and his like would like.  Quality of the food that can impact on competition is a surface property. We cannot also always trust people that they can judge the quality apart from the decor of the restaurant or its reputation – just like with wine, they are very likely to judge the quality based on a  review or the recommendation of a trusted acquaintance. In Glaeser’s analogy, we’re not really talking about the quality of food but the quality of the dining experience. And if we project this onto the quality of a school, we’re only increasing the scope of the problem. No matter how limited and unreliable, we can at least judge the quality of the overall dining experience by our own reaction to our experience. But with schools, the experience is mediated through the child and the most important criterion of quality – viz an educated human being at the end – is deferred until long after the decision on quality has been made. It’s like judging the quality of a restaurant we go to for an anniversary dinner by whether we will be healthy in 5 years. Of course, we can force such judgements but arbitrarily ranking schools based on a single number – like the disastrous UK league tables that haven’t improved the education of a single child but made a lot of people extremely anxious.

The top restaurants (where the competition makes a difference) don’t look at food from the perspective of what matters for life, namely nutrition. It’s quite likely the most popular restaurants don’t serve anything particularly healthy or prepared with regard to the environmental impact. Quality is only important to them as one of many competitive advantage. They also use a number of tricks to make the dining experience better – cheat on ingredients, serve small portions on large plates, etc. They rely on ‘secret recipes’ – the last thing we want to see in education. And this is exactly the experience of schools that compete in the market. They fudge, cheat and flat out lie to protect their competitive advantage.  They provide the minimum of education that they can get away with to look good. Glaeser also conveniently forgets that there is a huge amount of centralized oversight of New York restaurants – much more, in some ways, than on charter schools. Quality is only one of the results of rampant competition and oversight is necessary to protect consumers. This is much more important in schools than in restaurants (but it almost seems that restaurants have more of it, than schools – proportionally to their importance).

But that is only one part of this important mismapping, which is the process of competition. Many economists forget that the market forces don’t work on their own. They work off the backs of the cheated and underserved. Bad restaurants don’t go out of business by some market magic. They go out of business because enough people ate there and were cheated, served bad food or almost got poisoned. And this experience had to have been bad enough for them to talk about it and dissuade others from visiting. With restaurants the individual cost is relatively minor (at least for those comfortably off). You have to contribute one or two bad meals or ruined evenings a year to keep the invisible hand doing its business among the chefs of New York. (This could be significant to someone who only goes out once every few months but still something you can get over.) Also the cost of making a choice is virtually nill. It takes no effort to go to a different restaurant or to choose to eat at home. Except for the small risk of food poisoning, you’ve made no investment in your choice and the potential loss is minimal.

However, in the case of schooling, you’re making a long-term commitment (at least a semester or a year but most likely at least four years). You can shrug off a bad meal but what about a wasted half-a-decade of your child’s life? Or what if you enrolled your child in the educational equivalent of Burger King serving nothing but giant whoppers. Everything seems fine all along but the results are clogged intellectual arteries. Also the costs of a school going out of business (and here Glaeser is one of the honest few that admit to bankrupt schools as a desirable outcome of competition in education) are exceedingly high. Both financial and emotional. Let’s say a school goes out of business and a poor parent has invested in books, school uniform and transportation choice only to have to start this again in a new school. Or how about the toll that making new friends, getting used to new teachers, etc. takes on a child. How many ruined childhoods is Glaeser willing to accept for the benefits of his ideology? As far as I know, the churn among New York restaurants is quite significant – could the education system sustain 10% or even 1% of schools going out of business every year.

And more importantly what about great schools going out of business because of financial mismanagement of capitalist wannabes? Not all market failures (maybe even not most) are due to low quality. Bad timing, ruthless competition, impatient investors and insufficient growth have killed many a great product. How many great schools would succumb to one of these? And won’t we see the same race to mediocrity once the ‘safe middle ground’ of survival is discovered? How many schools will take on the risk of innovation in the face of relentless market pressures? For a Chef, one bad recipe is just a learning experience. For a school, one unsuccessful innovation can lead to absolute disaster.

But all that is assuming that we can even map the “quality of education” onto quality in any sphere of commercial activity whatsoever. What business do you get a product or service from for four or eight years that requires a daily performance of a complex and variable task such as caring for and educating a young person is? Not your electricity provider who provides a constant but a non-variable service, nor your medical care provider who offers a variable but only periodical service. Also, “the consumers of education’s” requirements keep changing over time. They may have wanted a rounded and fulfilling education for their child at the start but just want them to get to university at the end. You can measure quality by test scores or graduation rates but that still doesn’t guarantee success for roughly 10-20% of students even in the best of schools.

To conclude, fine food plays a role in the prosperity of restaurants but so does convenience and habit. The quality of education is too complex to map successfully on the quality of food (and possibly any single commercial product). And even if that was possible, the cost of making the market forces work is incomparably higher in education than in dining. Glaeser’s proposed model for reform is just as likely to produce pinnacles of excellence as ruthlessly competitive MacDonald’s-like chains of garbage.

There’s nothing wrong with using metaphors to try to look for ways to improve education. But generally, these should be very local rather than global and always have their limits carefully investigated. That means detailed understanding of both domains and meticulous mappings between them as well as the relationships between them. Not all mappings need to be perfect and some need not be there at all (for instance, computer virus is still useful metaphor even though it doesn’t spread through the air), but this should be done consciously and with care. Steve Jones once said of evolution that metaphor is to it like bird excrement is to statues. The same often goes for education, but it doesn’t have to.

Finally, this analysis didn’t necessarily imply that the current system is the best there can be or that it is even any good (although I think it’s pretty good). Just that reforming it based on this *cock-a*–*maney* metaphor could be extremely dangerous. New solutions must ultimately be judged on their own merit but with the many market metaphors, very many their merit is irretrievably tied to the power of the initial metaphor and not any intrinsic solution.

**UPDATE:** It seems I may have a been a bit too harsh on Glaeser. [Obsevational Epidemiology](http://observationalepidemiology.blogspot.com/2011/02/edward-glaeser.html) posts this quote form his book (the one he was promoting on the Freakonomics podcast):

> All of the world’s older cities have suffered the great scourges of urban life: disease, crime, congestion. And the fight against these ills has never been won by passively accepting things as they are or by mindlessly relying on the free market.

Ok, so he’s not just a mindless free-marketeer. So why on earth would he suggest the above as a suitable metaphor to base educational reform on?

### *Related*
```
./2011-03-11-the-brain-is-a-bad-metaphor-for-language.md
```
---
title: "The brain is a bad metaphor for language"
date: 2011-03-11
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/03/the-brain-is-a-bad-metaphor-for-language
---

**Note:** This was intended to be a brief note. Instead it developed into a monster post that took me two weeks of stolen moments to write. It’s very light on non-blog references but they exist. Nevertheless, it is still easy to find a number of oversimplifications,  conflations, and other imperfections below. The general thrust of the argument however remains.

How Far Can You Trust a Neuroscientist?
---------------------------------------

[![Shiny and colored objects usually attract Infa...](http://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Infant_looking_at_shiny_object.jpg/300px-Infant_looking_at_shiny_object.jpg "Shiny and colored objects usually attract Infa...")](http://commons.wikipedia.org/wiki/File:Infant_looking_at_shiny_object.jpg)

Image via Wikipedia

A couple of days ago I watched a [TED talk](http://en.wikipedia.org/wiki/TED_%28conference%29 "TED (conference)") called the Linguistic Genius of Babies by [Patricia Kuhl](http://en.wikipedia.org/wiki/Patricia_K._Kuhl "Patricia K. Kuhl"). I had been putting it off, because I suspected I wouldn’t like it but I was still disappointed at how hidebound it was. It conflated a number of really unconnected things and then tried to sway the audience to its point of view with pretty pictures of cute infants in brain scanners. But all it was, is a hodgepodge of half-implied claims that is incredibly similar to some of the more outlandish claims made by behaviorists so many years ago. Kuhl concluded that brain research is the next frontier of understanding learning. But she did not give a simple credible example of how this could be. She started with a rhetorical trick. Mentioned an at-risk language with a picture of a mother holding an infant facing towards her. And then she said (with annoying condescension) that this mother and the other tribe members know something we do not:

> What this mother — and the 800 people who speak Koro in the world — understand that, to preserve this language, they need to speak it to the babies.

This is garbage. Languages do not die because there’s nobody there to speak it to the babies (until the very end, of course) but because there’s nobody of socioeconomic or symbolic prestige children and young adults can speak the language to. Languages don’t die because people can’t learn them, they die because they have no reason (other than nostalgia) to learn them or have a reason not to learn them. Given a strong enough reason they would learn a [dying language](http://en.wikipedia.org/wiki/Language_death "Language death") even if they started at sixteen. They just almost never are given the reason. Why Kuhl felt she did not need to consult the literature on language death, I don’t know.

Patricia Kuhl has spent the last 20 years studying pretty much one thing: acoustic discrimination in infants (<http://ilabs.washington.edu/kuhl/research.html>). Her research provided support for something that had been already known (or suspected), namely that young babies can discriminate between sounds that adults cannot (given similar stimuli such as the ones one might find in the [foreign language](http://en.wikipedia.org/wiki/Foreign_language "Foreign language") classroom). She calls this the “linguistic genius of babies” and she’s wrong:

> Babies and children are geniuses until they turn seven, and then there’s a systematic decline.

First, the decline (if there is such a thing) is mostly limited to acoustic processing and even then it’s not clear that the brain is the thing that causes it. Second, being able to discriminate (by moving their head) between sounds in both English and Mandarin at age 6 months is not a sign of genius. It’s a sign of the baby not being able to differentiate between language and sound. Or in other words, the babies are still pretty dumb. But it doesn’t mean they can’t learn a similar distinction at a later age – like four or seven or twelve. They do. They just probably do it in a different way than a 6-month old would. Third, in the overall scheme of things, acoustic discrimination at the individual phoneme level (which is what Kuhl is studying) is only a small part of learning a language and it certainly does NOT stop at 7 months or even 7 years of age. Even children who start learning a [second language](http://en.wikipedia.org/wiki/Second_language "Second language") at the age of 6 achieve a native-like phonemic competence. [And even many adults do](http://psych.colorado.edu/~munakata/csh/mccandlissetal.pdf). They seem not to perform as well on certain fairly specialized acoustic tests but functionally, they can be as good as native speakers. And it’s furthermore not clear that accent deficiencies are due to the lack of some sort of brain plasticity. Fourth, [language learning](http://en.wikipedia.org/wiki/Language_acquisition "Language acquisition") and knowledge is not a binary thing. Even people who only know one language know it to a certain degree. They can be lexically, semantically and syntactically quite challenged when exposed to a sub-code of their language they have little to no contact with. So I’m not at all sure what Kuhl was referring to. [François Grosjean](http://en.wikipedia.org/wiki/Fran%C3%A7ois_Grosjean "François Grosjean") (an eminent researcher in the field) has been discussing all this [on his Life as Bilingual blog](http://www.psychologytoday.com/blog/life-bilingual) (and in books, etc.). To have any credibility, Kuhl must address this head on:

> There is no upper age limit for acquiring a new language and then continuing one’s life with two or more languages. Nor is there any limit in the fluency that one can attain in the new language with the exception of pronunciation skills.

Instead she just falls on old prejudices. She simply has absolutely nothing to support this:

> We think by studying how the sounds are learned, we’ll have a model for the rest of language, and perhaps for [critical periods](http://en.wikipedia.org/wiki/Critical_period "Critical period") that may exist in childhood for social, emotional and cognitive development.

A paragraph like this may get her some extra funding but I don’t see any other justification for it. Actually, I find it quite puzzling that a serious scholar would even propose anything like this today. We already know there is no critical period for social development. Well, we don’t really know what social development is, but there’s no critical brain period to what there is. We get socialized to new collective environments throughout our lives.

But there’s no reason to suppose that learning to interact in a new environment is anything like learning to discriminate between sounds. There are some areas of language linked to [perception](http://www.touchpsychiatry.com/files/article_pdfs/3_3.pdf) where that may partly be the case (such as discriminating shapes, movements, colors, etc.) but hardly things like morphology or syntax, where much more complexity is involved. But this argument cuts both ways. Let’s say a lot of language learning was like sound development. And we know most of it continues throughout life (syntax, morphology, lexicon) and it doesn’t even start at 6 months (unless you’re a crazy Chomskean who believes in some sort of magical parameter setting). So if sound development was like that, maybe it has nothing to do with the brain in the way Kuhl imagines – although she’s so vague that she could always claim that that’s what she’d had in mind. This is what Kuhl thinks of as additional information:

> We’re seeing the baby brain. As the baby hears a word in her language the auditory areas light up, and then subsequently areas surrounding it that we think are related to coherence, getting the brain coordinated with its different areas, and causality, one brain area causing another to activate.

So what? We know that that’s what was going to happen. Some parts of the brain were going to light up as they always do. What does that mean? I don’t know. But I also know that Patricia Kuhl and her colleagues don’t know either (at least not in the way she pretends). We speak a language, we learn a language and at the same time we have a brain and things happen in the brain. There are neurons and areas that seem to be affected by impact (but not always and not always in exactly the same way). Of course, this is an undue simplification. Neuroscientists know a huge amount about the brain. Just not how it links to language in a way that would say much about the language that we don’t already know. Kuhl’s next implied claim is a good example of how partial knowledge in one area may not at all extend to knowledge in another area.

> What you see here is the audio result — no learning whatsoever — and the video result — no learning whatsoever. It takes a human being for babies to take their statistics. The social brain is controlling when the babies are taking their statistics.

In other words, when the children were exposed to audio or video as opposed to a live person, no effect was shown. At 6 months of age! As is Kuhl’s wont, she only hints at the implications, but over at the Royal Society’s blog comments, [Eric R. Kandel](http://neuroscience.columbia.edu/department/index.php?ID=27&bio=97 "Eric R. Kandel") has spelled it out:

> I’m very much taken with Patricia Kuhl’s finding in the acquisition of a second language by infants that the physical presence of a teacher makes enormous difference when compared to video presence. We all know from personal experience how important specific teachers have been. Is it absurd to think that we might also develop methodologies that would bring out people’s potential for interacting empathically with students so that we can have a way of selecting for teachers, particularly for certain subjects and certain types of student? [Neuroscience: Implications for Education and Lifelong Learning](http://blogs.royalsociety.org/in-verba/2011/02/24/neuroscience-implications-for-education-and-lifelong-learning/).

But this could very well be absurd! First, Kuhl’s experiments were not about second language acquisition but sensitivity to sounds in other languages. Second, there’s no evidence that the same thing Kuhl discovered for infants holds for adults or even three-year olds. A six-month old baby hasn’t learned yet that the pictures and sounds coming from the machine represent the real world. But most four-year olds have. I don’t know of any research but there is plenty of anecdotal evidence. I have personally met several people highly competent in a second language who claimed they learned it by watching TV at a young age. A significant chunk of my own competence in English comes from listening to radio, audio books and watching TV drama. How much of our first language competence comes from reading books and watching TV? That’s not to say that personal interaction is not important – after all we need to learn enough to understand what the 2D images on the screen represent. But how much do we need to learn? Neither Kuhl nor Kandel have the answer but both are ready (at least by implication) to shape policy regarding language learning. In the last few years, several reports raised questions about some overreaching by neuroscience (both in [methods](http://prefrontal.org/blog/2010/02/paper-how-reliable-are-the-results-from-functional-magnetic-resonance-imaging/) and [assumptions](http://www.edvul.com/voodoocorr.php) about their [validity](http://prefrontal.org/blog/2010/11/paper-an-argument-for-proper-multiple-comparisons-correction/)) but even perfectly good neuroscience can be bad scholarship in extending its claims far beyond what the evidence can support.

The Isomorphism Fallacy
-----------------------

*This section of the post is partly based on a paper I presented at a Czech cognitive science conference about 3 years ago called [Isomorphism as a heuristic and philosophical problem](http://www.slideshare.net/bohemicus/izomorfie-jako-heuristickofilozofick-problm).*

[![IMG_7845](http://farm1.static.flickr.com/96/224213840_0d9e25dc6a_m.jpg)](http://www.flickr.com/photos/bradleypjohnson/224213840/ "IMG_7845 by bradleypjohnson, on Flickr")The fundamental problem underlying the overreach of basic neuroscience research is the fallacy of isomorphism. This fallacy presumes that the same structures we see in language, behavior, society must have structural counterparts in the brain. So there’s a bit of the brain that deals with nouns. Another bit that deals with being sorry. Possibly another one that deals with voting Republican (as Woody Allen proved in “[Everyone Says I Love You](http://en.wikipedia.org/wiki/Everyone_Says_I_Love_You "Everyone Says I Love You")“). But at the moment the evidence for this is extremely weak, at best. And there is no intrinsic need for a structural correspondence to exist. [Sidney Lamb](http://en.wikipedia.org/wiki/Sidney_Lamb) came up with a wonderful analogy that I’m still working my way through. He says (recalling an old ‘[Aggie](http://en.wikipedia.org/wiki/Texas_A%26M_Aggies "Aggies")‘ joke) that trying to figure out where the bits we know as language structure are in the brain is like trying to work out how to fit the roll that comes out of a tube of tooth paste back into the container. This is obviously a fool’s errand. There’s nothing in the tooth-paste container that in any way resembles the colorful and tubular object we get when we squeeze the paste container. We get that through an interaction of the substance, the container, external force, and the shape of the opening. It seems to me entirely plausible, that the link between language and the brain is much more like that between the paste, the container and their environment than like that between a bunch of objects and box. The structures that come out are the result of things we don’t quite understand happening in the brain interacting with its environment. (I’m not saying that that’s how it is, just that it’s plausible.) The other thing to lends it credence is the fact that things like nouns or fluency are social constructs with fuzzy boundaries, not hard discrete objects, so actually localizing them in the brain would be a bit of a surprise. Not that it can’t be done, but the burden of evidence of making this a credible finding is substantial.

Now, I think that the same problem applies to looking for isomorphism the other way. Lamb himself tries to look at grammar by looking for connections resembling the behavior of activating neurons. I don’t see this going anywhere. George Lakoff (who influenced me more than any other linguist in the world) seems to think that a [Neural Theory of Language](http://www.icsi.berkeley.edu/NTL/) is the next step in the development of linguistics. At one point he and many others thought that mirror neurons say something about language but now that seems to have been brought into question. But why do we need mirror neurons when we already know a lot of the immitative behaviors they’re supposed facilitate? Perhaps as [a treatment](http://www.ted.com/talks/vilayanur_ramachandran_on_your_mind.html) and diagnostic protocol for pathologies [but is this really more than story-telling](http://www.ted.com/talks/vs_ramachandran_the_neurons_that_shaped_civilization.html)? Jerome Feldman described NTL in his book “[From Molecule to Metaphor](http://www.amazon.co.uk/Molecule-Metaphor-Neural-Language-Bradford/dp/0262562359 "From molecule to metaphor")” but his main contribution seems to me lies in showing how complex language phenomena can be modelled with brain-like neural networks, not saying anything new about these phenomena (see [here for an even harsher treatment](http://www.talkingbrains.org/2008/07/supposed-neural-theory-of-language.html "Talking Brains Critique")). The same goes for the [Embodied Construction Grammar](http://ecgweb.pbworks.com "ecgweb.pbworks.com"). I entirely share ECG’s linguistic assumptions but the problem is that it tries to link its descriptive apparatus directly to the formalisms necessary for modeling. This proved to be a disaster for the generative project that projected its formalisms into language with a imperfect fit and now spends most of its time refining those formalisms rather than studying language.

So far I don’t see any advantage in linking language to the brain in either the way Kuhl et al or Feldman et al try to do it (again with the possible exception of pathologies). In his [recent paper on compositionality](http://www.computational-logic.org/content/events/iccl-ss-2010/slides/feldman/papers/pl.pdf), Feldman describes research that shows that spacial areas are activated in conjunction with spatial terms and that sentence processing time increases as the sentence gets removed from “natural spatial orientation”. But brain imaging at best confirms what we already knew. But how useful is that confirmatory knowledge? I would argue that not very useful. In fact there is a danger that we will start thinking of brain imaging as a necessary confirmation of linguistic theory. Feldman takes a step in this dangerous direction when he says that with the advent of new techniques of neuroscience we can finally study language “scientifically”. [Shudder.]

We know there’s a connection between language and the brain (more systematic than with language and the foot, for instance) but so far nobody’s shown convincingly that we can explain much about language by looking at the brain (or vice versa). Language is best studied as its own incredibly multifaceted beast and so is the brain. We need to know a lot more about language and about the brain before we can start projecting one into the other.

And at the moment, brain science is the junior partner, here. We know a lot about language and can find out more without looking for explanations in the brain. It seems as foolish as trying to illuminate language by looking inside a computer (as Chomsky’s followers keep doing). The same question that I’m asking for language was asked about cognitive processes (a closely related thing) by William Uttal in [The New Phrenology](http://mitpress.mit.edu/catalog/item/default.asp?tid=9665&ttype=2) who’s asking “whether psychological processes can be defined and isolated in a way that permits them to be associated with particular brain regions” and warns against a “neuroreductionist wild goose chase” – and how else can we characterize Kuhl’s performance – lest we fall “victim to what may be a ‘neo-phrenological’ fad”. [Michael Shremer](http://www.michaelshermer.com/2008/05/a-new-phrenology/) voiced a similar concern in the [Scientific American](http://www.scientificamerican.com/article.cfm?id=a-new-phrenology&page=2):

> The brain is not random kludge, of course, so the search for neural networks associated with psychological concepts is a worthy one, as long as we do not succumb to the siren song of phrenology.

What does a “siren song of phrenology” sound like? I imagine it would sound pretty much like this quote by Kuhl:

> We are embarking on a grand and golden age of knowledge about child’s brain development. We’re going to be able to see a child’s brain as they experience an emotion, as they learn to speak and read, as they solve a math problem, as they have an idea. And we’re going to be able to invent brain-based interventions for children who have difficulty learning.

I have no doubt that there are some learning difficulties for which a ‘brain-based intervention’ (whatever that is) may be effective. But it’s just a relatively small part of the universe of learning difficulties that it hardly warrants a bombastic claim like the one above. I could find nothing in Kuhl’s narrow research that would support this assertion. Learning and language are complex psycho-social phenomena that are unlikely to have straightforward counterparts in brain activations such as can be seen by even the most advanced modern neuroimaging technology. There may well be some straightforward pathologies that can be identified and have some sort of treatment aimed at them. The problem is that brain pathologies are not necessarily opposites of a typically functioning brain (a fallacy that has long plagued interpretation of the evidence from aphasias) – it is, as brain plasticity would suggest, just as  likely that at least some brain pathologies simply create new qualities rather than simply flipping an on/off switch on existing qualities. Plus there is the historical tendency of the self-styled hard sciences to horn in on areas where established disciplines have accumulated lots of knowledge, ignore the knowledge, declare a reductionist victory, fail and not admit failure.

For the foreseeable future, the brain remains a really poor metaphor for language and other social constructs. We are perhaps predestined to finding similarities in anything we look at but researchers ought to have learned by now to be cautious about them. Today’s neuroscientists should be very careful that they don’t look as foolish to future generations as phrenologists and skull measurers look to us now.

In praise of non-reductionist neuroscience
------------------------------------------

Let me reiterate, I have nothing against brain research. The more of it, the better! But it needs to be much more honest about its achievements and limitations (as much as it can given the politics of research funding). Saying the sort of things Patricia Kuhl does with incredibly flimsy evidence and complete disregard for other disciplines is good for the funding but awful for actually obtaining good results. (Note: The brevity of the TED format is not an excuse in this case.)

A much more promising overview of applied neuroscience is a report by the Royal Society on [education and the brain](http://royalsociety.org/brainwaves-education/) that is much more realistic about the state of neurocognitive research who admit at the outset: “There is enormous variation between individuals, and brain-behaviour relationships are complex.”

The report authors go on to enumerate the things they feel we can claim as knowledge about the brain:

1. The brain’s plasticity
2. The brain’s response to reward
3. The brain’s self-regulatory processes
4. Brain-external factors of cognitive development
5. Individual differences in learning as connected to the brain and genome
6. Neuroscience connection to adaptive learning technology

So this is a fairly modest list made even more modest by the formulations of the actual knowledge. I could only find a handful of statements made to support the general claims that do not contain a hedge: “research suggests”, “may mean”, “appears to be”, “seems to be”, “probably”. This modesty in research interpretation does not always make its way to the report’s policy suggestions (mainly suggestions 1 and 2). Despite this, I think anybody who thinks Patricia Kuhl’s claims are interesting would do well do read this report and pay careful attention to the actual findings described there.

Another possible problem for those making wide reaching conclusions is a relative newness of the research on which these recommendations are based. I [had a brief look at the citations in the report](https://spreadsheets.google.com/pub?hl=en_GB&hl=en_GB&key=0ApOerWNG_AmHdGhKYUdRbUxUczNKUXBPRWtKRkJGaEE&single=true&gid=0&output=html) and only about half are actually related to primary brain research. Of those exactly half were published in 2009 (8) and 2010 (20) and only two in the 1990s. This is in contrast to language acquisition and multilingualism research which can point to decades of consistently replicable findings and relatively stable and reliable methods. We need to be afraid, very afraid of sexy new findings when they relate to what is perceived as the “nature” of humans. At this point, as a linguist looking at neuroscience (and the history of the promise of neuroscience), my attitude is skeptical. I want to see 10 years of independent replication and stable techniques before I will consider basing my descriptions of language and linguistic behavior on neuroimaging. There’s just too much of ‘now we can see stuff in the brain we couldn’t see before, so this new version of what we think the brain is doing is definitely what it’s doing’. Plus the assumption that exponential growth in precision brain mapping will result in the same growth in brain function identification is far from being a sure thing (cf. genome decoding). Exponential growth in computer speed, only led to incremental increases in computer usability. And the next logical step in the once skyrocketing development of automobiles was not flying cars but pretty much just the same slightly better cars (even though they look completely different under the hood).

The sort of knowledge to learn and do good neuroscience is staggeringly awesome. The scientists who study the brain deserve all the personal accolades they get. But the actual knowledge they generate about issues relating to language and other social constructs is much less overwhelming. Even a tiny clinical advance such as helping a relatively small number of people to communicate who otherwise wouldn’t be able to express themselves makes this worthwhile. But we must not confuse clinical advances with theoretical advances and must be very cautious when applying these to policy fields that are related more by similarity than a direct causal connection.

### *Related*
```
./2011-03-13-do-science-fiction-writers-dream-of-fascist-dictatorships.md
```
---
title: "Do science fiction writers dream of fascist dictatorships?"
date: 2011-03-13
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/03/do-science-fiction-writers-dream-of-fascist-dictatorships
---

[![This is the cover to the January 1953 issue of...](http://upload.wikimedia.org/wikipedia/en/thumb/9/98/Galaxy_Science_Fiction_Jan_1953_front_cover.jpg/300px-Galaxy_Science_Fiction_Jan_1953_front_cover.jpg "This is the cover to the January 1953 issue of...")](http://en.wikipedia.org/wiki/File:Galaxy_Science_Fiction_Jan_1953_front_cover.jpg)Image via Wikipedia

Image via Wikipedia

Some years ago in a [book review](http://dominiklukes.net), I made an off-the-cuff comment that thriller writers tend to be quite right-wing in their outlook whereas science fiction authors are much more progressive and leftist. This is obviously an undue generalisation (as most of such comments tend to be) but it felt intuitively right. Even then I thought of Michael Chricton as the obvious counterexample – a thirller writer with distinctly liberal leanings – but I couldn’t think of a science fiction writer that would provide the counterexample. I put this down to my lack of comprehensive sci-fi reading and thought nothing more of it. Now, I’m not even sure that the general trend is there or at least that the implications are very straightforward.

Recently, I was listening to the excellent public policy lectures by [Mark Kleiman](http://en.wikipedia.org/wiki/Mark_A.R._Kleiman "Mark A.R. Kleiman") and remembered that years ago, I’d read some similar suggestions in the [Bio of the Space Tyrant](http://en.wikipedia.org/wiki/Bio_of_a_Space_Tyrant) by Pierce Anthony. It wasn’t a book (or rather a book series) I was going to reread but I set to it with a researcher’s determination. And frankly, I was shocked.

What I found was not a vision of a better society (Anthony projects the global politics of his day – the early 80s – into the Solar system 600 years hence) but rather a grotesque depiction of what the elites of the day would consider ‘common-sense’ policies: free-market entrepreneurship with social justice with a few twists. It was anti-corporalist and individualist on the surface but with a strong sense of collective duty (and pro-militarism) that was much more reminiscent of [fascism](http://en.wikipedia.org/wiki/Fascism) than communism. It espoused strong, charismatic leadership with a sense of duty and most of all a belief in the necessity of change led by common sense. The needs of the collective justified the suppression of the individual in almost any way. But all of this is couched in good liberal politics (like the free press, free enterprise, etc.)

It is not clear whether Anthony means this as a parody of a [fascist](http://en.wikipedia.org/wiki/Fascism) utopia but there are no hints there that this is the case. The overwhelming sense I get from this book is one of frustration of the intellectual elite that nobody is listening to what they have to say and a perverted picture of what the world would be like if they only got to start over with their policies.

Speaking of perverted. Through all of this is woven a bizzare and disturbing mix of patriarchy and progressive gender politics. On the one hand, Anthony is strongly against violence against women and treats women as strong and competent individuals. But on the other hand, his chief protagonist is an embodiment of a philanderer’s charter. All women love him but understand that he cannot love just one! The policies are there but what is to prevent any man from feeling that he is the one exception. So despite the progressive coating one is left feeling slightly unclean.

Now, is Anthony the exception I was looking for years ago? I don’t think so. First, I think he would fall in the liberal to libertarian camp if asked. But second, I don’t think he’s any exception at all. I recently reread some [SciFi](http://en.wikipedia.org/wiki/Science_fiction "Science fiction") classics and found hints of to full blown monuments to this rationalist yearning for control over society – the “if they only listened to us” syndrome, also known as the “TED syndrome”. We understand so much about how things work, so now we have the solution for how everything works. That’s why we should never seek to be ruled by philosopher kings (Plato, Hobbes, and any third rate philosopher – more likely to be fascist than liberal). Classics like “[Mote in God’s Eye](http://en.wikipedia.org/wiki/The_Mote_in_God%27s_Eye "The Mote in God's Eye")“, “[Starship Troupers](http://en.wikipedia.org/wiki/Starship_Troupers "Starship Troupers")” (the movie was a parody but the book wasn’t), “Foundation” or less well-known ones like “[The Antares Trilogy](http://www.scifi-az.com/)” or “[The Lost Fleet](http://en.wikipedia.org/wiki/The_Lost_Fleet "The Lost Fleet")“. They all unwittingly struggle with the dilemma of what happens when we know what to do but we also know that it can’t be achieved unless we have complete control. I found echoes of this even in cyberpunk like [Snowcrash](http://en.wikipedia.org/wiki/Snow_Crash "Snow Crash").

So am I seeing a trend that isn’t there? I’m not as widely read in SciFi as other genres so it’s possible I just happened on books that confirm my thesis (such as it is). Again, the exception I can think of immediately is [Cory Doctorow](http://www.craphound.com/ "Cory Doctorow") whose “[For the Win](http://www.amazon.com/Win-Cory-Doctorow/dp/0765322161%3FSubscriptionId%3D0G81C5DAZ03ZR9WH9X82%26tag%3Dbohemicaco%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D0765322161 "For the Win")” is as beautiful and sincere a depiction of the union movement as any song by [Pete Seger](http://www.youtube.com/watch?v=ZfXSlmWI_7c "Happy 90th Birthday Pete Seeger!"). And I’m sure there are many more. But are there enough to make my impression just that? (Of course, there’s SciFi where this doesn’t come up, at all.)

But this tendency of the extremely intelligent and educated (and SciFi writers are on the whole just as well versed in anthropology as they are in science) to tell stories of how their images of the just society can be projected onto society as a whole is certainly a worrying presence in the genre. It seems to be largely absent From fantasy, which generally deals with journeys of individuals within existing worlds. And while these worlds may be dystopic, they generally are not changed, only explored. Fantasy has a strong thread of historical nostalgia – looking for a pure world of yore – which can be quite destructive when mis-projected to our own world. But on the whole, I feel, it contains less public policy than the average science fiction novel.

### *Related*
```
./2011-03-24-comedian-identifies-a-critical-flaw-in-structuralism-are-distinctive-features-like-leather-sleeves.md
```
---
title: "Comedian identifies a critical flaw in structuralism: Are distinctive features like leather sleeves"
date: 2011-03-24
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/03/comedian-identifies-a-critical-flaw-in-structuralism-are-distinctive-features-like-leather-sleeves
---

I always thought this little bit by [Demetri Martin](http://en.wikipedia.org/wiki/Demetri_Martin "Demetri Martin") highlights a crucial deficiency in any distinctive feature analysis.

> Demetri Martin: “I was at a party, and I saw a guy with a leather jacket, and I thought, ‘That’s cool’. Then I saw a guy with a leather vest and I thought, ‘That’s not cool’. It was then that I realized what coolness is all about… leather sleeves.”

Is phonology all about leather sleeves?

### *Related*
```
./2011-04-03-why-dont-metaphorical-hawks-kill-metaphorical-doves.md
```
---
title: "Why don’t metaphorical hawks kill metaphorical doves?"
date: 2011-04-03
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/04/why-dont-metaphorical-hawks-kill-metaphorical-doves
---

[![An Iraqi woman looks on as U.S. Army Soldiers ...](http://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Houseraidiraqaug2007.jpg/300px-Houseraidiraqaug2007.jpg "An Iraqi woman looks on as U.S. Army Soldiers ...")](http://commons.wikipedia.org/wiki/File:Houseraidiraqaug2007.jpg)

Image via Wikipedia

A very common metaphor in the political discourse on war is that of [doves](http://en.wikipedia.org/wiki/Columbidae "Columbidae") (peaceniks) and [hawks](http://en.wikipedia.org/wiki/Hawk "Hawk") (war-mongers). It has been around at least since the cold war. But it stops at “doves=peaceful” and “hawks=aggressive”. It completely ignores other properties of the animals, e.g. the fact that “hawks hunt and kill doves”. I did a lot of searching a could not find any such extensions of the metaphor.

This is relatively unusual. Most metaphors in public discourse get dissected every which way. Look at “Iraq=Vietnam”, “Saddam=Hitler”, “Current financial crisis=X other financial crisis”. All of these were dissected and very inventively reassembled mapping by mapping. E.g. If Saddam is Hitler then we can choose between being France or Britain. If Iraq is Vietnam than we must count the wounded as dead and must look for media swaying public opinion. Etc. Etc.  We might argue that doves adn hawks are relatively dead metaphors but Palin’s crosshairs got dissected in minute detail and “having somebody in your cross hairs” no more implies that you’re going to shoot them than does being a dove imply you have wings.

So why didn’t anybody in the contentious debate over the Iraq war come up with this obvious extension of the “doves/hawks=democrats/republicans” metaphor? I would expect at least something along the lines of “the hawks went fiercely after the doves and tore them to shreds in the elections”. But there’s nothing. So, what gives?

I also posted this question (in a slightly shorter form) on [Quora](http://www.quora.com/ "Quora"): <http://qr.ae/c3td>

### *Related*
```
./2011-04-05-life-expectancy-and-the-length-and-value-of-life-on-a-historical-overimagination.md
```
---
title: "Life expectancy and the length and value of life: On a historical overimagination"
date: 2011-04-05
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/04/life-expectancy-and-the-length-and-value-of-life-on-a-historical-overimagination
---

[![History of Russia (1992–present)](http://upload.wikimedia.org/wikipedia/en/thumb/b/b2/Russian_male_life_expectancy.jpg/300px-Russian_male_life_expectancy.jpg "History of Russia (1992–present)")](http://en.wikipedia.org/wiki/File:Russian_male_life_expectancy.jpg)

Image via Wikipedia

About 10 years ago, I was looking through a book on populations changes in the [Czech lands](http://en.wikipedia.org/wiki/Czech_lands "Czech lands"). It consisted of pretty much just tables of data with little commentary. But I was shocked when I came across the life expectancy charts. But not shocked at how short people’s lives had been but how long. The headline figure of life expectancy in the early 1800s was pretty much on par with expectations (I don’t have the book to hand but it was in the high 30s or low 40s). How sad, I thought. So many people died in their 40s before they could experience life in full. But unlike most of the comparisons reporting life expectancy, this one went beyond the overall average. And it was the additional figures that shocked me. Turns out the extremely short life expectancy only applies right at birth. Once you make it to 10, you have a pretty good chance to make it into your late 50s and at 30, your chances of getting your ‘threescore and ten’ were getting pretty good. The problem is that life expectancy rates at birth only really measure child mortality not the typical lives of adults. You can see from this chart: http://www.infoplease.com/ipa/A0005140.html that in 1850, [the US](http://en.wikipedia.org/wiki/United_States "United States") [life expectancy at birth](http://en.wikipedia.org/wiki/Life_expectancy "Life expectancy") was a shocking 38 years. But that does not mean that there were a lot of 38-year-olds around dying. Because if you made it to 10, your life expectancy was 58 years and at 30, it was 64 years. Now these are average numbers so it is possible that for any age cohort, exactly half the people died at the start of it and exactly half died at the end of it. But that was not the case after a certain age. Remember, a population where exactly half the people born die at or near birth (age 0) and exactly half live to be 60 will have the average life expectancy of 30. If you reduce child mortality to 10%, you will have the average life expectancy of 54. If you reduce it to 1%, the average life expectancy will be 59.4 years. Most people still die at sixty but very few die at 1. Massive gains in child mortality reduction will have made no difference to the end of life.

In reality, as the US charts show, the life expectancy at birth doubled but life expectancy at 10 went up by only about a third. That’s still a significant gain but shows a much different profile of life span than the normal figure would have us believe. It was not unusual to live into the late 50s and early 60s. And there were still a large enough number of people who lived into their 70s and 80s. Now, there are exceptions to it, during famines, epidemics and wars and for certain groups in society, the life span was significantly shorter (notice the life expectancy of whites vs. non-whites in the US). But for most populations throughout history, the most common age of death for any given person born was before the age of 10 not in their 30s.

I don’t understand why this is not commonly known. Even many historians (particularly the ones who write popular history) either don’t know this or are unwilling to distrub their narrative of how young people died in the past (in other words, they lie). I certainly was not taught this during my brief (long-ago) studies of ancient and medieval history.

What brought all this to mind is a most disturbing example of this is in a just published book called Civilization by the prominent public historian [Niall Ferguson](http://en.wikipedia.org/wiki/Niall_Ferguson "Niall Ferguson"). In the preface he quotes a poem about death and suffering from [John Donne](http://en.wikipedia.org/wiki/John_Donne "John Donne") and he comments on it:

> “Everyone should read these lines who wants to understand better the human condition in the days when life expetancy was less than half what it is today.”

To say I was aghast is an understatement. I nearly threw my Kindle against the wall. Here’s this public intellectual, historian who goes about preaching on how it is important to understand history and yet he peddles this sort of nonsense. If he had said days with high child mortality and a shorter typical life span, I’d have no problem with it. But he didn’t and didn’t even hint that’s what he meant.

He then goes on blathering about how awful it is that all these historical luminaries died so young. Spinoza at 44, Pascal at 39. Saying:

> “Who knows what other great works these geniuses might have brought forth had they been granted the lifespans enjoyed by, for example the great humanists Erasmus (69) and Montaigne (59)?”

Common! Bringing forth great works! Really?!? Pathos much? He then goes on comparing Brahms (died old, disliked by Ferguson) and Shubert (died young, liked by Ferguson). So much for academic distance. Why on earth would Ferguson think that listing artists who died young means anything. Didn’t he ever hear of [Jimmy Hendrix](http://www.last.fm/music/Jimi%2BHendrix "Jimi Hendrix") or [Kurt Cobain](http://en.wikipedia.org/wiki/Kurt_Cobain "Kurt Cobain")?

But more importantly, he doesn’t seem to notice his own counterexamples. Erasmus died almost a hundred years before Spinoza was born. What does that tell us about life expectancy and historical periods?

And since when has naming random people’s ages been considered evidence of anything? What about: Isaac Newton 84, [Immanuel Kant](http://en.wikipedia.org/wiki/Immanuel_Kant "Immanuel Kant") 79, Galileo 77, [John Locke](http://en.wikipedia.org/wiki/John_Locke "John Locke") 72, Voltaire 83, [Louis Pasteur](http://en.wikipedia.org/wiki/Louis_Pasteur "Louis Pasteur") 72, [Michael Faraday](http://en.wikipedia.org/wiki/Michael_Faraday "Michael Faraday") 75, [Roger Bacon](http://en.wikipedia.org/wiki/Roger_Bacon "Roger Bacon") 80. Isn’t that evidence that people live long before the advent of modern medicine?

Or what’s any of that have to do with how much people may have contributed, had they lived l

[![Louis Pasteur](http://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Louis_Pasteur%2C_foto_av_F%C3%A9lix_Nadar.jpg/300px-Louis_Pasteur%2C_foto_av_F%C3%A9lix_Nadar.jpg "Louis Pasteur")](http://commons.wikipedia.org/wiki/File:Louis_Pasteur%2C_foto_av_F%C3%A9lix_Nadar.jpg)

Image via Wikipedia

onger? I don’t think longevity can serve as a measure of intellectual or cultural productivity. Can we compare Plato (80) and Aristotle (60). It seems to me that Aristotle produced a lot more and varied work than Plato with 20 fewer years to do it in. Aquinas (49) was no less prolific than [St Augustine](http://en.wikipedia.org/wiki/Augustine_of_Hippo "Augustine of Hippo") (75). Is it really possible to judge the impact of the inventive John L Austin (who died at 49 – in the 20th century!) is any less than of the tireless and multitalented Russell who lived pretty much forever (97)?

But there are still more counter examples. Let’s look at [the list of longest reigning monarchs](http://en.wikipedia.org/wiki/Listoflongestreigningmonarchsofall_time "Wikipedia"). The leader of that board is a 6th dynasty Pharaoh (who arguably acended to the throne as a child but still managed to live to a hundred (2200BC!). And most other long-lived monarchs were born during times when life expectancy was about half of what it is now. Sure, they were priveleged and they are relatively rare. And there were a lot of other rulers who went in their 50s and 60s. But not typically in their 40s! Maybe there is already a study out there that measures the longevity of kings with relation to their time but I doubt a straightforward corellation can be found.

Finally, I can match Ferguson poem by poem. From the ancient:

> Our days may come to seventy years,  
> or eighty, if our strength endures;  
> yet the best of them are but trouble and sorrow,  
> for they quickly pass, and we fly away.  
> ([Psalm 90:10](http://www.biblegateway.com/passage/?search=Psalm+90))

to the modern:

> Sadness is all I’ve ever known.  
> Inside my retched body it’s grown.  
> It has eaten me away, to what the fuck I am today.  
> There’s nothing left for me to say.  
> There’s nothing there for me to hate.  
> There’s no feelings, and there’s no thoughts.  
> My body’s left to fucking rot.  
> Life sucks, life sucks, life sucks, life sucks.  
>  [http://www.plyrics.com/lyrics/nocash/lifesucks.html](http://www.plyrics.com/lyrics/nocash/lifesucks.html "Life sucks")

Clearly all that medicine made less of an impact on our experience of life than Ferguson thinks.

Perhaps I shouldn’t get so exercised about a bit of rhetorical flourish in one of many books of historical cosmogeny and eschatology. But I’m really more disappointed than angry. I was hoping this book may have some interesting ideas in it (although I enter it with a skeptical mind) but I’m not sure I can trust the author not to surrender the independence of his frame of mind and bend the facts to suit his pet notions.

### *Related*
```
./2011-04-09-religion-if-it-exists-is-negotiation-of-underdetermined-metaphoric-cognition-updated.md
```
---
title: "Religion, if it exists, is negotiation of underdetermined metaphoric cognition [UPDATED]"
date: 2011-04-09
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/04/religion-if-it-exists-is-negotiation-of-underdetermined-metaphoric-cognition
---

Preamble
--------

[![Richard Buchta - Portrait of a Zande witchdoctor](http://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Richard_Buchta_-_Portrait_of_a_Zande_witchdoctor.jpg/300px-Richard_Buchta_-_Portrait_of_a_Zande_witchdoctor.jpg "Richard Buchta - Portrait of a Zande witchdoctor")](http://commons.wikipedia.org/wiki/File:Richard_Buchta_-_Portrait_of_a_Zande_witchdoctor.jpg)

Image via Wikipedia

I am an old atheist and a new agnostic. I don’t [believe in God](http://en.wikipedia.org/wiki/Belief_in_God "Belief in God") in the old-fashioned Russellian way – if I don’t believe in Krishna, Zeus, water sprites or the little teapot orbiting the Sun, I don’t believe in God and the associated supernatual phenomena (monotheism my foot!). However, I am agnostic about nearly everything else and everything else in the new atheist way is pretty much science and reason. If history is any judge (and it is) most of what we believe to be scientific truths today is bunk. This makes me feel not superior at all to people of faith. Sure I think what they believe is a stupid and irrational thing to believe, but I don’t think they are stupid or irrational people to believe it. The smartest people believe the most preposterous things just look at Newton, Chomsky or Dawkins.

But one thing I’m pretty certain about is religion. Or rather, I’m pretty certain it does not exist. It is in many ways an invention of [the Enlightenment](http://en.wikipedia.org/wiki/Age_of_Enlightenment "Age of Enlightenment") and just like equality and brotherhood it only makes sense until you see the first person winding the up [guillotine](http://en.wikipedia.org/wiki/Guillotine "Guillotine"). Religion only makes sense if you want to set a certain set of beliefs and practices aside, most importantly to deprive their holders of power and legitimacy.

But is it a useful concept for deliberation about human universals? I think on balance it is not. Religion is a collection of stated beliefs, internal beliefs and public and private practices. In other words, religion is a way of life for a community of people. Or to be etymological about it, it is what binds the community together. The nature of the content of those beliefs is entirely irrelevant to the true [human universal](http://en.wikipedia.org/wiki/Cultural_universal "Cultural universal"): a shared collection of beliefs and practices develops over a short amount of time inside any group of people. And when I say beliefs, I mean all explicit and implicit knowledge and applied [cognition](http://en.wikipedia.org/wiki/Cognition "Cognition").

In this sense, modern secular humanism is just as much a religion as rabid evangelicalism.

On the mundane nature of sacred thought
---------------------------------------

So, why the scientist asks, do all cultures develop knowledge system that includes belief in the supernatural? That’s because they don’t. For instance, as Geertz so beautifully described in his reinterpretation of the [Azande](http://en.wikipedia.org/wiki/Zande_people "Zande people"), witchcraft isn’t supernatural. It is the natural explanation after everything else has failed. We keep forgetting that until Einstein, everybody believed in this (as Descartes pointed out) supernatural force called gravity that could somehow magically transmit motion accross vast distances. And now (as Angel and Demetis point out) we believe in magical sheets that make gravity all nice and natural. Or maybe strings? Give me a break!

What about the distinction between the sacred and mundane you ask? Well, that obviously exists including the liminality between them. But sacred/mundane is not limited to anything supernatural and magical – just look at the US treatment of the flag or citizenship. In fact, even the most porfoundly sacred and mystical has a significant mundane dimension necessitated by its logistics.

There are no universals of faith. But there are some strong tendencies among the world’s cultures: Ancestor worship, belief in superhuman and non-human (often invisible, sometimes disembodied) agents, sympathetic magic and ritual (which includes belief in empowered and/or sapient substances and objects). This is combined with preserving and placating personal and collective practices.

All of the above describes western atheists as much as the witchcraft believing Azande. We just define the natural differently. Our beliefs in the power of various pills and the public professions of faith in the reality of evolution or the transformative nature of the market fall under the above just as nicely as the rain dance. Sure I’d much rather go to a surgeon with an inflamed appendix than a witch doctor but I’d also much rather go to a renowned witch doctor than an unknown one if that was my only choice. Medicine is simply witchcraft with better peer review.

Leaving the merits of the modern world aside. The question remains why do humans seem to converge on similar content of their beliefs? Helen de Cruz and the commenters on her post about the naturalness of religious belief: [http://www.cognitionandculture.net/Helen-De-Cruz-s-blog/does-atheism-challenge-the-naturalness-of-religious-belief.html](http://www.cognitionandculture.net/Helen-De-Cruz-s-blog/does-atheism-challenge-the-naturalness-of-religious-belief.html "Link to blog post") give a great overview of the current debate on the topic.

They pretty much put to rest some of the evolutionary notions and the innateness of mind/body dualism. I particularly like the proposition Helene de Cruz made building on Pascal’s remark that some people “seem so made that [they] cannot believe”. “For those people” continues de Cruz, “religious belief requires a constant cognitive effort.”

I think this is a profound statement. I see it as being in line with my thesis of frame negotiation. Some things require more cognitive effort for some people than other things for other people. It doesn’t have to be religion. We know reading requires more cognitive effort for different people in different ways (dyslexics being one group with a particular profile of cognitive difficulties). So does counting, painting, hunting, driving cars, cutting things with knives, taking computers apart, etc. These things are suceptible to training and practice to different degrees with different people.

So it makes perfect sense on the available evidence that different people require different levels of cognitive effort to maintain belief in what is axiomatic for others.

In the comments Mitch Hodge contributed a question to “researchers who propose that [mind-body dualism](http://en.wikipedia.org/wiki/Dualism_%28philosophy_of_mind%29 "Dualism (philosophy of mind)") undergirds representations of supernatural entities: What do you do with all of the anthropological evidence that humans represent most all supernatural entities as embodied? How do disembodied beings eat, wear clothes, physically interact with the living and each other?”

This is really important. Before you can talk about content of belief, you need to carefully examine all its aspects. And as I tried to argue above, starting with religion as a category already leads us down certain paths of argumentation that are less than telos-neutral.

But the answer to the “are humans natural mind-body dualists” does not have to be to choose one over the other. I suggest an alternative answer:

> **Humans are natural schematicists and schema negotiators**

What does that mean? Last year, I gave a talk (in Czech) on the “Schematicity and undetermination as two forgotten processes in mind and language”. In it I argue that operating on schematic or in other ways underdetermined concepts is not only possible but it is built into the very fabric of cognition and language. It is extremely common for people to hold incomplete images (Lakoff’s pizza example was the one that set me on this path of thinking) of things in their mind. For instance, on slide 12 of the presentation below, I show different images that Czechs submitted into a competition run online by a national newspaper on “what does [baby Jesus](http://en.wikipedia.org/wiki/Child_Jesus "Child Jesus") look like” (Note: In Czech, it is baby Jesus – or [Ježíšek](http://en.wikipedia.org/wiki/Je%C5%BE%C3%AD%C5%A1ek "Ježíšek") – who delivers the presents on Christmas Eve). The images ran from an angelic adult and a real baby to an outline of the baby in the light to just a light.

[slideshare id=6059571&doc=schematicnostanedourcenost-101207060558-phpapp02]  
This shows that people not only hold underdetermined images but that those images are determined to varying degrees (in my little private poll, I came across people who imagined Ježíšek as an old bearded man and personally, I did not explicitly associated the diminutive *ježíšek* with the baby Jesus, until I had to translate it into English). The discussions like those around Trinity or the embodied nature of key deities are the results of conversations about what parts of a shared schema is it acceptable to fill out and how to fill them out.

It is basically metaphor (or as I call it frame) negotiation. Early Christianity was full of these debates and it is not surprising that it wasn’t always the most cognitively parsimoneous image that won out.

It is further important that humans have various explicit and implicit strategies to deal with infelicitous schematicity or schema clashes, which is to defer parts of their cognition to a collectively recognised authority. I spent years of my youth believing that although the Trinity made no sense to me, there were people to who it did make sense and to whom as guardians of sense, I would defer my own imperfect cognition. But any study of the fights over the nature of the Trinity are a perfect illustration of how people negotiate over their imagery. And as in any negotiation it is not just the power of the argument but also the power of the arguer that determines the outcome.

Christianity is not special here in any regard but it does provide two millenia of documented negotiation of mappings between domains full of schemas and rich images. It starts with St Paul’s denial that circumcision is a necessary condition of being a Christian and goes on into the conceptual contortions surrounding the Trinity debates. Early Christian eschatology also had to constantly renegotiate its foundations as the world sutbbornly refused to end and was in that no different from modern eschatology – be it religion or science based. Reformation movements (from monasticism to Luther or Calvin) also exhibit this profound contrasting of imagery and exploration of mappings, rejecting some, accepting others, ignoring most.

All of these activities lead to paradoxes and thus spurring of heretical and reform movements. Waldensians or Lutherans or Hussites all arrived at their disagreement with the dogma through painstaking analysis of the imagery contained in the text. Arianism was in its time the “thinking man’s” Christianity, because it made a lot more sense than the Nicean consensus. No wonder it experienced a post-reformation resurgence. But the problems it exposed were equally serious and it was ultimately rejected for probably good reason.

How is it possible that the Nicean consensus held so long as the mainstream interpretation? Surely, Luther could not have been the first to notice the discrepancies between lithurgy and scripture. Two reasons: inventory of expression and undedetermination of conceptual representationa.

I will deal with the idea of **inventory** in a separate post. Briefly, it is based on the idea of cognitive grammar that language is not a system but rather a patterned invenotory of symbolic units. This inventory is neither static nor has it clear boundaries but it functions to constrain what is available for both speech and imagination. Because of the nature of symbolic units and their relationship, the inventory (a usage-based beast) is what constrains our ability to say certain things although they are possible by pure grammatical or conceptual manipulation. By the same token, the inventory makes it possible to say things that make no demonstrable sense.

Frame (or metaphor) negotiation operates on the inventory but also has to battle against its constraints. The units in the inventory range in their schematicity and determination but they are all schematic and underdetermined to some degree. Most of the time this aids effortless conceptual integration. However, a significant proportion of the time, particularly for some speakers, the conceptual integration hits a snag. A part of a schematic concept usually left underdetermined is filled out and it prevents easy integration and an appropriate mapping needs to be negotiated.

For example, it is possible to say that Jesus is God and Jesus is the Son of God even in the same sentence and as long as we don’t project the offspring mapping on the identity mapping, we don’t have a problem. People do these things all the time. We say things like “taking a human life is the ultimate decision” and “collateral damage must be expected in war” and abhor people calling soldiers “murderers”. But the alternative to “justified war” namely “war is murder” is just as easy to sanction given the available imagery. So people have a choice.

But as soon as we flesh out the imagery of “X is son of Y” and “X is Y” we see that something is wrong. This in no way matches our experience of what is possible. *Ex definitio* “X is son of Y” OR “X is Y”. Not AND. So we need to do other things make the nature of “X is Y” compatible with “X is the son of Y”. And we can either do this by attributing a special nature to one or both of the statements. Or we can acknowledge the problem and defer knowledge of the nature to a higher authority. This is something we do all the time anyway.

[![Drawing from René Descartes' (1596-1650) in ](http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Descartes_mind_and_body.gif/300px-Descartes_mind_and_body.gif "Drawing from René Descartes' (1596-1650) in ")](http://commons.wikipedia.org/wiki/File:Descartes_mind_and_body.gif)

Image via Wikipedia

So to bring the discussion to the nature of embodiment, there is no difficulty for a single person or a culture to maintained that some special being is disembodied but yet can perform many embodied functions (like eating). My favorite joke told to me by a devout Catholic begins: “The Holy Trinity are sitting around a table talking about where they’re going to go for their vacation…” Neither my friend nor I assumed that the Trinity is in any way an embodied entity, but it was nevertheless very easy for us to talk about its members as embodied beings. Another Catholic joke:

> A saussage goes to Heaven. St Peter is busy so he sends Mary to answer the Pearly Gates. When she comes back he asks: “Who was it?” She responds: “I don’t know but, it sure looked like the Holy Ghost.”

Surely a more embodied joke is very difficult to imagine. But it just illustrates the availability of rich imagery to fill out schemas in a way that forces us to have two incompatible images in our heads at the same time. A square circle, of sorts.

There is nothing sophisticated about this. Any society is going to have members who are more likely to explore the possibilities of integration of items within its conceptual inventory. In some cases, it will get them ostracised. In most cases, it will just be filed away as an idiosyncratic vision that makes a lot of sense (but is not worth acting on). That’s why people don’t organize their lives around the dictums of stand-up comedians in charge. What they say often “makes perfect sense” but this sense can be filed away into the liminal space of our brain where it does not interfere with what makes sense in the mundane or the sacred context of conceptual integration. And in a few special cases, this sort of behavior will start new movements and faiths.

These “special” individuals are probably present in quite a large number in any group. They’re the people who like puns or the ones who correct everyone’s grammar. But no matter how committed they are to exploring the imagery of a particular area (content of faith, moral philosophy, use of mobile phones or genetic engineering) they will never be able to rid it of its schematicity and indeterminacies. They will simply flesh out some schemas and strip off the flesh of others. As Kuhn said, a scientific revolution is notable not just for the new it brings but also for all the old it ignores. And not all of the new will be good and not all of the old will be bad.

Not that I’m all that interested in the origins of language but my claim is that the negotiation of the mappings between undertermined schemas is at the very foundation of language and thought. And as such it must have been present from the very begining of language – it may have even predated language. “Religious” thought and practice must have emerged very quickly; as soon as one established category came into contact with another category. The first statement of identity or similarity was probably quite shortly followed by “well, X is only Y, in as much as Z” (expressed in grunts, of course). And since bodies are so central to our thought, it is not surprising that imagery of our bodies doing special things or us not having a body and yet preserving our identity crops up pretty much everywhere. Hypothesizing some sort of innate mind-body dualism is taking an awfully big hammer to a medium-sized nail. And looking for an evolutionary advantage in it is little more than the telling of campfire stories of heroic deeds.

Epilogue
--------

To look for an evolutionary foundation of religious belief is little more sophisticated than arguing about the nature of virgin birth. If nothing else, the fervor of its proponents should be highly troubling. How important is it that we fill in all the gaps left over by neo-Darwinism? There is nothing special about believing in Ghosts or Witches. It is an epiphenomenon of our embodied and socialised thought. Sure, it’s probably worth studying the brains of mushroom-taking mystical groups. But not as a religious phenomenon. Just as something that people do. No more special than keeping a blog. Like this.

Post Script on Liminality [UPDATE a year or so later]
-----------------------------------------------------

Cris Campbell on his [Genealogy of Religion Blog](http://genealogyreligion.net/cognizing-the-supernatural-religion) convinced me with the aid of some useful references that we probably need to take the natural/supernatural distinction a bit more seriously than I did above. I still don’t agree it’s as central as is often claimed but I agree that it cannot be reduced to the sacred v. mundane as I tried above.  So instead I proposed the distinction between liminal and metaliminal in a comment on the blog. Here’s a slightly edited version (which may or may not become its own post):

I read with interest Hultkranz’s suggestion for an empirical basis for the concept of the supernatural but I think there are still problems with this view. I don’t see the warrant for the leap from “all religions contain some concept of the supernatural” to “supernatural forms the basis of religion”. Humans need a way to talk about the experienced and the adduced and this will very ‘naturally’ take the form of “supernatural” (I’m aware of McKinnon’s dissatisfaction with calling this non-empirical).

On this account, science itself is belief in the supernatural – i.e. postulating invisible agents outside our direct experience. And in particular speculative cognitive science and neuroscience have to make giant leaps of faith from their evidence to interpretation. What are the chances that much of what we consider to be givens today will in the future be regarded as much more sophisticated than phrenology? But even if we are more charitable to science and place its cognition outside the sphere of that of a conscientious sympathetic magician, the use of science in popular discourse is certainly no different from the use of supernatural beliefs. There’s nothing new, here. Let’s just take the leap from the science of electricity to Frankenstein’s monster. Modern public treatments of genetics and neuroscience are essentially magical. I remember a conversation with an otherwise educated philosophy PhD student who was recoiling in horror from genetic modification of fruit (using fish genes to do something to oranges) as unnatural – or monstrous. Plus we have stories of special states of cognition (absent-minded professors, en-tranced scientists, rigour of study) and ritual gnostic purification (referencing, peer review). The strict naturalist prescriptions of modern science and science education are really not that different from “thou shalt have no other gods before me.”

I am giving these examples partly as an antidote to the hidden normativity in the term ‘supernatural’ (I believe it is possible to mean it non-normatively but it’s not possible for it not to be understood that way by many) but also as an example of why this distinction is not one that relates to religion as opposed to general human existence.

However, I think Hultkranz’s objection to a complete removal of the dichotomy by people like Durkheim and Hymes is a valid one as is his claim of the impossibility of reducing it to the sacred/profane distinction. However, I’d like to propose a different label and consequently framing for it: meta-liminal. By “meta-liminal” I mean beyond the boundaries of daily experience and ethics (a subtle but to me an important difference from non-empirical). The boundaries are revealed to us in liminal spaces and times (as outlined by Turner) and what is beyond them can be behaviours (Greek gods), beings (leprechauns), values (Platonic ideals) or modes of existence (land of the dead). But most importantly, we gain access to them through liminal rituals where we stand with one foot on this side of the boundary and with another on the “other” side. Or rather, we temporarily blur and expand the boundaries and can be in both places at once. (Or possibly both.) This, however, I would claim is a discursively psychological construct and not a cognitively psychological construct. We can study the neural correlates of the various liminal rituals (some of which can be incredibly mundane – like wearing a pin) but searching for a single neural or evolutionary foundation would be pointless.

The quote from Nemeroff and Rozin that ‘“the supernatural” as that which “generally does not make sense in terms of the contemporary understanding of science.”’ sums up the deficiency of the normative or crypto-normative use of “supernatural”. But even the strictly non-normative use suffers from it.

What I’m trying to say is that not only is not religious cognition a special kind of cognition (in common with MacKendrick), but neither is any other type of cognition (no matter how Popperian its supposed heuristics). The different states of transcendence associated with religious knowing (gnosis) ranging from a vague sense of fear, comfort or awe to a dance or mushroom induced trance are not examples of a special type of cognition. They are universal psychosomatic phenomena that are frequently discursively constructed as having an association with the liminal and meta-liminal. But can we postulate an evolutionary inevitability that connects a new-age whackjob who proclaims that there is something “bigger than us” to a sophisticated theologian to Neil DeGrasse Tyson to a jobbing shaman or priest to a simple client of a religious service? Isn’t it better to talk of cultural opportunism that connects liminal emotional states to socially constructed liminal spaces? Long live the spandrel!

This is not a post-modernist view. I’d say it’s a profoundly empirical one. There are real things that can be said (provided we are aware of the limitations of the medium of speech). And I leave open the possibility that within science, there is a different kind of knowledge (that was, after all, my starting point, I was converted to my stance by empirical evidence so I am willing to respond to more).

### *Related*
```
./2011-04-24-poetry-without-metaphor-sure-but-can-it-darn-your-socks.md
```
---
title: "Poetry without metaphor? Sure but can it darn your socks?"
date: 2011-04-24
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/04/poetry-without-metaphor-sure-but-can-it-darn-your-socks
---

[![Chinese poet Li Bai from the Tang dynasty, in ...](http://upload.wikimedia.org/wikipedia/commons/4/4c/LiBai.jpg "Chinese poet Li Bai from the Tang dynasty, in ...")](http://commons.wikipedia.org/wiki/File:LiBai.jpg)

Image via Wikipedia

Over on the [Language Log](http://languagelog.ldc.upenn.edu/nll/?p=3108 "Language Log"), [Victor Mair](http://en.wikipedia.org/wiki/Victor_H._Mair "Victor H. Mair") puts to rest that all English expressions have to be tensed and thus prevent timeless poetry. He shares his translation of a 13th century [Chinese poet](http://en.wikipedia.org/wiki/List_of_Chinese_language_poets "List of Chinese language poets") thus:

> **Autumn Thoughts** by [Ma Zhiyuan](http://en.wikipedia.org/wiki/Ma_Zhiyuan)
>
> Withered wisteria, old tree, darkling crows –  
> Little bridge over flowing water by someone’s house –  
> Emaciated horse on an ancient road in the western wind –  
> Evening sun setting in the west –  
> Broken-hearted man on the horizon.

And indeed, he is right. The poem exudes timelessness (if a lack of something can be exuded). It is more difficult for some languages than others to avoid certain grammatical commitments (like gender or number) which makes translation more difficult but there’s always a way.

What struck me about the poem was something different. It is so rich in imagery and yet so poor in [figurative language](http://en.wikipedia.org/wiki/Literal_and_figurative_language "Literal and figurative language") . This is by no means unique but worth a note. In fact, there is no figurative language there at all if we discount such foundational figures as “sun setting in the West”, “broken-hearted” or “man on the horizon”. In fact, had I not known this was a Chinese poem, I could have easily believed it was a description of 17th century [Dutch master](http://en.wikipedia.org/wiki/Dutch_Golden_Age_painting "Dutch Golden Age painting")‘s painting or even something by [Constable](http://en.wikipedia.org/wiki/Constable "Constable").

But of course, the conceptual work we’re doing while reading this poem is not that different from the work we would do if it was full of metaphor. I’m working on a post of how adjectives and predicates are really very similar to metaphors and this is one example that illustrates the point. In order to appreciate this poem, we have to construct a series of fairly rich images and then we have to blend them with each other to place them in the same place.  We have to interpret “the broken hearted man on the horizon” is it just another image, the poet or ourselves? In other words, we have to map from the image presented by the poem to the images available to us by our experience. Which, in short, is the same work we have to do when interpreting metaphors and similies.  But the title is the clincher: “autumn thoughts” – what if the whole poem is a metaphor and the elements in it just figures signifying age, loneliness, the passage of time and so on and so forth. There are simply too many mappings to make. And there the escape from metaphor ends.

[![Enhanced by Zemanta](http://img.zemanta.com/zemified_e.png?x-id=0038e23f-ead2-47a0-97a7-c7a04c214ea1)](http://www.zemanta.com/ "Enhanced by Zemanta")

### *Related*
```
./2011-04-29-i-object-a-male-feminists-view-on-the-duchess-of-cambridges-wedding-dress.md
```
---
title: "I object: A male feminist’s view on the Duchess of Cambridge’s Wedding dress"
date: 2011-04-29
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/04/i-object-a-male-feminists-view-on-the-dutches-of-cambridges-wedding-dress
---

[![Welcome to our wedding](http://farm6.static.flickr.com/5144/5664356426_e656ccff2a_m.jpg "Welcome to our wedding")](http://www.flickr.com/photos/16061323@N07/5664356426)

Image by bobfranklin (mostly tacit) via Flickr

Maybe I should be watching more TV but I honestly had no idea what [Kate Middleton](http://en.wikipedia.org/wiki/Kate_Middleton "Kate Middleton") looked like. There must have been times I would have heard references to her and thought she was some kind of actress or model. And frankly, I still don’t care.

But I do care about her dress. I am quite naive in the way of things (despite my interest in the ethnography of the everyday) so the fact that it may matter what the future queen will be wearing on her wedding day was not obvious to me. And matter more to many than whether a former prime minister or two were invited. I heard about it on the [Today programme](http://www.bbc.co.uk/radio4/today/ "Today (BBC Radio 4)") this morning and realised that I had been pretty silly not to have thought about it and then all was clear when I got a text from a female friend who professed that the dress was the main thing of import.

And there’s really nothing all that wrong with that. The fate of two luminary has beens is really of no more [ritual](http://en.wikipedia.org/wiki/Ritual "Ritual") import (probably quite a bit less) than the dress of one of the key participants in the nuptial proceedings. There are all sorts of legitimate concerns such as the allusions to fashions and traditions, the nationality and status of the designer, the possibility of a radical statement being made, and so on. Dresses obviously matter. And the fact that they matter more to women than men should make them no less important.

[![Pince William and Kate Middleton's wedding](http://farm6.static.flickr.com/5103/5670038636_e5153e072f_m.jpg "Pince William and Kate Middleton's wedding")](http://www.flickr.com/photos/51065912@N08/5670038636)

Image by Lea Ann Belter Bridal via Flickr

But then I saw it. It was by accident on a page talking about online streaming records (the sort of thing I take an interest in of an afternoon). And I remembered how much I hate female dresses (almost as much as women’s shoes). First, I hate them because they look uncomfrotable (but then a certain amount of discomfort is to be expected during a ritual). But more importantly I hate them because of the actual ritual symbolism. Ms Middleton was standing next to Mr Windsor who was clad in some sort of military get up as befits the protector of a nation. And she was smiling presumably to indicate some sort of emotional attachment to the man (whether a genuine affection or a public performance or a mixture of both is of no relevance to me). However, whereas his dress spoke of conquest and spoils of war, hers was all captured fecundity. She was the symbol of putting all of the women whose gaze was firmly fixed on every frill and curve in their procreative and caring place. The Royal family captured the youth and fertility of the nation into its net and was displaying its prize.

I probably would have hated any [wedding dress](http://en.wikipedia.org/wiki/Wedding_dress "Wedding dress") but this one seemed to me particularly insidious in the understated manner with which it suggested tradition and a sexual act of possession being performed right before the adoring eyes. Why not break with tradition and wear Clintonesque trousers? You can allude to the past with a frilly hat if absolutely necessary! OK, perhaps here I am imputing my revolutionary desire onto a woman who probably quite enjoys the opportunity to play the role of a traditional princess. And I don’t believe there’s anything wrong with women playing traditional roles if that’s the sort of game they either enjoy or from which they can derive power. Also, it is entirely possible since I don’t speak the language of dresses that I misunderstood the symbolism of this one. Maybe it is one merging modernity with the past in a way I’m not able to understand. But even then I believe my general point stands: We need new rituals of formality for new times not reliant on gender roles just for the sake of them. And since the roles of men and women in marriage have changed, shouldn’t the way in which they are consecrated change also?

[![Man and Wife](http://farm6.static.flickr.com/5028/5668903265_ebd8868127_m.jpg "Man and Wife")](http://www.flickr.com/photos/53004883@N02/5668903265)

Image by Beacon Radio via Flickr

All dress is a mask in the performance of one role or another. But it is important that like any actor, a woman can step away from the role she playing. There’s lots of evidence that a burqa can be an empowering statement fraught with social and political as well as gender classifications. Only it is too easy a mask to weld onto a woman’s face. Just as much as a dress stressing sexual availability while the adjacent man’s demands executive power. There is nothing in our society that justifies that division of power so why not try to invent new rituals that promote the kind of public equality we want to see.

I have nothing against men and women signalling their [sexual identity](http://en.wikipedia.org/wiki/Sexual_identity "Sexual identity") through dress in the appropriate situations like clubs and pubs. But I think at formal public functions there’s no need to promulgate this stereotype. Dapper still indicates easy prosperity while resplendent or ravishing implies sexual possession. Why not have men extentuate their genitalia (as they do in many cultures) in these situations rather than pretend they’re there just to grab a woman for a bit of procreation and get back to their busy lives managing trade in the [East Indies](http://en.wikipedia.org/wiki/East_Indies "East Indies").

I started Metaphor Hacker to question the easy over-interpretation of metaphor as a trope of inevitable consequence. It is of course possible for a woman to code switch and perform important executive role while dressed in a conventional female manner. The historical interpretation of the female [formal dress](http://en.wikipedia.org/wiki/Formal_wear "Formal wear") need not apply today (as it may not have straigthforwardly applied in the past). What I’m asking for here is a political act relying on that historical interpretation and saying ‘no more’ or at least ‘only if we really feel like it’.

However, one feature of human communication I’m particularly keen to discuss more is the notion of inventory of patterns of expressions. So although the conceptual underpinnings of the ritual may not be straightforward, if the constant unvaried performance is all that there is, women may not be able to reach into the inventory for an effortless alternative. So while dresses are something that women talk about and should not be thought of as being of lesser value, it is all too easy to see them that way. Women should not be apologetic for this and I’m sure they’re not. But we all need to be careful not to go back to the time of [Odysseus](http://en.wikipedia.org/wiki/Odysseus "Odysseus") when men went to war and returned to slay suitors of the women who stayed behind to weave and keep chaste!

### *Related*
```
./2011-05-02-when-is-subtle-manipulation-of-data-a-flat-out-lie-truth-about-chinese-prisons-update.md
```
---
title: "When is subtle manipulation of data a flat out lie? Truth about Chinese prisons [UPDATE]"
date: 2011-05-02
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/05/when-is-subtle-manipulation-of-data-a-flat-out-lie-truth-about-chinese-prisons
---

I’ve been on a [China](http://en.wikipedia.org/wiki/China "China") kick lately ([reading](http://www.amazon.co.uk/China-History-John-Keay/dp/0007221789/) and [listening](http://www.chinahistorypodcast.com) about its history and global position) and a crime public policy kick ([reading](http://www.amazon.co.uk/When-Brute-Force-Fails-Punishment/dp/0691148643) and [listening](http://podcast.oid.ucla.edu/courses/2009-2010/2010winter/pp10a-1/podcast.xml) to [Mark Kleiman](http://en.wikipedia.org/wiki/Mark_A.R._Kleiman "Mark A.R. Kleiman")). I was struck when I heard Mark say in an interview that the US has more people in jail in absolute terms than China. So I went about to looking for some data. I found the most comprehensive source of info in the “[World Prison Population List](http://docs.google.com/viewer?a=v&q=cache:lzGQNLGCeZ0J:www.kcl.ac.uk/depsta/law/research/icps/downloads/world-prison-pop-seventh.pdf+chinese+prison+population&hl=en&gl=uk&pid=bl&srcid=ADGEESi8tLqSmM3bovvLsczZmFxd77uSek8aIbQTiiWsO14Y9ea0iMrb1RVVoclUbZ9wWTZq4i4f5XQwew_ehsS63rnVYyAG8yodlBOluLcRY3heNMf1jYkvOKpD--2NOypl1P30vuUC&sig=AHIEtbScQOPaOogNCd2X81PAVQhcUMRI9Q)” published by the [King’s College London](http://maps.google.com/maps?ll=51.5119444444,-0.116111111111&spn=0.01,0.01&q=51.5119444444,-0.116111111111%20(King%27s%20College%20London)&t=h "King's College London") [International Centre for Prison Studies](http://en.wikipedia.org/wiki/International_Centre_for_Prison_Studies "International Centre for Prison Studies"). Their top bullet point is alarming:

> More than 9.25 million people are held in [penal institutions](http://en.wikipedia.org/wiki/Prison "Prison") throughout the world, mostly aspre-trial detainees (remand prisoners) or assentenced prisoners. Almost half of these are inthe [United States](http://en.wikipedia.org/wiki/United_States "United States") (2.19m), China (1.55m plus pre-trial detainees and prisoners in ‘administrativedetention’) or Russia (0.87m).

But I was surprised by China. The US have a 738  people in prison per 100,000 of population, Russia 611 and China 111. [England and Wales](http://en.wikipedia.org/wiki/England_and_Wales "England and Wales") has more than China with 158. In fact, more than half of the countries of the world have more than China. I did some numbers in the spreadsheet below what that means with respect to the total population of each countries (throwing in the UK, India and Brazil for good measure):

And the results could not be clearer. China is not in any way comparable to Russia and the US when it comes to prison population. In fact, the UK is a worse offender (pun intended) when it comes to owning a disproportionate chunk of the global prison population. It is just under parity. India is by far the most lenient when it comes to incarceration with only 3.5% of the world prison population to 16% of the world’d global population. The Center provides no estimate of the pre-trial and administrative detainees in China. But even if it was another half-a-million people, it would still only give China a parity. To be as disproportionately prison-happy as the US, China would have to arrest more than 2.5 as many people as it has in jail right now.

But the question arises why did the Centre for Prison Studies choose to include US, Russia and China on the same list? My suggestion is prejudice combined with number magic. The authors were trying to come up with a way to get to say that half of the prisoners are in a small number of countries. And China is “known” for its human rights record, so it must be OK to list it there if it will bump up the numbers. But in effect, they managed to lie about China by saying something numerically true. It didn’t say anything flat out incorrect but it created an implicit category which clearly labels China as a bad country. This is a silly way to affirm Western supremacy where there is none.

There are lots of other things that could be estimated based on these numbers. I couldn’t find a clear estimate of how many people were sent to prison for things they didn’t do ([we can’t just extrapolate from death row exonerations](http://truthinjustice.org/exonerations-in-us.pdf)) but if we set it at about 0.5%, we get that there may be more unjustly imprisoned people in the US than there are [political prisoners](http://en.wikipedia.org/wiki/Political_prisoner "Political prisoner") in China (estimated at about 5,000) or slightly less if we count the same rate of miscarriage of justice across the rest of China’s prison population. This is, of course, too much guess work for drawing any firm conclusions but it certainly puts the numbers in some perspective.

**UPDATE:** I have actually interviewed Mark Kleiman (it was a long time ago but I only now remembered to update here) and his estimate is that there are 3-4% of people in US prisons who are there because of something they did not do (often because of police mis-behavior). Now it is important to qualify this by saying that most of these people have done other things for which they deserve to go to prison but were not caught, so the miscariage of justice is more technical than moral. But it shows the massive holes in the US vaunted “rule of law”. It is there, no doubt, when it comes to settling middle-class property and other business disputes (and by all accounts this would be very important thing to have in many countries in the Middle East and China). But it is not evenly distributed. I think it would not be completely outrageous to say that, for many of its citizens, the US is in effect a police state. Just like it could be said that for many of China’s citizens, China is not!

### *Related*
```
./2011-05-07-the-natural-logistics-of-life-the-internet-really-changes-almost-nothing.md
```
---
title: "The natural logistics of life: The Internet really changes almost nothing"
date: 2011-05-07
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/05/the-natural-logistics-of-life-the-internet-really-changes-almost-nothing
---

[![Cover of "You've Got Mail"](http://ecx.images-amazon.com/images/I/51JN65AE3YL._SL300_.jpg "Cover of \"You've Got Mail\"")](http://www.amazon.com/Youve-Got-Mail-Tom-Hanks/dp/6305368171%3FSubscriptionId%3D0G81C5DAZ03ZR9WH9X82%26tag%3Dzemanta-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D6305368171)

Cover of You've Got Mail

*This is a post that has been germinating for a long time. But it was most immediately inspired by [Marshall Poe](http://en.wikipedia.org/wiki/Marshall_Poe "Marshall Poe")‘s article claiming that “[The Internet Changes Nothing](http://www.hnn.us/articles/133910.html)“. And as it turns out, I mostly agree.*

OK, this may sound a bit paradoxical. Twelve years ago, when I submitted my first column to be published, I delivered the text to my editor on a diskette. Now, I don’t even have an editor (or at least not for this kind of writing). I just click a button and my text is published. But! If my server logs are to be trusted, it will be read by 10s or at best 100s of people over its lifetime. That’s more than if I’d just written some notes to myself or published it in an academic journal but much less than if I publish it in a national daily with a readership of hundreds of thousands. Not all of them will read what I write but more than would on this blog.  
So while democratising the [publishing industry](http://en.wikipedia.org/wiki/Publishing "Publishing") has worked for Kos, Huffington and many others, still many more blogs languish in obscurity. I can say anything I want but my voice matters little in the cacophony.

In terms of addressing an audience and having a voice, the internet has done little for most people. This is not because not enough people have enough to say but because there’s only so much content the world can consume. There is a much longer tail trailing behind [Clay Shirkey](http://shirky.com/ "Clay Shirky")‘s long tail. It’s the tail of 5-post 0-comment blogs and [YouTube videos](http://en.wikipedia.org/wiki/YouTube "YouTube") with 15 views. Even millions of typewriter-equipped monkeys with infinities of time can’t get to them all. Plus it’s hard to predict what will be popular (although educated guesses can produce results in aggregate). Years ago I took a short clip with my stills camera of a black-smith friend of mine making a candle-holder. It’s had 30 thousand views on YouTube. Why I don’t know. There’s nothing particularly exciting about it but there must be some sort of a long tail longing after it. None of the videos I hoped would take off did. This is the experience of many if not most. Most attempts at communities fail because the people starting them don’t realize how hard it is to nurture them to self-sustainability. I experienced this with my first site Bohemica.com. It got off to a really good start but since it was never my primary focus, the community kind of dissipated after a site redesign that was intended to foster it.

Just in terms of complete democratization of expression, the internet has done less for most than it may appear. But how about the speed of communication? I’m getting ready to do an interview with someone in the US, record it, transcribe it and translate it – all within a few days. The Internet (or more accurately Skype) makes the calling cheap, the recording and transcription is made much quicker by tools I didn’t have access to even in the early 2000s when I was doing interviews. And of course, I can get the published product to my editor in minutes via email. But what hasn’t changed is the process. The interview, transcription and translation take pretty much the same amount of time. The work of agreeing with the editor on the parameters of the interview, arranging it with the interviewee take pretty much as long as before. As does preparation for the interview. The only difference is the speed and ease of the transport of information from me to its target and me to the information. It’s faster to get to the research subject – but the actual research still takes about the same amount of time limited by the speed of my reading and the speed of my mind.

A chain is only as strong as its weakest link. And as long as humans are a part of the interface in a communication chain, the communication will happen at a human speed. I remember sitting over a print out of an obscure 1848 article on education from Jstor with an academic who started doing research in the 1970s and reminiscing how in the old days, he’d have to get on the train to London to get a thing like this in the British Library or at least having to arrange a protracted interlibrary loan. On reflection this is not as radical a change as it may seem. Sure, the information takes longer to get here. But people before the internet didn’t just sit around waiting for it. They had other stuff to read (there’s always more stuff to read than time) and writing to get on with in the meantime. I don’t remember anyone claiming that modern scholarship is any better than scholarship from the 1950s because we can get information faster. I’m as much in awe of some of the accomplishments of the scholars of the 1930s as people doing research now. And just as disdainful of others from any period. When reading a piece of scholarly work, I never care about the logistics of the flow of information that was necessary for the work to be completed (unless of course, it impinges on the methodology – where moderns scholars are just as likely to take preposterous shortcuts as ancient ones). During the recent Darwin frenzy, we heard a lot about how he was the communication hub of his time. He was constantly sending and receiving letters. Today, he’d have Twitter and a blog. Would he somehow achieve more? No, he’d still have to read all those research reports and piddle about with his worms. And it’s just as likely he’d miss that famous letter from Brno.

Of course, another fallacy we like to commit is assuming that communication in the past was simply communication today minus the internet (or telephone, or name your invention). But that’s nonsense. I always like to remind people that the “[You’ve Got Mail](http://en.wikipedia.org/wiki/You%27ve_Got_Mail "You've Got Mail")” where Tom Hanks and Meg Ryan meet and fall in love online is a remake of a 1940s film where the protagonists sent each other letters. But these often arrived the same day (particularly in the same city). There were many more messenger services, pneumatic tubes, and a reliable postal service. As the Internet takes over the burden of information transmission, these are either disappearing or deteriorating but that doesn’t mean that’s the state they were in when they were the chief means of information transmission. Before there were photocopiers and faxes, there were copyists and messengers (and both were pretty damn fast). Who even sends faxes now? We like to claim we get more done with the internet but take just one step back and this claim looses much of its appeal. Sure there are things we can do now that we couldn’t do before like attend a virtual conference or a webinar. That’s true and it’s really great. But what would have the us of the 1980s have done? No doubt something very similar like buying video tapes of lectures or attending Open Universities. And the us of the 1960s? Correspondence courses and pirate radio stations. We would have had far less choice but our human endeavor would have been roughly the same. The us of 1930s, 1730s or 330s? That’s a more interesting question but nobody’s claiming that the internet changed the us of those times. We mostly think of the Internet as changing the human condition as compared to the 1960s or 1980s. And there the technology changes have far outstripped the changes in human activity.

If it’s not true that the internet has enabled us to get things done in a qualitatively different manner on a personal level, it’s even less true that it has made a difference at the level of society. There are simply so many things involved and they take so much time because humans and human institutions were involved. Let’s take the “[Velvet Revolution](http://en.wikipedia.org/wiki/Velvet_Revolution "Velvet Revolution")” of 1989 in which I was an eager if extremely marginal participant. On Friday, November 17 a bunch of protesters got roughed up, on November 27, a general strike was held and on December 10, the president resigned. In Egypt, the demonstrations started on January 25, lots of stuff happened, on February 11 the president resigned. The Egyptians have the Czechs beat in their demonstration to resignation time by 5 days (17 v 23). This was the “Twitter” revolution. We didn’t even have mobile phones. Actually, we mostly even didn’t have phones. Is that what all this new global infrastructure has gotten us? Five days off on the toppling of a dictator? Of course, not. Twitter made no difference to what was happening in Egypt, at all, when compared to other revolutoin. If anything Al Jazeera played a bigger role. But on the ground, most people found out about things by being told by someone next to them. Just like we did. We even managed to let the international media up to speed pretty quickly, which could be argued is the main thing Twitter has done in the “Arab Spring” (hey another thing the Czechs did and failed at).

Malcolm Gladwell got a lot of criticism for pointing out the same thing. But he’s absolutely right:

> “high risk” social activism requires deep roots and strong ties <http://www.newyorker.com/online/blogs/newsdesk/2011/02/does-egypt-need-twitter.html>

And while these ties can be established and maintained purely virtually, it takes a lot more than a few tweets to get people moving. Adam Weinstein adds to Gladwell’s example:

> Anyone who lived through 1989 or the civil rights era or 1967 or 1956 knows that media technology is not a motive force for civil disobedience. Arguing otherwise is not just silly; it’s a distraction from the real human forces at play here.  
> <http://motherjones.com/mojo/2011/02/malcolm-gladwell-tackles-egypt-twitter>

Revolutions simply take their time. On paper, the Russian October Revolution of 1917 took just a day to topple the regime (as did so many others). But there were a bunch of unsuccessful revolutions prior to that and of course a bloody civil war lasting for years following. To fully institutionalize its aims, the Russian revolution could be said to have taken decades and millions dead. Even in ancient times, sometimes things moved very quickly (and always more messily than we can retell the story). The point about revolutions and wars is that they don’t move at the speed of information but at the speed of a fast walking revolutionary or soldier. Ultimately, someone has to sit in the seat where the buck stops, and they can only get there so fast even with jets, helicopters and fast cars. Such are the natural logistics of human communal life.

This doesn’t mean that there the speed or manner of communication doesn’t have some implications where logistics are concerned. But their impact is surprisingly small and easily absorbed by the larger concerns. In the Victorian Internet, Tom Standage describes how war ship manifests could no longer be published in The Times during the Crimean war because they could be telegraphed to the enemy faster than the ships would get there (whereas in the past, a spy’s message would be no faster than the actual ships). Also, betting and other financial establishments had to make adjustments not to get the speed of information get in the way of making profit. But if we compare the 1929 financial crisis with the one in 2008, we see that the speed of communication made little difference on the overall medium-term shape of the economy. Even though in 2008 we were getting up to the second information about the falling banking houses, the key decisions about support or otherwise took about the same amount of time (days). Sure, some stock trading is now done to the fraction of the second by computers because humans simply aren’t fast enough. But the economy still moves at about the same pace – the pace of lots and lots of humans shuffling about through their lives.

As I said at the start, although this post has been brewing in me for a while, it was most immediately inspired by that of Marshall Poe (of New Books in History) published about 6 months ago. What he said got no less relevant through the passage of time.

> Think for a moment about what you do on the Internet. Not what you could do, but what you actually do. You email people you know. In an effort to broaden your horizons, you could send email to strangers in, say, China, but you don’t. You read the news. You could read newspapers from distant lands so as to broaden your horizons, but you usually don’t. You watch videos. There are a lot of high-minded educational videos available, but you probably prefer the ones featuring, say, snoring cats. You buy things. Every store in the world has a website, so you could buy all manner of exotic goods. As a rule, however, you buy the things you have always bought from the people who have always sold them.

This is easy to forget. We call online shopping and food delivery a great achievement. But having shopping delivered was always an option in the past (and much more common than now when delivery boys are more expensive). Amazon is amazing but still just a glorified catalog.

But there are revolutionary inventions that nobody even notices. What about the invention of the space between words? None of the ancients bothered to put spaces between words or in general read silently. It has been estimated that putting spaces between words not only allowed for silent reading (a highly suspicious activity until the 1700s) but also sped up reading by about 30%. Talk about a revolution! I’m a bit skeptical about the 30% number but still nobody talks about it. We think about audio books as an post-Eddison innovation but in fact, all reading was partly listening not too long ago. Another forgotten invention is that of the blackboard which made large-volume dissemination of information much more feasible through a simple reconfiguration of space and attention between pupil and teacher.

[![Visualization of the various routes through a ...](http://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Internet_map_1024.jpg/300px-Internet_map_1024.jpg "Visualization of the various routes through a ...")](http://commons.wikipedia.org/wiki/File:Internet_map_1024.jpg)

Image via Wikipedia

David Weinberger recently wrote what was essentially a poem about the hypertext (a buzz word I haven’t heard for a while):

> The old institutions were more fragile than we let ourselves believe. They were fragile because they made the world small. A bigger truth burst them. The world is more like a messy, inconsistent, ever-changing web than like a curated set of careful writings. Truth burst the world made of atoms.
>
> Yes, there is infinite space on the Web for lies. Nevertheless, the Web’s architecture is a better reflection of our human architecture. We embraced as if it were always true, and as if we had known it all along, because it is and we did.  
>  [http://www.hyperorg.com/blogger/2011/05/01/a-big-question](http://www.hyperorg.com/blogger/2011/05/01/a-big-question/)

It is remarkable how right and wrong he can be at the same time. Yes, the web is more of a replication of the human architecture. It has some notable strengths (lack of geographic limitation, speed of delivery of information) and weaknesses (no internal methods for exchange of tangible goods, relatively limited methods for synchronous face-to-face communication.) I’d even go as far as calling the Internet “computer-assissted humanity”. But that just means that nothing about human organization online is a radical transformation of humanity offline.

What on Earth makes Weinberger think that the “existing institutions were fragile”? If anything they proved extremely robust. I find [The Cluetrain Manifesto](http://en.wikipedia.org/wiki/Cluetrain_Manifesto) extremely inspiring and in many ways moving. But I find “The Communist Manifesto” equally profound without wanting to live in a world governed by it. The “The Communist Manifesto” got the description of the world as it is perfectly right. Pretty much every other paragraph in it applies just as much today as it did then. But the predictions offered in the other paragraphs can really cause nothing but laughter today. “The Cluetrain Manifesto” gave the same kind of expression to the frustration with the Dilbert world of big corporations and asked for our humanity back. They were absolutely right.

Markets can be looked at as conversations and the internet can facilitate certain kinds of conversation. But they were wrong in assuming that there is just one kind of conversation. There are all sorts of group symbolic and ritualized conversations that make the world of humans go around. And they have never been limited just to the local markets. In practical terms, I can now complain about a company on a blog or in a tweet. And these can be viewed by others. But since there’s an Xsuckx.com website for pretty much all major brands, the incentive for companies to be responsive to this are relatively small. I have actually received some response to complaints from companies on Twitter. But only once it led to the resolution of the problem. But Twitter is still a domain of “the elite” so it pays companies to appease people. However, should it reach the level of ubiquitous obscurity that many pages have, it will become even less appealing due to the lack of permanence of Tweets.

The problem is that large companies with large numbers of customers can only scale if they keep their interaction with those customers at certain levels. It was always thus and will always remain so. Not because of intrinsic attitudes but because of configurational limitations of time and human attention. Even the industrially oppressed call-center operator can only deal with about 10 customers an hour. So you have to work in some 80/20 cost checks into customer support. Most of any company’s interaction with their customers will be one to many and not on one on one. (And this incidentally holds for communications about the company by customers).

There’s a genre of conversations in the business and IT communities that focus on ‘why is X’ successful. Ford of the 1920s, IBM of the 1960s, Apple of the 2000s. The constant in these conversations is the wilful effort of projecting the current convetnional wisdom about business practices onto what companies do and used to do. This often requires significant reimagining of the present and the past. Leo Laporte and Paul Thurott recently had a conversation (<http://twit.tv/ww207>) in which they were convinced that companies that interact and engage with their customers will be successful. But why then, one of them asks, is not Microsoft whose employees blog all the time is not more successful than Apple who couldn’t be more tightlipped about its processes and whose attitude to customers is very much take it or leave it? Maybe it’s the Apple Store, one of them comments. That must be it. That engages the crap out of the Apple’s customers. But neither of them asked what is the problem with traditional stores, then? What is the point of the internet. The problem is that as with any metaphoric projection, the customer engagement metaphor is just partial. It’s more a way for us to grasp with processes that are fairly stable at the macro institutional level (which is the one I’m addressing here), but basically chaotic at the level of individual companies or even industries.

So I agree with Marshall Poe about the amount of transformation going on:

> As for transformative, the evidence is thin. The basic institutions of modern society in the developed world—representative democracy, regulated capitalism, the welfare net, cultural liberalism—have not changed much since the introduction of the Internet. The big picture now looks a lot like the big picture then.

Based on my points above, I would even go as far as to argue that the basic institutions have not changed at all. Sure, foreign ministries now give advisories online, taxes can be paid electronically and there are new agencies that regulate online communication (ICANN) as well as old ones with new responsibilities. But as we read the daily news, can we perceive any new realities taking place? New political arrangements based on this new and wonderful thing called the Internet? No. If you read a good spy thriller from the 80s and one taking place now, you can hardly tell the difference. They may have been using payphones instead of the always on mobile smart devices we have now but the events still unfold in pretty much the same way: people go from place to place and do things.

> Writing, print, and electronic communications—the three major media that preceded the Internet—did not change the big picture very much. Rather, they were brought into being by major historical trends that were already well underway, they amplified things that were already going on.

Exactly! If you read about the adventures of Sinuhe, it doesn’t seem that different from something written by Karl May or Tom Clancy. Things were happening as they were and whatever technology was available to be used, was used as well as possible. Remember that the telephone was originally envisioned to be a way of attending the opera – people calling in to a performance instead of attending live.

As a result, many things that happened could not have happened exactly in the same way without the tools of the age being there. The 2001 portion of the war in Afghanistan certainly would have looked different without precision bombing. But now in 2011 it seems to be playing out pretty much along the same lines experienced by the Brits and the Soviets. Meaning: it’s going badly.

The role of TV imagery in the ending of the Vietnam war is often remarked on. But that’s just coincidental. There have been plenty of unpopular wars that were ended because the population refused to support them and they were going nowhere. Long before the “free press”, the First Punic Wars were getting a bad rep at home. Sure, the government could have done a better job of lying to the press and its population but that’s hard to do when you have a draft. It didn’t work for Ramses II when he got his ass handed to him at Kadesh and didn’t ultimately work for the Soviet misadventure in Afghanistan. The impact of the impact of the TV images can easily be overestimated. The My Lai Massacre happened in 1968 when the war was about in its mid-point. It still took 2 presidential elections and 1 resignation before it was really over. It played a role but if the government wanted, it could have kept the war going.

> Communications tools are not “media” in the sense we normally use the word. A stylus is not a scriptorium, movable type is not a publishing industry, and a wireless set is not a radio network. In order for media technologies to become full-fledged media, they need to respond to some big-picture demand.

It is so easy to confuse the technology with the message. On brief reflection, the McLuhan quote we all keep repeating like sheep is really stupid. The medium is the medium and the message is the message. Sometimes they are so firmly paired we can’t tell them apart, sometimes they have nothing in common. What is the medium of this message? HTML, the browser, your screen, a blog post, the Internet, TCP/IP, ehternet? They’re all involved in the transmission. We can choose whether we pay attention to some of them. If I’d posted somebody a parchment with this on it, it would certainly add to the message or become a part of it. But it still wouldn’t BE the message! Lots of artists like Apollinaire and his calligrams actually tried to blend the message and the medium in all sorts of interesting ways. But it was hard work. Leo Laporte (whose podcasts I enjoy listening to greatly) spent a lot of time trying to displace podcast with netcast to avoid an association with the medium. He claimed that his shows are not ‘podcasts’ but ‘shows’, i.e. real content. Of course, he somehow missed the fact that we don’t listen to programs but to the radio and don’t view drama but rather watch TV. The modes of transmission have always been associated with the message – including the word “show” – until they weren’t. We don’t mean anything special now when we say we ‘watch TV’.

Of course, the mode of transmission has changed how the “story” is told. Every new medium has always first tried to emulate the one it was replacing but ultimately found its own way of expression. But this is no different to other changes in styles. The impressionists were still using the same kinds of paints and canvasses, and modernist writers the same kind of inks and books. Every message exists in a huge amount of context and we can choose which of it we pay attention to at any one time. Sometimes the medium becomes a part of the context, sometimes it’s something else. Get over it!

There are some things Marshall Poe says I don’t agree with. I don’t think we need to reduce everything to commerce (as he does – perhaps having imbibed too much of Marxist historiography). But most importantly I don’t agree when he says that the Internet is mature in the same way that TV was mature in the 1970s. Technologies take different amounts of time to mature as widespread consumer utilities. It is always on the order of decades and sometimes centuries but there is no set trajectory. TV took less time than cars, planes took longer than TV, cars took longer than the Internet. (All depending on how we define mature – I’m mostly talking about wide consumer use – i.e. when only oddballs don’t use it and access is not disproportionately limited by socioeconomic status). The problem with the Internet is that there are still enough people who don’t use it and/or who can’t access it. In the 1970s, the majority had TVs or radios which were pretty much equivalent as a means of access to information and entertainment. TV was everywhere but as late as the 1980s, the BBC produced radio versions of its popular TV shows (Dad’s Army, All Gas and Gaiters, etc.) The radio performance of Star Wars was a pretty big deal in the mid-80s.

There is no such alternative access to the Internet. Sure, there are TV shows that play YouTube clips and infomercials that let you buy things. But it’s not the experience of the internet – more like a report on what’s on the Internet.

Even people who did not have TVs in the 1970s (both globally and nationally) could readily understand everything about their operation (later jokes about programing VCRs aside). You pushed a button and all there was to TV was there. Nothing was hiding. Nothing was trying to ambush you. People had to get used to the idiom of the TV, learn to trust some things and not others (like advertising). But the learning curve was flat.

The internet is more like cars. When you get in one, you need to learn lots of things from rules of manipulation to rules of the road. Not just how to deal with the machinery but also how to deal with others using the same machinery. The early cars were a tinkerer’s device. You had to know a lot about cars to use cars. And then at some point, you just got in and drove. At the moment, you still have to know a lot about the internet to use it. Search engines, Facebook, the rules of Twitter, scams, viruses. That intimidates a lot of people. But less so now than 10 years ago. Navigating the Internet needs to become as socially common place as navigating traffic in the street. It’s very close. But we’re not quite there yet on the mass level.

Nor do I believe that the business models on the Internet are as settled as they were with TV in the 1970s. Least of all the advertising model. Amazon’s, Google’s and Apple’s models are done – subject to normal developments. But online media are still struggling as are online services.

We will also see significant changes with access to the Internet going mobile as well as the increasing speed of access. There are still some possible transformations hiding there – mostly around video delivery and hyper-local services. I’d give it another 10 years (20 globally). By then the use of the internet will be a part of everyday idiom in a way that it’s still quite not now (although it is more than in 2001). But I don’t think the progress will go unchecked. The prospect of flying cars ran into severe limitations of technology and humanity. After 2021, I would expect the internet to continue changing under the hood (just like cars have since the 1960s) but not much in the way of its human interface (just like cars since the 1960s).

There are still many things that need working out. The role of social media (like YouTube) and social networking (like Facebook). Will they put a layer on top of the internet or just continue being a place on the internet? And what business models other than advertising and in-game purchases will emerge? Maybe none. But I suspect that the Internet has about a decade of maturing to get to where it will be recognisable in 2111. Today, cars from the 1930s don’t quite look like cars but those from the 1960s do. In this respect, I’d say the internet is somewhere in the 1940s or 50s. Both in usability, ubiquity, accessibility and it’s overall shape.

The most worrying thing about the future of the internet is a potential fight over the online commons. One possible development is that significant parts of the online space will become proprietary with no rights of way. This is not just net-neutrality but a possible consequence of the lack of it. It is possible that in the future so many people will only access the online space to take advantage of proprietary services tied to their connection provider that they may not even notice that at first some and later on most non-proprietary portions of the internet are no longer accessible. It feels almost unimaginable now but I’m sure people in 16th century East Anglia never thought their grazing commons would disappear (<http://www.eh-resources.org/podcast/podcast2010.html>). I’m not suggesting that this is a necessary development. Only that it is a configurational possibility.

As I’m writing this. A Tweet just popped up on my screen mentioning another shock in Almaty a place where I spent a chunk of time and where a friend of mine is about to take up a two-year post. I switch over to Google and find out no reports of destruction. If not for Twitter, I may not have even heard about it. I go on Twitter and see people joking about it in Russian. I sort of do my own journalism for a few minutes gathering sources. How could I still claim that the Internet changes nothing? Well, I did say “almost”. Actually, for many individuals the Internet changes everything. They (like me) get to do jobs they wouldn’t, find out things they couldn’t and talk to people they shouldn’t. But it doesn’t change (or even augment) our basic flesh-bound humanity. Sure, I know about something that happened somewhere I care about that I otherwise wouldn’t. But there’s nothing more I can do about it. I did my own news gathering about as fast as it would have taken to listen to a BBC report on this (I’ve never had a TV and now only listen to live radio in the mornings.) I can see some scenarios where the speed would be beneficial but when the speed is not possible we adjust our expectations. I first visited Kazakhstan in 1995 and although I had access to company email, my mother knew about what was happening at the speed of a postcard. And just the year before during my visit to Russia, I got to send a few telegrams. You work with what you have.

All the same, the internet has changed the direction my life has taken since about 1998. It allowed me to fulfil my childhood dream of sailing on the Norfolk Broads, just yesterday it helped me learn a great new blues lick on the guitar. It gives me reading materials, a place to share my writing, brings me closer to people I otherwise wouldn’t have heard of. It gives me podcasts like the amazing New Books in History or China History podcast! I love the internet! But when I think about my life before the internet, I don’t feel it was radically different. I can point at a lot of individual differences but I don’t have a sense of a pre-Internet me and post-Internet me. And equally I don’t think there will be a pre-Internet and post-Internet humanity. One of the markers of the industrial revolution is said to be its radical transformation of the shape of things. So much so that a person of 1750 would still recognize the shape of the country in 1500 but a person in 1850 would no longer see them the same. I wonder if this is a bit too simplistic. I think we need to bring more rigor to the investigation of human contextual identity and embeddedness in the environment. But that is outside the scope of this essay.

It is too tempting to use technologies as a metaphor for expressing our aspirations. We do (and have always done) this through poetry, polemic, and prose. Our depictions of what we imagine the Internet society is like appear in lengthy essays or chance remarks. They are carried even in tiny words like “now” when judiciously deployed. But sadly exactly the same aspirations of freedom and universal sisterhood were attached to all the preceding communication technologies, as well: print, telegraph, or the TV. Our aspirations aren’t new. Our attachment to projecting these aspiration into the world around us is likewise ancient. Even automatised factory production has been hailed by poets as beautiful. And it is. We always live in the future just about to come with regrets about the past that has never been. But our prosaic present seems never to really change who we are. Humans for better or worse.

### *Related*
```
./2011-06-01-language-learning-in-literature-as-a-source-domain-for-generative-metaphors-about-anything.md
```
---
title: "Language learning in literature as a source domain for generative metaphors about anything"
date: 2011-06-01
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/06/language-learning-in-literature-as-a-source-domain-for-generative-metaphors-about-anything
---

[![Portrait of Yoritomo, copy of the 1179 origina...](http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Minamoto_no_Yoritomo.jpg/300px-Minamoto_no_Yoritomo.jpg "Portrait of Yoritomo, copy of the 1179 origina...")](http://commons.wikipedia.org/wiki/File:Minamoto_no_Yoritomo.jpg)

Image via Wikipedia

In my thinking about things human, I often like to draw on the domain of [second language learning](http://en.wikipedia.org/wiki/Second_language_acquisition "Second language acquisition") as the source of analogies. The problem is that relatively few people in the English speaking world have experience with language learning to such an extent that they can actually map things onto it. In fact, in my experience, even people who have a lot of experience with language learning are actually not aware of all the things that were happening while they were learning. And of course awareness of research or language learning theories is not to be expected. This is not helped by the language teaching profession’s propaganda that language learning is “fun” and “rewarding” (whatever that is). In fact my mantra of language learning (I learned from my friend Bill Perry) is that “language learning is hard and takes time” – at least if you expect to achieve a level of competence above that of “impressing the natives” with your “please” and “thank you”. In that, language learning is like any other human endeavor but because of its relatively bounded nature — when compared to, for instance, culture — it can be particularly illuminating.

But how can not just the fact of language learning but also its visceral experience be communicated to those who don’t have that kind of experience? I would suggest engrossing literature.

For my money, one of the most “realistic” depictions of language learning with all its emotional and cognitive peaks and troughs can be found in [James Clavell](http://en.wikipedia.org/wiki/James_Clavell "James Clavell")‘s “[Shogun](http://www.amazon.com/Shogun-James-Clavell/dp/0440178002%3FSubscriptionId%3D0G81C5DAZ03ZR9WH9X82%26tag%3Dzemanta-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D0440178002 "Shogun")“. There we follow the Englishman [Blackthorne](http://en.wikipedia.org/wiki/Blackthorne "Blackthorne") as he goes from learning how to say “yes” to conversing in halting Japanese. Clavell makes the frustrating experience of not knowing what’s going on and not being able to express even one’s simplest needs real for the reader who identifies with Blackthorne’s plight. He demonstrates how language and cultural learning go hand in hand and how easy it is to cause a real life problem through a little linguistic misstep.

Shogun stands in stark contrast to most other literature where knowledge of language and its acquisition is viewed as mostly a binary thing: you either know it or you don’t. One of the worst offenders here is Karl May (virtually unknown in the English speaking world) whose main hero Old Shatterhand/[Kara Ben Nemsi](http://en.wikipedia.org/wiki/Kara_Ben_Nemsi "Kara Ben Nemsi") acquires effortlessly not only languages but dialects and local accents which allow him to impersonate locals in May’s favorite plot twists. Language acquisition in May just happens. There’s never any struggle or miscommunication by the main protagonist. But similar linguistic effortlessness in the face of plot requirements is common in literature and film. Far more than magic or the existence of Vampires, the thing that used to stretch my credulity the most in Buffy the Vampire Slayer was ease with which linguistic facility was disposed of.

To be fair, even in Clavell’s book, there are characters whose [linguistic competence](http://en.wikipedia.org/wiki/Linguistic_competence "Linguistic competence") is largely binary. Samurai either speak Portugese or Latin or they don’t – and if the plot demands, they can catch even whispered colloquial conversation. Blackthorne’s own knowledge of Dutch, Spanish, Portugese and Latin is treated equally as if identical competence would be expected in all four (which would be completely unrealistic given his background and which resembles May’s Kara Ben Nemsi in many respects).

Nevertheless, when it comes to Japanese, even a superficially empathetic reader will feel they are learning Japanese along with the main character. Largely through Clavell’s clever use of limited translation.

This is all the more remarkable given that Clavell obviously did not speak Japanese and relied on informants. This, as the “[Learning from Shogun](http://www.columbia.edu/~hds2/learning/Learning_from_shogun_txt.pdf "PDF Link")” book pointed out, led to many inaccuracies in the actual Japanese, advising readers not to rely on the language of Shogun too much.

Clavell (in all his books – not just Shogun) is even more illuminating in his depiction of intercultural learning and communication – the novelist often getting closer to the human truth of the process than the specialist researcher. But that is a blog post for another time.

Another novel I remember being an accurate representation of language learning is [John Grisham](http://en.wikipedia.org/wiki/John_Grisham "John Grisham")‘s “[The Broker](http://www.amazon.com/Broker-John-Grisham/dp/0739316478%3FSubscriptionId%3D0G81C5DAZ03ZR9WH9X82%26tag%3Dzemanta-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D0739316478 "The Broker (John Grisham)")” in which the main character Joel Backman is landed in a foreign country by the CIA and is expected to pick up Italian in 6 months. Unlike Shogun, language and culture do not permeate the entire plot but language learning is a part of about 40% of the book. “The Broker” underscores another dimension which is also present in the Shogun namely teaching, teachers and teaching methods.

Blackthorne in Shogun orders an entire village (literally on the pain of death) to correct him every time he makes a mistake. And then he’s excited by a dictionary and a grammarbook. Backman spends a lot of time with a teacher who makes him repeat every sentence multiple times until he knows it “perfectly”. These are today recognized as bad strategies. Insisting on perfection in language learning is often a recipe for forming mental blocks (Krashen’s cognitive and affective filters). But on the other hand, it is quite likely that in totally immersive situations like Blackthorne’s or even partly immersive situations like Backman’s (who has English speakers around him to help), pretty much any approach to learning will lead to success.

Another common misconception reflected in both works is the demand language learning places on rote memory. Both Blackthorne and Backman are described as having exceptional memories to make their progress more plausible but the sort of learning successes and travails described in the books would accurately reflect the experiences of anybody learning a foreign language even without a memory. As both books show without explicit reference, it is their strategies in the face of incomprehension that help their learning rather than a straight memorization of words (although that is by no means unnecessary).

So what are the things that knowing about the experience of second language learning can help us ellucidate? I think that any progress from incompetence to competence can be compared to learning a second language. Particularly when we can enhance the purely cognitive view of learning with an affective component. Strategies as well as simple brain changes are important in any learning which is why none of the brain-based approaches have produced unadulterated success. In fact, linguists studying language as such would do well to pay attention to the process of second language learning to more fully realize the deep interdependence between language and our being.

But I suspect we can be more successful at learning anything (from history or maths to computers or double entery book keeping) if we approach it as a foreign language. Acknowledge the emotional difficulties alongside cognitive ones.

Also, if we looked at expertise more as linguistic fluency than a collection of knowledge and skills, we could devise a program of learning that would take better into account not only the humanity of the learner but also the humanity of the whole community of experts which he or she is joining.

### *Related*
```
./2011-06-03-killer-app-is-a-bad-metaphor-for-historical-trends-good-for-pseudoteaching.md
```
---
title: "Killer App is a bad metaphor for historical trends, good for pseudoteaching"
date: 2011-06-03
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/06/killer-app-is-a-bad-metaphor-for-historical-trends-good-for-pseudoteaching
---

[![This map shows the countries in the world that...](http://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Latin_alphabet_world_distribution.svg/300px-Latin_alphabet_world_distribution.svg.png "This map shows the countries in the world that...")](http://commons.wikipedia.org/wiki/File:Latin_alphabet_world_distribution.svg)

Image via Wikipedia

[Niall Ferguson](http://en.wikipedia.org/wiki/Niall_Ferguson "Niall Ferguson") wrote in [The Guardian some time ago](http://www.guardian.co.uk/education/2011/mar/29/history-school-crisis-disconnected-events) about how awful history education has become with these “new-fangled” 40-year-old methods like focusing on “history skills” that leads to kids leaving school knowing “unconnected fragments of [Western history](http://en.wikipedia.org/wiki/Western_world "Western world"): Henry VIII and Hitler, with a small dose of Martin Luther King, Jr.” but not who was the reigning English monarch at the time of the Armada. Instead, he wants history to be taught his way: deep trends leading to the understanding why the “West” rules and why Fergusson is the cleverest of all the historians that ever lived. He even provided (and how cute is this) a lesson plan!

Now, personally, I’m convinced that the history of historical education teaches us mostly that historical education is irrelevant to the success of current policy. Not that we cannot learn from history. But it’s such a complex source domain for analogies that even very knowledgeable and reasonable people can and do learn the exact opposites from the same events. And even if they learn the “right” things it still doesn’t stop them from being convinced that they can do it better this time (kind of like people in love who think their marriage will be different). So Ferguson’s bellyaching is pretty much an empty exercise. But that doesn’t mean we cannot learn from it.

Ferguson, who is a serious historian of financial markets, didn’t just write a whiney column for the Guardian, he wrote a book called [Civilization](http://www.amazon.co.uk/Civilization-Ways-West-Beat-Rest/dp/1846142733) (I’m writing a review of it and a few others under the joint title “Western Historiographical Eschatology” but here I’ll only focus on some aspects of it) and is working on a computer game and teaching materials. To show how seriously he takes his pedagogic mission and possibly also how hip and with it he is, Ferguson decided to not call his historical trends trends but rather “killer apps”. I know! This is so laugh out loud funny I can’t express my mirth in mere words:))). And it gets even funnier as one reads his book. As a pedagogical instrument this has all the practical value of putting a spoiler on a Fiat. He uses the term about 10 times (it’s not in the index!) throughout the book including one or two mentions of “downloading” when he talks about the adoption of an innovation.

Unfortunately for Ferguson, he wrote his book before the terms “[pseudocontext](http://blog.mrmeyer.com/?p=8002 "Pseudocontext")” and “[pseudoteaching](http://fnoschese.wordpress.com/pseudoteaching/)” made an appearance in the edublogosphere. And his “killer apps” and the lesson plan based on them are a perfect example of both. Ferguson wrote a perfectly servicable and an eminently readable historical book (even though it’s a bit of a tendentious mishmash). But it is still a historical book written by a historian. It’s not particularly stodgy or boring but it’s no different from myriad other currently popular historical books that the “youth of today” don’t give a hoot about. He thinks (bless him) that using the language of today will have the youth flocking to his thesis like German princes to Luther. Because calling historical trends “killer apps” will bring everything into clear context and make all the convoluted syntax of even the most readable history book just disappear! This is just as misguided as thinking that talking about men digging holes at different speeds will make kids want to do math.

What makes it even more precious is that the “killer app” metaphor is wrong. For all his extensive research, Ferguson failed to look up “killer app” on Wikipedia or in a dictionary. There he would have found out that it doesn’t mean “a cool app” but rather an application that confirms the viability of an existing platform whose potential may have been questioned. There have only been a handful of killer apps. The one undisputed killer app was [Visicalc](http://en.wikipedia.org/wiki/VisiCalc "VisiCalc") which all of a sudden showed how an expensive computer could simplify the process of financial management through electronic spreadsheets and therefore pay for itself. All of a sudden, personal computers made sense to the most important people of all, the money counters. And thus the personal computer revolution could begin. A killer app proved that a personal computer is useful. But the personal computer had already existed as a platform when Visicalc appeared.

None of Ferguson’s “killer apps” of “competition, science, property rights, medicine, consumer society, work ethic” are this sort of a beast. They weren’t something “installed” in the “West” which then proved its viability. They were something that, according to Ferguson anyway, made the West what it was. In that they are more equivalent to the integrated circuit than Visicalc. They are the “hardware” that makes up the “West” (as Ferguson sees it), not the software that can run on it. The only possible exception is “medicine” or more accurately “modern [Western medicine](http://en.wikipedia.org/wiki/Medicine "Medicine")” which could be the West’s one true “killer app” showing the viability of its platform for something useful and worth emulating. Also, “killer apps” required a conscious intervention, whereas all of Ferguson’s “apps” were something that happened on its own in a myrriad disparate processes – we can only see them as one thing now.

But this doesn’t really matter at all. Because Ferguson, as so many people who want to speak the language of the “young people”, neglected to pay any attention whatsoever to how “young people” actually speak. The only people who actually use the term “killer app” are technology journalists or occasionally other journalists who’ve read about it. I did a quick Google search for “killer app” and did not find a single non-news reference where somebody “young” would discuss “killer apps” on a forum somewhere. That’s not to say it doesn’t happen but it doesn’t happen enough to make Ferguson’s work any more accessible.

This overall confusion is indicative of Ferguson’s book as a whole which is definitely less than the sum of its parts. It is full of individual insight and a fair amount of wit but it flounders in its synthetic attempts. Not all his “killer apps” are of the same type, some follow from the others and some don’t appear to be anything at all than Ferguson’s wishful thinking. They certainly didn’t happen on one “platform” – some seem the outcome rather than the cause of “Western” ascendancy. Ferguson’s just all too happy to believe his own press. At the beginning he talks about early hints around 1500AD that the West might achieve ascendancy but at the end he takes a half millenium of undisputed Western rule for granted. But in 1500, “the West” had still 250 years to go before the start of the industrial revolution, 400 years before modern medicine, 50 years before Protestantism took serious hold and at least another 100 before the Protestant work ethic kicked in (if there really is such a thing). It’s all over the place.

Of course, there’s not much innovative about any of these “apps”. It’s nothing a reader of the [Wall Street Journal](http://www.wsj.com/ "The Wall Street Journal") editorial page couldn’t come up with. Ferguson does a good job of providing interesting anecdotes to support his thesis but each of his chapters meanders around the topic at hand with a smattering of unsystematic evidence here and there. Sometimes the West is contrasted with China, sometimes the Ottomans, sometimes Africa! It is hard to see how his book can help anybody’s “chronological understanding” of history that he’s so keen on.

But most troublingly it seems in places that he mostly wrote the book for as a carrier for ultra-conservative views that would make his writing more suitable for The Daily Mail rather than the Manchester Pravda: “the biggest threat to [Western civilization](http://en.wikipedia.org/wiki/Western_culture "Western culture") is posed not by other civilizations, but by our own pusilanimity” unless of course it is the fact that “private property rights are repeatedly violated by governments that seem to have an insatiable appetite for taxing out incomes and our wealth and wasting a large portion of the proceeds”.

[![Panelist Economic Historian Niall Ferguson at ...](http://upload.wikimedia.org/wikipedia/commons/thumb/9/96/World_Debate_-_Niall_Ferguson_crop.jpg/300px-World_Debate_-_Niall_Ferguson_crop.jpg "Panelist Economic Historian Niall Ferguson at ...")](http://commons.wikipedia.org/wiki/File:World_Debate_-_Niall_Ferguson_crop.jpg)

Image via Wikipedia

It’s almost as if the “civilized” historical discourse was just a veneer that peels off in places and reveals the real Ferguson, a comrade of Pat Buchanan whose “The Death of the West” (the Czech translation of which screed I was once unfortunate enough to review) came from the same dissatisfaction with the lack of our confidence in the West. Buchanan also recommends teaching history – or more specifically, lies about history – to show us what a glorious bunch of chaps the leaders of the West were. Ferguson is too good a historian to ignore the inconsistencies in this message and a careful reading of his book reveals enough subtlety not to want to reconstitute the British Empire (although the yearning is there). But the Buchananian reading is available and in places it almost seems as if that’s the one Ferguson wants readers to go away with.

From metaphor to fact, Ferguson is an unreliable thinker flitting between insight, mental shortcut and unreflected cliche with ease. Which doesn’t mean that his book is not worth reading. Or that his self-serving pseudo-lesson plan is not worth teaching (with caution). But remember I can only recommend it because I subscribe to that awful “culture of relativism” that says that “any theory or opinion, no matter how outlandish, is just as good as whatever it was we used to believe in.”

**Update 1:** I should perhaps point out, that I think [Ferguson’s lesson plan](http://teachers.guardian.co.uk/resources.aspx?q=niall%20ferguson) is pretty good, as such things go. It gives students an activity that engages a number of cognitive and affective faculties rather than just rely on telling. Even if it is completely unrealistic in terms the amount of time allocated and the objectives set. “Students will then learn how to construct a causal explanation for Western ascendancy” is an aspiration, not a learning objective. Also, it and the other objectives really rely on the “historical skills” he derides elsewhere.

The lesson plan comes apart at about point 5 where the really cringeworthy part kicks in. Like in his book, Ferguson immediately assumes that his view is the only valid one – so instead of asking the students to compare two different perspectives on why the world looked like it did in 1913 as opposed to 1500 (or even compare maps at strategic moments) he simply asks them to come up with reasons why his “killer apps” are right (and use evidence while they’re doing it!) .

I also love his aside: “The groups need to be balanced so that each one has an A student to provide some kind of leadership.” Of course, there are shelf-fuls of literature on group work – and pretty much all of them come from the same sort of people who’re likely to practice “new history” – Ferguson’s nemesis.

I don’ think using Ferguson’s book and materials would do any more damage than using any other history book. Not what I would recommend but who cares. I recently spent some time at Waterstone’s browsing through modern history textbooks and I think they’re excellent. They provide far more background to events and present them in a much more coherent picture than Ferguson. They perhaps don’t encourage the sort of broad synthesis that has been the undoing of so many historians over the centuries (including Ferguson) but they demonstrate working with evidence in a way he does not.

The reason most people leave school not knowing facts and chronologies is because they don’t care, not because they don’t have an opportunity to learn. And this level of ignorance has remained constant over decades. At the end of the day, history is just a bunch of stories not that different from what you see on a soap opera or in a celebrity magazine, just not as relevant to a peer group. No amount of “killer applification” is going to change this. What remains at the end of historical education is a bunch of disconnected images, stories and conversation pieces (as many of them about the tedium of learning as about its content). But there’s nothing wrong with that. Let’s not underestimate the ability of disinterested people to become interested and start making the connections and filling in the gaps when they need to. That’s why all these “after-market” history books like Ferguson’s are so popular (even though for most people they are little more than tour guides to the exotic past).

**Update 2:** By a fortuitous coincidence, an announcement of the release of [George L. Mosse](http://en.wikipedia.org/wiki/George_Mosse)‘s lectures on European cultural history: <http://history.wisc.edu/mosse/george_mosse/audio_lectures.htm> came across my news feeds. I think it is important to listen to these side by side with Ferguson’s seductively unifying approach to fully realize the cultural discontinuity in so many key aspects between us and the creators of the West. Mosse’s view of culture, as his Wikipedia entry reads, was as “a state or habit of mind which is apt to become a way of life”. The practice of history after all is a culture of its own, with its own habits of mind. In a way, Ferguson is asking us to adopt his habits of mind as our way of life. But history is much more interesting and relevant when it is, Mosse’s colleague [Harvey Goldberg](http://en.wikipedia.org/wiki/Harvey_Goldberg) put it on [this recording](http://history.wisc.edu/goldberg/clips/Historian%20of%20Usable%20Past%203%20May%2074.mp3), a quest after a “usable past” spurred by our sense of the “present crisis” or “present struggle”. So maybe my biggest beef with Ferguson is that I don’t share his justificationist struggle.

[![Enhanced by Zemanta](http://img.zemanta.com/zemified_e.png?x-id=87613591-71c9-4962-bcaf-a4b120952bea)](http://www.zemanta.com/ "Enhanced by Zemanta")

### *Related*
```
./2011-11-02-moral-compass-metaphor-points-to-surprising-places.md
```
---
title: "Moral Compass Metaphor Points to Surprising Places"
date: 2011-11-02
author: Dominik Lukeš
source: https://metaphorhacker.net/2011/11/moral-compass-metaphor-points-to-surprising-places
---

I thought the moral compass metaphor has mostly left current political discourse but it just cropped up – this time pointing from left to right – as [David Plouffe accused Mitt Romney of not having one]((http://www.washingtonmonthly.com/political-animal/2011_10/no_core033193.php). As I keep repeating, George Lakoff once said “Metaphors can kill.” And Moral Compass has certainly done its share of homicidal damage. Justifying wars, interventions and unflinching black and white resolve in the face of gray circumstances. It is a killer metaphor!

But with a bit of hacking it is not difficult to subvert it for good. Yes, I’m ready to declare, it is good to have a moral compass, providing you make it more like a “true compass” to quote Plouffe. The problem is, as I learned during my sailing courses many years ago, that most people don’t understand how compasses actually work.

First, compasses don’t point to “the North”. They point to what is called the Magnetic North which is quite a ways from the actual North. So if you want to go to the North pole, you need make a lot of adjustment in where you’re going. Sound familiar? Kind of like following your convictions. They often lead you to places that are different from where you’re saying you’re going.

Second, the Magnetic North keeps moving. Yes, the difference of where it is in relation to the “actual” North changes from year to year. So you have to adjust your directions to the times you live in! Sound familiar? Being a devout Christian led people to different actions in the 1500s, 1700s and 1900. Although, we keep saying the “North” or faith is the same, the actual needle showing us where to go points to different directions.

Third, the compass is easily distracted by its immediate physical context. The distribution of metals on a boat, for instance, will throw it completely off course. So it needs to be calibrated differently for each individual installation. Sound familiar?

And it’s also worth noting that the south magnetic pole is not the exact polar opposite of the north magnetic pole!

So what can we learn from this newly hacked moral compass metaphor? Well, nothing terribly useful. Our real ethics and other commitments are always determined by the times we live and contexts we find ourselves in. And often we say we’re going one way when we’re actually heading another way. But we already knew that. Everybody knows that! Even people who say it’s not true (the anti-relativists) know that! They are not complete idiots after all, they just pretend to be to avoid making painful decisions!

As so often, we can tell two stories about the change of views by politicians or anybody else.

The first story is of the feckless, unprincipled opportunist who changes her views following the prevailing winds – supported by the image of the weather vane. This person is contrasted with the stalwart who sticks to her principles even as all around her are swayed the moral fad of the day.

The second story is of the wise (often old) and sage person who can change her views even as all around her persist in their simplistic fundamentalism. Here we have the image of the tree that bends in the wind but does not break. This person is contrasted with the bigot or the zealot who cannot budge even an inch from old prejudices even though they are obviously wrong?

So which story is true of Romney, Bush and Obama? We don’t know. In every instance, we have to fine tune our image and very carefully watch out for our tendencies to just tell the negative stories about people we don’t like. Whether one story is more convincing than the other depends, like the needle of a compass, no a variety of obvious and non-obvious contexts. The stories are here to guide us and help us make decisions. But we must strive to keep them all in mind at the same time. And this can be painful. They are a little bit like the Necker Cube, Vase, the Duck/Rabbit or similar [optical illusions](http://en.wikipedia.org/wiki/Optical_illusions). We know they’re both there but while we’re perceiving the one, it is easy to forget the others are there. So it is uncomfortable. And also not a little bit inconvenient.

Is this kind of metaphorical nuance something we can expect in a time of political competition? It can be. Despite their bad rep, politicians and the media surrounding them can be nuanced. But often they’re not. So instead of nuance, when somebody next trots out the moral compass, whether you like them or not, say: “Oh, you mean you’re a liar, then?” and tell them about the Magnetic North!

**Post Script:** Actually, Plouffe didn’t say Romney didn’t have a moral compass. He said that you “you need to have a true compass, and you’ve got to be willing to make tough calls.” So maybe he was talking about a compass adjusted for surrounding metals and the advice of whose needle we follow only having taken into account as much of our current context as we can. A “true compass” like a true friend! I agree with most of the “old Romney” and none of the “new Romney”. And I loved the old Obama created in the image of our unspoken liberal utopias, and I am lukewarm on the actual Obama (as I actually knew I would) who steers a course pointing to the North of reality rather than the one magnetically attracting our needles. So if its that kind of moral compass after all, we’re in good hands!

### *Related*
```
./2012-07-22-character-assasination-through-metaphoric-pomposity-when-one-metaphor-is-not-enough.md
```
---
title: "Character Assasination through Metaphoric Pomposity: When one metaphor is not enough"
date: 2012-07-22
author: Dominik Lukeš
source: https://metaphorhacker.net/2012/07/character-assasination-through-metaphoric-pomposity-when-one-metaphor-is-not-enough
---

George Lakoff is known for saying that “metaphors can kill” and he’s not wrong. But in that, metaphors are no different from any other language. The simple amoral imperative “Kill!” will do the job just as nicely. Nor are metaphors any better or worse at obfuscating than any other type of language. But they are very good at their primary purpose which is making complex connections between domains.

Metaphors can create very powerful connections where none existed before. And we are just as often seduced by that power as inspired to new heights of creativity. We don’t really have a choice. Metaphoric thinking is in our DNA (itself a metaphor). But just like with DNA, context is important, and sometimes metaphors work for us and sometimes they work against us. The more powerful they are, the more cautious we need to be. When faced with powerful metaphors we should always look for alternatives and we should also explore the limits of the metaphors and the connections they make. We need to keep in mind that nothing IS anything else but everything is LIKE something else.

I was reminded of this recently when listening to an LSE lecture by the journalist Andrew Blum who was promoting his book [“Tubes: Behind the Scenes at the Internet”](http://www2.lse.ac.uk/publicEvents/events/2012/07/20120703t1830vHKT.aspx). The lecture was reasonably interesting although he tried to make the subject seem more important than it perhaps was through judicious reliance of the imagery of covertness.

But I was particularly struck by the last example where he compared Facebook’s and Google’s data centers in Colorado. Facebook’s center was open and architecturally modern, being part of the local community. Facebook also shared the designs of the center with the global community and was happy to show Blum around. Google’s center was closed, ugly and opaque. Google viewed its design as part of their competitive advantage and most importantly didn’t let Blum past the parking lot.

From this Blum drew far reaching conclusions which he amplified by implying them. If architecture is an indication of intent, he implied, then we should question what Google’s ugly hidden intent is as opposed to Facebook’s shining open intent. When answering a question he later gave prosecutors in New England and in Germany as compounding evidence of people who are also frustrated with Google’s secrecy. Only reluctantly admitting that Google invited him to speak at their Authors Speak program.

Now, Blum may have a point regarding the secrecy surrounding that data center by Google, there’s probably no great competitive advantage in its design and no abiding security reason in not showing its insides to a journalist. But using this comparison to imply anything about the nature of Facebook or Google is just an example of typical journalist dishonesty. Blum is not lying to us. He is lying to himself. I’m sure he convinced himself that since he was so clever to come up with such a beautiful analogy, it must be true.

The problem is that pretty much anything can be seen through multiple analogies. And any one of those analogies can be stopped at any point or be stretched out far and wide. A good metaphor hacker will always seek out an alternative analogy and explore the limits of the domain mapping of the dominant one. In this case, not much work is needed to uncover what a pompous idiot Blum is being.

First, does this facilities reflect attitudes extend to what we know about the two companies in other spheres. And here the answer is NO. Google tells let’s you liberate your data, Facebook does not. Google lets you opt out of many more things that Facebook. Google sponsors many open source projects, Facebook is more closed source (even though they do contribute heavily to some key projects). When Facebook acquires a company, they often just shut it down leaving customers high and dry, Google closes projects too, but they have repeatedly released source code of these projects to the community. Now, is Google the perfect open company? Hardly. But Facebook with its interest in keeping people in its silo is can never be given a shinign beacon of openness. It might be at best a draw (if we can even make a comparison) but I’d certainly give Google far more credit in the openness department. But the analogy simply fails when exposed to current knowledge. I can only assume that Blum was so happy to have come up with it that he wilfully ignored the evidence.

But can we come up with other analogies? Yes. How about the fact that the worst dictatorships in the world have come up with grand idealistic architectural designs in history. Designs and structures that spoke of freedom, beautiful futures and love of the people for their leaders. Given that we know all that, why would we ever trust a design to indicate anything about the body that commissioned it? Again, I can only assume that Blum was seduced by his own cleverness.

Any honest exploration of this metaphor would lead us to abandoning it. It was not wrong to raise it, in the world of cognition, anything is fair. But having looked at both the limits of the metaphor and alternative domain mappings, it’s pretty obvious that it’s not doing us any good. It supports a biased political agenda.

The moral of the story is don’t trust one-metaphor journalists (and most journalists are one-metaphor drones). They might have some of the facts right but they’re almost certainly leaving out large amounts of relevant information in pursuit of their own figurative hedonism.

**Disclaimer**: I have to admit, I’m rather a fan of Google’s approach to many things and a user of many of their services. However, I have also been critical of Google on many occasions and have come to be wary of many of their practices. I don’t mind Facebook the company, but I hate that it is becoming the new AOL. Nevertheless, I use many of Facebook’s services. So there.

### *Related*
```
./2012-08-09-pseudo-education-as-a-weapon-beyond-the-ridiculous-in-linguistic-prescriptivism.md
```
---
title: "Pseudo-education as a weapon: Beyond the ridiculous in linguistic prescriptivism"
date: 2012-08-09
author: Dominik Lukeš
source: https://metaphorhacker.net/2012/08/pseudo-education-as-a-weapon-beyond-the-ridiculous-in-linguistic-prescriptivism
---

[![Teacher in primary school in northern Laos](http://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Teacher_in_Laos.jpg/300px-Teacher_in_Laos.jpg "Teacher in primary school in northern Laos")](http://commons.wikipedia.org/wiki/File:Teacher_in_Laos.jpg)

Teacher in primary school in northern Laos (Photo credit: Wikipedia)

Most of us are all too happy to repeat clichés about education to motivate ourselves and others to engage in this liminal ritual of mass socialization. One such phrase is “knowledge is power”. It is used to refer not just to education, of course, but to all sorts of intelligence gathering from business to politics. We tell many stories of how knowing something made the difference, from knowing a way of making something to work to knowing a secret only the hero or villain is privy to. But in education, in particular, it is not just knowing that matters to our tribe but also the display of knowing.

The more I look at education, the more I wonder how much of what is in the curriculum is about signaling rather than true need of knowledge. Signaling has been used in economics of education to indicate the complex value of a university degree but I think it goes much deeper. We make displays of knowledge through the curriculum to make the knowledge itself more valuable. Curriculum designers in all areas engage in complex dances to show how the content maps onto the real world. I have called this [education voodoo](http://eduvoodoo.net), other people have spoken of cargo cult education, and yet others have talked about [pseudo teaching](http://fnoschese.wordpress.com/pseudoteaching/). I wrote about pseudo teaching when I looked at [Niall Ferguson](http://en.wikipedia.org/wiki/Niall_Ferguson "Niall Ferguson")‘s amusing, I think I called it cute, [lesson plan of his own greatness](http://metaphorhacker.techczech.net/2011/06/killer-app-is-a-bad-metaphor-for-historical-trends-good-for-pseudoteaching/ "Killer App is a bad metaphor for historical trends, good for pseudoteaching"). But pseudo teaching only describes the activities performed by teachers in the mistaken belief that they have real educational value. When pseudo teaching relies on pseudo content, I think we can talk more generally about “pseudo education”.

We were all pseudo-educated on a number of subjects. History, science, philosophy, etc. In history lessons, the most cherished “truths” of our past are distorted on a daily basis (see Lies My Teacher told me). From biology, we get to remember misinformation about the theory of evolution starting from attributing the very concept of evolution to Darwin or reducing natural selection to the nonsense of survival of the fittest. We may remember the names of a few philosophers but it rarely takes us any further than knowing winks at a Monty Python sketch or mouthing of unexamined platitudes like “the unexamined life is not worth living.”

That in itself is not a problem. Society, despite the omnipresent alarmist tropes, is coping quite well with pseudo-education. Perhaps, it even requires it to function because “it can’t handle the truth”. The problem is that we then judge people on how well they are able to replicate or respond to these pseudo-educated signals. Sometimes, these judgments are just a matter of petty prejudice but sometimes they could have an impact on somebody’s livelihood (and perhaps the former inevitably leads to the latter in aggregate).

Note: I have looked at some history and biology textbooks and they often offer a less distorted portrayal of their subject than what seems to be the outcome in public consciousness. Having the right curriculum and associated materials, then, doesn’t seem to be sufficient to avoid pseudo-education (if indeed avoiding it is desirable).

The one area where pseudo-education has received a lot of attention is language. Since time immemorial, our ways of speaking have served to identify us with one group or layer of society or another. And from its very beginning, education sought to play a role in slotting its charges into the linguistic groups with as high a prestige, as possible (or rather as appropriate). And even today, in academic literature we see references to the educated speaker as an analytic category. This is not a bad thing. Education correlates with exposure to certain types of language and engagement with certain kinds of speech communities. It is not the only way to achieve [linguistic competence](http://en.wikipedia.org/wiki/Linguistic_competence "Linguistic competence") in those areas but it is the main way for the majority. But becoming “educated speaker” in this sense is mostly a by-product of education. Sufficient amount of the curriculum and classroom instruction is aimed in this direction to count for something but most students acquire the in-group ways of speaking without explicit instruction (disadvantaging those who would benefit from it). But probably a more salient output of language education is supposed knowledge about language (as opposed to knowledge of language).

Here students are expected not only to speak appropriately but also to know how this “appropriate language” works. And here is where most of what happens in schools can be called pseudo-education. Most teachers don’t really have any grasp of how language works (even those who took intro to linguistics classes). They are certainly not aware of the more complex issues around the social variability of language or its pragmatic dimension. But even in simple matters like grammar and usage, they are utterly clueless. This is often blamed on past deficiencies of the educational system where “grammar was not taught” to an entire generation. But judging by the behavior of previous generations who received ample instruction in grammar, that is not the problem. Their teachers were just as inept at teaching about language as they are today. They might have been better at labeling parts of speech and their tenses but that’s about it. It is possible that in the days of yore, people complaining about the use of the passive were actually more able to identify passive constructions in the text but it didn’t make that complaint any less inaccurate (Orwell made a right fool of himself when it turned out that he uses more passives than is the norm in English despite kvetching about their evil).

No matter what the content of school curriculum and method of instruction, “educated” people go about spouting nonsense when it comes to language. This nonsense seems to have its origins in half-remembered injunctions of their grade school teacher. And because the prime complainers are likely to either have been “good at language” or envied the teacher’s approbation of those who were described as being “good at language”, what we end up with in the typical language maven is a mishmash of linguistic prejudice and unjustified feeling smug superiority. Every little linguistic label that a person can remember, is then trotted out as a badge of honor regardless of how good that person is at deploying it.

And those who spout the loudest, get a reputation of being the “grammar experts” and everybody else who preemptively admits that they are “not good at grammar” defers to them and lets themselves be bullied by them. The most recent case of such bullying was a screed by an otherwise intelligent person in a position of power who decided that he will no longer hire people with bad grammar.

This prompted me to issue [a rant on Google Plus](https://plus.google.com/110777908713167103295/posts/RfZjZw1FLyh), repeated below:

> The trouble with pseudo educated blowhards complaining about grammar, like [+Kyle Wien](http://lifehacker.com/5930680/i-wont-hire-people-who-use-poor-grammar-heres-why), is that they have no idea what grammar is. 90% of the things they complain about are spelling problems. The rest is a mishmash of half-remembered objections from their grade school teacher who got them from some other grammar bigot who doesn’t know their tense from their time.
>
> I’ve got news for you Kyle! People who spell they’re, there and their interchangeably know the grammar of their use. They just don’t differentiate their spelling. It’s called homophony, dude, and English is chock full of it. Look it up. If your desire rose as you smelled a rose, you encountered homophony. Homophony is a ubiquitous feature of all languages. And equally all languages have some high profile homophones that cause trouble for spelling Nazis but almost never for actual understanding. Why? Because when you speak, there is no spelling.
>
> Kyle thinks that what he calls “good grammar” is indicative of attention to detail. Hard to say since he, presumably always perfectly “grammatical”, failed to pay attention to the little detail of the difference between spelling and grammar. The other problem is, that I’m sure that Kyle and his ilk would be hard pressed to list more than a dozen or so of these “problems”. So his “attention to detail” should really be read as “attention to the few details of language use that annoy Kyle Wien”. He claims to have noticed a correlation in his practice but forgive me if I don’t take his word for it. Once you have developed a prejudice, no matter how outlandish, it is dead easy to find plenty of evidence in its support (not paying attention to any of the details that disconfirm it).
>
> Sure there’s something to the argument that spelling mistakes in a news item, a blog post or a business newsletter will have an impact on its credibility. But hardly enough to worry about. Not that many people will notice and those who do will have plenty of other cues to make a better informed judgment. If a misplaced apostrophe is enough to sway them, then either they’re not convinced of the credibility of the source in the first place, or they’re not worth keeping as a customer. Journalists and bloggers engage in so many more significant pursuits that damage their credibility, like fatuous and unresearched claims about grammar, so that the odd it’s/its slip up can hardly make much more than (or is it then) a dent.
>
> **Note:** I replaced ‘half-wit’ in the original with ‘blowhard’ because I don’t actually believe that Kyle Wien is a half-wit. He may not even be a blowhard. But, you can be a perfectly intelligent person, nice to kittens and beloved by co-workers, and be a blowhard when it comes to grammar. I also fixed a few typos, because I pay attention to detail.

My issue is not that I believe that linguistic purism and prescriptivism are in some way anomalous. In fact, I believe the exact opposite. I think, following a brilliant insight by my linguistics teacher, that we need to think of these phenomena as integral to our linguistic competence. I doubt that there is a linguistic community of any size above 3 that doesn’t enact some form of explicit linguistic normativity.

But when pseudo-knowledge about language is used as a n instrument of power, I think it is right to call out the perpetrators and try to shame them. Sure, linguists laugh at them, but I think we all need to follow the [example of the Language Log](http://languagelog.ldc.upenn.edu/nll/?cat=62) and expose all such examples to public ridicule. Countermand the power.

**Post Script:** I have been similarly critical of the field of [Critical Discourse Analysis](http://en.wikipedia.org/wiki/Critical_discourse_analysis) which while based on an accurate insight about language and power, in my view, goes on to abuse the power that stems from the knowledge about language to clobber their opponents. My conclusion has been that if you want to study how people speak, study it for its own sake, and if you want to engage with the politics of what they say, do that on political terms not on linguistic ones. That doesn’t mean that you shouldn’t point out if you feel somebody is using language in a manipulative or misleading ways, but if you don’t need the apparatus of a whole academic discipline to do it, you’re doing something wrong.

### *Related*
```
./2012-08-26-cliches-information-and-metaphors-overcoming-prejudice-with-metahor-hacking-and-getting-it-back-again.md
```
---
title: "Cliches, information and metaphors: Overcoming prejudice with metahor hacking and getting it back again"
date: 2012-08-26
author: Dominik Lukeš
source: https://metaphorhacker.net/2012/08/cliches-information-and-metaphors-overcoming-prejudice-with-metahor-hacking-and-getting-it-back-again
---

[![Professor Abhijit Banerjee](http://farm4.static.flickr.com/3198/2312975911_c4323e9436_m.jpg "Professor Abhijit Banerjee")](http://www.flickr.com/photos/95674706@N00/2312975911)

Professor Abhijit Banerjee (Photo credit: kalyan3)

“We have to use [cliches](http://en.wikipedia.org/wiki/Clich%C3%A9 "Cliché"),” said professor [Abhijit Banerjee](http://en.wikipedia.org/wiki/Abhijit_Banerjee "Abhijit Banerjee") at the start of his [LSE lecture on Poor Economics](http://www2.lse.ac.uk/publicEvents/events/2012/03/20120326t1830vSZT.aspx). “The world is just too complicated.” He continued. “Which is why it is all the more important, we choose the right cliches.” [I’m paraphrasing here.]

This is an insight at the very heart of linguistics. Every language act we are a part of is an act of categorization. There are no simple unitary terms in language. When I say, “pull up a chair”, I’m in fact referring to a vast category of objects we refer to as chairs. These objects are not identified by any one set of features like four legs, certain height, certain ways of using it. There is no minimal set of features that will describe all chairs and just chairs and not other kinds of objects like tables or pillows. But chairs don’t stand on their own. They are related to other concepts or categories (and they are really one and the same). There are subcategories like stools and armchairs, containing categories like furniture or man-made objects and related categories like houses and shops selling objects. All of these categories are linked in our minds through a complex set of images, stories and definitions. But these don’t just live in our minds. They also appear in our conversations. So we say things like, “What kind of a chair would you like to buy?”, “That’s not real chair”, “What’s the point of a chair if you can’t sit in it?”, “Stools are not chairs.”, “It’s more of a couch than a chair.”, “Sofas are really just big plush chairs, when it comes down to it.”, “I’m using a box for a chair.”, “Don’t sit on a table, it’s not a chair.” Etc. [Categories](http://en.wikipedia.org/wiki/Category_of_being "Category of being") are not stable and uniform across all people, so we continue having conversations about them. There are experts on chairs, historians of chairs, chair craftsmen, people who buy chairs for a living, people who study the word ‘chair’, and people who casually use chairs. Some more than others. And their sets of stories and images and definitions related to chairs will be slightly different. And they will have had different types of conversations with different people about chairs. All of that goes into a simple word like “chair”. It’s really very simple as long as we accept the complexity for what it is. Philosophers of language have made a right mess of things because they tried to find simplicity where none exists. And what’s more where none is necessary.

But let’s get back to cliches. Cliches are types of categories. Or better still, cliches are categories with a particular type of social salience. Like categories, cliches are sets of images, stories and definitions compressed into seemingly simpler concepts that are labelled by some sort of an expression. Most prominently, it is a linguistic expression like a word or a phrase. But it could just as easily be a way of talking, way of dressing, way of being. What makes us likely to call something a cliche is a socially negotiated sense of awareness that the compression is somewhat unsatisfactory and that it is overused by people in lieu of an insight into the phenomenon we are describing. But the power of the cliche is in its ability to help us make sense of a complex or challenging phenomenon. But the sense making is for our benefit of cognitive and emotional peace. Just because we can make sense of something, doesn’t mean, we get the right end of the stick. And we know that, which is why we are wary of cliches. But challenging every cliche would be like challenging ourselves every time we looked at a chair. It can’t be done. Which is why we have social and linguistic coping mechanisms like “I know it’s such a cliche.” “It’s a cliche but in a way it’s true.” “Just because it’s a cliche, doesn’t mean, it isn’t true.” Just try Googling: “it’s a cliche \*”

So we are at once locked into cliches and struggling to overcome them. Like “chair” the concept of a “cliche” as we use it is not simple. We use it to label words, phrases, people. We have stories about how to rebel against cliches. We have other labels for similar phenomena with different connotations such as “proverbs”, “sayings”, “prejudices”, “stereotypes”. We have whole disciplines studying these like cognitive psychology, social psychology, political science, anthropology, etc. And these give us a whole lot of cliches about cliches. But also a lot of knowledge about cliches.

The first one is exactly what this post started with. We have to use cliches. It’s who we are. But they are not inherently bad.

Next, we challenge cliches as much as we use them. (Well, probably not as much, but a lot.) This is something I’m trying to show through my research into frame negotiation. We look at concepts (the compressed and labelled nebulas of knowledge) and decompress them in different ways and repackage them and compress them into new concepts. (Sometimes this is called [conceptual integration](http://en.wikipedia.org/wiki/Conceptual_blending "Conceptual blending") or blending.) But we don’t just do this in our minds. We do it in public and during conversations about these concepts.

We also know that unwillingness to challenge a cliche can have bad outcomes. Cliches about certain things (like people or types of people) are called stereotypes and particular types of stereotypes are called prejudices. And prejudices by the right people against the right kind of other people can lead to discrimination and death. Prejudice, stereotype, cliche. They are the same kind of thing presented to us from different angles and at different magnitudes.

So it is worth our while to harness the cliche negotiation that goes on all the time anyway and see if we can use it for something good. That’s not a certain outcome. The medieaval inquistions, anti-heresies, racism, slavery, genocides are all outcomes of negotiations of concepts. We mostly only know about their outcomes but a closer look will always reveal dissent and a lot of soul searching. And at the heart of such soul searching is always a decompression and recompression of concepts (conceptual integration). But it does not work in a vacuum. Actual physical or economic power plays a role. Conformance to communcal expectations. Personal likes or dislikes. All of these play a role.

[![George Lakoff](http://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Lakoff%2C_George.jpg/300px-Lakoff%2C_George.jpg "George Lakoff")](http://commons.wikipedia.org/wiki/File:Lakoff%2C_George.jpg)

George Lakoff (Photo credit: Wikipedia)

So what chance have we of getting the right outcome? Do we even know what is the right outcome?

Well, we have to pick the right cliches says Abhijit Banerjee. Or we have to frame concepts better says [George Lakoff](http://en.wikipedia.org/wiki/George_Lakoff "George Lakoff"). “We have to shine the light of truth” says a cliche.

“If you give people content, they’re willing to move away from their prejudices. Prejudices are partly sustained by the fact that the political system does not deliver much content.” says Banerjee. Prejudices matter in high stakes contexts. And they are a the result of us not challenging the right cliches in the right ways at the right time.

It is pretty clear from research in social psychology from Milgram on, that giving people information will challenge their cliches but only as long as you also give them sanction to challenge the cliches. Information on its own, does not seem to always be enough. Sometimes the contrary information even seems to reinforce the cliche (as we’re learning from newspaper corrections).

This is important. You can’t fool all of the people all of the time. Even if you can fool a lot of them a lot of the time. Information is a part of it. Social sanction of using that information in certain ways is another part of it. And this is not the province of the “elites”. People with the education and sufficient amount of idle time to worry about such things. There’s ample research to show that everybody is capable of this and engaged in these types of conceptual activities. More education seems to vaguely correlate with less [prejudice](http://en.wikipedia.org/wiki/Prejudice "Prejudice") but it’s not clear why. I also doubt that it does in a very straightforward and inevitable way (a post for another day). It’s more than likely that we’ve only studied the prejudices the educated people don’t like and therefore don’t have as much.

Bannerjee draws the following conclusion from his work uncovering cliches in development economics:

> “Often we’re putting too much weight on a bunch of cliches. And if we actually look into what’s going on, it’s often much more mundane things. Things where people just start with the wrong presumption, design the wrong programme, they come in with their own ideology, they keep things going because there’s inertia, they don’t actually look at the facts and design programmes in ignorance. Bad things happen not because somebody wants bad things to happen but because we don’t do our homework. We don’t think hard enough. We’re not open minded enough.”

It sounds very appealing. But it’s also as if he forgot the point he started out with. We need cliches. And we need to remember that out of every challenge to a cliche arises a new cliche. We cannot go around the world with our concepts all decompressed and flapping about. We’d literally go crazy. So every challenge to a cliche (just like every paradigm-shifting Kuhnian revolution) is only the beginning phase of the formation of another cliche, stereotype, prejudice or paradigm (a process well described in Orwell’s Animal Farm which itself has in turn become a cliche of its own). [It’s fun listening to Freakonomics radio](http://metaphorhacker.techczech.net/2011/02/the-most-ridiculous-metaphor-of-education/) to see how all the cliche busting has come to establish a new orthodoxy. The constant reminders that if you see things as an economist, you see things other people don’t don’t see. Kind of a new witchcraft. That’s not to say that Freakonomics hasn’t provided insights to challenge established wisdoms (a term arising from another perspective on a cliche). It most certainly has. But it hasn’t replaced them with “a truth”, just another necessary compression of a conceptual and social complex. During the moments of decompression and recompression, we have opportunities for change, however brief. And sometimes it’s just a memory of those events that lets us change later. It took over 150 years for us to remember the French revolution and make of it what we now think of as democracy with a tradition stretching back to ancient Athens. Another cliche. The best of a bad lot of systems. A whopper of a cliche.

So we need to be careful. Information is essential when there is none. A lot of prejudice (like some racism) is born simply of not having enough information. But soon there’s plenty of information to go around. Too much, in fact, for any one individual to sort through. So we resort to complex cliches. And the cliches we choose have to do with our in-groups, chains of trust, etc. as much as they do with some sort of rational deliberation. So we’re back where we started.

Humanity is engaged in a neverending struggle of personal and public negotiation of concepts. We’re taking them apart and putting them back together. Parts of the process happen in fractions of a second in individual minds, parts of the process happen over days, weeks, months, years and decades in conversations, pronouncements, articles, books, polemics, laws, public debates and even at the polling booths. Sometimes it looks like nothing is happening and sometimes it looks like everything is happening at once. But it’s always there.

So what does this have to do with metaphors and can a metaphor hacker do anything about it? Well, metaphors are part of the process. The same process that lets us make sense of metaphors, lets use negotiated cliches. Cliches are like little analogies and it takes a lot of cognition to understand them, take them apart and make them anew. I suspect most of that cognition (and it’s always discursive, social cognition) is very much the same that we know relatively well from metaphor studies.

But can we do anything about it? Can we hack into these processes? Yes and no. People have always hacked collective processes by inserting images and stories and definitions into the public debate through advertising, following talking points or even things like pushpolling. And people have manipulated individuals through social pressure, persuasion and lies. But none of it ever seems to have a lasting effect. There’re simply too many conceptual purchase points to lean on in any cliches to ever achieve a complete uniformity for ever (even in the most totalitarian regimes). In an election, you may only need to sway the outcome by a few percent. If you have military or some other power, you only need to get willing compliance from a sufficient number of people to keep the rest in line through a mix of conceptual and non-conceptual means. Some such social contracts last for centuries, others for decades and some for barely years or months. In such cases, even knowing how these processes work is not much better than knowing how continental drift works. You can use it to your advantage but you can’t really change it. You can and should engage in the process and try to nudge the conversation in a certain way. But there is no conceptual template for success.

But as individuals, we can certainly do quite a bit monitor our own cognition (in the broadest sense). But we need to choose our battles carefully. Use cliches but monitor what they are doing for us. And challenge the right ones at the right time. It requires a certain amount of disciplined attention and disciplined conversation.

This is not a pessimistic message, though. As I’ve said elsewhere, [we can be masters of our own thoughts and feelings.](http://metaphorhacker.techczech.net/2011/03/are-we-the-masters-of-our-morality-yes/) And we have the power to change how we see the world and we can help others along with how they see the world. But it would be [foolish to expect to world to be changed beyond all recognition just through the power of the mind](http://metaphorhacker.techczech.net/2010/07/why-ideas-arent-enough-to-solve-the-palestine-israeli-conflict/). In one way or another, it will always look like our world. But we need to keep trying to make it look like the best possible version of our world. But this will not happen by following some pre-set epistemological route. Doing this is our human commitment. Our human duty. And perhaps our human inevitability. So, good luck to us.

### *Related*
```
./2012-09-28-the-complexities-of-simple-what-simple-language-proponents-should-know-about-linguistics-updated.md
```
---
title: "The complexities of simple: What simple language proponents should know about linguistics [updated]"
date: 2012-09-28
author: Dominik Lukeš
source: https://metaphorhacker.net/2012/09/the-complexities-of-simple-what-simple-language-proponents-should-know-about-linguistics
---

Update
------

Part of this post was incorporated into an article I wrote with Brian Kelly and Alistair McNaught that appeared in [the December issue of Ariadne](http://www.ariadne.ac.uk/issue70/kelly-et-al). As part of that work and feedback from Alistair and Brian, I expanded the final section from a simple list of bullets into a more detailed research programme. You can see it below and in the article.

Background: From spelling reform to plain language
--------------------------------------------------

[![Simple](http://farm5.static.flickr.com/4149/4843655940_a8479f5c4d_m.jpg "Simple")](http://www.flickr.com/photos/12836528@N00/4843655940)

Simple (Photo credit: kevin dooley)

The idea that if we could only improve how we communicate, there would be less misunderstanding among people is as old as the hills.

Historically, this notion has been expressed through things like school reform, spelling reform, publication of communication manuals, etc.

The most radical expression of the desire for better understanding is the invention of a whole new [artificial language](http://en.wikipedia.org/wiki/Constructed_language "Constructed language") like Esperanto with the intention of providing a universal language for humanity. This has had a long tradition but seemed to gain most traction towards the end of last century with the introduction and relative success of Esperanto.

But artificial languages have been a failure as a vehicle of global understanding. Instead, in about the last 50 years, the movement for [plain English](http://en.wikipedia.org/wiki/Plain_English "Plain English") has been taking the place of constructed languages as something on which people pinned their hopes for clear communication.

Most recently, there have been proposals suggesting that “simple” language should become a part of a standard for accessibility of web pages along side other accessibility standards issued by the W3C standards body. http://www.w3.org/WAI/RD/2012/easy-to-read/Overview. This post was triggred by this latest development.

Problem 1: Plain language vs. linguistics
-----------------------------------------

The problem is that most proponents of plain language (as so many would be reformers of human communication) seem to be ignorant of the wider context in which language functions. There is much that has been revealed by linguistic research in the last century or so and in particular since the 1960s that we need to pay attention to (to avoid confusion, this [does not refer to the work of Noam Chomsky](http://metaphorhacker.techczech.net/2010/08/why-chomsky-doesnt-count-as-a-gifted-linguist/) and his followers but rather to the work of people like [William Labov](http://en.wikipedia.org/wiki/William_Labov "William Labov"), [Michael Halliday](http://en.wikipedia.org/wiki/Michael_Halliday "Michael Halliday"), and many others).

Languages are not a simple matter of grammar. Any proposal for content accessibility must consider what is known about language from the fields of pragmatics, sociolinguistics, and cognitive linguistics. These are the key aspects of what we know about language collected from across many fields of linguistic inquiry:

* Every sentence communicates much more than just its basic content (propositional meaning). We also communicate our desires and beliefs (e.g. “It’s cold here” may communicate, “Close the window” and “John denied that he cheats on his taxes” communicates that somebody accused John of cheating on his taxes. Similarly chosing a particular form of speech, like slang or jargon, communicates belonging to a community of practice.)
* The understanding of any utterance is always dependent on a complex network of knowledge about language, about the world, as well as about the context of the utterance. “China denied involvement.” requires the understanding of the context in which countries operate, as well as metonomy, as well as the grammar and vocabulary. Consider the knowledge we need to possess to interpret “In 1939, the world exploded.” vs. “In Star Wars, a world exploded.”
* There is no such thing as purely literal language. All language is to some degree figurative. “Between 3 and 4pm.”, “Out of sight”, “In deep trouble”, “An argument flared up”, “Deliver a service”, “You are my rock”, “Access for all” are all figurative to different degrees.
* We all speak more than one variety of our language: formal/informal, school/friends/family, written/spoken, etc. Each of these variety has its own code. For instance, “she wanted to learn” vs. “her desire to learn” demonstrates a common difference between spoken and [written English](http://en.wikipedia.org/wiki/Standard_written_English "Standard written English") where written English often uses clauses built around nouns.
* We constantly switch between different codes (sometimes even within a single utterance).
* Bilingualism is the norm in language knowledge, not the exception. About half the world’s population regularly speaks more than one language but everybody is “bi-lingual” in the sense that they deal with multiple codes.
* The “standard” or “correct” English is just one of the many dialects, not English itself.
* The difference between a language and a dialect is just as much political as linguistic. An old joke in linguistics goes: “[A language is a dialect with an army and a navy](http://en.wikipedia.org/wiki/A_language_is_a_dialect_with_an_army_and_navy "A language is a dialect with an army and navy").”
* Language prescription and requirements of [language purity](http://en.wikipedia.org/wiki/Linguistic_purism "Linguistic purism") (incl. simple language) are as much political statements as linguistic or cognitive ones. All language use is related to power relationships.
* [Simplified languages](http://en.wikipedia.org/wiki/Controlled_natural_language "Controlled natural language") develop their own complexities if used by a real community through a process known as creolization. (This process is well described for pidgins but not as well for artificial languages.)
* All languages are full of redundancy, polysemy and homonymy. It is the context and our knowledge of what is to be expected that makes it easy to figure out the right meaning.
* There is no straightforward relationship between grammatical features and language obfuscation and lack of clarity (e.g. It is just as easy to hide things using active as passive voice or any Subject-Verb-Object sentence as Object-Subject-Vern).
* It is difficult to call any one feature of a language universally simple (for instance, [SVO word order](http://en.wikipedia.org/wiki/Subject%E2%80%93verb%E2%80%93object "Subject–verb–object") or no morphology) because many other languages use what we call complex as the default without any increase in difficulty for the native speakers (e.g. use of verb prefixes/particles in English and German)
* Language is not really organized into sentences but into texts. Texts have internal organization to hang together formally (John likes coffee. *He* likes *it* a lot.) and semantically (As I said about John. He likes coffee.) Texts also relate to external contexts (cross reference) and their situations. This relationship is both implicit and explicit in the text. The shorter the text, the more context it needs for interpretation. For instance, if all we see is “He likes it.” written on a piece of paper, we do not have enough context to interpret the meaning.
* Language is not used uniformly. Some parts of language are used more frequently than others. But this is not enough to understand frequency. Some parts of language are used more frequently together than others. The frequent coocurrence of some words with other words is called “collocation”. This means that when we say “bread and …”, we can predict that the next word will be “butter”. You can check this with a linguistic tool like a corpus, or even by using Google’s predictions in the search. Some words are so strongly collocated with other words that their meaning is “tinged” by those other words (this is called semantic prosody). For example, “set in” has a negative connotation because of its collocation with “rot”.
* All language is idiomatic to some degree. You cannot determine the meaning of all sentences just by understanding the meanings of all their component parts and the rules for putting them together. And vice versa, you cannot just take all the words and rules in a language, apply them and get meaningful sentences. Consider “I will not put the picture up with John.” and “I will not put up the picture with John.” and “I will not put up John.” and “I will not put up with John.”

It seems to me that most plain language advocates do not take most of these factors into account.

Some examples from the “How to write in plain English” guide: http://www.plainenglish.co.uk/files/howto.pdf.

> Try to call the reader ‘you’, even if the reader is only one of many people you are talking about generally. If this feels wrong at first, remember that you wouldn’t use words like ‘the applicant’ and ‘the supplier’ **if you were speaking to somebody sitting across a desk from you.** [emphasis mine]

This example misses the point about the contextuality of language. The part in bold is the very crux of the problem. It is natural to use a different code (or register) with someone we’re speaking to in person and in a written communication. This is partly a result of convention and partly the result of the different demands of writing and speaking when it comes to the ability to point to what we’re speaking about. The reason it feels wrong to the writer is that it breaks the convention of writing. That is not to say that this couldn’t become the new convention. But the argument misses the point.

> Do you want your letters to **sound active or passive** − crisp and professional or stuffy and bureaucratic?  
> Using the passive voice and sounding passive are not one and the same thing. This is an example of polysemy. The word “passive” has two meanings in English. One technical (the passive voice) and one colloquial (“he’s too passive”). The booklet recommends that “The mine had to be closed by the authority. (Passive)” should be replaced with “The authority had to close the mine. (Active)” But they ignore the fact that word order also contributes to the information structure of the sentence. The passive sentence introduces the “mine” sooner and thus makes it clear that the sentence is about the mine and not the local authority. In this case, the “active” construction made the point of the sentence more difficult to understand.

The same is true of nominalization. Another thing recommended against by the Plain English campaign: “The implementation of the method has been done by a team.” is not conveying the same type of information as “A team has implemented the method.”

The point is that this advice ignores the context as well as the audience. Using “you” instead of “customers” in “Customers have the right to appeal” may or may not be simpler depending on the reader. For somebody used to the conventions of written official English, it may actually take longer to process. But for someone who does not deal with written English very often, it will be easier. But there is nothing intrinsically easier about it.

Likewise for the use of jargon. The campaign gives as its first example of unduly complicated English:

> High-quality learning environments are a necessary precondition for facilitation and enhancement of the ongoing learning process.

And suggests that we use this instead:

> Children need good schools if they are to learn properly.

This may be appropriate when it comes to public debate but within the professional context of, say, policy communication, these 2 sentences are not actually equivalent. There are more “learning environments” than just schools and the “learning process” is not the same as having learned something. It is also possible that the former sentence appeared as part of a larger context that would have made the distinction even clearer but the page does not give a reference and a Google search only shows pages using it as an example of complex English. http://www.plainenglish.co.uk/examples.html

The *How to write in plain English* document does not mention coherence of the text at all, except indirectly when it recommends the use of lists. This is good advice but even one of their examples has issues. They suggest that the following is a good example of a list:

> Kevin needed to take:  
> • a penknife  
> • some string  
> • a pad of paper; and  
> • a pen.

And on first glance it is, but lists are not just neutral replacements for sentences. They are a genre in its own right used for specific purposes (Michael Hoey called them “text colonies”.) Let’s compare the list above to the sentence below.

> Kevin needed to take a penknife, some string, a pad of paper and a pen.

Obviously they are two different kinds of text used in different contexts for different purposes and this would impinge on our understanding. The list implies instruction, and a level of importance. It is suitable to an official document, for example something sent before a child goes to camp. But it is not suitable to a personal letter or even a letter from the camp saying “All Kevin needed to take was a penknife, some string, a pad of paper and a pen. He should not have brought a laptop.” To be fair, the guide says to use lists “where appropriate”, but does not mention what that means.

The issue is further muddled by the “grammar quiz” on the Plain English website: http://www.plainenglish.co.uk/quiz.html. It is a hodgepodge of irrelevant trivia about language (not just grammar) that has nothing to do with simple writing. Although the Plain English guide gets credit for explicitly not endorsing petty peeves like not ending a sentence with a preposition, they obviously have peeves of their own.

Problem 2: Definition of simple is not simple
---------------------------------------------

There is no clear definition of what constitutes simple and easy to understand language.

There are a number of intuitions and assumptions that seem to be made when both experts and lay people talk about language:

* Shorter is simpler (fewer syllables, charactes, sounds per word, fewer words per sentence, fewer sentences per paragraph)
* More direct is simpler (X did Y to Z is simpler than Y was done to Z by X)
* Less variety is simpler (fewer different words)
* More familiar simpler

These assumptions were used to create various measures of “readability” going back to the 1940s. They consisted of several variables:

* Length of words (in syllables or in characters)
* Length of sentences
* Frequency of words used (both internally and with respect to their general frequency)

Intuitively, these are not bad measures, but they are only proxies for the assumptions. They say nothing about the context in which the text appears or the appropriateness of the choice of subject matter. They say nothing about the internal cohesion and coherence of the text. In short, they say nothing about the “quality” of the text.

The same thing is not always simple in all contexts and sometimes too simple, can be hard. We could see that in the example of lists above. Having a list instead of a sentence does not always make things simpler because a list is doing other work besides just providing a list of items.

Another example I always think about is the idea of “semantic primes” by Anna Wierzbicka. These are concepts like DO, BECAUSE, BAD believed to be universal to all languages. There are only about 60 of them (the exact number keeps changing as the research evolves). These were compiled into a Natural Semantic Metalanguage with the idea of being able to break complex concepts into them. Whether you think this is a good idea or not (I don’t but I think the research group working on this are doing good work in surveying the world’s languages) you will have to agree that the resulting descriptions are not simple. For example, this is the Natural Semantic Metalanguage description of “anger”:

> anger (English): when X thinks of Y, X thinks something like this: “this person did something bad; I don’t want this; I would want to do something bad to this person”; because of this, X feels something bad

This seems like a fairly complicated way of describing anger and even if it could be universally understood, it would also be very difficult to learn to do this. And could we then capture the distinction between this and say “seething rage”? Also, it is clear that there is a lot more going on than combining 60 basic concepts. You’d have to learn a lot of rules and strategies before you could do this well.

Problem 3: Automatic measures of readability are easily gamed
-------------------------------------------------------------

There are about half dozen automated readability measures currently used by software and web services to calculate how easy or difficult it is to read a text.

I am not an expert in readability but I have no reason to doubt the references in Wikipedia claiming that they correlate fairly well overall with text comprehension. But as always correlation only tells half the story and, as we know, it is not causation.

It is not at all clear that the texts identified as simple based on measures like number of words per sentence or numbers of letters per word are actually simple because of the measures. It is entirely possible that those measures are a consequence of other factors that contribute to simplicity, like more careful word choice, empathy with an audience, etc.

This may not matter if all we are interested in is identifying simple texts, as you can do with an advanced Google search. But it does matter if we want to use these measures to teach people how to write simpler texts. Because if we just tell them use fewer words per sentence and shorter words, we may not get texts that are actually easier to understand for the intended readership.

And if we require this as a criterion of page accessibility, we open the system to gaming in the same way Google’s algorithms are gamed but without any of the sophistication. You can reduce the complexity of any text on any of these scores simply by replacing all commas with full stops. Or even with randomly inserting full stops every 5 words and putting spaces in the middle of words. The algorithms are not smart enough to capture that.

Also, while these measures may be fairly reliable in aggregate, they don’t give us a very good picture of any one individual text. I took a blog post from the Campaign for Plain English site http://www.plainenglish.co.uk/news/chrissies-comments.html and ran the text through several websites that calculate ease of reading scores:

* http://www.online-utility.org/english/readability\_test\_and\_improve.jsp,
* http://www.editcentral.com
* http://www.read-able.com

The different tests ranged by up to 5 years in their estimate of the length of formal education required to understand the text from 10.43 to 15.57. Read-able.com even went as far as providing an average, coming up with 12. Well that doesn’t seem very reliable.

I preferred http://textalyser.net which just gives you the facts about the text and doesn’t try to summarize them. The same goes for the Plain English own little app that you can download from their website http://www.plainenglish.co.uk/drivel-defence.html.

By any of these measures, the text wasn’t very simple or plain at all. The longest sentence had 66 words because it contained a complex embedded clause (something not even mentioned in the Plain English guide). The average sentence length was 28 words.

The Plain English app also suggested 7 alternative words from their “alternative dictionary” but 5 of those were misses because context is not considered (e.g. “a sad state” cannot be replaced by “a sad say”). The 2 acceptable suggestions were to edit out one “really” and replace one “retain” with “keep”. Neither of which would have improved the readability of the text given its overall complexity.

In short, the accepted measures of simple texts are not very useful for creating simple texts of training people in creating them.

See also http://en.wikipedia.org/w/index.php?title=Readability&oldid=508236326#Using\_the\_readability\_formulas.

See also this interesting study examining the effects for L2 instruction: http://www.eric.ed.gov/PDFS/EJ926371.pdf.

Problem 4: When simple becomes a new dialect: A thought experiment
------------------------------------------------------------------

But let’s consider what would happen if we did agree on simple English as the universal standard for accessibility and did actually manage to convince people to use it? In short, it would become its own dialect. It would acquire ways of describing things it was not designed to describe. It would acquire its own jargon and ways of obfuscation. There would arise a small industry of experts teaching you how to say what you want to say or don’t want to say in this new simple language.

Let’s take a look at [Globish](http://www.globish.com), a simplified English intended for international communication, that I have seen suggested as worth a look for accessibility. Globish has a restricted grammar and a vocabulary of 1500 words. They helpfully provide a tool for highlighting words they call “not compatible with Globish”. Among the words it highlighted for the blog post from the Plain English website were:

> basics, journalist, grandmother, grammar, management, principle, moment, typical

But event the transcript of a speech by its creator, Jean-Paul Nerriere, advertised as being completely in Globish, contained some words flagged up as incompatible:

> businessman, would, cannot, maybe, nobody, multinational, software, immediately

Globish seems to based on not much more than gueswork. It has words like “colony” and “rubber” but not words like “temperature” or “notebook”, “appoint” but not “appointment”, “govern” but not “government”. But both the derived forms “appointment” or “government” are more frequent (and intuitively more useful) than the root forms. There is a chapter in the eBook called “1500 Basic Globish Words Father 5000” so I assume there are some rules for derivation, but the derived forms more often than not have very “idiomatic” meanings. For example, “appointment” in its most commons use does not make any sense if we look at the core meanings of “appoint” and the suffix “-ment”. Consider also the difference between “govern” and “government” vs “enjoy” and “enjoyment”.

Yet, Globish supposedly avoids idioms, cultural references, etc. Namely all the things that make language useful. The founder says:

> Globish is correct English without the English culture. It is English that is just a tool and not a whole way of life.

Leaving aside the dubious notion of correctness, this would make Globish a very limited tool indeed. But luckily for Globish it’s not true. Why have the word “colony” if not to reflect cultural preference? If it became widely used by a community of speakers, the first thing to happen to Globish would be a blossoming of idioms going hand in hand with the emergence of dialects, jargons and registers.

That is not to say that something like Globish could not be a useful tool for English learners along the way to greater mastery. But it does little for universal accessibility.

Also we need to ask ourselves what would it be like from the perspective of the users creating these simplified texts? They would essentially have to learn a whole new code, a sort of a dialect. And as with any second language learning, some would do it better than others. Some would become the “simple nazis”. Some would get jobs teaching others “how to” speak simple. It is not natural for us to speak simply and “plainly” as defined in the context of accessibility.

There is some experience with the use of controlled languages in technical writing and in writing for second language acquisition. This can be done but the universe of subjects and/or the group of people creating these texts is always extremely limited. Increasing the number of people creating simple texts to pretty much everybody would increase the difficulty of implementation exponentially. And given the poor state of automatic tools for analysis of “simplicity”, quality control is pretty much out of reach.

But would even one code/dialect suffice? Do we need one for technical writing, govenment documents, company filings? Limiting the vocabulary to 1500 words is not a bad idea but as we saw with Globish, it might need to be different 1500 words for each area.

Why is language inaccessible?
-----------------------------

Does that mean we should give up on trying to make communication more accessible? Definitely not. The same processes that I described as standing in the way of a universal simple language are also at the root of why so much language is inaccessible. Part of how language works to create group cohesion which includes keeping some people out. A lot of “complicated” language is complicated because the nature of the subject requires it, and a lot of complicated language is complicated because the writer is not very good at expressing themselves.

But as much complicated language is complicated because the writer wants to signall belonging to a group that uses that kind of language. The famous Sokal Hoax provided an example of that. Even instructions on university websites on how to write essays are an example. You will find university websites recommending something like “To write like an academic, write in the third person.” This is nonsense, research shows that academics write as much in the first as in the third person. But it also makes the job of the people marking essays easier. They don’t have to focus on ideas, they just go by superficial impression. Personally, I think this is a scandal and complete failure of higher education to live up to its own hype but that’s a story for another time.

How to achieve simple communication?
------------------------------------

So what can we do to avoid making our texts too inaccessible?

The first thing that the accessibility community will need to do is acknowledge Simple language is its own form of expression. It is not the natural state we get when we strip out all the artifice out of our communication. And learning how to communicate simply requires effort and practice of all individuals.

To help with the effort, most people will need some guides. And despite what I said about the shortcomings of the Plain English Guide above, it’s not a bad place to start. But it would need to be expanded. Here’s an example of some of the things that are missing:

* Consider the audience: What sounds right in an investor brochure won’t sound right in a letter to a customer
* Increase cohesion and coherence by highlighting relationships
* Highlight the text structure with headings
* Say new things first
* Consider splitting out subordinate clauses into separate sentences if your sentence gets too long
* Leave all the background and things you normally start your texts with for the end

But it will also require a changed direction for research.

Further research needs for simple language language
---------------------------------------------------

I don’t pretend to have a complete overview of the research being done in this area but my superficial impression is that it focuses far too much on comprehension at the level of clause and sentence. Further research will be necessary to understand comprehension at the level of text.

There is need for further research in:

* How collocability influences understanding
* Specific ways in which cohesion and coherence impact understanding
* The benefits and downsides of elegant variation for comprehension
* The benefits and downsides of figurative language for comprehension by people with different cognitive profiles
* The processes of code switching during writing and reading
* How new conventions emerge in the use of simple language
* The uses of simple language for political purposes including obfuscation

[[Updated for Ariadne article mentioned above](http://www.ariadne.ac.uk/issue70/kelly-et-al):] In more detail, this is what I would like to see for some of these points.

**How collocability influences understanding:** How word and phrase frequency influences understanding with particular focus on collocations. The assumption behind software like TextHelp is that this is very important. Much research is available on the importance of these patterns from corpus linguistics but we need to know the practical implications of these properties of language both for text creators and consumers. For instance, should text creators use measures of collocability to judge the ease of reading and comprehension in addition to or instead of arbitrary measures like sentence and word lengths.

**Specific ways in which cohesion and coherence affect understanding:** We need to find the strategies challenged readers use to make sense of larger chunks of text. How they understand the text as a whole, how they find specific information in the text, how they link individual portions of the text to the whole, and how they infer overall meaning from the significance of the components. We then need to see what text creators can do to assist with these processes. We already have some intuitive tools: bullets, highlighting of important passages, text insets, text structure, etc. But we do not know how they help people with different difficulties and whether they can ever become a hindrance rather than a benefit.

**The benefits and downsides of elegant variation for comprehension, enjoyment and memorability:** We know that repetition is an important tool for establishing the cohesion of text in English. We also know that repetition is discouraged for stylistic reasons. Repetition is also known to be a feature of immature narratives (children under the age of about 10) and more “sophisticated” ways of constructing texts develop later. However, it is also more powerful in spoken narrative (e.g. folk stories). Research is needed on how challenged readers process repetition and elegant variation and what text creators can do to support any naturally developing meta textual strategies.

**The benefits and downsides of figurative language for comprehension by people with different cognitive profiles:** There is basic research available from which we know that some cognitive deficits lead to reduced understanding of non-literal language. There is also ample research showing how crucial figurative language is to language in general. However, there seems to be little understanding of how and why different deficits lead to problems with processing figurative language, what kind of figurative language causes difficulties. It is also not clear what types of figurative language are particularly helpful for challenged readers with different cognitive profiles. Work is needed on typology of figurative language and a typology of figurative language deficits.

**The processes of code switching during writing and reading:** Written and spoken English employ very different codes, in some ways even reminiscent of different language types. This includes much more than just the choice of words. Sentence structure, clauses, grammatical constructions, all of these differ. However, this difference is not just a consequence of the medium of writing. Different genres (styles) within a language may be just as different from one another as writing and speaking. Each of these come with a special code (or subset of grammar and vocabulary). Few native speakers never completely acquire the full range of codes available in a language with extensive literacy practices, particularly a language that spans as many speech communities as English. But all speakers acquire several different codes and can switch between them. However, many challenged writers and readers struggle because they cannot switch between the spoken codes they are exposed to through daily interactions and the written codes to which they are often denied access because of a print impairment. Another way of describing this is multiple literacies. How do challenged readers and writers deal with acquiring written codes and how do they deal with code switching?

**How do new conventions emerge in the use of simple language?** Using and accessing simple language can only be successful if it becomes a separate literacy practice. However, the dissemination and embedding of such practices into daily usage are often accompanied by the establishment of new codes and conventions of communication. These codes can then become typical of a genre of documents. An example of this is Biblish. A sentence such as “Fred spoke unto Joan and Karen” is easily identified as referring to a mode of expression associated with the translation of the Bible. Will similar conventions develop around “plain English” and how? At the same time, it is clear that within each genre or code, there are speakers and writers who can express themselves more clearly than others. Research is needed to establish if there are common characteristics to be found in these “clear” texts, as opposed to those inherent in “difficult” texts across genres?

All in all, introducing simple language as a universal accessibility standard is still too far from a realistic prospect. My intuitive impression based on documents I receive from different bureaucracies is that the “plain English” campaign has made a difference in how many official documents are presented. But a lot more research (ethnographic as well as cognitive) is necessary before we properly understand the process and its impact. Can’t wait to read it all.

### *Related*
```
./2013-01-26-framing-and-constructions-as-a-bridge-between-cognition-and-culture-two-abstracts-for-cognitive-futures.md
```
---
title: "Framing and constructions as a bridge between cognition and culture: Two Abstracts for Cognitive Futures"
date: 2013-01-26
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/01/framing-constructions-as-a-bridge-between-cognition-and-culture-two-abstracts-for-cognitive-futures
---

I just found out that both abstracts I submitted to the Cognitive Futures of the Humanities Conference were accepted. I was really only expecting one to get through but I’m looking forward to talking about the ideas in both.

The first first talk has foundations in a paper I wrote almost 5 years ago now about the nature of evidence for discourse. But the idea is pretty much central to all my thinking on the subject of culture and cognition. The challenge as I see it is to come up with a cognitively realistic but not a cognitively reductionist account of culture. And the problem I see is that often the learning only goes one way. The people studying culture are supposed to be learning about the results of research on cognition.

Frames, scripts, scenarios, models, spaces and other animals: Bridging conceptual divides between the cognitive, social and computational
-----------------------------------------------------------------------------------------------------------------------------------------

While the cognitive turn has a definite potential to revolutionize the humanities and social sciences, it will not be successful if it tries to reduce the fields investigated by the humanities to merely cognitive or by extension neural concepts. Its greatest potential is in showing continuities between the mind and its expression through social artefacts including social structures, art, conversation, etc. The social sciences and humanities have not waited on the sidelines and have developed a conceptual framework to apprehend the complex phenomena that underlie social interactions. This paper will argue that in order to have a meaningful impact, cognitive sciences, including linguistics, will have to find points of conceptual integration with the humanities rather than simply provide a new descriptive apparatus.

It is the contention of this paper that this can be best done through the concept of frame. It seems that most disciplines dealing with the human mind have (more or less independently) developed a similar notion dealing with the complexities of conceptualization variously referred to as frame, script, cognitive model or one of the as many as 14 terms that can be found across the many disciplines that use it.  This paper will present the different terms and identify commonalities and differences between them. On this, it will propose several practical ways in which cognitive sciences can influence humanities and also derive meaningful benefit from this relationship. I will draw on examples from historical policy analysis, literary criticism and educational discourse.

See the [presentation on Slideshare](http://www.slideshare.net/bohemicus/frames-and-other-animals).

The second paper is a bit more conceptually adventurous and testing the ideas put forth in the first one. I’m going to try to explore a metaphor for the merging of cultural studies with linguistic studies. This was done before with structuralism and ended more or less badly. For me, it ended when I read the Lynx by Lévi-Strauss and realized how empty it was of any real meaning. But I think structuralism ended badly in linguistics, as well. We can’t really understand how very basic things work in language unless we can involve culture. So even though, I come at this from the side of linguistics, I’m coming at it from the perspective of linguistics that has already been informed by the study of culture.

### If Lévi-Strauss had met Langacker: Towards a constructional approach to the patterns of culture

Construction/cognitive grammar (Langacker, Lakoff, Croft, Verhagen, Goldberg) has broken the strict separation between the lexical and grammatical linguistic units that has defined linguistics for most of the last century. By treating all linguistic units as meaningful, albeit on a scale of schematicity, it has made it possible to treat linguistic knowledge as simply a part of human knowledge rather than as a separate module in the cognitive system. Central to this effort is the notion of language of as an organised inventory of symbolic units that interact through the process of conceptual integration.

This paper will propose a new view of ‘culture’ as an inventory of construction-like patterns that have linguistic, as well, as interactional content. I will argue that using construction grammar as an analogy allows for the requisite richness and can avoid the pitfalls of structuralism. One of the most fundamental contributions of this approach is the understanding that cultural patterns, like constructions, are pairings of meaning and form and that they are organised in a hierarchically structured inventory. For instance, we cannot properly understand the various expressions of politeness without thinking of them as systematically linked units in an inventory available to members of a given culture in the same as syntactic and morphological relationships. As such, we can understand culture as learnable and transmittable in the same way that language is but without reducing its variability and richness as structuralist anthropology once did.

In the same way that Jakobson’s work on structuralism across the spectrum of linguistic diversity inspired Lévi-Strauss and a whole generation of anthropological theorists, it is now time to bring the exciting advances made within cognitive/construction grammar enriched with blending theory back to the study of culture.

See the [presentation on SlideShare](http://www.slideshare.net/bohemicus/constructional-foundations-of-cultural-patterns).

### *Related*
```
./2013-04-03-do-we-need-a-gaming-literacy-literacy-metaphor-hack.md
```
---
title: "Do we need a gaming literacy: Literacy metaphor hack"
date: 2013-04-03
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/04/do-we-need-a-gaming-literacy-literacy-metaphor-hack
---

I am a gaming semi-literate!
----------------------------

I was listening to the discussion of the latest BioShock game on [the latest TWiT podcast](http://twit.tv/show/this-week-in-tech/399) when I realized that I am in fact game illiterate. I am hearing these stories and descriptions of experiences but I know I can’t access them directly without a major investment in knowledge and skill acquisition. So, this is what people with no or limited literacy must feel like in highly literacy-dependent environments. I really want to access the stories in the way they are told by the game. But I know I can’t. I will stumble, be discouraged, not have a very good time before I can have a good time. I will be a struggling gamer, in the same way that there are struggling readers.

**Note:** When I say game, I mean mostly a non-casual computer game such as BioShock or War of Worldcraft or SimCity.

What would a game literacy entail?
----------------------------------

What would I need to learn in order to access gaming? Literacy is composed of a multiplicity of knowledge areas and skills. I already have some of these but not enough. Roughly, I will need to get at the following:

* *Underlying cognitive skills* (**For reading:** transforming the sight of letters into sounds or corresponding mental representations. **For gaming:** transforming desired effects on screen into actions on a controller)
* *Complex perceptual and productive fluency* (Ability to employ the cognitive skills automatically in response to changing stimuli in multiple contexts).
* *Context-based or task-based strategies* (Ability to direct the underlying skills towards solving particular problems in particular contexts. **For reading:** Skim text, or look things up in the index, or skip acknowledgements, discover the type of text, or adopt reading speed appropriate to type of text, etc. **For gaming** Discover the type of game, or gather appropriate achievements, or find hidden bonuses, etc.)
* *Metacognitive skills and strategies* (Learn the terminology and concepts necessary for further learning and to achieve the appropopriate aims using stratgies.)
* *Socialization skills and strategies* (Learn to use the skills and knowledge to make connections with other people and exploit those connections to acquire further skill, knowledge as well as social capital derriving from those)

Is literacy a suitable metaphor for gaming? Matches and mismatches!
-------------------------------------------------------------------

With any metaphor it is worth to explore the mapping to see if there are sufficient similarities. In this case, I’ll look at the following areas for matches and mismatches:

* Skill
* Mode
* Status
* Socialization
* Content
* Purpose

### Skill

Both reading/writing (I will continue to use reading for both unless I need to stress the difference) and gaming require skill that can become automatic and that takes time to acquire. People can be both “better” and “worse” at gaming and reading.

But reading is a more universal skill (although not as universal as most people think) whereas gaming skills are more genre based.

The skill at gaming can be more easily measured by game achievement. Quality of reading measures are a bit more tenuous because speed, fluency and accuracy are all contextual measures. However, even game achievement is a bit more relative, such as in recommendations to play at normal or easy to experience the game.

In this gaming is more like reading than for instance, listening to music or watching a skill which do not require any overt acquisition of skill. See [Dara O’Briain’s funny bit on the differences between gaming and reading](http://www.youtube.com/watch?v=yKIiUsbOO24). Of course, when he says “you cannot be bad at watching a film”, we could quibble that much preparation is required for watching some films, but such training does not involve the development of underlying cognitive skills (assuming the same cultural and linguistic environment). Things are a bit more complex for some special kind of listening to music. Nevertheless people do talk about “media literacy”.

### Mode

Reading is mostly a uni-modal experience. It is possible to read out loud or to read while listening but ultimately reading is its own mode. Reading has an equivalent in writing that though not a mirror image skill, requires relatively the same skill.

Gaming is a profoundly multimodal experience combining vision, sound, movement (and often reading, as well). There are even efforts to involve smell. Gaming does not have a clear expressive counterpart. The obvious expressive equivalent to writing would be game design but that clearly requires a different level of skill. However, gaming allows complex levels of self-expression within the process of game play which does not have an equivalent in reading but is not completely dissimilar to creative writing (like fanfiction).

### Status

Reading is a neutral to high status activity. The act itself is neutral but status can derrive from content. Writing (expressive rather than utilitarian) is a high status activity.

Gaming is a low status to neutral activity. No loss of status derives from inability to game to not gaming in a way that is true of reading. Some games have less questionable status and many games are played by people who derive high status from outside of gaming. There are emerging status sanction systems around gaming but none have penetrated outside gaming, yet.

### Socialization

Reading and writing are significant drivers of wider socialization. They are necessary to perform basic social functions and often represent gateways into important social contexts.

Gaming is only required to socialize in gaming groups. However, this socialization may become more highly desirable over time.

### Content

Writing is used to encode a wide variety of content – from shopping lists to neuclear plant manuals to fiction.

Games on the other hand, encode a much more narrower range of content. Primarily narrative and primarily finctional. Although more non-narrative and non-fictional games may exist. There are also expository games but so far, none that would afford easy storage of non-game information without using writing.

### Purpose

Reading and writing are very general purpose activities.

Gaming on the other hand has a limited range of purposes: enjoyment, learning, socialization with friends, achieving status in a wider community. You won’t see a bus stop with a game instead of a timetable (although some of these require puzzle solving skills to decipher).

Why may game literacy be important?
-----------------------------------

As we saw, there are many differences between gaming and reading and writing. Nevertheless, they are similar enough that the metaphor of ‘game literacy’ makes sense provided we see its limitations.

Why is it important? There will be a growing generational and populational divide of gamers and non-gamers. At the moment this is not very important in terms of opportunities and status but it could easily change within a generation.

Not being able to play a game may exclude people from social groups in the same way that not-playing golf or not engaging in some other locally sanctioned pursuit does (e.g. World of Warcraft).

But most importantly, as new generations of game creators explore the expressive boundaries of games (new narratives, new ways of story telling), not being able to play games may result in significant social exclusion. In the same way that a quick summary of what’s in a novel is inferior to reading the novel, films based on games will be pale imitations of playing the games.

I can easily imagine a future where the major narratives of the day will be expressed in games. In the same way that TV serials have supplanted novels as the primary medium of sharing crucial societal narratives, games can take over in the future. The inner life novel took about 150 years to mature and reigned supreme for about as long while drama and film functioned as its accompaniment. The TV serial is now solidifying its position and is about where the novel was in the 1850s. Gaming may take another couple of decades to get to a stage where it is ready as a format to take over. And maybe nothing like that will happen. But if I had a child, I’d certainly encourage them to play computer games as part of ensuring a more secure future.

### *Related*
```
./2013-04-13-how-we-use-metaphors.md
```
---
title: "How we use metaphors"
date: 2013-04-13
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/04/how-we-use-metaphors
---

I was reminded by [this blog post on LousyLinguist](http://thelousylinguist.blogspot.co.uk/2013/04/the-birth-of-metaphor.html) that many people still see metaphor as an unproblematic homogeneous concept leading to much circular thinking about them.  I wrote about that quite a few years ago in:

Lukeš, D., 2005. Towards a classification of metaphor use in text: Issues in conceptual discourse analysis of a domain-specific corpus. In *Third Workshop on Corpus-Based Approaches to Figurative Language*. Birmingham.

I suggested that a classification of metaphor had better focused on their use rather than inherent nature. I came up with the heuristic device of: cognitive, social and textual uses of metaphor.

Some of the uses I came up with (inspired by the literature from Halliday to Lakoff) were:

* Cognitive
  + Conceptual (constitutive)
  + Attributive
* Social (Interpersonal)
  + Conceptual/Declarative (informational)
  + Figurative (elegant variation)
  + Innovative
  + Exegetic
  + Prevaricative
  + Performative
* Textual
  + Cohesive (anaphoric, cataphoric, exophoric)
  + Coherent

I also posited a continuum of salience and recoverability in metaphors:

* High salience and recoverability
* Low salience and recoverability

Read the **[entire paper here](http://metaphorhacker.techczech.net/files/2013/04/Luke%C5%A1-2005-Towards-a-classification-of-metaphor-use-in-text-.pdf)**.

My thinking on metaphor has moved on since then – I see it as a special case of framing and conceptual integration rather than a sui generis concept – but I still find this a useful guide to return to when confronted with metaphor use.

### *Related*
```
./2013-09-20-storms-in-all-teacups-the-power-and-inequality-in-the-battle-for-science-universality.md
```
---
title: "Storms in all Teacups: The Power and Inequality in the Battle for Science Universality"
date: 2013-09-20
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/09/storms-in-all-teacups-the-power-and-inequality-in-the-battle-for-science-universality
---

The great blog [Genealogy of Religion](http://genealogyreligion.net/salubrious-storm) posted this video with a somewhat approving commentary:

The video started off with panache and promised some entertainment, however, I found myself increasingly annoyed as the video continued. The problem is that this is an exchange of cliches that pretends to be a fight of truth against ignorance. Sure, Storm doesn’t put forward a very coherent argument for her position, but neither does Minchin. His description of science vs. faith is laughable (being in awe at the size of the universe, my foot) and nowhere does he display any nuance nor, frankly, any evidence that he is doing anything other than parroting what he’s heard on some TV interview with Dawkins. I have much more sympathy with the Storms of this world than these self-styled defenders of science whose only credentials are that they can remember a bit of high school physics or chemistry and have read an article by some neo-atheist in Wired. What’s worse, it’s would be rationalists like him who do what passes for science reporting in major newspapers or on the BBC.

But most of all, I find it distasteful that he chose a young woman as his antagonist. If he wished to take on the ‘antiscience’ establishment, there are so many much better figures to target for ridicule. Why not take on the pseudo spiritualists in the mainstream media with their ecumenical conciliatory garbage. How about taking on tabloids like Nature or Science that publish unreliable preliminary probes as massive breakthroughs. How about universities that put out press releases distorting partial findings. Why not take on economists who count things that it makes no sense to count just to make things seem scientific. Or, if he really has nothing better to do, let him lay into some super rich creationist pastor. But no, none of these captured his imagination, instead he chose to focus his keen intellect and deep erudition on a stereotype of a young woman who’s trying to figure out a way to be taken seriously in a world filled with pompous frauds like Minchin.

The [blog post commenting on the video](http://genealogyreligion.net/salubrious-storm) sparked a debate about the limits of knowledge (Note: This is a modified version of my own comment). But while there’s a debate to be had about the limits of knowledge (what this blog is about),  this is not the occasion. There is no need to adjudicate about which of these two is more ‘on to something’. They’re not touching on anything of epistemological interest, they’re just playing a game of social positioning in the vicinity of interesting issues. But in this game, people like Michin have been given a lot more chips to play with than people like Storm. It’s his follies and prejudices and not hers that are given a fair hearing. So I’d rather spend a few vacuous moments in her company than endorse his mindless ranting.

And as for ridiculing people for stupidity or shallow thinking, I’m more than happy to take part. But I want to have a look at those with power and prestige, because they just as often as Storms act just as silly and irrationally the moment they step out of their areas of expertise. I see this all the time in language, culture and history (where I know enough about to judge the level of insight). Here’s [the most recent one](http://www.aeonmagazine.com/living-together/human-beings-do-not-have-an-instinct-for-war) that caught my eye:

It comes from a side note in a post about evolutionary foundations of violence by a self-proclaimed scientist (the implied hero in Minchin’s rant):

>  It is said that the Bedouin have nearly 100 different words for camels, distinguishing between those that are calm, energetic, aggressive, smooth-gaited, or rough, etc. Although we carefully identify a multitude of *wars* — the Hundred Years War, the Thirty Years War, the American Civil War, the Vietnam War, and so forth — we don’t have a plural form for *peace*.

Well, this paragon of reason could be forgiven for not knowing what sort of non-sense this ‘100 words for’ cliche is. The Language Log has spilled enough bits on why [this and other](http://languagelog.ldc.upenn.edu/nll/?category_name=snowclones) *[snowclones](http://languagelog.ldc.upenn.edu/nll/?category_name=snowclones)*are silly. But the second part of the argument is just stupid. And it is a typical scientist blundering about the world as if the rules of evidence didn’t apply to him outside the lab and as if data not in a spreadsheet did not require a second thought. As if being a PhD in evolutionary theory meant everything else he says about humans must be taken seriously. But how can such a moronic statement be taken as anything but feeble twaddle to be laughed at and belittled? How much more cumulatively harmful are moments like these (and they are all over the place) than the socializing efforts of people like Storm from the video?

So, I should probably explain why this is so brainless. First, we don’t have a multitude of words *war*(just like the Bedouin don’t have 100 or even 1 dozen for a camel). We just have the one and we have a lot of adjectives with which we can modify its meaning. And if we want to look for some that are at least equivalent to possible camel attributes, we won’t choose names of famous wars but rather things like *civil war, total war, cold war, holy war, global war, naval war, nuclear war*, etc. I’m sure West Point or even [Wikipedia](http://en.wikipedia.org/wiki/Outline_of_war#Types_of_war) has much to say about a possible classification. And of course,  all of this applies to *peace* in exactly the same way. There are ‘peaces’ with names like *Peace of Westphalia, Arab-Israeli Peace*, etc. with just as many attributive pairs like *international peace, lasting peace, regional peace, global peace, durable peace, stable peace, great peace*, etc.  I went to a [corpus](http://corpus2.byu.edu/coca/) to get some examples but that this must be the case was obvious and a simple Google search would give enough examples to confirm a normal language speaker’s  intuition. But this ‘scientist’ had a point to make and because he’s spent twenty years doing research in evolution of violence, he must surely be right about everything on the subject.

[![Creative Commons License](http://metaphorhacker.techczech.net/wp-content/plugins/compfight/images/cc.png "Creative Commons License")](http://creativecommons.org/licenses/by/2.0/ "Attribution License") [jbraine](http://www.flickr.com/photos/77879815@N00/2346699537/ "jbraine") via [Compfight](http://www.compfight.com/ "Compfight")

Now, I’m sure this guy is not an idiot. He’s obviously capable of analysis and presenting a coherent argument. But there’s an area that he chose to address about which he is about as qualified to make pronouncements as Storm and Minchin are about the philosophy of science. And what he said there is stupid and he should be embarrassed for having said it. Should he be ridiculed and humiliated for it the way I did here? No. He made the sort of mistake everyone makes from high school students to Nobel laureates. He thought he knew something and didn’t bother to examine his knowledge. Or he did try to examine it but  didn’t have the right tools to do it. Fine. But he’s a scientist (and a man not subject to stereotypes about women) so we give him and too many like him a pass. But Storm, a woman who like so many of her generation uses star signs to talk about relationships and is uncomfortable with the grasping maw of classifying science chomping on the very essence of her being, she is fair game?

It’s this inequality that makes me angry. We afford one type of shallowness the veneer respectability and rake another one over the coals of ridicule and opprobrium. Not on this blog!

[![Creative Commons License](http://metaphorhacker.techczech.net/wp-content/plugins/compfight/images/cc.png "Creative Commons License")](http://creativecommons.org/licenses/by/2.0/ "Attribution License") [Juliana Coutinho](http://www.flickr.com/photos/10217810@N05/4756594270/ "Juliana  Coutinho") via [Compfight](http://www.compfight.com/ "Compfight")

**UPDATE:** I was just listening to [this interview with a philosopher and historian of science](http://newbooksinscitechsoc.com/2013/09/08/michael-ruse-the-gaia-hypothesis-science-on-a-pagan-planet-university-of-chicago-press-2013/) about why there was so much hate coming from scientists towards the Gaia hypothesis and his summation, it seems to me, fits right in with what this post is about. He says: “When scientists feel insecure and threatened, they turn nasty.” And it doesn’t take a lot of study of the history and sociology of science to find ample examples of this. The ‘science wars’, the ‘linguistics wars’, the neo-Darwinst thought purism, the list just goes on. The world view of scientism is totalising and has to deal with exactly the same issues as other totalising views such as monotheistic religions with constitutive ontological views or socio-economic utopianisms (e.g. neo-liberalism or Marxism).

And one of those issues is how do you afford respect to or even just maintain conversation with people who challenge your ideological totalitarianism – or in other words, people who are willfully and dangerously “wrong”. You can take the Minchin approach of suffering in silence at parties and occasionally venting your frustration at innocent passerbys, but that can lead to outbreaks group hysteria as we saw with the Sokal hoax or one of the many moral panic campaigns.

Or you can take the more difficult journey of giving up some of your claims on totality and engaging with even those most threatening to to you as human beings; the way Feyerabend did or Gould sometimes tried to do. This does not mean patiently proselytizing in the style of evangelical missionaries but more of an ecumenical approach of meeting together without denying who you are. This will inevitably involve moments where irreconcilable differences will lead to a stand on principles (cf. [Is multi-culturalism bad for women](http://www.amazon.co.uk/Multiculturalism-Women-Susan-Moller-Okin/dp/0691004323)?) but even in those cases an effort at understanding can benefit both sides as with [the question of vaccination described in this interview](http://newbooksinmedicine.com/crossposts/mark-a-largent-vaccine-the-debate-in-modern-america-johns-hopkins-up-2012/). At all stages, there will be temptation at “understanding” the other person by reducing them to our own framework of humanity. Psychologizing a religious person as an unsophisticate dealing with feelings of awe in the face of incomprehensible nature or pitying the atheist for not being able to feel the love of God and reach salvation. There is no solution. No utopia of perfect harmony and understanding. No vision of lions and lambs living in peace. But acknowledging our differences and slowing down our outrage can perhaps make us into the better versions of us and help us stop wasting time trying to reclaim other people’s stereotypes.

[![Storm in a teacup](http://farm7.staticflickr.com/6167/6244195131_20235bdf74_b.jpg "Storm in a teacup")](http://www.flickr.com/photos/46623835@N06/6244195131/ "Storm in a teacup")[![Creative Commons License](http://metaphorhacker.techczech.net/wp-content/plugins/compfight/images/cc.png "Creative Commons License")](http://creativecommons.org/licenses/by/2.0/ "Attribution License") [BruceW.](http://www.flickr.com/photos/46623835@N06/6244195131/ "BruceW.") via [Compfight](http://www.compfight.com/ "Compfight")

**UPDATE 2:**I am aware of the paradox between the introduction and the conclusion of the previous update. Bonus points for spotting it. I actually hold a slightly more nuanced view than the first paragraph would imply but that is a topic for another blog post.

### *Related*
```
./2013-10-27-pervasiveness-of-obliging-metaphors-in-thought-and-deed.md
```
---
title: "Pervasiveness of Obliging Metaphors in Thought and Deed"
date: 2013-10-27
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/10/pervasiveness-of-oblidging-metaphors-in-thought-and-deed
---

> “when history is at its most obliging, the history-writer needs be at his most wary.” ([China by John Keay](http://www.amazon.co.uk/China-History-John-Keay/dp/0007221789))

[![Die Mykologen - Glückspilze - Lucky Fellows - Fungi Experts](http://farm7.staticflickr.com/6166/6220425549_cc19140a63.jpg "Die Mykologen - Glückspilze - Lucky Fellows - Fungi Experts")](http://www.flickr.com/photos/16230215@N08/6220425549/ "Die Mykologen - Glückspilze - Lucky Fellows - Fungi Experts")I came across this nugget of wisdom when I was re-reading the Introduction to John Keay’s history of China. And it struck me that in some way this quote could be a part of the motto of this blog. The whole thing might then read something like this:

> *Hack at your thoughts at any opportunity to see if you can reveal new connections through analogies, metonymies and metaphors. Uncover hidden threads, weave new ones and follow them as far as they take you. But when you see them give way and oblige you with great new revelations about how the world really is, be wary!*

Metaphors can be very obliging in their willingness to show us that things we previously thought separate are one and the same. But that is almost always the wrong conclusion. Everything is what it is, it is never like something else. (In this I have been subscribing to ‘tiny ontology’ even before I‘ve heard about it). But we can learn things about everything when we think about it as something else. Often we cannot even think of many things other than through something else. For instance, electricity. Electrons are useful to think of as particles or as waves. Electrons are electrons, they are not little balls nor are they waves. But when we start treating them as one or the other, they become more tractable for some problems (electrical current makes more sense when we think of them as waves and electricity generating heat makes sense when we think of them as little balls).

George Lakoff and Mark Johnson summarize metaphors in the X IS Y format (e.g. LOVE IS A JOURNEY) but this implied identity is where the danger lies. If love is a journey as we can see in a phrase like, ‘We’ve arrived at a junction in our relationship’, then it surely must be a journey in all respects: it has twists and turns, it takes time, it is expensive, it happens on asphalt! Hold on! Is that last one the reason ‘love can burn with an eternal flame’? Of course not. Love IS NOT a journey. Some aspects of what we call love make more sense to us when we think of them as a journey. But others don’t. Since it is obvious that love is not a journey but is like a journey, we don’t worry about it. But it’s more complicated than that. The identities implied in metaphor are so powerful (more so to some people than others) that some mappings are not allowed because of the dangers implied in following them too far. ‘LOVE IS A CONTRACT’ is a perfectly legitimate metaphor. There are many aspects of a romantic relationship that are contract-like. We agree to exclusivity, certain mode of interaction, considerations, etc. when we declare our love (or even when we just feel it – certain obligations seem to follow). But our moral compass just couldn’t stomach (intentional mix) the notion of paying for love or being in love out of obligation which could also be traced from this metaphor. We instinctively fear that ‘LOVE IS A CONTRACT’ is a far too obliging a metaphor and we don’t want to go there. (By we, I mean the general rules of acceptable discourse in certain circles, not every single cognizing individual.)

So even though metaphors do not describe identity, they imply it, and not infrequently, this identity is perceived as dangerous. But there’s nothing inherently dangerous about it. The issue is always the people and how willing they are to let themselves be obliged by the metaphor. They are aided and abetted in this by the conceptual universe the metaphor appears in but never completely constrained by it. Let’s take the common metaphor of WAR. I often mention the continuum of ‘war on poverty’, ‘war on drugs’, and ‘war on terror’ as an example of how the metaphors of ‘war’ do not have to lead to actual ‘war’. Lakoff showed that they can in ‘metaphors can kill’. But we see that they don’t have to. Or rather we don’t have to let them. If we don’t apply the brakes, metaphors can take us almost anywhere.

There are some metaphors that are so obliging, they have become cliches. And some are even recognized as such by the community. Take, for instance, the Godwin law. X is Hitler or X is Nazi are such seductive metaphors that sooner or later someone will apply them in almost any even remotely relevant situation. And even with the awareness of Godwin’s law, people continue to do it.

The key principle of this blog is that anything can be a metaphor for anything with useful consequences. Including:

* United States is ancient Rome
* China today is Soviet Union of the 1950s
* Saddam Hussein is Hitler
* Iraq is Vietnam
* Education is a business
* Mental difficulties are diseases
* Learning is filling the mind with facts
* The mind is the software running on the hardware of the brain
* Marriage is a union between two people who love each other
* X is evolved to do Y
* X is a market place

But this only applies with the HUGE caveat that we must never misread the ‘is’ for a statement of perfect identity or even isomorphims (same shapedness). It’s ‘is(m)’. None of the above metaphors are perfect identities – they can be beneficially followed as far as they take us, but each one of them is needs to be bounded before we start drawing conclusions.

Now, things are not helped by the fact that any predication or attribution can appear as a kind of metaphor. Or rather it can reveal the same conceptual structures the same way metaphors do.

‘John is a teacher.’ may seem like a simple statement of fact but it’s so much more. It projects the identity of John (of whom we have some sort of a mental image) into the image schema of a teacher. That there’s more to this than just a simple statement can be revealed by ‘I can’t believe that John is a teacher.’ The underlying mental representations and work on them is not that different to ‘John is a teaching machine.’ Even simple naming is subject to this as we can see in ‘You don’t look much like a Janice.’

Equally, simple descriptions like ‘The sky is blue’ are more complex. The sky is blue in a different ways than somebody’s eyes are blue or the sea is blue. I had that experience myself when I first saw the ‘White Cliffs of Dover’ and was shocked that they were actually white. I just assumed that they were a lighter kind of cliff than a typical cliff or having some white smudges. They were white in the way chalk is white (through and through) and not in the way a zebra crossing is white (as opposed to a double yellow line).

A famous example of how complex these conceptualisations can get is ‘In France, Watergate would not have harmed Nixon.’ The ‘in France’ and ‘not’ bits establishe a mental space in which we can see certain parts of what we know about Nixon and Watergate projected onto what we know about France. Which is why sentences like “The King of France is bald.” and “Unicorns are white.” make perfect sense even though they both describe things that don’t exist.

Now, that’s not to say that sentences like ‘The sky is blue’, ‘I’m feeling blue’,’I’ll praise you to the sky.’, or ‘He jumped sky high.’ and ‘He jumped six inches high.’ are cognitively or linguistically exactly the same. There’s lots of research that shows that they have different processing requirements and are treated differently. But there seems to be a continuum in the ability of different people (much research is needed here) to accept the partiality of any statement of identity or attribution. On the one extreme, there appears something like autism which leads to a reduced ability to identify figurative partiality in any predication but actually, most of the time, we all let ourselves be swayed by the allure of implied identity. Students are shocked when they see their teacher kissing their spouse or shopping in the mall. We even ritualize this sort of thing when we expect unreasonable morality from politicians or other public figures. This is because over the long run overtly figurative sentence such as ‘he’s has eyes like a hawk’ and ‘the hawk has eyes’ need similar mental structures to be present to make sense to us. And I suspect that this is part of the reason why we let ourselves be so easily obliged by metaphors.

**Update:**This post was intended as a warning against over-obliging metaphors that lead to perverse understandings of things as other things in unwarranted totalities. In this sense, they are the ignes fatui of Hobbes. But there’s another way in which over-obliging metaphors can be misleading. And that is, they draw on their [other connections](http://metaphorhacker.techczech.net/2012/07/character-assasination-through-metaphoric-pomposity-when-one-metaphor-is-not-enough/ "Character Assasination through Metaphoric Pomposity: When one metaphor is not enough") to make it seem we’ve come to a new understanding where in fact all we’ve done is rename elements of one domain with the names of elements of another domain without any elucidation. This was famously and devastatingly the downfall of Skinner’s *Verbal Behavior* under Chomsky’s critique. He simply (at least in the extreme caricature that was Chomsky’s review) took things about language and described them in terms of operant conditioning. No new understanding was added but because the ‘new’ science of psychology was in as the future of our understanding of everything, just using those terms made us assume there was a deeper knowledge. Chomsky was ultimately right-if only to fall prey to the same danger with his computational metaphors of language. Another area where that is happening is evolution, genetics and neuroscience which are often used (sometimes all at once) to simply relabel something [without adding any new understanding whatsoever](http://metaphorhacker.techczech.net/2011/03/the-brain-is-a-bad-metaphor-for-language/ "The brain is a bad metaphor for language").

**Update 2:** Here’s another example of overobliging metaphor in the seeking of analogies to the worries about climate change: <http://andrewgelman.com/2013/11/25/interesting-flawed-attempt-apply-general-forecasting-principles-contextualize-attitudes-toward-risks-global-warming/#comment-151713>.  My comment was:

…analogies work best when they are opportunistic, ad hoc, and abandoned as quickly as they are adopted. Analogies, if used generatively (i.e. to come up with new ideas), can be incredibly powerful. But when used exegeticaly (i.e. to interpret or summarize other people’s ideas), they can be very harmful.

The big problem is that in our cognition, ‘x is y’ and ‘x is like y’ are often treated very similarly. But the fact is that x is never y. So every analogy has to be judged on its own merit and we need to carefully examine why we’re using the analogy and at every step consider its limits. The power of analogy is in its ability to direct our thinking (and general cognition) i.e. not in its ‘accuracy’ but in its ‘aptness’.

I have long argued that history should be included in considering research results and interpretations. For example, every ‘scientific’ proof of some fundamental deficiencies of women with respect to their role in society has turned out to be either inaccurate or non-scalable. So every new ‘proof’ of a ‘woman’s place’ needs to be treated with great skepticism. But that does not mean that one such proof does not exist. But it does mean that we shouldn’t base any policies on it until we are very very certain.

Image [![Creative Commons License](http://metaphorhacker.techczech.net/wp-content/plugins/compfight/images/cc.png "Creative Commons License")](http://creativecommons.org/licenses/by/2.0/ "Attribution License") [Hartwig HKD](http://www.flickr.com/photos/16230215@N08/6220425549/ "Hartwig HKD") via [Compfight](http://www.compfight.com/ "Compfight")

### *Related*
```
./2013-11-17-three-books-of-the-year-2013-and-some-books-of-the-century-1900-2013.md
```
---
title: "Three books of the year 2013 and some books of the century 1900-2013"
date: 2013-11-17
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/11/three-books-of-the-year-2013-and-some-books-of-the-century-1900-2013
---

I have been asked (as every year) to nominate three books of the year for Lidové Noviny (a Czech paper I contribute to occasionally). This is always a tough choice for me and some years I don’t even bother responding. This is because I don’t tend to read books ‘of the moment’ and range widely in my reading across time periods. But I think I have some good ones this time. Additionally, Lidové Noviny are celebrating 120 years of being a major Czech newspaper so they also asked me for a book of the century (since 1900 till now). It makes no sense to even try to pick ‘the one’, so I picked three categories that are of interest to me (language, society and fiction) and chose three books in each.

[![The Colorful Library of an Interaction Designer (Juhan Sonin) / 20100423.7D.05887.P1 / SML](http://farm5.staticflickr.com/4025/4556156477_c21fa939a8_b.jpg "The Colorful Library of an Interaction Designer (Juhan Sonin) / 20100423.7D.05887.P1 / SML")](http://www.flickr.com/photos/48973657@N00/4556156477/ "The Colorful Library of an Interaction Designer (Juhan Sonin) / 20100423.7D.05887.P1 / SML")[![Creative Commons License](http://metaphorhacker.techczech.net/wp-content/plugins/compfight/images/cc.png "Creative Commons License")](http://creativecommons.org/licenses/by/2.0/ "Attribution License") [See-ming Lee](http://www.flickr.com/photos/48973657@N00/4556156477/ "See-ming Lee") via [Compfight](http://www.compfight.com/ "Compfight")

Three books of 2013
-------------------

Thanks to the New Books Network, I tend to be more clued in on the most recent publications, so 2 of my recommendations are based on interviews heard there.

**A Cultural History of the Atlantic World, 1250-1820** by John K. Thornton is without question a must read for anyone interested in, well, history. Even though he is not the first, Thornton shows most persuasively how the non-Europeans on both sides of the Atlantic (Africa and the Americas) were full-fledged political partners of the Europeans who are traditionally seen simply as conquerors with their dun powder, horses and steel weapons. Bowerman shows how these were just a small part of the mix, having almost no impact in Africa and playing a relatively small role in the Americas. In both cases, Europeans succeeded through alliances with local political elites and for centuries simply had no access to vast swathes of both continents.

**Raising Germans in the Age of Empire: Youth and Colonial Culture, 1871-1914** by Jeff Bowersox. This book perhaps covers an exceedingly specific topic (compared to the vast sweep of my first pick) but it struck a chord with me. It shows the complex interplay between education, propaganda and their place in the lives of youth and adults alike.

**Writing on the Wall: Social Media – the First 2,000 Years** by Tom Standage. Standage’s eye opening book on the telegraph (The Victorian Internet) now has a companion dealing with social communication networks going back to the Romans. Essential corrective to all the gushing paradigm shifters. He doesn’t say there’s nothing new about the Internet but he does say that there’s nothing new abou humans. Much lighter reading but still highly recommended.

Books of the Century
--------------------

This really caught my fancy. I was asked for books that affected me, but I thought more about those that had an impact going beyond the review cycle of a typical book.

### Language

**Course in General Linguistics** by Ferdinand de Saussure published in 1916. The Course (or *Le Cours*) Published posthumously by Saussure’s students from lecture notes is the cornerstone of modern linguistics. I think many of the assumptions have been undermined in the past 30-40 years and we are ripe for a paradigm change. But if you talk to a modern linguist, you will still hear much of what Saussure was saying to his students in the early 1900s in Geneva. (Time to rethink the Geneva Convention in language?)

**Syntactic Structures** by Noam Chomsky published in 1957. Unlike The Course, which is still worth reading by anyone who wants to learn about language, Syntactic Structures is now mostly irrelevant and pretty much incomprehensible to non-experts. However, it launched the Natural Language Processing revolution and its seeds are still growing (although not in the Chomskean camp). Its impact may not survive the stochastic turn in NLP but the computational view of language is still with us for good and for ill.

**Metaphors We Live By** by George Lakoff and Mark Johnson published in 1980 while not completely original, kickstarted a metaphor revival of sorts. While, personally, I think Lakoff’s *Women, Fire, and Dangerous Things* is by far the most important book of the second half of the 20th century, *Metaphors We Live By*is a good start (please, read the 2003 edition and pay special attention to the Afterword).

### Society

**The Second Sex** by Simone de Beauvoir published in 1949 marked a turning point in discourse about women. Although the individual insights had been available prior to Beauvoir’s work, her synthesis was more than just a rehashing of gender issues.

**Language and Woman’s Place** by Robin Tolmach Lakoff published in 1973 stands at the foundation of how we speak today about women and how we think about gender being reflected in language. I would now quible with some of the linguistics but not with the main points. Despite the progress, it can still open eyes of readers today.

**The Savage Mind** by Claude Levi-Strauss published in 1962 was one of the turning points in thinking about modernity, complexity and backwardness. Strauss’s quip that philosophers like Sartre were more of a subject of study for him than valuable interlocutors is still with me when I sit in on a philosophy seminar. I read this book without any preparation and it had a profound impact on me that is still with me today.

### Fiction

None of the below are my personal favourites but all have had an impact on the zeit geist that transcended just the moment.

**1984** by George Orwell published in 1949. Frankly I can’t stand this book. All of its insight is skin deep and its dystopian vision (while not in all aspects without merit) lacks the depth it’s often attributed. There are many sci-fi and fantasy writers who have given the issue of societal control and freedom much more subtle consideration. However, it’s certainly had a more profound impact on general discourse than possibly any piece of fiction of the 20th century.

**The Joke** by Milan Kundera published in 1967 is the only book by Kundera with literary merit (I otherwise find his writing quite flat). Unlike Orwell, Kundera has the capacity to show the personal and social dimensions of totalitarian states. In *The Joke* he shows both the randomness of dissent and the heterogeniety of totalitarian environments.

**The Castle** by Franz Kafka published in 1912 (or just the collected works of Kafka) have provided a metaphor for alienation for the literati of the next hundred years. I read The Castle first so it for me more than others illustrates the sense of helplessness and alienation that a human being can experience when faced with the black box of anonymous bureaucracy. Again, I rate this for impact, rather than putting it on a ‘good read’ scale.

My personal favorites would be authors rather than individual works: Kurt Vonnegut, Robertson Davies, James Clavell would make the list for me. I also read reams of genre fiction and fan fiction that can easily stand up next to any of “the greats”. I have no shame and no guilty pleasures. I’ve read most of Terry Pratchett and regularly reread childhood favorites by the likes of Arthur Ransome or Karl May. I’ve quoted from Lee Child and Tom Clancy in academic papers and I’ve published an extensive review of a Buffy the Vampire Slayer fan fiction novel.

Finally, for me, the pinnacle of recent literary achievement is Buffy the Vampire Slayer. I’ve used this as an example of how TV shows have taken over from the Novel, as the narrative format addressing weighty issues of the day, and Buffy is one of the first examples. Veronica Mars is right up there, as well, and there are countless others I’d recommend ‘reading’.

### *Related*
```
./2013-12-14-binders-full-of-women-with-mighty-pens-what-is-metonymy.md
```
---
title: "Binders full of women with mighty pens: What is metonymy"
date: 2013-12-14
author: Dominik Lukeš
source: https://metaphorhacker.net/2013/12/binders-full-of-women-with-mighty-pens-what-is-metonymy
---

Metonymy in the wild

[![](http://25.media.tumblr.com/tumblr_md37c5dYtG1rj8amio1_1280.jpg)](http://25.media.tumblr.com/tumblr_md37c5dYtG1rj8amio1_1280.jpg)

Things were not going well for Mitt Romney in early autumn of last year. And then he responded to a query about gender equality with this sentence:

> “I had the chance to pull together a cabinet, and all the applicants seemed to be men… I went to a number of women’s groups and said, ‘Can you help us find folks?’ and they brought us whole binders full of women.” http://en.wikipedia.org/wiki/Binders\_full\_of\_women

This became a very funny meme that stuck around for weeks. The reason for the longevity was the importance of women’s issues and the image of Romney himself. Not the phrase itself. What it showed or rather confirmed that journalists who in the same breath bemoan the quality of language education are completely ignorant about issues related to language. Saying things like:

> In fairness, “binders” was most likely a slip of the tongue. http://edition.cnn.com/2012/10/17/opinion/cardona-binders-women/index.html

The answer to this is NO. This was not some ‘freudian slip of the tongue’ nor was it an inelegant phrase. It was simply a perfectly straightforward use of metonymy. Something we use and hear used probably a dozen times every day without remarking on it (or mostly so – see below).

What is metonymy
----------------

**Metonymy is a figure of speech** where something stands for something else because it has a connection to it. This connection can be physical, where a part of something can stand for a whole and a whole can stand for one of its parts.

* **Part** **for** **a whole:** In *I got myself some new wheels.*, ‘wheels’ stand in for ‘car’.
* **Whole for a part:** In *My bicycle got a puncture.*, ‘bicycle’ stands for a ‘tyre‘ which is a part of the it.

But the part/whole relationship does not have to be physical. Something can be a part of a process, idea, or configuration. The part/whole relationship can also be a membership or a cause and effect link. There are some subdomain instantiations where whole sets of conventional metonymies often congregate. Tools also often stand for jobs and linguistic units can stand for their uses. Materials can also be used to stand for things made from them. Some examples of these are:

* **Membership for members:** “The Chess club sends best wishes.” < the ‘chess club’ stands for its members
* **Leader** **for** **lead:** “The president invaded another country.” < the ‘president’ stands for the army
* **Tool for person:** “hired gun” < the tool stands for the person
* **Linguistic units for uses:** “no more ifs and buts’ < if’ and ‘but’ stand for their types of questions
* **End of a process for process:** “the house is progressing nicely” < the ‘house’ is the final end of a process which stands for the process as a whole.
* **Tool/position for** **job****:** “chair person” < ‘chair’ stands for the role of somebody who sits on it.
* **Body part for** **use****:** “lend a hand”, the ‘hand’ stands for the part of the process where hands are used.
* **City for inhabitants:** “Detroit doesn’t like this” < the city of ‘Detroit’ stands for the people and industries associated with the city.
* **Material for** **object** **made from material:** “he buried 6 inches of steel in his belly” < the steel stands for a sword as in “he filled him full of lead”, lead stands for bullets.

Metonymy chaining
-----------------

Metonymies often occur in chains. A famous example by Michael Reddy is

> “You’ll find better ideas than that in the library.”

where ideas are expressed in words, printed on pages, bound in books, stored in libraries.

In fact the ‘binders full of women’ is an example of a metonymic chain where women stand for profiles which are written on pages contained in binders.

It has been argued that these chains illustrate the very nature of metonymic inference. (See more below in section on reasoning.) In fact, it is not unreasonable to say that most metonymy contains some level of chaining or potential chaining. Not in cases of direct parts like ‘wheels’ standing for ‘cars’ but in the less concrete types like ‘hands’ standing for help or ‘president’ for the invading army, there is some level of chaining involved.

Metonymy vs. synechdoche
------------------------

Metonymy is a term which is a part of [a long standing classification of rhetorical tropes.](http://lucian.uchicago.edu/blogs/mediatheory/keywords/metaphormetonymy/) The one term from this classification that metonymy is most closely associated with is **synechdoche**. In fact, what used to be called synechdoche is now simply subsumed under metonymy by most people who write about it.

The distinction is:  
– **Synechdoche** describes a part standing for a whole (traditionally called *pars pro* *toto*) as in ‘The king built a cathedral.’ or the whole standing for a part (traditionally called *totum pro parte*) as in ‘Poland votes no’  
– **Metonymy** describes a connection based on a non-part association such as containment, cause and effect, etc. (see above for a variety of examples)

While this distinction is not very hard to determine in most cases, it is not particularly useful and most people won’t be aware of it. In fact, I was taught that synechdoche was *pars* *pro* *toto*and metonymy was *totum pro parte* and all the other uses are an extension of these types. This makes just as much as sense as any other division but doesn’t seem to be the way the ancients looked at it.

Metaphor vs. metonymy
---------------------

More commonly and perhaps more usefully, metonymy is contrasted with metaphor. In fact, ‘metaphor/metonymy’ is one of the key oppositions made in studies of figurative language.

People studying these tropes in the Lakoff and Johnson tradition will say something along the lines of metonymy relies on continguity whereas metaphor relies on similarity.

So for example:

* “you‘re such a kiss ass” is a metaphor because ‘kissing ass’ signifies a certain kind of behavior, but the body part is not involved, while
* “I got this other car on my ass” is a metonymy because ‘ass’ stands for everything that’s behind you.

Or:

* “all men are pigs” is a metaphor because we ascribe the bad qualities of pigs to men but
* “this is our pig man” is a metonymy because ‘pig’ is part of the man’s work

Some people (like George Lakoff himself) maintain that the distinction between metaphor and metonymy represent a crucial divide. Lakoff puts metonymic connections along with metaphoric ones as the key figurative structuring principles of conceptual frames (along with propositions and image schemas). But I think that there is evidence to show that they play a similar role in figurative language and language in general. For example, we could add a third sentence to our ‘ass’ opposition such as ‘she kicked his ass’ which could be either metonymic when actual kicking occured but only some involved the buttocks or metaphoric if no kicking at all took place. But even then the metaphor relies on an underlying metonymy.

When we think of metaphor as a more special instance of domain mapping (or conceptual blending, as I do on this blog), then we see that very similar connections are being made in both. Very often both metaphor and metonymy are involved in the same figurative process. There is also often a component of social convention where some types of connections are more likely to be made.

For example, in “pen is mightier than the sword” the connections of ‘pen’ to writing and ‘sword’ to war or physical enforcement is often given as an example of metonymy. But the imagery is much richer than that. In order to understand this phrase, we need to compare two scenarios (one with the effects of writing and one with the effects of fighting) which is exactly what happens in the conceptualisation taking place in metaphors and analogies. These two processes are not just part of a chain but seem to happen all at once.

Another example is ‘enquiring minds want to know’ the labeling of which was the subject of a recent debate. We know that minds often metonymically stand for thinkers as in ‘we have a lot of sharp minds in this class’. But when we hear of ‘minds’ doing something, we think of metaphor. This is not all that implausible because ‘my mind has a mind of its own’ is out there: http://youtu.be/SdUZe2BddHo. But this figure of speech obviously relies on both conceptualisations at once (at least in the way some people will construe it).

Metonymy and meronymy
---------------------

One confusion, I’ve noticed is putting metonymy into opposition to meronymy. However, the term ‘meronymy‘ has nothing to do with the universe of figurative language. It is simply a term for a name used to label the meaning of a word in relationship to another word where one of these words denotes a whole and another its part. So ‘wheels’ are a meronym of ‘car’ and ‘bike’ but calling a nice car ‘sharp wheels’ is synechdoche, not meronymy as this post http://wuglife.tumblr.com/post/68572697017/metonymy-or-meronymy erroneously claims.  
Meronyms together with hyponyms and hyperonyms are simply terms that describe semantic relationships between words. You could say that synechdoche relies on the meronymic (or holonymic) relationship between words or that it uses meronyms for reference.

It doesn’t make much difference for the overall understanding of the issues but perhaps worth clarifying.

William Croft also claims that meronymy is the only constituent relationship in his radical construction grammar (something which I have a lot of time for but not something hugely relevant to this discussion).

Metonymic imagery
-----------------

Compared to metaphor, metonymy is often seen as the more pedestrian figure of speech. But as we saw in the reactions to Romney’s ‘binders of women’ that this is not necessarily the case:

> he managed to conjure an image confirming every feminist’s worst fears about a Romney presidency; that he views women’s rights in the workplace as so much business admin, to be punched and filed and popped on a shelf http://www.theguardian.com/world/shortcuts/2012/oct/17/binders-full-of-women-romneys-four-words

The meme that sprang up around it consisted mostly of people illustrating this image, many of which can be found on [http://bindersfullofwomen.tumblr.com](http://bindersfullofwomen.tumblr.com/) (see one such image above).

This is not uncommon in the deconstructions and hypostatic debates about metonymies. ‘Pen is mightier than the sword’ is often objected to on the basis that somebody with a sword will always prevail over somebody with a pen. People will also often critique the ’cause of’ relationships, as in ‘the king did not erect this tower, all the hard-working builders did’. Another example could be all the gruesome jokes about ‘lending a hand’ or ‘asking for a hand in marriage’. I still remember a comedy routine from my youth which included the sentence, “The autopsy was successful, the doctor came over to me extending a hand…for me to take to the trash.”

But there is a big difference in how the imagery works in metonymy and metaphor. Most of the time we don’t notice it. But when we become aware of the rich evocative images that make a metaphor work, we think of the metaphor as working and those images illustrate the relationship between the two domains. But when we become aware of the images that are contained in a metonymy (as in the examples above), we are witnessing a failure of the metonymy. It stops doing its job as a trope and starts being perceived as somehow inappropriate usage. But metaphor thus revealed typically does its job even better (though [not in all cases](http://metaphorhacker.techczech.net/2013/10/pervasiveness-of-oblidging-metaphors-in-thought-and-deed/) as I’ve often illustrated on this blog).

Reasoning with metonymy
-----------------------

Much has been written about metaphoric reasoning (sometimes in the guise of ‘analogic reasoning’) but connection is just as an important part of reasoning as similarity is.

Much of sympathetic magic requires both connection and similarity. So the ‘voodoo doll’ is shaped like a person but is connected to them by a their hair, skin, or an item belonging to them.

But reasoning by connection is all around us. For instance, in science, the relationship of containment is crucial to classification and much of logic. Also, the question of sets being part of sets which has spurred so much mathematical reasoning has both metaphoric and metonymic dimensions.

But we also reason by metonymy in daily life when we pay homage to the flag or call on the president to do something about the economy. Sometimes we understand something metonymically by compression, as if when we equate the success of a company with the success of its CEO. Sometimes we use metonymy to elaborate as when we say something like 12 hard working pistons brought the train home.

Metonymy is also involved in the process of exemplars and paragons. While the ultimate conceptualization is metaphoric, we also ask that the exemplar has some real connection. Journalists engage the process of metonymy when they pick someone to tell their story to exemplify a larger group. This person has to be both similar and connected to engage the power of the trope fully. On a more accessible level, insults and praise often have a metonymic component. When we call someone ‘an asshole’ or ‘a hero’, we often substitute a part of who they are for the whole, much to the detriment of our understanding of who they are (note that a metaphor is also involved).

Finally, many elements of representative democracy rely on metonymic reasoning. We want MPs to represent particular areas and think it is best if they originate in that area. We think because we paid taxes, the police ‘work for us’. Also, the ideology of nationalism and nation states are very much metonymic.

Warning in conclusion
---------------------

I have [often warned against the dangers](http://metaphorhacker.techczech.net/2012/08/cliches-information-and-metaphors-overcoming-prejudice-with-metahor-hacking-and-getting-it-back-again/) of overdoing the associations generated by metaphors. But in many ways metonymy is potentially even more dangerous because of the magic of direct connection. It can be a very useful (and often necessary) shortcut to communication (particularly when used as compression) but just as often it can lead us down dangerous paths if we let it.

Background
----------

This post is an elaboration and reworking of [my comment on Stan Carey’s post on metonymy](http://www.macmillandictionaryblog.com/what-is-metonymy/comment-page-1#comment-331742): It seemed to me a surprisingly confused and unclear about what metonymy does. This could be because Stan is no linguistic lightweight so I have expected more. But it’s easy to get this wrong, and rereading my comment there, it seems, I got a bit muddled myself. And, I’m sure even my more worked out description here could be successfully picked over. Even Wikipedia, which is normally quite good in this area, is a bit confused on the matter. The different entries for synechdoche and metonymy as well as related terms seem a bit patched together and don’t provide a straightforward definition.

Ultimately, the finer details don’t matter as long as we understand the semantic field. I hope this post contributes to that understanding but I’ll welcome any comments and corrections.

### *Related*
```
./2014-01-01-5-things-everybody-should-know-about-language-outline-of-linguistics-contribution-to-the-liberal-arts-curriculum.md
```
---
title: "5 things everybody should know about language: Outline of linguistics’ contribution to the liberal arts curriculum"
date: 2014-01-01
author: Dominik Lukeš
source: https://metaphorhacker.net/2014/01/5-things-everybody-should-know-about-language-outline-of-linguistics-contribution-to-the-liberal-arts-curriculum
---

Drafty
------

This was written in some haste and needs further refinement. Maybe one day that will come. For now, it will be left as it stands.

Background
----------

This post outlines what I think are the key learnings from the output of the research of the field of linguistics that should be reflected in the general curriculum (in as much as any should be). This is in reaction to the recent posts by Mark Liberman suggesting the role and form of grammar analysis in general education. I argue that he is almost entirely wrong in his assumptions as well as in his emphasis. I will outline my arguments against his position at the end of the post. At the beginning I will outline key easily digestible lessons of modern linguistics that should be incorporated into language education at all levels.

I should note that despite my vociferous disagreement, Mark Liberman is one of my heros. His ‘Breakfast Experiments(tm)’ have brought me much joy and his and his fellow contributors to the Language Log make me better informed about developments in linguistics outside my own specialty that I would otherwise not know about. Thanks Mark for all your great work.

I have addressed some of these issues in previous posts here, here and here.

What should linguistics teach us
--------------------------------

In my post on what proponents of simple language should know about linguistics, I made a list of findings that I propose are far more important than specific grammatical and lexicographic knowledge. Here I take a slightly more high-level approach – but in part, this is a repetition of that post.

Simply, I propose that any school-level curriculum of language education should 1. expose students (starting at primary level) to the following 5 principles through reflection on relevant examples, and 2. these principles should be reflected in the practical instruction students receive toward the acquisition of skills and general facility in the standards of that language.

### Summary of key principles

1. Language is a dialect with an army and a navy
2. Standard English is just one of the many dialects of English
3. We are all multilingual in many different ways
4. A dictionary is just another text written in the language, not a law of the language
5. Language is more than words and rules

### Principle 1: Language is a dialect with an army and a navy

This famous dictum (see [Wikipedia on origins](http://en.wikipedia.org/wiki/A_language_is_a_dialect_with_an_army_and_navy_) ) encapsulates the fact that language does not have clear boundaries and that there is no formula for distinguishing where one language ends and another begins. Often, this disctinction depends on the political interests of different groups. In different political contexts, the different Englishes around the world today, could easily qualify for separate language status and many of them have achieved this.

But exploring the examples that help us make sense of this pithy phrase also teaches us the importance of language in the negotiation of our identity and its embeddedness in the wider social sphere. There are piles and piles of evidence to support this claim and learning about the evidence has the potential of making us all better human beings less prone to disenfranchise others based on the way they speak (in as much any form of schooling is capable of such a thing). Certainly more worthy than knowing how to tell the passive voice.

### Principle 2: Standard English is just one of the many dialects of English

Not only are there no clear boundaries between languages, there are no clear principles of what constitutes an individual language. A language is identified by its context of use as much as by the forms it uses. So if *kayak* and *a propos* can be a part of English so can *ain’t* and *he don’t*. It is only a combination of subconscious convention and conscious politics that decides which is which.

Anybody exploring the truth of this statement (and, yes, I’m perfectly willing to say the word *truth* in this context) will learn about the many features of English and all human languages such as:

* stratification of language through registers
* regional and social variation in language
* processes of change in language over time
* what we call good grammar are more or less fixed conventions of expression in certain contexts
* the ubiquity of multiple codes and constant switching between codes (in fact, I think this is so important that it gets a top billing in this list as number 3)

Again, althoguh I’m [highly skeptical](http://eduvoodoot.net) of claims to causality from education to social change, I can’t see why instruction in this reality of our lives could not contribute to an international conversation about language politics. Perhaps, an awareness of this ‘mantra’ could reduce the frequency of statements such as:

* I know I don’t speak very good English
* Word/expression X is bad English
* Non-native speaker X speaks better English than native speaker Y

And just maybe, teachers of English will stop abusing their students with ‘this is bad grammar’ and instead guide them towards understanding that in different contexts, different uses are appropriate. Even at the most elementary levels, children can have fun learning to speak like a newscaster or a local farm hand, without the violent intrusion into their identity that comes from the misguided and evil labeling of the first as proper and the second as ‘not good English’. Or how about giving the general public enough information to have judged the abominable behavior of the the journalist pseudo elites during the ‘Ebonics controversy’ as the disgraceful display of shameful ignorance it was.

Only and only when they have learned all that, should we mention something about the direct object.

### Principle 3: We are all multilingual in many different ways

One of the things linguistics has gathered huge amounts of evidence about is the fact that we are all constantly dealing with multiple quite distinct codes. This is generally not expressed in quite as stark terms as I do here, but I take my cue from bilingualism studies where it has been suggested (either by Chaika or Romaine – I can’t track down the reference to save my life) that we should treat all our study of language as if bilingualism was the default state rather than some exception. This would make good sense even if we went by the educated guess that just over half of the world’s population speaks regularly two or more languages. But I want to go further.

First, we know from principle 1 that there is no definition of language that allows us draw clear boundaries between individual languages. Second, we know from principle 2 that each language consists of many different ‘sub-languages’ or ‘codes’. Because language is so vast and complex, it follows that knowing a language is not an either/or proposition. People are constantly straddling boundaries between different ways of speaking and understanding. Speaking in different ways for different purposes, to different people in different codes. And we know that people switch between the codes constantly for different reasons, even in the same sentence or just one word (very common in languages with rich morphologies like Czech – less common in English but possible with ‘un-fucking-convinving’). Some examples that should illustrate this: “Ladies and gentlemen, we’re screwed” and “And then Jeff said unto Karen”

We also know from all the wailing and gnashing of teeth derriving from the ignorance of principle 2, that acquiring these different codes is not easy. The linguist Jim Miller has suggested to me that children entering school are in a way required to learn a foreign language. In Czech schools, they are instructed in a new lexicon and new morphology (e.g. say ‘malý’ instead of ‘malej’). in English schools they are taught a strange syntax with among other things a focus on nominal structures (cf. ‘he went and’ vs. ‘his going was’) as well as an alien lexicon (cf. ‘leave’ vs. ‘depart’). This is compounded with a spelling system whose principles are often explained on the basis of a phonology they don’t understand (e.g. much of England pronuncing ‘bus’ and ‘booss’ but using teaching materials that rhyme ‘bus’ with ‘us’).

It is not therefore a huge leap to say that for all intents and purposes, we are all multilingual even if we only officially speak one language with its own army and a navy. Or at least, we enagage all the social, cognitive and linguistic processes that are involved in speaking multiple languages. (There is some counter evidence from brain imaging but in my view it is still too early to interpret this either way.)

But no matter whether we accept the strong or the weak version of my proposition, learning about the different pros and cons would make students’ lives much easier at all levels. Instead of feeling like failures over their grammar, they could be encouraged to practice switching between codes. They could also take comfort in the knowledge that there are many different ways of knowing a language and no one person can know it all.

If any time is left over, let’s have a look at constituent structures.

### Principle 4: A dictionary is just another text written in the language, not a law of the language

The defference shown to ‘official’ reference materials is at the heart of a myth that the presense of a word in a dictionary in some way validates the word as being a ‘real’ word in the language. But the absolute truth about language that everyone should know and repeat as a mantra every time they ask ‘is X a word’ is that dictionaries are just another text. In fact, they are their own genre of a type that Michael Hoey calls text colonies. This makes them cousins of the venerable shopping list. Dictionaries have their own conventions, their own syntax and their own lexicon. They have ‘heads’ and ‘definitions’ that are both presented in particular ways.

What they most emphatically do not do is confirm or disconfirm the existence of a word or its meaning. It’s not just that they are always behind current usage, it’s that they only reflect a fraction of the knowledge involved in knowing and using words (or as the philosopher John Austin would say ‘doing things with words’). Dictionaries fullfil two roles at once. They are useful tools for gathering information to enable us to deal with the consequences of principle 3 (i.e. to function in a complex multi-codal linguistic environment both as passive and active participants). And they help us express many beliefs about our world such as:

* The world is composed of entities with meanings
* Our knowledge is composed of discrete items
* Some things are proper and others are improper

Perhaps this can become more transparent when we look at entries for words like ‘the’ or ‘cat’. No dictionary definition can help us with ‘the’ unless we can already use it. In this case, the dictionary serves no useful role other than as a catalog of our reality. Performatively assuring us of its own relevance by its irrelevance. How about the entry for ‘cat’. Here, the dictionary can play a very useful role in a bilingual situation. A German will see ‘cat = Katze’ and all will be clear in an instant. A picture can be helpful to those who have no language yet (little children). But the definition of ‘cat’ as “a small domesticated carnivorous mammal with soft fur, a short snout, and retractile claws” is of no use to anybody who doesn’t already know what ‘cat’ means. Or at the very least, if you don’t know ‘cat’, your chances of understanding any definition in the dictionary are very low. A dictionary can be helpful in reminding us that ‘cat’ is also used to refer to ‘man’ among jazz musicians (as in “he’s a cool cat”) but again, all that requires existing knowledge of cat. A dictionary definition that would say ‘a cat is that thing you know as a cat but jazz musicians sometimes use cat to refer to men’ would be just as useful.

In this way, a dictionary is like an audience in the theatre, who are simultaneously watching a performance, and performing themselves the roles of theatre audiences (dress, behavior, speech).

It is also worthwhile to think about what is required of the dictionary author. While the basic part of the lexicographer’s craft is the collection of usage examples (on index cards in the past and in corpora today) and their interpretation, all this requires a prior facility with the language and much introspection about the dictionary makers own linguistic intuitions. So lexicographers make mistakes. Furthermore, in the last hundred years or so, they also almost never start from scratch. Most dictionaries are based on some older dictionaries and the order of definitions is often as much a reflection of a tradition (e.g. in the case of the word ‘literally’ or the word ‘brandish’) as analysis of actual usage.

Why should this be taught as part of the language education curriculum? Simple! Educated people should know how the basic tools surrounding their daily lives work. But even more importantly, they should never use the presence of a word in a dictionary, and as importantly the definition of a word in a dictionary, as the definitive argument for their preferred meaning of a word. (Outside some contexts such as playing SCRABBLE or confirming an uncertainty over archaic or specialist words).

An educated person should be able to go and confirm any guidance found in a dictionary by searching a corpus and evaluate the evidence. It’s not nearly as hard as as identifying parts of speech in a sentence and about a million times more useful for the individual and beneficial for society.

### Principle 5: Language is more than words and rules

Steven Pinker immortalised the traditional structuralist vision of what language consists of in the title of his book “Words and rules”. This vision is almost certainly wrong. It is based on an old articulation of language as being the product of a relatively small number of rules applied to a really large number of words (Chomsky expressed this quite starkly but the roots of this model go much deeper).

That is not to say that words and rules are not useful heuristic shortcuts to talking about language. I use this metaphor myself every day. And I certainly am not proposing that language should not be taught with reference to this metaphor.

However, this is a very impoverished view of language and rather than spend time on learning the ‘relatively few’ rules for no good reason other than to please Mark Liberman, why not learn some facts we know about the vastness and complexity of language. That way instead of having a completely misguided view of language as something finite that can be captured in a few simple precepts (often expressed in one of those moronic ‘Top X grammatical errors lists’), one could actually have a basic understanding of all the ways language expresses our minds and impresses itself on our life. Perhaps, we could even get to a generation of psycholinguists and NLP specialists who try to deal with language as it actually is rather than in its bastardised form that can be captured by rules and words.

Ok, so I’m hoisting my theoretical flag here, flying the colors of the ‘usage-based’, ‘construction grammar’, ‘cognitive semantics’ crowd. But the actual curricular proposal is theory free (other than in the ‘ought’ portion of it) and based on well-known and oft-described facts – many of them by the Language Log itself.

To illustrate the argument, let’s open the dictionary and have a look at the entry ‘get’. It will go on for several pages even if we decide to hide all its phrasal friends under separate entries. [Wiktionary](http://en.wiktionary.org/wiki/get) lists 26 definitions as a verb and 4 as a noun which is fairly conservative. But each of these definitions also comes with usage examples and usage exceptions. For instance, in ‘get behind him’, it is intransitive but in ‘get Jim to come’, it is transitive. This is combined with general rules that apply across all uses such ‘got’ as the past tense and ‘gets’ as the third person singular. Things can be even more complex as with the word ‘bad’ which has the irregular superlative ‘worst’ when it is used in a negative sense as in ‘teaching grammar in schools is the worst idea’ and ‘baddest’ in the positive sense as in ‘Mark Liberman is the baddest linguist on the internet’. ‘Baddest’ is also only appropriate in certain contexts (so my example is at the same time an illustration of code mixing). When we look at any single word in the dictionary, the amount of conscious and unconscious knowledge required to use the word in our daily speech is staggering. This is made even trickier by the fact that not everyone in any one speech community has exactly the same grasp of the word leading to a lot of negotiation and conversation repair.

It is also the sort of stuff that makes understanding of novel expressions like ‘she sneezed the napking off the table’ possible. If we must, let’s do some sentence diagramming now.

### Some other things to know

I could go on, some of my other candidate principles that didn’t make this list either because they could be subsumed by one of the items, or they are too theory laden, or because I wanter a list of 5, or because this blog post is over 3,000 words already, are:

* All lexical knowledge is encyclopedic knowledge
* Rules of the road like conversation repair, turn taking or text cohesion are just as much part of language as things like passives, etc.
* Metaphors (and other types of figurative language) are normal, ubiquitous and necessary for language
* Pretty much every prejudice about gender and language is wrong (like who is more conservative, etc.)
* No language is more beatiful or amazing than any other, saying this is most likely part of a nationalistic discourse
* Children are not very good language learners when you put them in the same learning context as adults (e.g. two hours of instruction a week as opposed to living in a culture with no other obligation but to learn)
* Learning a language is hard and it takes time
* The etymology of a word does not reflect some deeper meaning of the word
* Outside some very specific contexts (e.g. language death), languages don’t decline, they change
* Etc.

Why we should not teach grammar in schools
------------------------------------------

So, that was my outline of what linguistic expertise should be part of the language education curriculum – and as importantly should inform teachers across all subjects. Now, let’s have a look, as promised, at why Mark Liberman is wrong to call for the teaching of grammar in schools in the first place.

To his credit, he does not trot out any of the usual utilitarian arguments for the teaching of grammar:

* It will make learning of foreign languages easier
* It will make today’s graduates better able to express themselves
* It will contribute to higher quality of discourse
* It will stop the decline of English
* It will improve critical thinking of all students

These are all bogus, not supported by evidence and with some evidence against them (see this report for a summary of a part of them).

My argument is with his interpretation of his claim that

> a basic understanding of how language works should be part of what every educated person knows

I have a fundamental problem with the very notion of ‘educated person’ because of its pernicious political baggage. But in this post I’ve used it to accept the basic premise that if we’re going to teaching lots of stuff to children in schools, we might as well teach them the good stuff. Perhaps, not always the most immediately useful stuff but definitely the stuff that reflects the best in what we have to offer to ourselves as the humanity we want to be.

But if that is the case, then I don’t think his offer of

> a modern version of the old-fashioned idea that grammar (and logic and rhetoric :-)) should be for everyone

is that sort of stuff. Let’s look at what that kind of education did for the likes of Orwell, and Stunk and White who have had the benefit of all the grammar education a school master’s cane can beat into a man and yet committed such outrageous, embarrassing and damaging transgressions against linguistic knowledge (not infrequently decried on the Language Log).

The point is that ‘grammar’ (and ‘logic’ and ‘rhetoric’) do not represent even a fraction of the principles involved in how language works. The only reason why we would privilege their teaching over the teaching of the things I propose (which cover a much larger area of how language works) is because they have been taught in the past. But why? Basing it on something as arbitrary as the hodgepodge that is the treebank terminology proposed by Mark Liberman only exposes the weakness of the argument – sure, it’s well known and universally understood by professional linguists but it hides as much about language as it reveals. And as Mark acknowledges, the aim is not to educate future linguists. There are alternatives such as Dickson’s excellent Basic Linguistic Theory that take into account much more subtly the variation across languages. But even then, we avoid all the really interesting things about language. I’m not against some very basic metalinguistic terminology to assist students in dealing with language but parsing sentences for no other reason than to do it seems pointless.

The problem with basing a curriculum on old-fashioned values is that we are catering to the nostalgia of old men (and sorry Mark, despite my profound appreciation for your work, you are an old man). (By the way, I use ‘men’ to evoke a particular image rather than to make any assertions about the gender of the person in question.) But it’s not just nostalgia. It’s also their disorientation in a changing world and discomfort with encountering people who are not like them – and, oh horror, can’t tell the passive voice from the past tense. Yes, it would be more convenient for me, if everyone I spoke to had the same appreciation for what an adverb is (particularly when I was teaching foreign languages). But is that really the best we have to offer when we want to show what should be known? How much of this is just the maintenance of the status of academics who want to see their discipline reflected in the cauldron of power and respectability that is the school curriculum? If the chemists get to waste everyone’s time with polymers, why not us with trees and sentence diagrams? In a [follow up post](http://languagelog.ldc.upenn.edu/nll/?p=9431), Dick Hudson claims that at present “we struggle to cope with the effects of [the disaster of no grammar teaching]”. But I don’t see any disaster going on at the moment. Why is teaching no grammar more disasterous than the teaching of grammar based on Latin and Greek with little connection to the nature of English? Whose rules are we after?

The curriculum is already full to bursting with too much stuff that someone threw up as a shibboleth for being educated and thus eligible for certain privileges. But perhaps our curriculum has now become the kind of stable that needs the janitorial attention of a modern Heracles.

Post script: Minimalist metalinguistic curriculum
-------------------------------------------------

I once analysed the Czech primary curriculum and found over 240 metalinguistic terms. I know, riddiculous. The curriculum was based on the work of eminent Czech structuralists (whose theorizing influenced much of the rest of the world). It didn’t make the Czechs any more educated, eloquent, or better at learning foreign languages – although it did make it easier for me to study linguistics. But as I said above, there is certainly some place for metalanguage in general education. Much of it comes from stylistics but when it comes to grammar, I’d stick to about 15. This is not a definitive list:

1. Noun
2. Verb
3. Adjective
4. Adverb
5. Preposition
6. Pronoun
7. Prefix
8. Suffix
9. Clause
10. Past form of verb
11. Future form of verbs
12. Present form of verbs
13. Subject
14. Object
15. Passive

Languages with rich morphology might need a few others to cover things like case but overall in my career as a language educator, I’ve never felt the need for any more, and nor have I felt in the presence of uneducated people of people who couldn’t tell me what the infinitive was. In fact, I’d rather take some items away (like adverb, prefix, suffix, or clause) than add new ones.

Sentence diagramming is often proposed as a way of instilling some metalinguistic awareness. I don’t see any harm in that (and a lot of potential benefit). But only with the enormous proviso that students use it to learn the relationship between parts of their language in use and NOT as a gateway to a cancerous taxonomy pretending to the absolute existence of things that could easily be just artifacts of our metacognition.

Things are different when it comes to the linguistic education of language teachers. On the one hand, I’m all for language teachers having a comprehensive education in how language works. On the other hand, I have perpetrated a lot of such teacher training over the years and have watch others struggle with it, as well. And the effects are dispiriting. I’ve seen teachers who can diagram a sentence with the best of them and are still quite clueless when it comes to understanding how speech acts work. Very often language teachers find any such lessons painful and something to get through. This means that the key thing they remember about the subject is that linguistics is hard or boring or both.

Photo Credit: [CarbonNYC](http://www.flickr.com/photos/15923063@N00/5757504378/) via [Compfight](http://compfight.com) [cc](http://creativecommons.org/licenses/by/2.0/)

### *Related*
```
./2014-02-15-linguistics-according-to-fillmore.md
```
---
title: "Linguistics according to Fillmore"
date: 2014-02-15
author: Dominik Lukeš
source: https://metaphorhacker.net/2014/02/linguistics-according-to-fillmore
---

While people keep banging on about [Chomsky](http://metaphorhacker.techczech.net/2010/08/why-chomsky-doesnt-count-as-a-gifted-linguist/ "Why Chomsky doesn’t count as a gifted linguist") as being the be all and end all of linguistics (I’m looking at you philosophers of language), there have been many linguists who have had a much more substantial impact on how we actually think about language in a way that matters. In my post on why [Chomsky is not really a linguist at all](http://metaphorhacker.techczech.net/2010/08/why-chomsky-doesnt-count-as-a-gifted-linguist/ "Why Chomsky doesn’t count as a gifted linguist") I listed a few.

Sadly, one of these linguists died yesterday. It was [Charles J Fillmore](http://en.wikipedia.org/wiki/Charles_J._Fillmore) who was a towering figure among linguists without writing a single book. In my mind, he changed the face of linguistics three times with just three articles (one of them co-authored). Obviously, he wrote many more but compared to his massive impact, his output was relatively modest. His ideas have been with me all through my life as a linguist and on reflection, they form a foundation about what I know language to be. Therefore, this is not so much an obituary (for which I’m hardly the most qualified person out there) as a manifesto for a linguistics of a truly human language.

The case for Fillmore
---------------------

The first article, more of a slim monograph at 80 odd pages, was [Case for Case](http://en.wikipedia.org/wiki/Case_grammar) (which, for some reason, I first read in Russian translation). Published in 1968 it was one of the first efforts to find deeper functional connections in generative grammar (following on his earlier work with transformations). If you’ve studied Chomskean Government and Binding, this is where thematic roles essentially come from. I only started studying linguistics in 1991 which is when Case for Case was already considered a classic. Particularly in Prague where function was so important. But even after all those years, it is still worth reading for any minimalist  out there. Unlike so many in today’s divided world, Fillmore engaged with the whole universe of linguistics, citing Halliday, Tesniere, Jakobson,  Whorf, Jespersen, and others while giving an excellent overview of the treatment of case by different theories and theorists. But the engagement went even deeper, the whole notion of ‘case’ as one “base component of the grammar of every language” brought so much traditional grammar back into contact with a linguistics that was speeding away from all that came before at a rate of knots.

From today’s perspective, its emphasis on the deep and surface structures, as well as its relatively impoverished semantics may seem a bit dated, but it represents an engagement with language used to express real meaning.  The thinking that went into deep cases transformed into what has become known as [Frame Semantics](http://en.wikipedia.org/wiki/Frame_semantics_(linguistics)) (“I thought of each case frame as characterizing a small abstract ‘scene’ or ‘situation’, so that to understand the semantic structure of the verb it was necessary to understand the properties of such schematized scenes” [1982]) which is where things really get interesting.

Fillmore in the frame
---------------------

When I think about frame semantics, I always go to his 1982 article *Frame Semantics* published in the charmingly named conference proceedings ‘Linguistics in the morning calm’ but it had its first outing in 1976. George Lakoff used it as one of the key inspirations to his idealized cognitive models in *Women, Fire, and Dangerous things* which is where this site can trace its roots. As I have said before, I essentially think about metaphors as a special kinds of frames.

In it, he says:

> By the term ‘frame’ I have in mind any system of concepts related in such a way that to understand anyone of them you have to  understand the whole structure in which it fits; when one of the things in such a structure is introduced into a text, or into a conversation, all of the others are automatically made available. I intend the word ‘frame’ as used here to be a general cover term for the set of concepts variously known, in the literature on natural language understanding, as ‘schema: ‘script’, ‘scenario’, ‘ideational scaffolding’, ‘cognitive model’, or ‘folk theory’.

It is a bit of a mouthful but it captures in a paragraph the absolute fundamentals of the semantics of human language as opposed to projecting the rules of formal logic and truth conditions onto an impoverished version of language that all the generative-inspired approaches try to do. Also, it brings together many other concepts from different fields of scholarship. Last year I presented [a paper on the power of the concept of frame](http://metaphorhacker.techczech.net/2013/01/framing-constructions-as-a-bridge-between-cognition-and-culture-two-abstracts-for-cognitive-futures/ "Framing and constructions as a bridge between cognition and culture: Two Abstracts for Cognitive Futures") where I found [even more terms](http://www.slideshare.net/bohemicus/frames-and-other-animals) that have a close affinity to it which only underscores the far reaching consequences of Fillmore’s insight.

As I was looking for some more quotes from that article, I realized that I’d have to pretty much cut and paste in the whole of it. Almost, every sentence there is pure gold. Rereading it now after many many years, it’s becoming clear how many things from it I’ve internalized (and frankly, reinvented some of the ideas I forgot had been there).

Constructing Fillmore
---------------------

About the same time, and merging the two earlier insights, Fillmore started working on the principles that have come to be known as [construction grammar](http://en.wikipedia.org/wiki/Construction_grammar). Although, by then, the ideas were some years old, I always think of his 1988 article with Paul Kay and Mary Catherine O’Conner as a proper construction grammar manifesto. In it they say:

> The overarching claim is that the proper units of a grammar are more similar to the notion of construction in traditional and pedagogical grammars than to that of rule in most versions of generative grammar.

Constructions, according to Fillmore have these properties:

1. They are not limited to the constituents of a single syntactic tree. Meaning, they span what has been considered as the building blocks of language.
2. They specify at the same time syntactic, lexical, semantic and pragmatic information.
3. Lexical items can also be viewed as constructions (this is absolutely earth shattering and I don’t think linguistics has come to grips with it, yet).
4. They are idiomatic. That is, their meaning is not built up from their constituent parts.

Although Lakoff’s study of ‘there constructions’ in *Women, Fire, and Dangerous Things* came out a year earlier (and is still essential reading), I prefer Fillmore as an introduction to the subject (if only because I never had to translate it).

The beauty of construction grammar (just as the beauty of frame semantics) is in that it can bridge much of the modern thinking about language with grammatical insights and intuitions of generations of researchers from across many schools of thought. But I am genuinely inspired by its commitment to language as a whole, expressed in the 1999 article by Fillmore and Kay:

> To adopt a constructional approach is to undertake a commitment in principle to account for the entirety of each language. This means that the relatively general patterns of the language, such as the one licensing the ordering of a finite auxiliary verb before its subject in English as illustrated in 1, and the more idiomatic patterns, such as those exemplified in 2, stand on an equal footing as data for which the grammar  must provide an account.
>
> (1) a. What have you done?  b. Never will I leave you. c. So will she. d. Long may you prosper! e. Had I known, . . . f. Am I tired! g. . . . as were the others h. Thus did the hen reward Beecher.
>
> (2) a. by and large b. [to] have a field day c. [to] have to hand it to [someone]  d. (\*A/\*The) Fool that I was, . . . e. in x’s own right
>
> Given such a commitment, the construction grammarian is required to develop an explicit system of representation, capable of encoding economically and without loss of generalization all the constructions (or patterns) of the language, from the most idiomatic to the most general.

Notice that they don’t just say ‘language’ but ‘each language’. Both of those articles give ample examples of how constructions work and what they do and I commend them to your linguistic enjoyment.

Ultimately, I do not subscribe to the exact version of construction grammar that Fillmore and Kay propose, agreeing with William Croft that it is still too beholden to the formalist tradition of the generative era, but there is something to learn from on every page of everything Fillmore wrote.

Once more with meaning: the FrameNet years
------------------------------------------

Both frame semantics and construction grammar impacted Fillmore’s work in lexicography with Sue Atkins and culminated in [FrameNet](https://framenet.icsi.berkeley.edu) a machine readable frame semantic dictionary providing a model for a semantic module to a construction grammar. To make the story complete, we can even see FrameNet as a culmination of the research project begun in *Case for Case*which was the development of a “valence dictionary” (as he summarized it in 1982). While FrameNet is much more than that and has very much abandoned the claim to universal deep structures, it can be seen as accomplishing the mission of a language with meaning Fillmore set out on in the 1960s.

Remembering Fillmore
--------------------

I only met Fillmore once when he came to lecture at a summer school in Prague almost twenty years ago. I enjoyed his lectures but was really too star struck to take advantage of the opportunity. But I saw enough of him to understand why he is remembered with deep affection and admiration by all of his colleagues and students whose ranks form a veritable who’s who of linguists to pay attention to.

In [my earlier post,](http://metaphorhacker.techczech.net/2010/08/why-chomsky-doesnt-count-as-a-gifted-linguist/ "Why Chomsky doesn’t count as a gifted linguist") I compared him in stature and importance to Roman Jakobson (even if Jakobson’s crazy voluminous output across four languages dwarfs Fillmore’s – and almost everyone else’s). Fillmore was more than a linguist’s linguist, he was a linguist who mattered (and matters) to anyone who wanted (and wants) to understand how language works beyond a few minimalist soundbites. Sadly it is possible to meet graduates with linguistics degrees who never heard of Jakobson or Fillmore. While it’s almost impossible to meet someone who doesn’t know anything about language but has heard of Chomsky. But I have no doubt that in the decades of language scholarship to come, it will be Fillmore and his ideas that will be the foundation upon which the edifice of linguistics will rest. May he rest in peace.

### Post Script

I am far from being an expert on Fillmore’s work and life. This post reflects my personal perspective and lessons I’ve learned rather than a comprehensive or objective reference work. I may have been rather free with the narrative arc of his work. Please be free with corrections and clarifications. Language Log reposted [a more complete profile of his life](http://languagelog.ldc.upenn.edu/nll/?p=10497).

References
----------

* Fillmore, C., 1968. The Case for Case. In E. Bach & R. Harms, eds. *Universals in Linguistic Theory*. New York: Holt, Rinehart and Winston, pp. 1–88. Available at: http://pdf.thepdfportal.com/PDFFiles/123480.pdf [Accessed February 15, 2014].
* Fillmore, C.J., 1976. Frame Semantics and the nature of language. *Annals of the New York Academy of Sciences*, 280 (Origins and Evolution of Language and Speech), pp.20–32.
* Fillmore, C., 1982. Frame Semantics. In The Linguistic Society of Korea, ed. *Linguistics in the morning calm : International conference on linguistics : Selected papers*. Seoul  Korea: Hanshin Pub. Co., pp. 111–139.
* Fillmore, C.J., Kay, P. & O’Connor, M.C., 1988. Regularity and Idiomaticity in Grammatical Constructions: The Case of Let Alone. *Language*, 64(3), pp.501–538.
* Kay, P. & Fillmore, C.J., 1999. Grammatical constructions and linguistic generalizations: the What’s X doing Y? construction. *Language*, 75(1), pp.1–33.

### *Related*
```
./2014-03-04-what-is-not-a-metaphor-modelling-the-world-through-language-thought-science-or-action.md
```
---
title: "What is not a metaphor: Modelling the world through language, thought, science, or action"
date: 2014-03-04
author: Dominik Lukeš
source: https://metaphorhacker.net/2014/03/what-is-not-a-metaphor-modelling-the-world-through-language-thought-science-or-action
---

The role of metaphor in science debate (Background)
---------------------------------------------------

Recently, the [LSE podcast an interesting panel on the subject of “Metaphors and Science”](http://www.lse.ac.uk/newsAndMedia/videoAndAudio/channels/publicLecturesAndEvents/player.aspx?id=2289). It featured three speakers talking about the interface between metaphor and various ‘scientific’ disciplines (economics, physics and surgery). Unlike many such occasions, all speakers were actually very knowledgeable and thoughtful on the subject.

In particular, I liked Felicity Mellor and [Richard Bronk](http://www.lse.ac.uk/researchAndexpertise/experts/profile.aspx?KeyValue=r.bronk%40lse.ac.uk) who adopted the same perspective that underlies this blog and which I most recently articulated in [writing about obliging metaphors](http://metaphorhacker.net/2013/10/pervasiveness-of-oblidging-metaphors-in-thought-and-deed). [Felicity Mellor](http://www.imperial.ac.uk/AP/faces/pages/read/Home.jsp?person=f.mellor&_adf.ctrl-state=g30lcwtcs_3&_afrRedirect=1604205418236000) put it especially eloquently when she said:

> “Metaphor allows us to speak the truth by saying something that is wrong. That means **it can be creatively liberating but it can also be surreptitiously coercive**.”

This dual nature of coerciveness and liberation was echoed throughout the discussion by all three speakers. But they also shared the view of ubiquity of metaphor which is what this post is about.

What is not a metaphor? The question!
-------------------------------------

The [moderator of the discussion](https://twitter.com/bnglaser) was much more stereotypically ambivalent about such expansive attitude toward metaphor and challenged the speakers with the question of ‘what is the opposite of metaphor’ or ‘what is not a metaphor’. He elicited suggestions from the audience, who came up with this list:

> model, diagram, definition, truths, math, experience, facts, logic, the object, denotation

The interesting thing is that most of the items on this list are in fact metaphorical in nature. Most certainly models, diagrams and definitions (more on these in future posts). But mathematics and logic are also deeply metaphorical (both in their application but also internally; e.g. the whole logico mathematical concept of proof is profoundly metaphorical).

Things get a bit more problematic with things like truth, fact, denotation and the object. All of those seem to be pointing at something that is intuitively unmetaphorical. But it doesn’t take a lot of effort to see that ‘something metaphorical’ is going on there as well. When we assign a label (denotation), for instance, ‘chair’ or ‘coast’ or ‘truth’ we automatically trigger an entire cognitive armoury for dealing with things that exist and these things have certain properties. But it is clear that ‘chair’, ‘coast’ and ‘metaphor’ are not the same kind of thing at all. Yet, we can start treating them the same way because they are both labels. So we start asking for the location, shape or definition of metaphor, just because we assigned it a label in the same way we can ask for the same thing about a chair or a coast. We want to take a measure of it, but this is much easier with a chair than with a coast (thus the famous [fractal puzzle about the length of the coast of Britain](http://en.wikipedia.org/wiki/How_Long_Is_the_Coast_of_Britain%3F_Statistical_Self-Similarity_and_Fractional_Dimension)). But chairs are not particularly easy to nail down (metaphorically, of course) either, as I discussed in [my post on clichés and metaphors](http://metaphorhacker.net/2012/08/cliches-information-and-metaphors-overcoming-prejudice-with-metahor-hacking-and-getting-it-back-again).

### Brute facts of tiny ontology

So what is the thing that is not a metaphor? Both Bronk and Mellor suggested the “brute fact”. A position George Lakoff called *basic realism* and I’ve recently come to think of as *tiny ontology*. The idea, as expressed by Mellor and Bronk in this discussion, is that there’s a real world out there which impinges upon our bodily existence but with which we can only interact through the lens of our cognition which is profoundly metaphorical.

But ultimately, this does not give us a very useful answer. Either everything is a metaphor, so we might as well stop talking about it, or there is something that is not a metaphor. In which case, let’s have a look. Tiny ontology does not give us the solution because we can only access it through the filter of our cognition (which does not mean consciously or through some wilful interpretation). So the real question is, **are there some aspects of our cognition that are not metaphorical?**

### Metaphor as model (or What is metaphor)

The solution lies in the revelation hinted at above that labels are in themselves metaphors. The act of labelling is metaphorical, or rather, it triggers the domain of objects. What do I mean by that? Well, first let’s have a look at how metaphor actually works. I find it interesting that nobody during the entire discussion tried to raise that question other than the usual ‘using something to talk about something else’. Here’s my **potted summary of how metaphor works (**see more details in the [About section](http://metaphorhacker.net/about)).

> **Metaphor is a process of projecting one conceptual domain onto another.** All of our cognition involves this process of conceptual integration (or blending). This integration is fluid, fuzzy and partial. In language, this domain mapping is revealed through the process of deixis, attribution, predication, definition, comparison, etc. Sometimes it is made explicit by figurative language. Figurative language spans the scale of overt to covert. Figurative language has a conceptual, communicative and textual dimension (see my [classification of metaphor use](http://metaphorhacker.net/2013/04/how-we-use-metaphors)). In cognition, this process of conceptual integration is involved in identification, discrimination, manipulation. All of these can be more or less overtly analogical.

So all of this is just a long way of saying, that **metaphor is a metaphor for a complicated process** which is largely unconscious but not uncommonly conscious. In fact, in my research, I no longer use the term ‘metaphor’ because it misleads more than it helps. There’s simply too much baggage from what is just overt textual manifestation of metaphor – the sort of ‘common sense’ understanding of metaphor. However, this common sense ordinary understanding of ‘metaphor’ makes using the word a useful shortcut in communication with people who don’t have much of a background in this thought. But when we think about the issue more deeply, it becomes a hindrance because of all the [different types of uses of metaphor](http://metaphorhacker.techczech.net/2013/04/how-we-use-metaphors/ "How we use metaphors") I described here (a replay of the dual liberating and coercive nature of metaphor mentioned above – we don’t get escape our cognition just because we’re talking about metaphors).

In my work, I use the term **frame**, which is just a label for a sort of **conceptual** **model** (originally suggested by Lakoff as Idealized Cognitive Model). But I think in this context the term **‘model’** is a bit more revealing about what is going on.

So we can say that **every time, we engage conceptually with our experience, we are engaging in an act of modelling (or framing).** Even when I call something ‘true’, I am applying a certain model (frame) that will engage certain heuristics (e.g. asking for confirmation, evidence). Equally, if I say something like ‘education is business’, I am applying a certain model that will allow me to talk about things like achieving economies of scale or meeting consumer demand but will make it much harder to talk about ethics and personal growth. That doesn’t mean that I cannot apply more than one model, a combination of models or build new models from old ones. (*Computer virus* is a famous example, but *natural law* is another one. Again more on this in later posts.)

### Action as an example of modelling

The question was asked during the discussion by an audience member, whether I can experience the world directly (not mediated by metaphoric cognition). The answer is yes, but even this kind of experience involves modelling. When I walk along a path, I automatically turn to avoid objects – therefore I’m modelling their solid and interactive nature. Even when I’m lying still, free of all thought and just letting the warmth of the shining sun wash over me, I’m still applying a model of my position in the world in a particular way. That is, my body is not activating my ears to hear the sun rays, nor is it perceiving the bacteria going about their business in my stomach. A snake, polar bear or a fish would all model that situation in a different way.

This may seem like unnecessary extension of the notion of a model. (But it echos the position of the third speaker [Roger Kneebone](https://twitter.com/ProfKneebone) who was talking about metaphor as part of the practice of surgery.) It is not particularly crucial to our understanding of metaphor, but I think it’s important to divert us from a certain kind of perceptual mysticism in which many people unhappy with the limitations of their cognitive models engage. The point is that **not all of our existence is necessarily conceptual but all of it models our interaction with the world and switches between different models as appropriate.** E.g. my body applies different models of the world when I’m stepping down from a step on solid ground or stepping into a pool of water.

The languages of metaphor: Or how a metaphor do
-----------------------------------------------

I am aware that this is all very dense and requires a lot more elaboration (well, that’s why I’m writing a blog, after all). But I’d like to conclude with a warning that the language used for talking about metaphor brings with it certain models of thinking about the world which can be very confusing if we don’t let go of them in time. Just the fact that we’re using words is a problem. When words are isolated (for instance, in a dictionary or at the end of the phrase ‘What is a…’) it only seems natural that they should have a definition. We have a word “metaphor” and it would seem that it needs to have some clear meaning. The kind of thing we’re used to seeing on the right-hand side of dictionaries. But **insisting that dictionary-like definition is what must be at the end of the journey is to misunderstand what we’ve seen along the way**.

There are many contexts in which the construction “metaphor is…” is not only helpful but also necessary. For example when clarifying one’s use: “In this blog, what I mean by metaphor is much broader than what traditional students of figurative language meant by it.” But in the context of trying to get at what’s going on in the space that we intuitively describe as metaphorical, we should almost be looking for something along to the lines of “metaphor does” or “metaphors feels like”. Or perhaps refrain from the construction “metaphor verb” altogether and just admit that **we’re operating in a kind of metaphor-tasting soup**. We can get at the meaning/definition by disciplined exploration and conversation.

In conclusion, **metaphor is a very useful model when thinking about cognition, but it soon fails us, so we can replace it with more complex models, like that of a model.** We are then left with the rather unsatisfactory notion of a metaphor of metaphor or a model of model. The sort of dissatisfaction that lead Derrida and his like to the heights of obscurity. I think we can probably just about avoid deconstructionist obscurantism but only if we adopt one of its most powerful tools, **the fleeting sidelong glance** (itself a metaphor/model). Just like the Necker cube, this life on the edge of metaphor is constantly shifting before our eyes. Never quite available to us perceptually all at once but readily apprehended by us in its totality. At once opaque and so so crystal clear. Rejoice all you parents of freshly screaming thoughts. It’s a metaphor!  
Photo Credit: [@Doug88888](http://www.flickr.com/photos/29468339@N02/3025297913/) via [Compfight](http://compfight.com) [cc](http://creativecommons.org/licenses/by-nc-sa/2.0/)

### *Related*
```
./2014-05-17-what-does-it-mean-when-words-really-mean-something-dismiss-the-miss.md
```
---
title: "What does it mean when words ‘really’ mean something: Dismiss the Miss"
date: 2014-05-17
author: Dominik Lukeš
source: https://metaphorhacker.net/2014/05/what-does-it-mean-when-texts-really-mean-something
---

A few days ago, I tweeted a link to an [article in TES](http://www.tes.co.uk/article.aspx?storycode=6427726):

Today, I got the following response back:

@lizzielh is absolutely right. As the title of an as yet unpublished blog post of mine goes: **“Words don’t mean things, people mean things”**. I even wrote a whole [book chapter on that with the same title as this post](https://www.academia.edu/7069654/What_does_it_mean_when_texts_really_mean_something_Types_of_evidence_for_conceptual_patterns_in_discourse).

Indeed, if it had been me writing on the topic, I would have chosen a more judicious title. Such as “The legacy of discrimination behind the humble Miss” or “Past and present inequalities encoded in the simple Miss”.

In fact, the only reason I tweeted that article in the first place was because it was making a much more subtle and powerful point than simple etymology (as you would expect from one based on the work of [the eminent scholar of language and gender Jennifer Coates](http://www.roehampton.ac.uk/staff/Jen-Coates/)). Going all the way back to *Language and the Woman’s Place* and even before, people have been trying to peg the blame on simple words. All along the response has been, but these are just words, we don’t mean anything bad by them. Or, these are just words, the real harm is done in the real world.

Many women I meet continue to like the Miss/Mrs distinction despite the long availability of the now destigmatized Ms. It was not too long ago that I set up a sign up form with only *Prof Dr Mr Ms* and got lots of complaints from women who wanted to keep their *Miss* or *Mrs*. So restigmatizing *Miss* is actively harmful to the self-image of many women whose identity is tied with that label. Feminists tend to make light of the ‘unfeminist’ cry of “I like it when men open the door to me”, or “Carrying my bag for me just shows respect”. Or going back even further, “I don’t need a vote, I exercise my influence through my husband.” But **change is literally hard, it takes time and effort, so an attempt at making the world better will always making temporarily wors**e (at least for some people).

The fact is that *Miss* is bound up in a network of meanings, interactions and power relations. And even if it takes some mental pain, it’s worth picking at all it covers up.

But not every minute of every day. **Sometimes, we need to say something to get from conversational point A to conversational point B and even a laden word may be better than no word.** As one of the respondents in the article says:

> My response is always that my name isn’t Miss; it’s Mrs Coslett. But if I’m in a school where students don’t know me and they call me Miss, I’m fine with that. They’re showing respect by giving me a title, rather than ‘hey’ or ‘oi, you’ or whatever.

Most of the time contentious words are used, challenging them is not feasible. But she’s wrong in her conclusion:

> That’s just the way the English language works.

That’s absolutely not true. Just like words don’t mean anything on their own, **language does not just work. It’s used to do things** (to riff on Austin’s famous book) by people. It is not always used purposefully but its use is always bound in the many ways and means of people. The way we speak now is a result of centuries of little power plays, imitations of prestige, prescriptions of obedience. When you look closer, they’re all easy to see.

Things have let up considerably since the 1970s. Many fewer people are concerned about how language encodes gender inequality and it’s worthwhile reminding ourselves that many of the historical unfairnesses hidden in word histories are still with us. Just like you can’t get away with saying “I didn’t mean anything by the ‘n’ word”, you can’t just shrug off the critique of the complex tapestry of gender bias in ‘Miss’.

*Miss* does not “really mean” anything. It’s just a sequence of letters or sounds. And most people using it do not “really mean” anything by it. Or it does not “really mean” anything to them. But context is everything.

It is a truism to say that racism will be done away with when people don’t dislike each other because of the color of their skin. But the opposite is the case. The sign that racism has disappeared is when I can say “I really don’t like black people” simply because I don’t like the color of their skin in the same way I may prefer redheads to blondes. Preference for skin colour is then just a harmless quirk. But we’re centuries away from that because any such preference is tied to a system of discrimination going back a long way. (BTW: just to avoid misunderstanding, I personally find black skin beautiful.)

The same thing applies to “Miss”, **we can’t just turn our back on its pernicious potential.** Most of the time it’s hidden from sight but it’s recoverable at a moment’s notice. Because we live in a world where male is still the default position. We have to work to change that. Change our minds, hearts, cognitions and languages. They don’t just work on their own. We make them work. So let’s make them work for us. The ‘us’ we want to be, rather than the ‘us’ we used to be in the bad old days.

Photo Credit: [abdallahh](http://www.flickr.com/photos/22168167@N00/5305099871/) via [Compfight](http://compfight.com) [cc](https://creativecommons.org/licenses/by-nc/2.0/)

### *Related*
```
./2014-08-03-anthropologists-metaphorical-shenanigans-or-how-not-to-research-metaphor.md
```
---
title: "Anthropologists’ metaphorical shenanigans: Or how (not) to research metaphor"
date: 2014-08-03
author: Dominik Lukeš
source: https://metaphorhacker.net/2014/08/anthropologists-metaphorical-shenanigans-or-how-not-to-research-metaphor
---

Over on the excellent [‘Genealogy of Religion’](http://genealogyreligion.net/invisible-disenchantments), Cris Campbell waved a friendly red rag in front of my eyes to make me incensed over exaggerated claims (some) anthropologists make about metaphors. I had expressed some doubts in previous comments but felt that perhaps this particular one deserves its own post.

The book Cris refers to is a collection of essays  [*America in 1492: The World of the Indian Peoples Before the Arrival of Columbus*](http://www.amazon.com/America-1492-Peoples-Arrival-Columbus/dp/0679743375)(1991, ed. Alvin Josephy) which also contains an essay by Joel Sherzer called “A Richness of Voices”.  I don’t have the book but I looked up a few quotes on metaphor from the book.

The introduction summarizes the conclusion thus:

> “Metaphors about the relations of people to animals and natural forces were essential to the adaptive strategies of people who lived by hunting.” (p. 26)

This is an example what Sherzer has to say about metaphor:

> “Another important feature of native vocabularies was the metaphor – the use of words or groups of words that related to one realm of meaning to another. To students they provide a window into American Indian philosophies. … The relationship between the root and the derived form was often metaphorical.” (p. 256)

The first part of both statements is true but the second part does not follow. That is just bad bad scholarship. I’m not a big Popperian but if you want to make claims about language you have to **postulate some hypotheses and try really really really hard to disprove them**. Why? Because there are empirical aspects to the questions that can have empirical support. Instead the hypotheses are implied and no attempt is made to see if they work. So this is what I suggest are Sherzer’s **implicit hypotheses**that should be made explicit and tested:

1. American Indian languages use metaphors for essential parts of their understanding of the world. (**Corollary**: If we understand the metaphors, we can understand the worldview of the speakers of those languages.)
2. American Indian language use of metaphors was necessary to their survival because of their hunter-gatherer lifestyles.
3. American Indian languages use metaphor more than the SAE (Standard Average European) languages.

**Re 1:** This is demonstrably true. It is true of all languages so it is not surprising here. However, exactly how central this metaphorical reasoning is and how it works cognitively is an open question. I addressed some of this in [my review of Verena Haser’s book](https://www.academia.edu/7857439/Review_Haser_Verena_Metaphor_Metonymy_and_Experientialist_Philosophy_Challenging_Cognitive_Semantics).

As to the corollary, I’ve mentioned this time and time again. There is no straightforward link between metaphor and worldview. War on poverty, war on drugs, war on terror all draw on different aspects of war. As does Salvation Army, Peace Corps and the Marine Corps. You can’t say that Salvation Army subscribes to the same level of violence than a ‘real’ Army. The same goes for metaphors like ‘modern Crusades’ or the various notions of ‘Jihad’. Metaphor works exactly because it does not commit us to a particular course of action.

That’s not to say that the use of metaphor can never be revealing of underlying conceptualizations. For instance, calling something a rebellion vs. calling it a ‘civil war’ imposes a certain order on the configuration of participants and reveals the speaker’s assumptions. But calling someone ‘my rock’ does not reveal any cultural preoccupation with rocks. The latter (I propose) is much more common than the former.

**Re 2:** I think this is demonstrably false. From my (albeit incomplete) reading of the literature, most of the time metaphors just got in the way of hunting. Thinking of the ‘Bear’ as the father to whom you have to ritually apologise before killing him seems a bit excessive. Over metaphorisation of plants and animals has also led to their over or under exploitation. E.g. the Nuer not eating birds and foregoing an important source of nutrition or the Hawaiians hunting rare birds to extinction for their plumes. Sure, metaphors were essential to the construction of folk taxonomies but that is equally true of Western ‘scientific’ taxonomies which map into notions of descent, progress and containment. (PS: I’ve been working on a post called ‘Taxonomies are metaphors’ where I elaborate on this).

**Re 3:** This is just out and out nonsense. The example given are stuff like bark of the tree being called ‘skin’ and spatial prepositions like ‘on top of’ or ‘behind’ being derived from body parts. The author obviously did not bother to consult an English etymological dictionary where he could discover that ‘top’ comes from ‘tuft’ as in ‘tuft of hair’ (or is at the very least connected). And of course, the connection of ‘behind’ to body part (albeit in the other direction) should be pretty obvious to anyone. Anyway, body part metaphors are all over all languages in all sorts similar but inconsistent ways: mountains have feet (but not heads), human groups have heads (but not feed), trees have trunks (but not arms), a leader may have someone as their right arm (but not their left foot). And ‘custard has skin’ in English (chew on that). In short, unless the author can show even a hint of a quantitative tendency, it’s clear that American Indian languages are just as metaphorical as any other languages.

Sherzer comes to this **conclusion**:

> “Metaphorical language pervaded the verbal art of the Americas in 1492, in part because of the closeness Native American had always felt to the natural world around them and their social, cultural, aesthetic, and personal identification with it and in part because of their faith in the immediacy of a spirit world whose presence could be manifest in discourse.”

But that displays fundamental misunderstanding of how metaphor works in language. ‘Faith in immediacy’ has no link to the use of metaphors (or at the very least Sherzer did not demonstrate any link because he confused lyricism with scholarship). Sure, metaphors based on the natural world might indicate ‘closeness to the natural world around’ but that’s just as much of a discovery as saying that people who live in an area with lots of oaks have a word that means ‘oak’. The opposite would be surprising. The problem is that if you analyzed English without preconceptions about the culture of its speakers you would find as much of a closeness to the natural world (e.g a person can be ‘a force of nature’, ‘eyes like a hawk’, ‘dirty as a pig’, ‘wily as a fox’, ‘slow as a snail’, ‘beautiful as a flower’, ‘sturdy as a tree’, etc.).

While this seems deep, it’s actually meaningless.

> “The metaphorical and symbolic bent of Mesoamerica was reflected in the grammars, vocabularies, and verbal art of the region. (p. 272)

Mesoamerica had no ‘symbolic bent’. Humans have a symbolic bent, just like they have spleens, guts and little toes.  So let’s stop being all gushy about it and study things that are worth a note.

PS: This just underscores [my comments on an earlier post of Cris’](http://genealogyreligion.net/reading-aztec-ritual) where I took this quote to task:

> **“Nahuatl was and is a language rich in metaphor, and the Mexica took delight in exploring veiled resemblances…”** This is **complete and utter nonsense.** Language is rich in metaphor and all cultures explore veiled resemblances. That’s just how language works. All I can surmise is that the author did not learn the language very well and therefore was translating some idioms literally. It happens. Or she’s just mindlessly spouting a bullshit trope people trot out when they need to support some mystical theory about a people.
>
> And the conclusion!? “In a differently conceptualized world concepts are differently distributed. If we want to know the metaphors our subjects lived by, we need first to know how the language scanned actuality. Linguistic messages in foreign (or in familiar) tongues require not only decoding, but interpretation.” Translated from bullshit to normal speak: “When you translate things from a foreign language, you need to pay attention to context.” Nahuatl is no different to Spanish in this. In fact, the same applies to British and American English.

Finally, this metaphor mania is not unique to anthropologists. I’ve seen this in philosophy, education studies, etc. Metaphors are seductive… Can’t live without them…

Image by [moune.drah](https://www.flickr.com/photos/70148128@N00/12893857533/) CC BY NC SA

### *Related*
```
./2014-11-05-what-language-looks-like-dictionary-and-grammar-are-to-language-what-standing-on-one-foot-is-to-running.md
```
---
title: "What language looks like: Dictionary and grammar are to language what standing on one foot is to running"
date: 2014-11-05
author: Dominik Lukeš
source: https://metaphorhacker.net/2014/11/what-language-looks-like-dictionary-and-grammar-are-to-language-what-standing-on-one-foot-is-to-running
---

Background
----------

Sometimes a rather obscure and complex analogy just clicks into place in one’s mind and allows a slightly altered way of thinking that just makes so much sense it hurts. Like putting glasses on in the morning and the world suddenly snapping into shape.

This happened to me this morning when reading the [Notes from Two Scientific Psychologists blog](http://psychsciencenotes.blogspot.co.uk/2014/10/do-people-really-not-know-what-running.html) and the post *Do people really not know what running looks like?*

It describes the fact that many famous painters (and authors of instructional materials on drawing) did not depict running people correctly. When running, it is natural (and essential) to put forward the arm opposite the leg that’s going forward. But many painters who depict running (including the artist who created the poster for the 1922 Olympics!) do it the wrong way round. Not just the wrong way, the way that is almost impossible to perform. And this has apparently been going on for as long depiction has been a thing. But it’s not just artists (who could even argue that they have other concerns). What’s more when you ask a modern human being to imitate somebody running by assuming a stationary pose (as somebody did on the website [Phoons­](http://www.phoons.com)) they will almost invariably do it the wrong way round. Why? There are really two separate questions here.

1. Why don’t the incorrect depictions of running strike most people as odd?
2. Why don’t we naturally arrange our bodies into the correct stance when asked to imitate running while standing still?

Andrew Wilson (one of the two psychologists) has the perfect answer to question 2:

> **Asking people to pose as if running is actually asking them to stand on one leg in place**, and from their point of view these are two very different things with, potentially, two different solutions. [my emphasis]

And he prefaces that with a crucial point about human behavior:

> people’s behaviour is shaped by the demands of the task they are actually solving, and that might not be the task you asked them to do.

Do try this at home, try to imitate a runner standing up, then slowly (mime-like), then speed it up. Standing into the wrong configuration is the natural thing to do. Doing it the ‘right’ way round, is hard. It’s not until I sped up into an actual run that my arms found the opposite motion natural until I couldn’t keep track of what was going on any more. I would imagine that this would be the case for most people. In fact, the few pictures I could find of runners arranged standing at the start of the race have most of them also with the ‘wrong’ hand/leg position and they’re not even standing on one leg. (See [here](http://www.allposters.com/-sp/Female-Runners-at-the-Start-of-a-Track-Race-Posters_i6071560_.htm) and [here](http://www.allposters.com/-sp/Female-Runners-at-the-Start-of-a-Track-Race-Posters_i6071576_.htm).)

Which brings us back to the first question. Why does not anybody notice? I personally find it really hard to even identify the wrong static description at a glance. I have to slow down, remember what is correct, then match it to the image. What’s going on? We obviously don’t have any cognitive control over the part of running that controls the movement ofarms in relation to the movement of legs. We also don’t have any models or social scripts that pay attention to this sort of thing. It is a matter of conscious effort, a learned behaviour, to recognize these things.

Why is this relevant to language?
---------------------------------

If you ask someone to describe a language, they will most likely start telling you about the words and the rules for putting them together. In other words, compiling a dictionary and a grammar. They will say something like: “In Albanian, the word for ‘bread’ is ‘bukë'”. Or they will say something like “English has 1 million words.”, “Czech has no word for training.” or “English has no cases.”

All of these statements reflect a notion of language that has a list of words that looks a little like this:

> bread n. = 1. baked good, used for food, 2. metaphor for money, etc.  
> eat v. = 1. process of ingestion and digestion, 2. metaphor, etc.  
> people n. plural = human beings

And a grammar that looks a little bit like this.

> Sentence = Noun (subj.) + Verb + Noun (obj.)

All of this put together will give us a sentence like:

> `People eat food.`

All you need is a long enough list of words and enough (but not as many) rules and you got a language.

But as linguists have discovered through not a bit of pain, you don’t have a language. You have something that looks like a language but not something that you can actually speak as a language. It’s very similar to language but it’s not language.

Kind of like the picture of the runner with the arms going in the opposite direction. It looks very much like someone running but it’s not, it’s just a picture of them imitating running and the picture is fundamentally mismatched with the stated aim. Just not in a way that is at all obvious to most people most of the time.

Why grammars and dictionaries seem like a good portrait of language
-------------------------------------------------------------------

So, we can ask the same two questions again.

1. Why does the stilted representation of language as rules and words not strike most people (incl. Steven Pinker) as odd?
2. Why don’t we give more realistic examples of language when asked to imitate one?

Let’s start with question 2 again which will also give us a hint as to how to answer question 1.

So why, when asked to give an example of English, am I more likely to come up with:

> John loves Mary.

or

> Hello. Thank you. Good bye.

than

> Is it cold in here? Could you pass the sugar, please. No no no. I’ll think about it?

It’s because I’m achieving a task that is different from actually speaking the language. When asked to illustrate a language, we’re not communicating anything in the language. So our very posture towards the language changes. We start thinking in equivalencies and left and right sides of the word (word = definition) and building blocks of a sentence. Depending on who we’re speaking to, we’ll choose something very concrete or something immediately useful. We will not think of nuance, speech acts, puns or presupposition.

But the vast majority of our language actions are of the second kind. And many of the examples we give of language are actually good for only one thing: Giving an example of the language. (Such as the famous example from classical logic illustrating a proposition ‘A man walks’ which James MacCawley analysed as only being usable in one very remote sense.)

As a result, if we’re given the task of describing language, coming up with something looking like a dictionary and a grammar is the simplest and best way of fullfilling the assignment. If we take a scholarly approach to this task over generations, we end up with something that very much looks like the modern grammars and dictionaries we all know .

The problem is that these don’t really give us “a picture of language”, they give us “a picture of a pose of language” that looks so much like language to our daily perception, that we can’t tell the difference. But in fact, they are exactly the opposite of what language looks like in motion.

Now, we’re in much more complex waters than running. Although, I imagine the exact performance of running is in many ways culturally determined, the amount of variation is going to be limited by the very physical nature of the relatively simple task. Language on the other hand, is almost all culture. So, I would expect people in different contexts to give different examples. I read somewhere (can’t track down the reference now) that Indian grammarians tended to give examples of sentences in the imperative. Early Greeks (like Plato) had a much more impoverished view of the sentence than I showed above. And I’m sure there are languages with even more limited metalanguage. However, the general point still stands. The way we tend to think about language is determined by the nature of the task

The key point I’ve repeated [over](http://metaphorhacker.techczech.net/2014/01/5-things-everybody-should-know-about-language-outline-of-linguistics-contribution-to-the-liberal-arts-curriculum/) and [over](http://linguistics.stackexchange.com/questions/8738/is-language-infinite/8748#8748) (following Michael Hoey) is that grammars and dictionaries are above all texts written in the language. They don’t stand apart from it. They have their own rules, conventions and inventories of expression. And they are susceptible to the politics and prejudices of their time. Even the OUP. At the same time, they can be very useful tools to developing language skills or dealing with unfamiliar texts. But so does asking a friend or figuring out the meaning in context.

Which brings us to question 1. Why has nobody noticed that language doesn’t quite move the way we paint it? The answer is that – just like with running – people have. But only when they try to match the description with something that is right in front of them. Even then, they frequently (and I’m talking about professional linguists like Stephen Pinker here) ignore the discrepancy or ascribe it to a lack of refinement of the descriptions. But most of the time, the tasks that we fulfil with language do not require us to engage the sort of metacognitive aparatus that would direct us to reflect on what’s actually going on.

What does language really look like
-----------------------------------

So is there a way to have an accurate picture of language? Yes. In fact, we already have it. It’s all of it. We don’t perhaps have all the fine details, but we have enough to see what’s going on – if we look carefully. It’s not like linguists of all stripes have not described pretty much everything that goes on with language in one way or another. The problem is that they try to equate the value of a description to the value of the corresponding model that very often looks like an algorithm amenable to being implemented in a computer program. So, if I describe a phenomenon of language as a linguist, my tendency is to immediately come up with a fancy looking notation that will look like ‘science’. If I can make it ‘mathematical’, all the better. But all of these things are only models. They are ways of achieving a very particular task. Which is to – in one way or another – model language for a particular purpose. Development of AI, writing of pedagogic grammars, compiling word lists, predicting future trends, tracing historical developments, estimating psychological impact, etc. All of these are distinct from actual pure observation of what is going on. Of course, even simple description of what I observe is a task of its own with its own requirements. I have to choose what I notice and decide what I report on. It’s a model of a sort, just like an accurate painting of a runner in motion is just a model (choosing what to emphasize, shadows, background detail, facial expression, etc.) But it’s the task we’re really after: Coming up with as accurate and complete a picture of language as is possible for a collectivity of humans.

People working in construction grammars in the usage-based approach are closest to the task. But they need to talk with people who work on texts, as well, if they really want to start painting a fuller picture.

Language is signs on doors of public restrooms, dirty jokes on TV, mothers speaking to children, politicians making speeches, friends making small talk in the street, newscasters reading the headlines, books sold in bookshops, gestures, teaching ways of communication in the classroom, phone texts, theatre plays, songs, blogs, shopping lists, marketing slogans, etc.

Trying to reduce their portrait to words and rules is just like trying to describe a building by talking about bricks and mortar. They’re necessary and without them nothing would happen. But a building does not look like a collection of bricks and mortar. Nor does knowing how to put a brick to brick and glue them together help in getting a house built. At best, you’d get a knee-high wall. You need a whole of other knowledge and other kinds of strategies of building corners, windows, but also getting a planning permission, digging a foundation, hiring help, etc. All of those are also involved in the edifices we construct with language.

An easy counterargument here would be: That’s all well and good but the job of linguistics is to study the bricks and the mortar and we’ll leave the rest to other disciplines like rhetoric or literature. At least, that’s been Chomsky’s position. But the problem is that even the words and grammar rules don’t actually look like what we think they do. For a start, they’re not arranged in any of the ways in which we’re used to seeing them. But they probably don’t even have the sorts of shapes we think of them in. How do I decide whether I say, “I’m standing in front of the Cathedral” or “The Cathedral is behind me.”? Each of these triggers a very different situation and perspective on exactly the same configuration of reality. And figuring out which is which requires a lot more than just the knowledge of how the sentence is put together. How about novel uses of words that are instantly recognizable like “I sneezed the napkin off the table.” What exactly are all the words and what rules are involved?

Example after example shows us that language does not look very much like that traditional picture we have drawn of it. More and more linguists are looking at language with freshly open eyes but I worry that they may get off task when they’re asked to make a picture what they see.

Where does the metaphor break
-----------------------------

Ok, like all metaphors and analogies, even this one must come to an end. The power of a metaphor is not just finding where it fits but also pointing out its limits.

The obvious breaking point here is the level of complexity. Obviously, there’s only one very discretely delineated aspect of what the runners are doing that does not match what’s in the picture. The position of the arms. With language, we’re dealing with many subtle continua.

Also, the notion of the task is taken from a very specific branch of cognitive psychology and it may be inappropriate extending it to areas where tasks take a long time, are collaborative and include a lot of deliberately chosen components as well as automaticity.

But I find it a very powerful metaphor nevertheless. It is not an easy one to explain because both fields are unfamiliar. But I think it’s worth taking the time with it if it opens the eyes of just one more person trying to make a picture of language looks like.

### *Related*
```
./2018-03-19-10-ways-in-which-music-is-like-language-and-8-more-important-ways-in-which-it-is-not.md
```
---
title: "10 ways in which music is like language and 8 (more important) ways in which it is not"
date: 2018-03-19
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/03/10-ways-in-which-music-is-like-language-and-8-more-important-ways-in-which-it-is-not
---

People often talk about music as if it were language. Leonard Bernstein even recorded a series of lectures applying [Chomsky’s theory of generative grammar to music](https://www.youtube.com/watch?v=MB7ZOdp__gQ). [Chomsky himself](https://www.youtube.com/watch?v=Kojvij-PNq8) answered a question on this in a not very satisfying manner. Some people can get very exercised over this.

But it seems to me that a playing around with strengths and weakness of the music = language metaphor can help us come to grips with the question a bit better. We can find a number of mappings between music and language but an equal number of mis-mappings. We do not need to go very far into it to see where they are. That does not mean that a deeper investigation into musical properties of language and linguistic properties of music cannot be fruitful. And obviously they are both universal human faculties — but looking for a musical essence in language or a linguistic essence in music is what a metaphor-aware approach to this question is hoping to warn against.

Here are some of the obvious similarities and dissimilarities. (Note: After, I finished my list, I came across a Chomskean [comparison by Jackendoff](http://ase.tufts.edu/cogstud/jackendoff/papers/Parallels%26nonparallelsprintversion.pdf)which has a slightly different focus but comes to the same general conclusion.)

### **Music is like (a) language in that:**

1. It can be described through **a system of rules that operate on a limited vocabulary**. There are 12 notes (on the Western chromatic scale) that can produce an infinite variety of melodies just purely in their combination further enhanced by their combination with rhythms, tempos and harmonies. (Although I have argued elsewhere that [language is not actually much like this](http://metaphorhacker.net/2014/11/what-language-looks-like-dictionary-and-grammar-are-to-language-what-standing-on-one-foot-is-to-running/), at all.)
2. It combines **small building blocks into larger components**that are like words, phrases, sentences and text. In fact, we talk about phrasing in music. But we have things like bars, stanzas, movements, etc.
3. It is **recursively expressive**. I can embed little segments of music in others indefinitely. Bach’s variations are an example of this as is jazz improvisation.
4. It has **dual articulation**in that smaller segments like scales are organized independently of large segments. This is well-known about language (in certain circles). We articulate sounds into words and words into statements at the same time but also seemingly independently of each other — we know this because we can be good at one and bad at the other (thus dual articulation). In music, producing individual notes (e.g. fingering on piano or guitar, or breathing and embouchure on a trumpet or trombone) is a skill independent of expressing the musical ideas contained in the notes.
5. It has **phraseology and idioms**: We speak of musical phrasing but that is more a question of production. But music also has set ways of expressing certain things. There are things like chord progressions or minor or major modes that combine together to express musical meaning. They are more than the sum of their parts and form their own building blocks.
6. It can **cross-reference**between compositions (texts): We can hear echoes of folk songs in classical music or we see direct quotations of melodies in jazz. (But it should be noted that this is much less pervasive than in language where co-reference is one of the core components of language.)
7. It can communicate emotion both **segmentally**(sequences of notes) and **suprasegmentally**(expression, emphasis, etc.) In the same way, any phrase (such as *Please, sit down.)*can be pronounced in many different ways (e.g. in a welcoming, quizzical or threatening manner; deliberately, offhand, formally or casually, etc.).
8. It has **styles, genres and dialects or even accents**. We can instantly recognise music recorded in different time periods or in different styles. Even individual artists have particular ways of expressing themselves musically that can be imitated or parodied. YouTube is full of videos of people playing X in the style of Y.
9. It can be **acquired and learned**. To reach a ‘fluency’ in music requires an effort that is not dissimilar to the acquisition or learning of language. Part of it happens naturally, simply through exposure to music and part of it is formal — such as learning words to name parts of music, such as notes, chords, harmony, etc. or learning to ‘read sheet music’.
10. It is **culturally conditioned**. Different cultures have developed very different takes on what music sounds like. Chinese music does not sound very musical to Western ears due to the very different approach to tonality.

This list makes it seem like music and language are very similar. But the next list of dissimilarities shows that they are also different in fundamental ways.

### **Music is NOT like (a) language in that:**

1. It cannot be used to directly **communicate propositional meaning**. I can say, ‘my house is right at the end of the street’ or ‘that will be 50 cents’. But there’s no way to express this kind of content in music. Sometimes music tries to imitate language (Janáček is often cited doing that) but without the words, nobody would know what an opera is about.
2. It has a **radically smaller set of building blocks and rules**for their combination than language. There are only 12 intervals/tones in Western Music. But this in itself would not be a problem. There are languages with similarly low numbers of phonemes (distinct sounds). However, there is no intermediary unit of expression equivalent to the word. The rules of melodic composition operate directly on these 12 (or more if we include microtones) tones.
3. It does not have **internal instruments of disambiguation**. Being able to repair a conversation that is broken with phrases like ‘what did you say’ or ‘can you say this again’ is a fundamental part of the communicative process. Without them, language would not be nearly as useful. There’s nothing like that to be found within the ‘communicative’ inventory of music that does not rely on verbal or written language in one way or another.
4. It **can only be universally acquired in the most rudimentary sense**(i.e. everybody can hum a tune but very few people can play an instrument). Everybody can and does learn their first language. And everybody acquires some musicality as part of their socialisation into their culture. But most of what we would consider musical fluency is learned through some means of instruction. Music (in this strict sense) is more like written than spoken language.
5. **There is a much greater difference between receptive and productive competence.**Everybody knows more of their language receptively (passively) than productively. Depending on context, this gap is very small or very large. A person speaking a language of a small community without a lot of specialisation will have a smaller gap between what they can say and what they can understand (although there are many specialised languages even in these contexts). But this difference will be greater when it comes to technical language between a first-year university student and their professor. But in music, everybody can listen passively and receive most of the intended effect while their ability to produce the same music will be severely limited. Many people can hum back a simple tune but they cannot reproduce a full musical performance. Even professional musicians will vary in their ability here.
6. There is **much greater variability in individuals’ ability to produce music**beyond the most trivial. It requires effort and study to produce music in a way that we think of as music. We can say that everyone is musical to some degree but most people cannot actually produce anything beyond the simplest of tunes. However, in language, everybody can communicate (even people with impairments) to a significant degree. The differences in competence only appear at the higher levels.
7. Much more of the **production process requires cooperation**among individuals. While not a requirement, most music we consume is produced by groups of people. Or if not another person, it requires an instrument made by another person. Language production (at least in spoken form) is primarily by individuals. (Although, there are instances of group production — theatre, speeches, etc.)
8. It is much more **limited in its dialogic potential**(i.e. it is most often used for one-way communication between few producers and more recipients or joint co-production of producer/recipients). Language is fundamentally dialogic. Anything that is said can be responded to. Questions can be answered, propositions can be countered or elaborated. Music, on the other hand, is primarily declarative. Of course, metaphorically, we can talk about dialogic elements in music. In jazz or blues, we have call and response, in classical music we have things like counterpoint. We can also talk about members of an orchestra communicating and responding to each others’ musical ideas. But there is no such thing in music as saying: ‘No, I disagree with you about X, instead, I believe Y and this is why.’

Ultimately, this is not all that important. We know what language is and we know what music is. Saying one is or is not like the other in some way won’t change any of that. However, it can help us think more clearly about them and avoid ignoring important aspects and unique properties of both.

### **Note: What is music**

You often hear popularising musicians saying things like ‘Everybody is musical’ or ‘everything is music’. But that is not what most people’s intuitions about music tell them. For most people, music is the sort of thing they hear on the radio. It is the result of composition and production. There are instruments involved and skills and ability to play those instruments. That is the sense in which I’m comparing language to music. When I sing in the shower, I may be engaging in a musical activity but it is not the prototypical meaning of the word. And if we try to build our case for music around that, we’d be leaving other important aspects out.

### **Language of X**

Lists similar to this one could be constructed for other cases where people talk about the ‘language of X’. Programming, gestures, art, or architecture. These would probably end up with lists that overlap with this one in many ways.

There are different cliches in use about many of these domains. So people tend to overestimate the extent to which facial expressions or architecture or art are like language but underestimate the degree to which programming languages are like natural language.

So in some contexts, I’d want to stress the dissimilarities. When people say things like ‘He can express all he needs through dance.’ or ‘90% of all language is nonverbal’, we would want to point to the propositional and dialogic aspects of language that are lacking in these domains.

But in other contexts, we’d want to point to the parallels. For instance, we may want to remind ourselves that programming languages are more like natural language in many (but not all) of the ways, music is like language. They have dialects, phrases and idioms, multiple levels of articulation, recursiveness (duh!), etc.

**Note:**

This post started life as [an answer on Stack Exchange](https://linguistics.stackexchange.com/posts/10013/revisions) which I then [cleaned up for Tumblr](http://metaphornik.tumblr.com/post/107870296587/music-is-like-a-natural-language-in-some-respects). This is an expanded version. It is also posted on Medium. This version has been slightly amended for [spelling and punctuation](https://medium.com/metaphor-hacker/10-ways-in-which-music-is-like-language-and-8-more-important-ways-in-which-it-is-not-7a1e82aad88c).

### *Related*
```
./2018-05-16-how-to-read-women-fire-and-dangerous-things-guide-to-essential-reading-on-human-cognition.md
```
---
title: "How to read ‘Women, Fire and Dangerous Things’: Guide to essential reading on human cognition"
date: 2018-05-16
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/05/how-to-read-women-fire-and-dangerous-things-guide-to-essential-reading-on-human-cognition
---

Note:
-----

These are rough notes for a metaphor reading group, not a continuous narrative. Any comments, corrections or elaborations are welcome.

Why should you read WFDT?
-------------------------

**Women, Fire, and Dangerous Things: What Categories Reveal About the Mind** is still a significantly underappreciated and (despite its high citation count) not-enough-read book that has a lot to contribute to thinking about how the mind works.

I think it provides one of the most concise and explicit models for how to think about the mind and language from a cognitive perspective. I also find its argument against the still prevalent approach to language and the mind as essentially fixed objects very compelling.

The thing that has been particularly underused in subsequent scholarship is the concept of ‘ICMs’ or ‘Idealised Cognitive Models’ which both puts metaphor (for work on which Lakoff is most well known) in its rightful context but also outlines what we should look for when we think about things like frames, models, scripts, scenarios, etc. Using this concept would have avoided many undue simplifications in work in the social sciences and humanities.

Why this guide
--------------

Unfortunately, the concision and explicitness I extolled above is surrounded by hundreds of pages of arguments and elaborations that are often less well-thought out than the central thesis and have been a vector for criticism (I’ve responded to some of these in my [review of Verena Haser’s book](https://www.academia.edu/7857439/Review_Haser_Verena_Metaphor_Metonymy_and_Experientialist_Philosophy_Challenging_Cognitive_Semantics)).

As somebody who translated the whole book into Czech and penned extensive commentary on its relevance to the structuralist linguistic tradition, I have perhaps spent more time with it than most people other than the author and his editors.

Which is why when people ask me whether to read it, I usually recommend an abreviated tour of the core argument with some selections depending on the individual’s interest.

Here are some of my suggestions.

Chapters everyone should read
-----------------------------

### Chapters 3, 4, 5, 6 – Core contribution of the book – Fundamental structuring principles of human cognition

These four chapters summarize what I think everybody who thinks about [language, mind and society](http://metaphorhacker.net/2013/08/sunsets-horizons-and-the-languagemindculture-distinction/) should know about how categories work. Even if it is not necessarily the last word on every (or any) aspect, it should be the starting point for inquiry.

All the key concepts (see below) are outlined here.

### Preface and Chapter 1 – Outline of the whole argument and its implications

These brief chapters lay out succinctly and, I think very clearly, the overall argument of the book and its implications. This is where he outlines the core of the critique of objectivism which I think is very important (if itself open to criticism).

### Chapter 2: Precursors

This is where he outlines the broader panoply of thinkers and research outcomes in recent intellectual history whose insights this books tries to systematise and take further.

The chapter takes up some of the key thinkers who have been critical of the established paradigm. Read it not necessarily for understanding them but for a way of thinking about their work in the context of this book.

### Case studies

The case studies represent a large chunk of the book and few people will read all 3. But I think at least one of them should be part of any reading of the book. Most people will be drawn to number 1 on metaphor but I find that number 2 shows off the key concepts in most depth. It will require some focus and patience from non-linguists but I think is worth the effort.

Case study 3 is perhaps too linguistic (even though it introduces the important concept of constructions) for most non-linguist.

Key concepts
------------

No matter how the book is read, these are the key concepts I think people should walk away with understanding.

### Idealized Cognitive Models (also called *Frames* in Lakoff’s later work)

I don’t know of any more systematic treatment of how our conceptual system is structured than this. It is not necessarily the last word but should not be overlooked.

### Radial Categories

When people talk about family resemblances they ignore the complexity of the conceptual work that goes into them. Radial categories give a good sense of that depth.

### Schemas and rich images

While image schemas are still a bit controversial as actual cognitive constructs, Lakoff’s treatment of them alongside rich images shows the importance of both as heuristics to interpreting cognitive phenomena.

### Objectivism vs Basic Realism

Although *objectivism* (nothing to do with Ayn Rand) is not a position taken by any practicing philosophers and feels a bit straw-manny, I find Lakoff’s outline of it eerily familiar as I read works across the humanities and social sciences, let alone philosophy. When people read the description, they should avoid dismissing it with ‘of course nobody thinks that’ and reflect on how many people approach problems of mind and language as if they did think that.

### Prototype effects and basic-level categories

These concepts are not original to Lakoff but are essential to understanding the others.

### Role of metaphor and metonymy

Lakoff is best known for his earlier work on metaphor (which is why figurative language is not a key concept in itself) but this book puts metaphor and metonymy in perspective of the broader cognition.

### Embodiment and motivation

Embodiment is an idea thrown around a lot these days. Lakoff’s is an important early contribution that shows some of the actual interaction between embodiment and cognition.

I find it particularly relevant when he talks about how concepts are motivated but not determined by embodied cognition.

### Constructions

Lakoff’s work was taking shape alongside [Fillmore’s work on construction](http://metaphorhacker.net/2014/02/linguistics-according-to-fillmore/) grammar and Langacker’s on cognitive grammar. While the current construction grammar paradigm is much more influenced by those, I think it is still worth reading Lakoff for his contribution here. Particularly case studies 2 and 3 are great examples of the power of this approach.

Additional chapters of interest
-------------------------------

### Elaborations of core concepts

Chapters 17 and 18 elaborate on the core concepts in important ways but many people never reach them because they follow a lot of work on philosophical implications.

Chapter 17 on Cognitive Semantics takes another more deeper look at ICMs (idealized cognitive models) across various dimensions.

Chapter 18 deals with the question of how conceptual categories work across languages in the context of relativism. The name of the book is derived from a non-English example but this takes the question of universals and language specificity head on. Perhaps not the in the most comprehensive way (the debate on relativism has moved on) but it illuminates the core concepts further.

### Case studies

Case Studies 2 and 3 should be of great interest to linguists. Not because they are perfect but because they show the depth of analysis required of even relatively simple concepts.

### Philosophical implications

Lakoff is not shy about placing his work in the context of disrruption of the reigning philosophical paradigm of his (and to a significant extent our) day. Chapter 11 goes into more depth on how he understands the ‘objectivist paradigm’. It has been criticised for not representing actual philosophical positions (which he explicitly says he’s not doing) but I think it’s representative of many actual philosophical and other treatments of language and cognition.

This is then elaborated in chapters 12 – 16 and of course in his subsequent book with Mark Johnson *Philosophy in the Flesh*. I find the positive argument they’re making compelling but it is let down by staying on the surface of the issues they’re criticising.

What to skip
------------

Where Lakoff (and elsewhere Lakoff and Johnson) most open themselves to criticism is their relatively shallow reading of their opponents. Most philosophers don’t engage with this work because they don’t find it speaks their language and when it does, it is easily dismissed as too light.

While I think that the broad critique this book presents of what it calls ‘objectivist approaches’ is correct, I don’t recommend that anyone takes the details too seriously. Lakoff simultaneously gives it too little and too much attention. He argues against very small details but leaves too many gaps.

This means that those who should be engaging with the very core of the work’s contribution fixate on errors and gaps in his criticism and feel free to dismiss the key aspects of what he has to say (much to their detriment).

For example, his critique of situational semantics leaves too many gaps and left him open to successful rejoinders even if he was probably right.

What is missing
---------------

While Lakoff engages with cognitive anthropology (and he and Johnson acknowledge their debts in the preface to *Metaphors We Live By*), he does not reflect the really interesting work in this area. Goffman (shockingly) gets no mention, nor does Victor Turner whose work on liminality is pretty important companion.

There’s also little acknowledgement of work on texts such as that by Halliday and Hasan (although, that was arguably still waiting for its greatest impact in the mid 1980s with the appearance of corpora). But Lakoff and most of the researchers in this areas stay firmly at the level of a clause. But give that [my own work](https://independent.academia.edu/DominikLukes) is mostly focusing on discourse and text-level phenomena, I would say that.

What to read next
-----------------

Here are some suggestions for where to go next for elaborations of the key concepts or ideas with relevance to those outlined in the book.

* **Moral politics** by Lakoff launched his forays into political work but I think it’s more important as an example of this way of thinking applied for a real purpose. He replaces Idealized Cognitive Models with Frames but shows many great examples of them at work. Even if it falls short as an exhaustive analysis of the issues, it is very important as a methodological contribution of how frames work in real life. I think of it almost as a fourth case study to this book.
* **The Way We Think** by Gilles Fauconnier and Mark Turner provides a model of how cognitive models work ‘online’ during the process of speaking. Although, it has made a more direct impact in the field of construction grammar, its importance is still underappreciated outside it. I think of it as an essential companion to the core contribution of this book. Lakoff himself draws on Fauconnier’s earlier work on *mental spaces* in this book.
* **Work on construction grammar** This book was one of the first places where the notion of ‘construction’ in the sense of ‘construction grammar’ was introduced. It has since developed in its own substantive field of study that has been driven by others. I’d say the work of Adele Goldberg is still the best introduction but for my money William Croft’s ‘Radical Construction Grammar’ is the most important. Taylor’s overview of the related ‘Cognitive Grammar’ is also not a bad next read.
* **Work on cognitive semantics** There is much to read here. Talmy’s massive 2 volumes of ‘Cognitive Semantics’ are perhaps the most comprehensive but most of the work here happens across various journals. I’m not aware of a single shorter introduction.
* **Philosophy and the Mirror of Nature** by Richard Rorty is a book I frankly wish Lakoff had read. Rorty’s taking apart of philosophy’s epistemological imaginings is very much complementary to Lakoff’s critique of ‘objectivism’ but done while engaging deeply with the philosophical issues. While I basically go along with Lakoff’s and later Lakoff and Johnson’s core argument, I can see why it could be more easily dismissed than Rorty. Of course, Rorty’s work is also better known for its reputation than deeply reflected in much of today’s philosophy. Lakoff and Johnson’s essential misunderstanding of Rorty’s contribution and fundamental compatibility with their project in *Philosophy in the Flesh* is an example of why so many don’t take that aspect of this work seriously. (Although, they are right that both Rorty and Davidson would have been better served by a less impoverished view of meaning and language.)

### *Related*
```
./2018-05-16-therapy-for-frege-a-brief-outline-of-the-theory-of-everything.md
```
---
title: "Therapy for Frege: A brief outline of the theory of everything"
date: 2018-05-16
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/05/therapy-for-frege-a-brief-outline-of-the-theory-of-everything
---

Frege’s trauma
--------------

I found the following quote from Frege on the [Language goes on holiday blog](http://languagegoesonholiday.blogspot.co.uk/2018/05/fixing-frege.html) and it struck as the perfect starting point for this essay which has been written for a while now:

“Frege (“Logic in Mathematics”): Definitions proper must be distinguished from elucidations [Erläuterungen]. In the first stages of any discipline we cannot avoid the use of ordinary words. But these words are, for the most part, not really appropriate for scientific purposes, because they are not precise enough and fluctuate in their use. Science needs technical terms that have precise and fixed Bedeutungen, and in order to come to an understanding about these Bedeutungen and exclude possible misunderstandings, we provide elucidations. Of course in so doing we have again to use ordinary words, and these may display defects similar to those which the elucidations are intended to remove. So it seems that we shall then have to provide further elucidations. Theoretically one will never really achieve one’s goal in this way. In practice, however, we do manage to come to an understanding about the Bedeutungen of words. Of course we have to be able to count on a meeting of minds, on others’ guessing what we have in mind.”

Duncan Richter’s commentary then follows:

“Frege’s problem is of a different kind [from Mill]. There is something wrong with what he wants. He sees the problems himself, but still, apparently, goes on wanting the same thing. So pointing out the problems won’t help at all. We might say he needs a kind of therapy, although this won’t be regular psycho-therapy.”

Well, I have been thinking about the need for exactly such a therapy and it must stem from an understading that Frege was wrong about the extent to which we can in practice determine the precise Bedeutungen of our terms. As I hope to show below, the infinite regress of elucidation intrudes on our every day thinking in many ways that make even relatively simple communication or understanding difficult (a never ending process of negotiation). Difficulties stemming from what I call below the impossibility of perfect reference are not a matter of some distant perifery of hypothetical paradoxes, they make themselves known as insurmountable obstacles in seemingly innocuous. Or in other words, it is *Erläuterungen* all the way down.

And this problem does not have an epistemological solution (even if we don’t have to go as far as Rorty in rejecting epistemology as a beneficial enterprise altogether). Our only course of action is acceptance and making peace with the fundamental indeterminacy of reference. The acknowledgment of the need to make peace is the therapeutic part because the alternative is dissolution into madness of circularity or arbitrary absolutism (which is a kind of madly willful blindness, in itself).

Halting Problem of Rationality
------------------------------

The original impetus for these notes was reading a recent [review of Elezier Yudkowsky’s new book on Inadequate Equilibria by Scott Alexander](http://slatestarcodex.com/2017/11/30/book-review-inadequate-equilibria). Yudkowsky and Alexander’s review seem to me an object study of what I’ve come to thinking about as the halting problem of rationality.

This problem has many formal kindred spirits in the form undecidability, computability (P=NP), etc. From everything we know, we should be exteremely skeptical of rationality to solve its own problems without any appeal to a sort of axiomatic arbiter (a Godelian ‘because I said so’, perhaps.)

Scott Alexander shows the infinite regression of the process of finding the final level at which to decide which perspective is valid (or even useful). Based on Yudkovsky’s book, he arbitrarily (or perhaps magically) uses two perspectives but they are clearly just points on a continuum which itself is on an infinite plane rather than just a neat straight line.

Now, Yudkowsky does not seem to be bothered by the infinity of it all. He uses a whole lot of Bayesian heuristics to build up a priors machine that spits out one good decision after another. Prior ex machina, if you will. And it’s not always good. That’s why Alexander calls the book’s core argument ‘theodicy’. And that’s how most rationalist epistemological arguments strike me. They are the same sort of hermeneutics performed on the Bayesian heuristic canon that biblical scholars engaged in with the Bible. Read the text and its understanding will reveal THE truth.

The impossibility of true hermeneutics
--------------------------------------

My arguement is that hermeneutics (in this sense) is impossible and always the wrong goal. What’s more it is very easy to mistake our heuristics for hermeneutics. In other words, it is almost an instinct to assume that the analytic instruments we use to handle the world around us for specific (if often implicit) purposes are isomorphic with the world. And the more successful the instrument, the more likely it is we will assume it reflects the actual ‘true’ and complete image of the world. So computers, have been hugely influential and successful in emulating (and enhancing) some previously difficult mental processes and therefore the world is made up of information and our minds are just computers. We can control so much of the world around us by manipulating chemical elements, and therefore everything we are is really chemistry and our goal in describing the human condition should be a transcription into chemical notation because only that is the language in which a true image of the world can be captured. We can describe a sentence with a transformational rule and therefore the true representation of language is a formal description. We can design precise logical proofs for truth conditions, and therefore all that a meaning of a word or a statement is, is its conditions for truth. We can describe the utility of an economic transation by its marginal value and therefore all that defines value is the margin. And so on.

Richard Rorty pretty much showed how this works in *Philosophy and the Mirror of Nature* and later on also showed how to deal with it through his ironist approach. But rationalists are too cool to read Rorty. Wittgenstein and Derrida saw the problem and instead of talking about it, they tried to reveal it through cryptic koans.

I’d like to go about this differently and offer an outline of what a proof might look like that there is no ultimate external referent available for adjudication of referential problems. I also show that this causes problems not just on the edges but all the time across all aspects of academic and daily life.

Outline of the theory of everything
-----------------------------------

Lets start with a key assumption from which everything else derives:

**Everything exists!**

### On the word ‘exist’

Now, the word exist obviously has multipe meanings. I’m obviously not saying that everything exists as an object in the world. So I’m perfectly happy with the statement ‘Unicorns don’t exist’. I’m using it in the most universal sense similar to the logical notation E. In this sense it is impossible for something I can refer to with the word ‘something’ or even think about not to exist. But I don’t have to have a word or a thought for something to exist. In facts, words make it seem as if everything existed as some kind of entity. But those words and thoughts themselves exist and so does the relationship between them and the things they refer to as well as my reference to that relationship and my reference to that reference. And so on ad infinitum. In fact, the very act of naming brings things into existence. Existence in this sense is a Parmenidian totality – it is not temporal. Everything includes past and future. It is not dimensional – if it turns out there are infinite parallel worlds, everything will still exist. Parallel words are also part of everything. And if it turns out there’s no such thing, everything will still exist. The parallel worlds will just exist as an idea that turned out not to have identifiable external correlate. Everything does not require finiteness nor infinity. Infinity is still everything. But even if it turns out that infinity is just a mathematical construct and the physical world is actually finite in the shape of some bizzare multidimensional space-time sphere, that’s still everything. When Wittgenstein said ‘That of which I cannot speak, I must stay silent’, he was alluding to the same concept of everything. If it can exist it does exist, if it cannot, it does not. Everything exists. Anything that does not exist does not exist. What it means that there is nothing outside of existence in the sense of x E everything. There is no such special mode of being as metaexistence – existence beyond existence, existence about existence. Now, this is not the proof, this is the Cartesian axiom abstracted – X exists, therefore X exists.

### Impossibility of perfect reference

The key consequence of everything existing is the impossibility of perfect referrentiality. This presents a problem because our entire epistemology is built on the assumption of referentiality. If something exists, we can refer to it with a concept, word, label, or at least point at it. In other words, signifier vs signified. We cannot speak or think without relying the perfect applicability of this abstraction. And most of the time it sort of works. In ‘Pass the salt’, ‘pass’ refers to an action, ‘salt’ to an object, ‘the’ to a relationship between the object and our perception of it. The ‘sort of’ refers to the fact that even simple sign/meaning pairings get very complicated very fast. Semioticians have been dining out on this since at least Peirce. (But medieval logicians and Indian ones before that have also taking this complexity apart as far as it can be taken apart.)

But it stops even sort of working very soon when we get even close to any attempt at metareferentiality. Just look what sort of verbal gymnastics I had to go through to even hint at what I mean by a simple statement ‘everything exists’. The problem is that referentiality is not a passive fact outside of existence. Every act of reference creates a new relationship between the refered, referee, and reference (at its most oversimplified). And that’s something we can then go and refer to, thus creating an infinite regress, that’s not linear but exponential. Because any new act of reference creates not one but at least four potential things to refer to. 1. The act of reference itself, 2. the referee in the act of reference, 3. the referent as being referred to, 4. the signfifier being used for that reference. Most often we can multiply that by referring to other participants in the act of reference, the relationship of that act to prior acts and their relationship to this act. In short, it’s not a pretty picture.

Borges in his psychedelic ways showed how the quest for perfect reference falls on its face in his short story about the mapmakers trying to create an ever better map but making it more and more closely resemble reality until it became as big as the land it was representing. By the end of his story, it simply lay abandoned on the edge of town. But the mapmakers did not even come close to achieving perfection. Because in the perfect representation of the world, the map itself would have to be included as well. But then an even bigger map would have to be created to capture the map, the reality and their relationship, but then we’d need another even bigger map to capture the previous relationships. And so on. A perfect map is a physical impossibility. Even in an infinite universe, there’s not enough transfinity to hold it.

There’s nothing new about this. Zeno, Russell, Goedel, Turing, Mandelbrot are just the most famous of the names who dealt with this problem in one way or another in the formal realm of mathematics. And Rorty did it for philosophy – while of course all the major philosophers of the last 300 years had hints of it, as well. Hume, Kant, Hegel, Marx, Nietsche, Heidegger, Wittgenstein, Rorty, Feyerabend. Of the western ancients Parmenides. But of course, so called eastern philosophy is rife with this, as well.

### Meaning without perfect reference

So what does this mean? Is meaning impossible? Can we not speak? No. Meaning is obviously possible. But not in the way it suggests itself to us. When we say something means something we are implying a perfect one-to-one mapping of symbol to entity. But this is a false implication. When I point at an object and say this is a ‘chair’, I have a feeling that I have thus exhaustively described that object. That I engaged in perfect reference. But because everything about that chair exists, not just it chairness, I have simply pointed to a whole complex of existence and the word ‘chair’ only describes one of its infinitely many dimensions. When I set the chair on fire, at what point does it stop being a chair? When does it start being a chair during the contruction process? When the tree’s cut down with the intention of making furniture? When the last bit of varnish dries? Or somewhere in between? Maybe when it takes on the recognizable shape of a chair or when it can start functioning as a chair. What if it is a modernist chair and I can only recognize it as such when somebody puts a label on it? What if it is a chair in a picture? The label chair can do a lot of this work but it is not a perfect reference that maps nicely onto a thing.

This is all kind of obvious, so obvious that we take it all in our stride in our everyday acts of reference. But it starts causing problems as soon as we try to pin it down in the assumption that if we only stop being everyday about our reference, we can easily identify the ‘real’ referent exactly in the way our usual every-day unthinking reference suggests we are doing already. Oh, we’re just being sloppy thinkers, taking quick shortcuts for convenience. But if we sacrifice some of that convenience, take a bit more time, we will be able to stop the infinite referential regress. There has to be an end to it. But there cannot be. Not within the system of reference itself. Every moment we take to try to nail down the reference, creates another referent for us to refer. It just never ends.

Infinite perfect reference is impossible in principle. And we cannot resolve this by stepping outside the system of reference as we can do with maths in Godel’s theorem. Because, we can only consider reference using referential tools. This is so crazy-making and frustrating that generations of great thinkers simple assumed that it cannot be so. But in fact, it cannot be otherwise. Or if you think, it can. Show me how! I’ve been wrong before. (Obviously the Augustinian God who is outside of time – and presumably reference, or Buddhist karma – the extinguishment of existence itself – are pretty good conceptual exits out of the worry but they don’t provide any usable heuristics for dealing with the paradoxes of reference within the referential model itself.)

### Summary of the key consequence

In summary, there’s a paradoxical **consequence of the theory of everything**. Beause everything exists, perfect reference is impossible, and therefore nothing exists in the way our words and thoughts make it seem it does. Or in a pithier (but less accurate) heuristic I recommend to all philosophers and rationalists:  
**“Just because there’s a word for it, it does not mean it exists.”**

### Edge cases in our midst

So what? Who cares about some edge cases on the margins of infinity? We can just happily go on to use our ‘ordinary’ language and take care of the really important problems like designing more efficient energy storage.

If only it were that easy. But as the example with the chair showed, the problems of reference are all around us. They pop up all the time in daily conversation or in basic academic discourse. They are not just something people in the most abstract domains have to deal with on their darker days. They are something we all deal with everyday – all of us – from Socrates to the Macedonian swineherd.

Lets take energy storage. It is a perfect way of thinking about batteries or pumping up water on an incline. But is there really a thing called energy we are storing the same way we may be storing bags of dried beans in a cupboard? Is there even such a ‘thing’ as energy? Well, there’s a whole lot of maths used to describe the measurements in the physical world that make it easy to think about a lot of things in terms of energy. Not only can we think of the world that way, we can all of a sudden compare things like burning fire and the rubbing of hands and the running of horses, pile of coal and pile of dinosaurs, etc. But what is happening when we say X is releasing energy? Is the pumping of water up a hill the same thing as a burning fire? What is it that we’re describing with the math? It is certainly not a given that energy is always a useful concept. People say things like, because everything is energy, I don’t believe in God but in universal energy that connects us all. We may laugh at charlatans like Deepak Chopra, but what is the mathematics describing energy really referring to? Is that one example of perfect reference? There is one energy and one value of energy in the world? Further indivisible? The ultimate building block of our semantics?

No. Theory of everything does not claim that no reference is possible. Or even that it is impossible to have one perfect one to one relationship between a signifier and signified. Just that that sort of atomic reference is not very useful. I can agree with my fellow referees that henceforth ‘dog’ refers to Spot at 5pm on July 23, 2011 in my living room (with the rest of the infinite specification taken as read). But that will render the word completely useless. I will have to then come up with a new word to refer to Spot at 5.01pm or Spot who’s wondered into the garden. Or I may choose the much more sensible option of refering to the fuzzy and ever changing universe of dogness. That word will be imprecise and fuzzy but that will make it useful. We will have broad agreement and negotiate around the edges.

So I can equally say, the word energy refers only to a set of mathematical formulae. But then I severly constrain what I can do with it. Which (in the case of physics) maybe exactly what I want. But it is a solution that does not scale as every effort to come up with a precise language has demonstrated and even if it did, it would necessarily run into paradoxes predicted by the theory of everything.

### Possible objections

What are some possible objections to the theory of everything? I can think of several.

1. The premise is wrong. Everything does not exist. There is a mode of metaexistence (for instance, human consciousness or a state of nirvana) that will make it possible to know all.
2. There’s no problem. We just need an alternative epistemology which does not rely on reference.
3. So what if perfect reference is impossible. We just need to come up with simpler formulae that will describe more complex ones and build a perfect reference by proxy.
4. How does this apply to the theory of everything? How can you say everything exists when by your definition you should not be able to make any statements like that?
5. You made a logical mistake and it is indeed possible to have perfect reference even when everything exists.

Re 1: Many years ago I read about a Buddhist school of semantics that claimed that the meaning of anything is everything that it is not. And the way Buddha himself was able to confirm that something does not exists was by looking at everything and finding that nothing was it. (This was a long time ago and I’m probably mangling this but it will suffice for illustration.) So is it possible that we can achieve some alternate level of consciousness – perhaps even stepping outside the ‘karmic wheel’ on which everything turns and grasping the whole world non-referrentially as one or simply being aware of everything through a vastly expanding consciouness where the limits of infinity don’t apply. Every mystical tradition would have you believe that you can.

But even if you could (and why not), it wouldn’t solve any of the problems in the here and now. Maybe we should realign our goals and instead of striving for accumulating ever more referential possessions, seek this new alternative consciousness. Sure. But again, this does not solve the problem for this consciousness.

re 2. Well, if you can come up with an epistemology not based around some notion of reference I’d like to see it. Now, there are many philosophical approaches that take the very impossibility (or at least great difficulty) of perfect (or even very good) reference to heart and integrate it into its epistemological toolbox. Zen Koans are one example, floating signifiers of post-modernist semioticians are another. But these approaches don’t actually transcend referentiality. They merely break it and through that breakage reveal the boundaries that reference imposes on us. The best Zen masters such as Derrida in his postcards or Wittgenstein in his investigations do a great job.

But, again this only exarcebates the problem rather than resolve it. There is no bulshit filter on koans. I can just as easily remain clueless as englightened and I have no way of knowing which one I am. Most of the reference transcending statements are as likely as not interpretted as if they are referential and simply referring to something not yet seen. Well, that does not help anyone.

re 3. The whole point of reference is that it simplifies the world. Who cares about perfection. As long as we can come up with simple and beautiful mathematics to describe the complex world, we’ll be in good shape. I call this **generative referentiality**. And if it could get us out of the jam, it would be nice. But it fails on two counts.

Count 1: Assume you come up with a nice function to describe a chunk of the world. Now, if you plug it into a computer, it will eventually spit out a perfect image of that chunk of the world. But then you’ve created a new object that needs to be generated by another function, including that function itself. Now, you might think that you could Cantor your way out of this. Just map one to one until infinity – no problem if it seems that one set should be smaller than the other. Yes, but Cantor never worried about everything. Russell did and look where that got him.

Count 2: But even if we assumed that generative referentiality can solve this problem, it is still arguable that it actually does do the job we assume referentiality does. Look at Madelbrot’s set. It is a dead simple formula (albeit with complex numbers) that generates infinitudes of self-similar shapes when plotted in a 2D space. But does knowing the formula actually constitute knowing the set? Can we know the set without knowing the formula? Do we need to know both? We can certainly take the formula as the signifier of the whole complex thing. But then it would seem to be mostly doing a job of referring to something complicated and calling it Bob (or Madelbrot’s set) would be just as good. There is something magical about knowing the names of things but knowing the names is not knowing the things. Generative referentiality is extermely useful and we might say it provides the foundations of our current civilisation. But confusing it with perfect referentiality has caused a lot of problems.

re 4. How do the epistemological limitations of the theory of everything apply to the theory itself? This is a typical worry of any foundational epistemological theory that tries to encompass all of cognition. How do you deal with self-referentiality without running into a paradox? The strictures are even more severe on any theory that tries to deal with self-referentiality itself. The limits on perfect reference of course apply to anything I say just as much as anything else. However, there is a small reprieve for reference that does not try to do anything useful. The whole point of reference is that it allows us to grasp something external to us. And the hidden strength of reference (at least hidden from most mainstream logicians) is that it is profoundly simplifying. It only works because it ignores almost everything and only zooms in on what is most important. However, there is a kind of perfect reference that is profoundly useless except as a foundational axiom. And that is **tautology**.

I can in fact avoid all the problems with chairs, love, kings of France or anything referentiality struggles with if I just say they are exactly what they are. So instead of positing that X = a, I simply say X = X. I can thus refer to everything as being everything and be quite happy that that reference includes itself and everything that surrounds it. Just like I can say that a set of all sets is a set of truly all sets including itself. The problems start when I try to build a non-selfreferntial system out of this assumption. Because I can’t.

I would say that **the foundation of the theory of everything is purely therapeutic**. It points to some fundamental impossibilities of our system without saying ‘and for my next trick, I will now show you how to simply resolve it’. **There is no next trick.** However, I will try to outline some heuristics that can be used to get around this. Deconstruction is one such approach – Derrida’s horizons come to mind here (but not something I know a lot about.) But even very simple rationalist heuristics will do as long as we don’t assume that they are external to the limits on perfect reference.

re 5. It is possible that I made a mistake somewhere. In fact, I would not be surprised in the least if I did – this kind of thinking is hard and not my strong suit. But what remains is the empirical fact that perfect reference is nearly impossible. It is so hard that nobody has yet managed to crack it in any system capable of expressing something like language. Even algebra. I never quite managed to understand the details of Goedel’s proof but this is what I imagine he was after. But for him, undecidability was an internal problem for any system with an outside observer. But with everything there is no outside observer. (Or at least not any outside observer we have access to.)

Words-as-models heuristic and the halting problem
-------------------------------------------------

So what are we to do? **Perfect reference is impossible but our language-thought processes behave as if all reference was perfect.** Is there a way out? No, there is no way out. You cannot be out of everything but there’s a way of living with this limitation.

One simple heuristic I suggest is to think of anything we say or think as a model. Each word, sentence, concept. It is a model of the thing it refers to. Then we can then go on and live with the statistician’s dictum: All models are wrong, but some are useful.

Of course, the world does not need me for this. Those assumptions have been around for a long time. But what has been missing is the next step. Ok, so some models are useful, how do we know which ones? **Can we come up with a universal procedure for determining usefulness of models?** And here the analogy with the halting problem comes in.

Models are a type of (by definition) imperfect reference. So, if we could get a perfect procedure for identifying the utility of models, we could build out a model of the whole world just based on utility. But utility of models is itself a mode and, therefore, by its nature imperfect. Which means we cannot have a perfect external procedure for identifying utility. So, what can we have?

As always, we need to remind ourselves of the heuristic ‘just because there’s a word for it, does not mean it exists’. We have a notion and a word of utility but that does not mean that there is a nice monadic entity of utility floating around in the world that we can attach that word to. We can pretend there is (just like the utilitarians) but that is not going to help us avoid paradoxes and other odius conclusions (just like the utilitarians). We don’t know whether a model is useful until we have examined all of its aspects with respect to all aspects of reality. But that is no more possible than it is possible to examine all steps of an infinitely recursive algorithm. At best we can follow the line of steps as far as the eye can see and say, well, it seems like it will continue for a while. Let’s go get a sandwich.

But with utility, things are even more difficult because it is not intrinsically a point on a simple scale from less useful to more useful. To simplify dealing with utility, we may convert it into a unidimensional scale of ‘utils’ spanning from negative to positive infinity. But that only makes the calculations of utility themselves easier by pushing all the difficult work one step down the line. We still have to decide in every case how to map the utility we perceive onto that scale. And we also have to decide how to measure that mapping. So by committing to a simple scale we have simplified one part of the process but we didn’t solve any of the problems. We simply pushed them upstream to the foundational issues.

How do we halt the infinite regress if we don’t know whether there is an actual end to it? In practice, we already do the only thing we can do. We give up when it feels right. Or when we’re exhausted. Or when we’ve reached a point of some sort of equilibrium or conversely leverage. Our only sane option is to do what we’re doing and not pretend that we’ve cracked the halting problem. Pretend (with conviction to the point of self-delusion) that we’ve come to a decision because a decision at that point makes sense. Dance as if noone is watching and there’s an externally arbitrated rational reason for stopping. Or a common sense one. But those are just pragmatic, ad hoc (or as Rorty insists contingent) decisions. **The assumptions of external rationality are therapeutic ones, not epistemological.**

### Dealing with imperfect reference through heuristics: rationalists, postmodernists and pragmatists

Now, given we know all of the above and assuming we want to be reasonably honest about acknowledging there’s a problem, how do we go about continuing to speak and reason referentially while knowing that the reference we are working with as real is actually impossible? The postmodernists have suggested provisional knowledge. And they’re not wrong. All knowledge has to be provisional. The rationalists have come up with the Bayesian ‘strong opinions weakly held’ and updating priors. And they’re not wrong. And the Pragmatists have come up with conflating epistemology with ethics. I like these the most.

But these are just the general slogans of intent. What is really interesting (and actually useful) are the heuristics developed by each of these traditions.

The rationalists assume (implicitly) that perfect reference is indeed possible but very hard. They have come up (as the scholastics – Western and Eastern – before them) with a number of heuristics in the form of logical fallacies that help point out some of the paradoxes. They sort of present them as if avoiding these fallacies would avoid all problems. But while they help avoiding a lot of problems, they don’t avoid all or even most and they also create new ones. But simply dismissing them because of this would be foolish.

The postmodernists, on the other hand, focus on the impossibility of perfect reference and emphasize the provisionality of knowledge. They have developed a lot of deconstructive techniques to direct the mind to the boundaries of possibility. They almost write poetry about the abundance of everything and the futility of its conquest (Feyerabend being one of the most eloquent here). But they tend to reject even some of the more useful heuristics and are very likely to drown in bulshit. The rationalists are prone to non-sense, as well, but I think the profound embarassment of the Sokal hoax is unique to the postmodernists. The rationalists just assume that the infinite regress can be halted if we put up enough barriers of logic in its way, but postmodernists are sometimes all too happy to see something rhyme and don’t care if it could be made reasonable sense of (albeit provisionally) with some simple rationalist heuristics.

Then, there are the pragmatists. They are closest to my heart and I think Rorty pretty much said everything that I ever wanted to say. They emhasize the contingency of knowledge on situation and social commitments. But unlike the postmodernists, they are happy to take provisional stances for something and do something specific with them. When James spoke about the importance of commitments to others as being the foundation of epistemology, he touched on something fundamental. I came up with the slogan **‘epistemology is ethics’** without knowing about James or the details of Rorty’s analysis but when I read Philosophy and the Mirror of Nature, I knew Rorty and I were soul mates.

But I think Rorty was too quick to dismiss epistemology. He rightly took it down a lot of pegs and showed the impossibility of an ultimate epistemological theory. But he did not give it enough credit in thinking through some of the impossible problems while asssuming they are merely very hard. His ‘liberal ironist’ stance in later essays is a good practical application of the core insight but again, it does not give enough room to the basic heuristics.

That makes it much easier for the traditional epistemologists and scientists to dismiss him as irrelevant. While in fact, he speaks to the very core of their enterprise. But it feels to them like he is taking away the very foundations on which all of their heuristics stand and somehow invalidates them along with it.

But Rorty should be viewed as therapeutic. If I can hope to add anything to Rorty, it is this. Similar to the New Wittgenstein studies. Everytime we run into a referential paradox, we can take solace in its totality and turn away from the brink. We can also just simply save time and not worry about justifying stopping following the referential regress. But we can also let ourselves an out by remembering that we stopped simply for pragmatic reasons. And if new reasons (contingencies) appear, we can resume our journey along the infinite refrential web.

### Serenity through disciplined conversation

What I am ironically calling ‘theory of everything’ is designed to do just that. Acknowledge that there is a problem and that there’s nothing that can be done about it.

Very much like Alcoholics Anonymous. The difference is that the wisdom to tell the difference between things we can and cannot do something about is not revealed by a deity but is a constant subject of disciplined conversation. Conversation that reflects the contingencies of the present as much as those of the past. A conversation that cannot have an end but which we must inevitably take part in. The serenity one hopes to get out of this will not come from resignation but from embracing of the totality without assuming that we can grasp its every possible aspect.

This is the therapy Frege needs. As do we all.

### *Related*
```
./2018-05-22-not-ships-in-the-night-metaphor-and-simile-as-process.md
```
---
title: "Not ships in the night: Metaphor and simile as process"
date: 2018-05-22
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/05/not-ships-in-the-night-metaphor-and-simile-as-process
---

In some circles (rhetoric and analytics philosophy come to mind), much is made of the difference between metaphor and simile.

(Rhetoricians pay attention to it because they like [taxonomies](https://en.wikipedia.org/wiki/Figure_of_speech) of communicative devices and analytic philosophers spend time on it because of their commitment to [a truth-theoretical account of meaning](https://en.wikipedia.org/wiki/Truth-conditional_semantics) and naive assumptions about compositionality).

It is true that their surface and communicative differences have an impact in certain contexts but if we’re interested in the conceptual underpinnings of metaphor, we’re more likely to ignore the distinction altogether.

But what’s even more interesting, is  to think about metaphor and simile as just part of the process of interpersonal meaning construction.  Consider this [quote from a blog on macroeconomics](https://mainlymacro.blogspot.co.uk/2018/05/a-rotten-corporate-culture.html):

> [1a] Think of [1b] the company as a ship. [2] The captain has steered the ship too close to the rocks, and seeing the impending disaster has flown off in the ship’s helicopter and with all the cash he could find. After the boat hit the rocks no lives were lost, but many of the passengers had a terrifying ordeal in the water and many lost possessions, and the crew lost their jobs. [3] Now if this had happened to a real ship you would expect the captain to be in jail stripped of any ill gotten gains. [4] But because this ship is a corporation its captains are free and keep all their salary and bonuses. [5] The Board and auditors which should have done something to correct the ship’s disastrous course also suffer no loss.

Now, this is really a single conceptual creation but it happens in about 5 moves which I highlighted above. (Note: I picked these 5 as an illustrative heuristic but this is not to assume some fixed sequence).

[1] The first move establishes an idea of similarity through a simile. But it is not in the traditional form of ‘X is like Y’. Rather, it starts with the performative ‘Think of’ [1a] and then uses the simile ‘as’. [1b]. ‘Think of X as Y’ is a common construction but it is rarely seen as an example in discussions of similes.

[2] This section lays out an understanding of the source domain for the metaphorical projection. It also sets the limit on the projection in that it is talking about ‘company as a ship traveling through water’ in this scenario, not a ship as a metonym for its internal structure (for instance, the similarities in the organisational structure of ships and companies.) This is another very common aspect of metaphor discourse that is mostly ignored. It is commonly deployed as an instrument in the process of what I like to call ‘frame negotiation’. On the surface, this part seems like a narrative with mostly propositional content that could easily stand alone. But…

[3] By saying, ‘if this happened to a real ship’ the author immediately puts the preceding segment into question as an innocent proposition and reveals that it was serving a metaphorical purpose all along. Not that any of the readers were really lulled into a false sense of security, nor that the author was intending some dramatic reveal. But it is an interesting illustration of how the process of constructing analogies contains many parts.

[4] This part looks like a straightforward metaphor: ‘the ship is a corporation’ but it is flipped around (one would expect ‘the corporation is a ship’. This move links [2] and [3] and reminds us that [1].

[5] This last bit seems to refer to both domains at once. ‘The board and the auditors’ to the business case and ‘ships course’ to the narrative in the simile. But we could even more profitably think of it as referring to this new blended domain in which we have a hypothetical model in which both the shipping and business characteristics were integrated.

But the story does not end there, even though people who are interested in metaphors often feel that they’ve done enough at this stage (if they ever reach it). My recommended heuristic for metaphor analysts is to always look at what comes next. This is the start of the following paragraph:

> To say this reflects everything that is wrong with neoliberalism is I think too imprecise. [1] I also think focusing on the fact that Carillion was a company built around public sector contracts misses the point. (I discussed this aspect in an earlier [post](https://mainlymacro.blogspot.co.uk/2018/01/what-carillion-tells-us-about-public.html).)

If you study metaphor in context, this will not surprise you. The blend is projected into another domain that is in a complex relationship to what precedes and what follows. This is far too conceptually intricate to take apart here but it is of course completely communicatively transparent to the reader and would have required little constructive effort on the part of the author (who is most likely to have spent time on constructing the simile/metaphor and its mappings but little on their embedding into the syntactic and textual weave that give it its intricacy).

In the context of the whole text, this is a local metaphor that plays as much an affective as it does a  cognitive role. It opens up some conceptual spaces but does not structure the whole argument.

The metaphor comes up again later and in this case it also plays the role of an anaphor by linking 2 sections of the text:

> Few people would think that never being able to captain a ship again was a sufficient disincentive for the imaginary captain who steered his boat too close to the rocks.

Also of note is the use of the word ‘imaginary’ which puts that statement somewhere between a metaphor (similarity expressed as identity) and simile (similarity expressed as comparison).

There are two lessons here:

1. The distinction between metaphor and simile could be useful in certain contexts but in practice, their use blends together and is not always easy to establish boundaries between them. But even if we could, the underlying cognition is the same (even if truth-conditionally they may differ on the surface). We could even complicate things further and introduce terms such as analogy, allegory, or even parable in this context but it is hard to see how much they would help us elucidate what is going on.
2. Both metaphor and simile are not static components of a larger whole (like bricks in a wall or words in a dictionary). They are surface aspects of a rich and dynamic process of meaning making.  And the meaning is ‘literally’ (but not really literally) being made here right in front of our eyes or rather by our eyes.  What metaphor and simile (or the sort of hybrid metasimile present here) do is  help structure the conceptual spaces (frames) being created but they are not doing it alone. There are also narratives, schemas, propositions,  definitions, etc. All of these help fill out the pool of meaning into which we may slowly immerse ourselves or hurtle into headlong.  This is not easy to see if we only look at metaphor and simile outside their natural habitat of real discourse. Let that be a lesson to us.

### *Related*
```
./2018-05-28-does-machine-learning-produce-mental-representations.md
```
---
title: "Does machine learning produce mental representations?"
date: 2018-05-28
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/05/does-machine-learning-produce-mental-representations
---

TL;DR
-----

* Why is this important? Many people believe that mental representations are the next goal for ML and a prerequisite for AGI.
* Does machine learning produce mental representations equivalent to human ones in kind (if not in quality or quantity)? Definitely not, and there is no clear pathway from current approaches to a place where it would. But it is worth noting that mental representations in humans are also not something straightforward to identify or describe.
* Is there a currently viable approach to ML that could eventually lead to mental representations with more engineering? It appears not but then again, no one expected neural nets would get so successful.

**Update:** Further **[discussion on Reddit](http://metaphorhacker.net/2018/05/does-machine-learning-produce-mental-representations/)****.**

Background
----------

Over the last few months, I’ve been catching up more systematically on what’s been happening in machine learning and AI research in the last 5 years or so and noticed that a lot of people are starting to talk about the neural net developing a ‘mental’ representation of the problem at hand. As someone who’s preoccupied with mental representations a lot, this struck me as odd because what was being described for the machine learning algorithms did not seem to match what else we know about mental representations.

So I’ve been formulating this post when I was pointed to this interview with [Judea Pearl](https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515). And he makes exactly the same point:

“That sounds like sacrilege, to say that all the impressive achievements of deep learning amount to just fitting a curve to data. From the point of view of the mathematical hierarchy, no matter how skillfully you manipulate the data and what you read into the data when you manipulate it, it’s still a curve-fitting exercise, albeit complex and nontrivial.”

He continues:

“If a machine does not have a model of reality, you cannot expect the machine to behave intelligently in that reality.”

What does this model of reality look like? Pearl seems to reduce it to ‘cause and effect’ but I would suggest that the model needs more than that (Note: I haven’t read his book just the interview and [this intro](https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/#module-whats-inside).)

What are mental representations?
--------------------------------

Mental representations are all sorts of images (ranging from rich to schematic and from static to dynamic) in our mind on which we draw sometimes consciously but mostly unconsciously to deal with the world. They are essential for producing and understanding language (from even the simplest sentence) and for basic reasoning. They can be represented as schemas, rich images, scenarios, scripts, dictionaries or encyclopedic entries. They can be in many modalities – speech, sound, image, moving picture.

Here are some examples to illustrate.

#### Static schemas

What does ‘it’ refer to in pairs of sentences such as these (example from [here](http://dataskeptic.com/blog/episodes/2018/winograd-schema-challenge)):

1. The *trophy* wouldn’t fit into the *suitcase* because **it** was too *big*.
2. The *trophy* wouldn’t fit into the *suitcase* because **it** was too *small*.

It takes no effort at all for a human to determine that **it** in (1) refers to *trophy* and in (2) to *suitcase*. Why, because, we have schemas of containment and we know almost intuitively that big things don’t fit into smaller things. And when we project that schema onto trophy and suitcase we immediately know what has to be too big or too small in order for one not to fit into the other.

You can even do it with a single sentence as in *Jane is standing behind Clare so you cannot see* ***her****.* It is clear that **her** refers to Jane and not Clare but only because we can project a schema of 2 similar-sized objects positioned relative to the observer’s line of sight.

So we also know that only sentence 1 below makes sense because of the schema we have for things of unequal size being positioned relative to each other and their impact on our ability to see them.

1. The statue is in front of the cathedral.
2. The cathedral is in front of the statue.

However, unlike with the trophy and suitcase, it is possible to imagine contexts in which sentence 2 would be acceptable. For instance, in a board game where all objects are printed on blocks of the same size and positioned on a 2D space.

This is to illustrate that the schemas are not static but interact with the rich conceptualisations we create in context.

#### Force dynamics

This is a notion pioneered by Leonard Talmy that explains many aspects of cognitive and linguistic processes through dynamic schemas of proportional interaction. Thus we know that all things being equal, bigger things will influence smaller things, faster things will overtake slower things, etc.

So we can immediately interpret the **it** in sentences such as:

1. The foot hit the ball and **it** flew off.
2. The bird landed on the perch and **it** fell apart.

But we also apply these to more abstract domains. We can thus easily interpret the situations behind these 2 sentences:

1. The mother walked in and the baby calmed down.
2. The baby walked in and the mother calmed down.

If asked to tell the story that led to 1 or 2, people would converge on very similar scenarios around each sentence.

#### Knowledge of the world

Sometimes, we marshall quite rich (encyclopedic) knowledge of the world in the process of constructing an understanding of what we hear or see. Imagine what is required to match the following 2 pairs of sentences (drawing on Langacker):

1. The Normans conquered England with …
2. The Smiths conquered England with….
3. a. … their moody music.
4. b. … their superior army.

Obviously the right pairings are 1b and 2a. But none of this is contained in the surface form. We must have the ‘encyclopedic’ knowledge of who The Normans and The Smiths were but also the force dynamic schemas of who can conquer who.

So on hearing the sentence ‘Mr and Mrs Smith conquered Britain’, we would be looking for some metaphorical mapping to explain the mismatch between the force we know conquering requires and the force we know a married couple can exert. With sufficiently rich knowledge, this is immediately obvious as in ‘John and Yoko conquered America.’

#### How does machine learning do on interpreting human mental representations?

For AI, examples such as the above are a difficult challenge. It was recently proposed that a much more effective and objective Turing test would be to ask an AI to interepret sentences such as these under the [ Winograd Schema Challenge] (<https://en.wikipedia.org/wiki/Winograd_Schema_Challenge)>.

A database of pairs of sentences such as:

1. The city **councilmen** refused the demonstrators a permit because **they** *feared* violence.
2. The city councilmen refused the **demonstrators** a permit because **they** *advocated* violence.

This has the great advantage of perfect objectivity. Unlike with the Turing test, it is always clear which answer is correct.

The best machine learning algorithms use various tricks but they still only do slightly better than chance (57%) at interpreting these schemas.

The only problem is that it is quite hard to construct these pairs in a way that could not be solved with simple statistical distributions. For instance, the Smiths and Normans example above could be easily resolved with current techniques simply by searching which words occur most frequently together.

Also, it is not clear how the schematic and force dynamic aspects interact with the encyclopedic aspects. Can you have one without the other? Can we classify the Winograd schema sentences into different types, some of which would be more suspectible to ML approaches?

### Do mental representations exist?

There is a [school of thought](http://psychsciencenotes.blogspot.co.uk) that claims that mental representations do not actually exist. There is nothing like what I described above in the brain. It is actually just a result of perceptual task orientation. This is the ecological approach developed in the study of perception and physical manipulation (such as throwing or catching a ball).

I am always very sceptical of any approach that requires we find some bits of information resembling what we see stored in the brain. Which is why I am quite sympathetic to the notion that there are no actual mental representations directly encoded into the synaptic activations of our brain.

But even if all of these were just surface representations of completely different neural processes, it is undeniable that something like mental representations is necessary to explain how we think at speak at some level. At the very least to articulate the problems that have to be solved by machine learning.

**Note:** I have completely ignored the problem of embodiment which would make things even more complicated. Our bodily experience of the world is definitely involved. But to what extent are our bodies actually a part of the reasoning process (as opposed to the brain as an independent computational contrl module) is a subject of hot debate.

How does machine learning represent the problem space?
------------------------------------------------------

Now, ML experts are not completely wrong to speak about representations. Neural nets certainly build some sort of representation of the problem space (note, I don’t call it world). We have 4 sources of evidence:

1. Structure of data inputs: Everything is a vector encoded as a string of numbers.
2. Patterns of activation in the neural nets (weights): This is where the ‘curve fitting’ happens.
3. Performance on real world tasks: More reliable than humans on dog breed recognition but penguins can also be identified as pandas.
4. Adversarial attacks: Adding seemingly random and imperceptible noise to a image or sound can make it produce radically different outputs.

If we take together the vector inputs and the weights on the nodes in the neural net, we have one level of representation. But that is perhaps the less interesting and as complexity increases, it becomes impossible to truly figure out much about it.

But is it possible that all of that actually creates some intermediate layer that has the same representational properties as mental representations? I would argue that at this stage, it is all inputs and weights and all the representational aspects are provided by the human interpreting the outputs. But if we only had the outputs, we could still posit some representational aspects. But the adversarial attacks reveal that the representational level is missing.

**Note:** Humans can also be subject to adversarial attacks with all sorts of perceptual and cognitive illusions. They seem to be on a different representational level to me but they would be worth exploring further in this context.

**Update:** A [commenter on Reddit](https://www.reddit.com/r/MachineLearning/comments/8moils/d_does_or_can_machine_learning_produce_mental/dzyauwj/) suggested that I look at this post on [feature visualisation](https://distill.pub/2017/feature-visualization/) and I think that mostly supports my point. It looks like there are lots of representations shown in that article, but they are really just visualisations of what inputs lead to certain neuron activations on specific layers of the neural net. Those are not ‘representations’ the neural net has independent access to. I think in the same way, we would not think of Pavlov’s dogs salivating on the sounds of the bell as having ‘mental representation’ of the ‘bell means food’ causal connection. Perhaps we could rephrase the question of whether training a neural net is similar to [classical or operant conditioning](https://en.wikipedia.org/wiki/Operant_conditioning). and what that means with respect to the question of representation.

Can we create mental representations in machines?
-------------------------------------------------

Judea Pearl thinks that nothing current ML is doing is going to lead to a ‘model of the world’ or as I call it ‘mental representations’. But I’m skeptical that his solution is a path to mental representations either:

“The first step, one that will take place in maybe 10 years, is that conceptual models of reality will be programmed by humans.”

This is what the early AI expert systems tried to do but it proved very elusive. One example of manually coding mental representations is [FrameNet](https://%3cspan%20class=%22inline-comment%22%3eframenet.icsi.berkeley.edu), a database of words linked to semantic frames but it barely scratches the surface. For instance, here’s the [frame for container](https://%3c/span%3eframenet2.icsi.berkeley.edu/fnReports/data/frameIndex.xml?frame=Containers) which links to suitcase. But that still doesn’t help with the idea of trophy being sometimes small enough to fit and sometimes too big. I can see how FrameNet could be used on very small subsets of problems but I don’t see a way for scaling it up in a way that could take into account everything involved in the examples I mentioned. We are faced with the curse of dimensionality here. The possible combinations just grow too fast for us to compute them.

I’m also not sure that simply running more data through bigger and bigger RNNs or CNNs will get us there either. But I can’t rule out that brute force won’t get us close enough for it not to matter that mental representations are not involved.

Perhaps, if label enough text of some subdomain with framenet schemas, we could train a neural net on this. But that will help with the examples where rich knowledge of the world is not required. We can combine a schema of a suitcase and a trophy with that of ‘fit’ and match ‘it’ with the more likely antecedent. Would that approach help with the demonstrators and councilmen? But even if so, the Winograd Schema Challenge is only an artificially constructed set of sentence pairs designed for a particular purpose. The mental representations involved crop up everywhere all the time. So we not only need a way of invoking mental representations but also a way to decide if they are needed and, if so, which ones.

Machine learning fast and slow up the garden path
-------------------------------------------------

Let’s imagine that we can somehow engineer a solution that can beat the Winograd Schema Challenge. Would that mean that it has created mental representations? We may want to reach for Searl’s [‘Chinese Room Argument’](https://plato.stanford.edu/entries/chinese-room) and the various responses to it. But I don’t think we need to go that deep.

One big aspect of human intelligence that is often lumped together with the rest is *metacognition*. This is the ability to bring the process of thinking (or speaking) to conscious awarenes and control it (at least to a degree). This is reminiscent of Kahneman’s two systems in ‘Thinking Fast and Slow’.

Machine learning produces almost exclusively ‘fast thinking’ – instantaneous matching of inputs to outputs. It is the great advance over previous expert system models of AI which tried to reproduce slow thinking.

Take for instance the famous [Garden path sentences](https://en.wikipedia.org/wiki/Garden_path_sentence). Compare these 2:

1. The horse raced past the barn quickly.
2. The horse raced past the barn fell.

Imagine the mental effort required to pause and retrace your steps when you reach the word ‘fell’ in the second sentence. It is a combination of instantanous production of mental images that crash and slow deliberate parsing of the sentence to construct a new image that is consistent with our knowledge of the world and the syntactic schema used to generate it.

Up until the advent of stochastic approaches to machine learning in the 1990s (and neural nets in 2010s), most AI systems tried to reproduce the slow thinking through expert systems encoded as decision trees. But they mostly failed because the slow thinking only works because of the fast thinking which provides the inputs to it. Now neural nets can match complex patterns that we once thought impossible. But they do it very differently from us. There doesn’t seem to be much thinking about how to go about developing the sort of metacognition that is required to combine the two. All of the conditional decisionmaking around what to do with the outputs of ML algorithms has to be hardcoded. Alexa can recognize my saying ‘turn on bedroom light’ but I had to give it a name and if I want to make it part of a more complex process (make sure bedroom light is off when I leave home), I have to go to IFTTT.

I don’t see how [Pearl’s approach](https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/#module-whats-inside) will take us there. But I don’t see an alternative, either. Perhaps, the mental representations will emerge epiphenomenally as the neural nets grow and receive more sophisticated inputs about the spatial nature of world (rather than converting everything to vectors). Maybe they will be able to generate their own schemas as training inputs. I doubt it, but wouldn’t want to bet against it.

What is just as likely is that we will reach a plateau (maybe even resulting in a new [AI winter](https://en.wikipedia.org/wiki/AI_winter)) that will only see incremental improvements and won’t take the next step until a completely new paradigm emerges (which may not happen for decades if ever).

Conclusion
----------

It is not always obvious that more in-depth knowledge of a domain contributes to a better model of it. We are just as likely to overfit our models as to improve them when we dive too deep. But I think that mental representations at least reveal an important problem domain which should be somehow reflected in what machines are being taught to learn.

**Update**
----------

In response [to a comment on Reddit](https://www.reddit.com/r/MachineLearning/comments/8moils/d_does_or_can_machine_learning_produce_mental/dzyauwj/), I wanted to add the following qualification.

I think I ended up sounding a bit more certain than I feel. I know I’m being speculative but I note that all the critics are pointing at hypotheticals and picking at my definition of mental representation (which is not necessarily unwarranted).

But what I would like to hear is a description of the next 5 specific problems to be solved to get nearer to say 75% on the Winograd Schema Challenge that can then be built on further (ie not just hacking around collocation patterns Watson style).

I also wanted to note that I omitted a whole section on the importance of collocability in language with a reference to [Michael Hoey’s work on Lexical Priming](https://academic.oup.com/ijl/article-abstract/19/3/327/954608?redirectedFrom=fulltext), which I think is one of the 2 most important contributions to the study of language in the last 20 years, the other being William Crofts [Radical Construction Grammar.](https://books.google.co.uk/books/about/Radical_Construction_Grammar.html?id=3OwDr0gb9CcC&redir_esc=y) The reading of which would be of benefit to many ML researchers along with Fauconnier’s and Turner’s [The Way We Think](http://markturner.org/wwt.html).

### *Related*
```
./2018-10-16-innovation-is-bad-for-business-3-more-i-words-to-compare-innovation-to.md
```
---
title: "Innovation is bad for business: 3 more ‘I’ words to compare innovation to"
date: 2018-10-16
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/10/innovation-is-bad-for-business-3-more-i-words-to-compare-innovation-to
---

Innovation is the ‘in’ thing. Innovate or die is the buzz up and down the hive mind. Everybody is feeling like they must innovate all of the things all of the time. But is the incessant innovation the right mode of approaching this?

We constantly spin up stories of the intrepid innovator and the change they bring about in the world. But is that what is really happening on the ground? I think we can bring up some metaphors to bear on this that may open up some different possibilities of conceptualizing innovation.

**Note:** I’m writing this as an early adopter and some time professional innovator. But despite a personal drive to constantly try new things, I find that approaching innovation uncritically and without regard to the full diversity of its instantiations is counterproductive. Therefore, this is meant to be a corrective as much to myself as others.

When an innovation spreads through an institution, it does so just like an infection. It starts attacking existing systems who then have to spend time and resources on averting the damage done by the attack. We only tell the stories where the attack led to the strengthening of the system – like with childhood maladies or inoculation. But chronic disease and death of the system are also not uncommon – we just don’t tell them in association with innovation.

This weakening happens through many processes that every innovator and innovatee (and this covers most people in one way or another) will have direct experience of. Innovators have experienced resistance, doubt, slow response times. Those are all defense mechanisms the disease of innovation has to overcome.

The people who experience the innovation as the infected cells, can attest to lower productivity because of the need to learn new things, endless meetings on how to implement the new thing keeping them from doing the job, miscommunication and misunderstanding leading to higher error rate (be it in production or management).

Where this metaphor breaks down is that if the innovation is successful, the system is transformed. Almost, as if instead of a tumor killing us it would grow us a new useful organ while others may fall off without much harm to the organism as a whole.

On the other hand, the success of the system in extinguishing a malignant innovation can make it more resilient to innovation in the future. And this may lower its chances of survival in the face of environmental changes that make it easier to thrive for those where innovation took the system over. This latter aspect is what proponents of innovation as an unalloyed good point to. But that is a backward perspective. From the ground, the system as an organism will always have to start by defending against innovation as infection no matter how well-intentioned everybody involved may be.

Innovation is often equated with knowledge. People research new ways of doing things, they bring together existing strands of knowledge and weave from them beautiful tapestries of brighter futures. But in practice, innovation almost always benefits from ignorance. Or even depends on it.

Ignorance by inventors is a well-known companion to some of the biggest inventions and discoveries. When Morse set out to create the telegraph system, it was received wisdom that what he was trying to do was physically impossible but he did not know that. Columbus is often given as the example of the innovator who was right and pursued his correct knowledge in spite of ridicule. But the truth was he was a zealot crank and completely wrong about everything. Everybody had known the Earth was round for over a thousand years by the time of Columbus and they also knew how large it was. He did not doubt it was round but he subscribed to a crank theory that it was much smaller than it was. He just got lucky there was a continent in the way.

This ignorance-of-the-impossible narrative can be applied to many of the other famous inventors. But this story is often told with the naysayers as hidebound blocks to progress and inventors as courageous pursuers of the truth. But this way the narrative misses the overwhelming majority of ignorant would-be inventors being simple cranks. For every clueless Morse and cranky Columbus, there were thousands of unknown failures who did not know or believe something truly impossible was impossible (just like most random mutations do not win the natural selection lottery). The correct response to somebody claiming they are able to do something known to be impossible is to doubt it. The trick is being able to update one’s priors in a way that helps us better judge the signs of success.

But we should also not overlook the ignorance among the adopters of innovations. The lack of information on the side of adopters of innovation is another necessary ingredient to success. Every innovation is too uncertain and often unreliable in its earliest stages to be considered by the well-informed other than as a bet. This ignorance is partly a result of pure uncertainty as to the viability of something new. But much more commonly, it is just ignorance of how the new thing works, what are its limitations – and how it truly differs from the old. This results in Potemkin innovations like the original Mechanical Turk. The innovations or their effects are often too complex to be fully understood (even by their inventors). This then leads to the creation of a zeitgeist (a sort of general framing) which provides the innovation with enough vectors for infection and the possibility for improvement.

But it also makes it very easy for impostors to sneak in. At present, there are many examples of companies simply labeling products with ‘machine learning’ or ‘blockchain’ and selling it to credulous investors and customers even if the underlying technology is not actually using anything that could be meaningfully described that way.

Innovation is associated with inventiveness and creativity. Strokes of brilliance and flashes of genius. But almost all of the great innovations were imitating a previous less successful attempt. It is well known that great inventions and discoveries often appear multiple times simultaneously as different people synthesize available information into similar outcomes. Perhaps the most famous examples are Newton and Leibniz for calculus and Darwin and Wallace for natural selection. But this holds true for almost all the great inventions. Either somebody figured it out as well, or was getting very close.

But more importantly, by the time we get to talk about almost any innovation, it will have reached us through a long chain of imitations. Novel ways of thinking or doing things really only become innovations when somebody copies them.

This process of imitation is similar to that of natural selection, so it usually leads to refinement and strengthening of the original idea. But let’s not forget that natural selection is based around the idea of imperfect copies (random mutations) finding uses that increase their chances of spreading (reproduction). So as part of this metaphor, innovation without copying would just be lots of random ideas that go nowhere.

Not only is innovation the result of imitation, without imitation, there would be no point to it in the first place.

Conclusion
----------

There is not meant to be conclusion here. Investigating metaphors just opens up new prisms that slightly change the way we look at things. Sometimes, it’s the process of thinking through mappings in the metaphor that forces you to investigate one of the domains more closely. And that’s what this is all about.

### *Related*
```
./2018-10-19-3-easy-things-that-are-hard-for-both-humans-and-ai.md
```
---
title: "3 “easy” things that are hard for both humans and AI"
date: 2018-10-19
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/10/3-easy-things-that-are-hard-for-both-humans-and-ai
---

Everybody is agog at what AI systems can do. Nobody thought even 10 years ago that machines could be trained to recognise images or transcribe natural speech as well as they do now. And because of this leap forward everybody has started worrying about AI taking over the world because it will soon be able to do everything people can but better.

On the other hand, there are AI naysayers who point at incredible feats of human creativity and ingenuity and say ‘no machines will ever be able to write a poem’ or ‘manage a company’.

While I’m more than skeptical about the true possibilities of AI, I am equally ekeptical about this supposed limitless human creativity that is beyond the bounds of computation.

I think we can reveal more about the limits and nature of human intelligence and thus the targets (possible limits) for AI development, if we look at very simple things with which both humans and AI struggle albeit in different ways.

Machines are often thought of as capable only of algorithmic processing (such as adding lots of numbers) and humans are thought to excel at massively parallel tasks – also known as intuition (such as telling part dogs from cats). But we will see that they seem to trade these roles in the ways they approach and fail at these appartently simple problems.

I call these problems ‘easy’ because they can be broken into very easy and straightforward components. But they are hard if not impossible in reality because of the curse of dimensionality. Even the slightest variation in those simple components, will grow into an exponential mess.

1. Figuring out time zones
--------------------------

Apple Watches recently stopped working because of Summer Time in Australia. And just the other day, Outlook asked me if I wanted to switch to a continental time zone in Europe. After I said yes, it started scheduling all meetings 2 hours off.

On the other hand, I’ve been arranging meetings between 2 time zones 1 hour apart for 20 years and I still get it wrong about 3 times out of 10.

So what gives? Time zones are conceptually very straightforward. You just have a database of times and places with notes on what time it is when and where relative to some fixed point. Then all you do is subtract anywhere between 1 and 12. What could be easier?

Well, you have to add in change of dates, so you have to switch between today, tomorrow and yesterday quite a lot. But still. There is a finite number of times and places and their combinations, so how hard can it be for human programmers to sit down and write all the code once and for all? Turns out, incredibly hard. There are just too many permutations and they keep changing as the database of times and places is being updated with new information.

So, the magnitude of the problem seems to be too great for humans to come up with exhastively detailed algorithms to deal with it. (To be clear, the core has been solved, but we don’t seem to be able to nail all the edge cases. Things would be a lot worse without computers.)

So why don’t we unleashe machine deep learning on the problem? Well, partly because there’s no good data for a machine to learn on. This is mostly an algorithmic problem. But the inputs of the algorithm come from very human perceptions of how time relates to cyclical things like days and relationships like comparing states between time zones with respect to days. Again, none of this is all that complex. But the algorithmic part is too complex for humans to describe as a series of if-then commands to a computer without making lots of mistakes. And the perspective and context part seems to be completely outside of what any ML algorithm can access at the moment.

So we’re stuck with something that mostly works but not always and is mostly understood but also always confusing.

2. Scheduling a meeting
-----------------------

Scheduling meetings is another simple algorithmic problem related to time. Simply compare two series of numbers, find where they differ and spit out the result. But all of this starts interacting with a lot of human complexities that make the problem completely intractable if what we wanted to do is write a series of commands in the form of ‘if you see this, do that’.

That’s why the work of the human assistant handling the scheduling for a busy person (who rates an assistant) is not just to provide her intelligence or understanding of calendars. It involves conversations with the person whose calendar is being managed about their priorities, options, possible scenarios, conversations with other people, other assistants, eventually arriving at some compromise which is then entered into the straightforward if-then format of a calendar.

It is this conversation with other people that is often overlooked (“tell your people to call my people”). In the case of the assistants of the other busy people who rate an assistant also have to synthesize the priorities and value of their charges through the same process of conversations and adjustments.

The final matching algorithm is very simple – so simple that it seems like noone should need a human assistant any more. But the inputs into the algorithm need to come from sources that are too rich and complex to treat algorithmically or through some multi-dimensional analysis of hidden regularities (like deep neural nets). The inputs require either a fairly general artificial intelligence (although not full blown AGI) or that everyone keeps their calendar in the same way. (Even then we’d probably have to deal with travelling-salesman problems – but at least we have some ideas about the limits on the computability of those.)

There are many individual components of this process that could be algorithmically assisted. But often the simpler algorithms and heuristics such as preference polls and shared calendars are more effective aids than opaque machine learning output.

So although, this looks like a problem that should be solvable through ML, early attempts have been less than impressive.

3. Importing data about people into a table (deduplication)
-----------------------------------------------------------

Computers are great as aids to managing structured data. But the input into the structure has to be provided by humans. Can AI help here?

Imagine you’re organising an event and you want people to tell you if they’re coming. You can just ask and keep in your head who said yes. But that soon becomes too much. As a next step, you ask them to email or to send an RSVP so you can look at the messages and remind yourself who said yes. But even that becomes difficult soon, so you start a list. And the more people and events you need to manage, the more complicated the list is and the more time you have to spend structuring your data and inputing it into some sort of a table for managing and reviewing the data.

The world is littered with Excel sheets kept by event organisers. Now imagine you wanted to feed all the idiosyncratic Excel sheets with event information at a large organisation into a machine learning algorithm and get one number of the total number of participants or the total cost of lunch breaks.

If everybody kept their spreadsheets exactly the same way, this would be trivial. But they don’t. Computers make the task of managing this kind of structured data much easier but they constantly struggle with errors in the input from busy, overworked and cognitively limited humans.

On the surface of it, there’s nothing to prevent this part (ie participant registration and management) of event management from being completely automated. But there’s always a person involved in dealing with this. So could there be an AI system that does all of this? So far we’re not even very close to this. A system that processes some RSVPs via email, others via forms, and others from other sources (“Hi, Clare, Frances told me she was coming to your party!”) does not exist.

So let’s simplify the task even more. Take data from one table of a system (let’s say a registration table) and put it into another table on a different system (let’s say account creation). All the AI system would have to do is figure out what is important to one system and get the right data from another system. At the moment, humans are involved. In better cases by creating an API and programming algorithms to transfer data between systems. In the worse case, they download a spreadsheet from one system, modify it, if needed, and upload it into another system.

This is trivial if you’ve designed both systems and know they have to integrate. But the permutations get out of hand surprisingly quickly when you take any 2 random systems designed by different people for a similar purpose but without the intention to integrate. Is ‘Last name’ always the ‘Second name’, when the full name is in one column, is first name always first? Any one difficulty is easy to spot for a human and disambiguate. But it gets very error prone at scale and there are always some unexpected edge cases.

Even such a simple thing as contact deduplication between two devices of one person is not a completely solved problem.

Why isn’t there an AI system that can evaluate the data and transfer it as appropriate but at scale and without the errors human data processors or programmers or data processing algorithms make?

As always, even the most trivial algorithms require very complex inputs. And with even minor variation in the possible inputs, the if-then logic becomes too unweildy. Although computers in general are great at pursuing if-then logic chains regardless of complexity (within limits), AI algorithms are not. They provide guesses with probabilities. In certain areas, most notably speech and image recognition, their guesses are becoming very good and resembling humans. They may even outperform humans at scale.

But all the if-then part of what to do with these guesses is still handled by if-then algorithms designed by humans. There’s some talk of ‘Programming 2.0’ but nobody seems to be applying it to some of the day-to-day simple problems with complex scaling. Because even small errors in the inputs result in big aggregate problems and AI systems have no way of assessing whether their guesses ‘make sense’.

Is AI impossible?
-----------------

Maybe AI is just too hard. But these examples don’t claim it’s impossible, they just show that some difficult problems are just difficult. Even if they appear straightforward on the surface.

I have learned not to bet against engineers’ ability to figure out solutions in the long run. It’s not always clear what is solvable by AI and what is not ahead of time. Sometimes, specialised ML systems can be developed to solve problems that don’t generalise (e.g. GO or chess machines). But I would have expected more people to deal with these problems, if there was an easy solution to be found. And there hundreds more similar task-based problems that just won’t be magicked away by slapping the label ‘AI’ on it. Individual ones may be solved by one way or another. Perhaps by breaking them into component parts. But I’m not seeing any specific steps being taken to create general purpose Machine Learning that would deal with all of them. Just wishful thinking about AGI (Artificial General Intelligence) emerging to solve these problems without regard to the actual complexity of some of them or the complexity of the intermediate steps it would take to get there.

### *Related*
```
./2018-11-07-3-burning-issues-in-the-study-of-metaphor.md
```
---
title: "3 burning issues in the study of metaphor"
date: 2018-11-07
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/11/3-burning-issues-in-the-study-of-metaphor
---

I’m not sure how ‘burning’ these issues are as such but if they’re not, I’d propose that they deserve to have some kindling or other accelerant thrown on them.

1. What is the interaction between automatic metaphor processing and deliberate metaphor application?
-----------------------------------------------------------------------------------------------------

Metaphors have always been an attractive subjects of study. But they have seen an explosionof interest since ‘Metaphors we live by’ by Lakoff and Johnson. In an almost Freudian turn, these previously seemingly superfluous baubles of language and mind, became central to how we think and speak. All of a sudden, it appeared that metaphors reveal something deeper about our mind that would otherwise remain hidden from view.

But our ability to construct and deconstruct metaphors was mostly left unexamined. But this happens ‘literally’ all the time. People test the limits of ‘metaphor’ through all kinds of dicoursive patterns. From, saying things like ‘X is more like Y’ to ‘X is actually Y’ or even ‘X is like Y because’.

How does this interact with the automatic, instantaneous and unconscious processing of language. (Let’s not forget that this is more common)

2. What is the relationship between the cognitive (conceptual) and textual metaphor?
------------------------------------------------------------------------------------

Another way to pose this question is: What happens in text and cognition in between all the metaphors? Many approaches to the study of metaphor only focus on the metaphors they see. They seem to ignore all the text and thought in between the metaphorical. But, often, that is most of goes on.

With a bit of effort, metaphors can be seen everywhere but they are not the same kind of thing. ‘Time is money’, ‘stop wasting my time’, and ‘we spent some time together’ are all metaphorical and relying on the same conceptual metaphor of TIME IS A SOMETHING THAT CAN BE EXCHANGED. But they are clearly not doing the same job of work for the speaker and will be interpreted very differently by the listener.

But there’s even more at stake. Imagine a sentence like ‘Stop wasting my time. I could have been weeding my garden spending time with my children instead of listening to you.’ Obviously, the ‘wasting time’ plays a different role than in a sentence ‘Stop wasting my time. My time is money and when you waste my time, you waste my money.’ The coceptual underpinnings are the same, but way they can be marshalled into meaning is different.

Metaphor analysts are only too happy to ignore the context – which could often be most of the text. I propose that we need a better model for accounting for metaphor in use.

3. What are the different processes used to process figurative language
-----------------------------------------------------------------------

There are 2 broad schools of the psychology of metaphor. They are represented by the work of Sam Glucksberg and Raymond Gibbs. The difference between them can be summarised as ‘metaphor as polysemy’ vs ‘metaphor as cognition’. Metaphor, according to the first, is only a kind of additional meaning, words or phrases have. While the second approach sees it as a deep interconnected underpinning of our language and thought.

Personally, I’m much closer to the cognitive approach but it’s hard to deny that the experimental evidence is all over the place. The more I study metaphor, the more I’m convinced that we need a unified theory of metaphor processing that takes both approaches into account. But I don’t pretend I have a very clear idea of where to even start.

I think such a theory would also have to account for differences in how inviduals process metaphors. There are figurative language pathologies (e.g. gaps in ability to process metaphor is associated with autism). But clearly, there are also gradations in how well individuals can process metaphor.

Any one individual is also going to vary over time and specific instances in how much they are able  and/or willing to consider something to be metaphorical. Let’s take the example of ‘education is business’. Some people may not consider this to be a metaphor and will consider it a straightforward descriptive statement along the lines of ‘dolphins are mammals’. Others will treat it more or less propositionally but will dispute it on the grounds that ‘education is education’, and therefore clearly not business. But those same people may pursue some of the metaphorical mappings to bolster their arguments. E.g. ‘Education is business and therefore, teachers need to be more productive.’ or ‘Education is not business because schools cannot go bankcrupt’.

Bonus issue: What are the cognitive foundations shared by metaphor with the rest of language?
---------------------------------------------------------------------------------------------

This is not really a burning issue for metaphor studies so much as it is one for linguistics. Specifically semantics and pragmatics but also syntax and lexicography.

If we think of metaphor as conceptual domain (frame) mapping, we find that this is fundamental to all of language. Our understanding of attributes and predicates relies on the same ability to project between 2 domains as does understanding metaphor. (Although, there seems to be some additional processing burden on novel metaphors).

Even seemingly simple predicates such as ‘is white’ or ‘is food’ require a projection between domains.

Compare:

1. Our car is white.
2. Milk chocolate is white.
3. His hair is white.

Our ability to understand 1 – 3 requires that we map the domain of the ‘subject’ on to the domain of the ‘is white’ predicate. Chocolate is white through and through whereas cars are only white in certain parts (usually not tires). Hair, on the other hand, is white in different ways. And in fact, ‘is white’ can never be fully informative when it comes to hair because there are too many models. In fact, it is even possible to have opposite attributes mean the same thing. ‘Nazi holocaust’ and ‘Jewish holocaust’ are both use to label the same event (with similar frequency) and yet it is clear that they refer to one event. But this ‘clarity of meaning’ depends on projections between various domains. Some of these include ‘encyclopedic knowledge’. For instance, ‘Hungarian holocaust’ does not possess such clarity outside of specialist circles.

It appears that understanding simple predicates relies on the same processes as understanding metaphor does. What makes metaphor special then? Do we perhaps need to return to a more traditional view of metaphor as a rhetorical device but change the way we think about language?

That is what I’ve been doing in my thinking about language and metaphor but most linguistic theories treat these as unremarkable phenomena. This leads them to ignore some pretty fundamental things about language.

### *Related*
```
./2018-11-08-cats-and-butterflies-2-misunderstood-analogies-in-scientistic-discourse.md
```
---
title: "Cats and butterflies: 2 misunderstood analogies in scientistic discourse"
date: 2018-11-08
author: Dominik Lukeš
source: https://metaphorhacker.net/2018/11/cats-and-butterflies-2-misunderstood-analogies-in-scientistic-discourse
---

Butterfly effect and Schrödinger’s cat are 2 very common ways of signalling one’s belonging to the class of the scientifically literate. But they are almost always told wrong. They were both constructed as illustrations of paradoxes or counterintuitive findings in science. Their retelling always misses the crucial ‘as if’.

This is an example of metaphor becoming real through its sheer imagistic and rhetorical power. But it also underscores the need to carefully investigate both domains being mapped onto each other, as well as the act of mapping. Metaphors used generatively are only useful if they are abandoned quickly enough. In this case, the popular imagination not only did not abandon the metaphor, it made it into a literal statement with practical consequences.

The way the two narratives are constructed is usually in the form of:

Science shows us that

1. Cats can be both dead and alive in a box with an aparatus controlled by superimposed quantum states.
2. Butterflies can cause hurricanes on the other side of the world.

But the actual formulation should be:

Science produces a lot of counterintuitive and (seemingly) paradoxical results some of which are at odds with each other and/or our experience of the world. For instance:

1. If we were to apply Heisenberg’s quantum uncertainty principle to the world we know, we would have to admit that a cat in a box with a quantum killing machine is dead and alive at the same time. And that is obviously nonsense.
2. If we were to apply what we know about chaos theory to the world of causes and effects, we would have to admit that a butterfly flapping its wings on one side of the world, can cause a hurricane on another side of the world. And that is obviously nonsense because butterflies have no real impact on the world on scales larger than a flower.

Both Schrodinger and Lorenz were trying to illustrate the counterintuitive conclusions of their respective scientific fields – quantum mechanics and dynamic (chaotic) systems. And in both cases, it badly backfired.

Although Schödinger’s dilemma was much more foundational to the structure of our universe, it was Lorenz, whose funny paper to an obscure symposium did the more lasting damage.

It is of no practical consequence whether or not in the retelling of Schrödinger’s paradox, we omit the word ‘paradox’ and assert that ‘science tells us that there are machines that can make cats alive and dead at the same time.’ This is merely par for the course in the general magical nature of the public scientific discourse. And it can even spur the development of new models of the physical universe.

But the ‘butterfly effect’ is more dangerous because it seems like it could have practical applications. Lorenz was not stating a paradox per se, only a counterintuitive conclusion that goes against our most common scenarios of causal relations. Our basic experience of the world is that big things move big things and small things don’t. So any suggestions we can make small things move big things seems intriguing. We know levers and pullies can get us some of the way towards that, so the dream of a magical lever is always there. Homeopathy “works” on the same magical principle. But this is not the lesson of complexity.

The most common reformulation of the ‘Butterfly effect’ is: ‘small actions can have a big impact’. However, this confuses sensitivity to initial conditions with a cumulative cascade effect. Every single snowflake contributes equally to an avalanche as do all the other aspects of the environment. Although none of them individually have any effect on the world at human scale, when combined, they can move much larger objects. But it is that combination (into a larger whole) that has the impact.

Whether any particular snowflake is the last to fall or somebody clapped loudly near a snow drift just before the avalanche fell says nothing about the ability of small things to have big effects. Only about our inability to measure small variations in big things accurately enough.

It is not true that a butterfly’s wings cause anything but minute variations of air right next to them. But it may be true that they are one of the infinite variations of the whole weather system that is simply impossible to measure with finite precision. It’s not that it is hard to calculate all the variations, it is that there are more variations than we have atoms to calculate them with.

Sure, we can talk about proximate and ultimate causes, but that again hides the problem of calculation. And if we ignore the practical problems of measuring the infinite with finite tools, we only get mired in philosophical musings on prime movers and free will. And these have yet to lead anywhere in two and a half millennia.

The only thing we can learn from the butterfly effect is that we cannot measure complex systems accurately enough to predict their behavior over the long term with enough precision. The big mismatch is that while the variation in ‘initial conditions’ is too small to measure, the variation in the outcomes is not. And that feels wrong.

Complexity is unsurprisingly too complicated to be captured by a single metaphor. The ‘butterfly effect’ is a good metaphor for the sensitivity to initial conditions aspect of it. But only if we understand that it is a metaphor that illustrates the counterintuitive nature of complexity and not complexity itself.

The larger lesson here is that metaphor is a process. It doesn’t just lie in a bit of text waiting for us to encounter it and understand it. It is picked up as part of stories. It is told, retold, reexamined, abandoned, readopted, and so on. If you unleash a generative metaphor on the world, you should keep an eye on it to make sure it’s still doing the job you meant it to do. That means a lot of talking and then more talking. Just like with butterflies, the ultimate outcome is never certain. That is fine. Metaphors are supposed to open up new spaces. But some of those spaces may have lions in them and we do know that lions have big impacts on human scales. Bon appetit!

### *Related*
```
./2019-04-28-what-would-make-linguistics-a-better-science-science-as-a-metaphor.md
```
---
title: "What would make linguistics a better science? Science as a metaphor"
date: 2019-04-28
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/04/what-would-make-linguistics-a-better-science-science-as-a-metaphor
---

Background
----------

This is a lightly edited version of a comment posted on Martin Haspelmath’s blog post “[Against traditional grammar – and for normal science in linguistics](https://dlc.hypotheses.org/1741)“.  In it he offers a critique of the current linguistic scene as being unclear as to its goals and in need of better definitions. He proposes ‘normal science’ as an alternative:

> In many fields of science, comparative research is based on **objective measurements**, not on categories that are hoped to be universal natural kinds. In linguistics, we can work with objectively defined **comparative concepts** ([Haspelmath 2010](https://zenodo.org/record/1303024)).

While I am in broad agreement with the critique, I’m not sure the solution is going to lead to a ‘better science’ of linguistics. (Also, I’m not sure that this is an accurate description of how science actually works.)

Problem with ‘normal science’ approach to linguistics
-----------------------------------------------------

I would say that the problem with the ‘normal science’ approach is that it makes it seem natural to turn to a structural description as a mode of ‘doing good linguistics’. But I think that this is misleading as to the nature of language. The current challenge of the radical potential coming from the constructionism (covering Fillmore, Croft, Goldberg) on the one hand and cognitive semantics (Lakoff, Talmy, Langacker) on the other makes a purely structural description (even imbued with functionalism) less appealing as the foundation of a newly scientificised linguistics.

It’s curious that it’s physics and chemistry that get mentioned in this context with their fully mathematised personas and not biology or geography. In both of those, precise definitions are much more provisional and iterative. Even foundational terms such as species or gene are much more fluid and less well defined than it might seem (I recommend Keller’s ‘Century of the Gene’ for an account of how discrepancies on how gene is defined among various labs was actually beneficial for the development of genetics).

That’s not to say that I strongly disagree with any of Haspelmath’s proposals but they don’t particularly make me excited to do linguistics. I found Dixon’s ‘Basic Linguistic Theory’ an exhilarating read but it was not because I felt that Dixon’s programme would lead to more consistency but because it was a radically new proposal (despite his claims to the contrary) for a theoretical basis for a comparative linguistic research agenda. Which is also why I like Haspelmath’s body of work (exemplified in projects such as the [World Atlas of Language Structures](https://wals.info/) and [Glottolog](https://glottolog.org)).

But I doubt that the road ahead is in better definitions. I’m not opposed to them just skeptical that they will lead to much. The road ahead is in **better data and better theory**. I think that between corpus linguistics, frame semantics and construction grammar we can get both. I proposed the analogy of ‘[dictionary and grammar being to language what standing on one foot is to running](http://metaphorhacker.techczech.net/2014/11/what-language-looks-like-dictionary-and-grammar-are-to-language-what-standing-on-one-foot-is-to-running/)‘ . I think linguistics needs to embrace the dynamism of language as a human property rather than as a fixed effect (to borrow [Clark’s phrase](https://www.sciencedirect.com/science/article/pii/S0022537173800143)). [Fillmore](http://metaphorhacker.techczech.net/2014/02/linguistics-according-to-fillmore/) and Kay’s early writing on construction grammar was a first step but things seemed to have settled into the bad old ways of static structural description.

Data and theory need each other in a dialectic fashion. You need data to create a theory but you needed some proto-theory to see the data in the first place. And then you need your theory to collect more data and that data then further shapes your theory which in turns let you see the data in different ways. The difference between biology and linguistics is that our proto-theories of the biological world correspond much better to the dynamic structures which can be theorized (modeled) based on systematic data collection and its modeling. Which is why folk taxonomies of the biological world are much closer to those of botany or zoology than folk taxonomies of language are to linguistic structures. (They are much more elaborate – to start with – at least at the level available to human perception.)

My proposal is to take seriously human ability to reflect (hypostaticaly) on the way they speak (cf. [Talmy’s defense of introspection](https://doi.org/10.1163/9789004349575_007)) because this is at the start of any process that bootstraps a theory of language. We then need to be mindful of the way this awareness interacts with the subconscious automaticity in which the patterns of regularity we call structures seem to be used. In the same way that Fillmore and Kay asked any theory of grammar to account for the exceptions (or even take them as a starting point), I’d want to ask any theory of language to take bilingualism and code mixing as its starting point (inspired by Elaine Chaika) and take seriously the variability of acquisition of the ability to automatically use those structures.

None of this is precludes or denies the utility of the great work of linguistics like Haspemath. But it is what I think would lead to linguistics being a ‘better’ science (at least, in the sense of Wissenschaft or ‘natural philosophy’ rather than in the sense implied by the physics envy which often characterizes these efforts).

**Update:**
-----------

After I finished writing this, I was listening to [this episode of the Unsupervised Thinking podcast](http://unsupervisedthinkingpodcast.blogspot.com/2019/04/episode-44-can-biologist-fix-radio.html) where the group was discussing two papers critiquing some of the theoretical foundations of biology (“Can a biologist fix a radio?”) and neuroscience (“Could a Neuroscientist Understand a Microprocessor?”). The general thrust of the discussion was that better definitions would be important. Because they would allow better measurement and thus quantifiable models.  But the discussion also veered towards the question of theory and pre-theoretical knowledge. To me it underscored the tension between data and theory.

My concern is only about the assumption that definitions are the solution. But I’d say that a definition (unless purely disambiguating of polysemy) is just a distillation or a snapshot of a slice in time in the never-ending push and pull of data and the model used to make sense of it as well as collect it (otherwise known as theory). This is not that different from the definition of a lexical item in a dictionary.

That is not to deny the heuristic usefulness of definitions. Which reminded me of the critique of modern axiomatic mathematics (in particular set theory and number theory) exemplified by [NJ Wildberger](https://www.youtube.com/watch?v=Bo2w25fDLwY) in his online courses on Math Foundations. Wildberger is also calling for more precise definitions in mathematics and less reliance on axioms.

**Future directions:**
----------------------

I outlined some of the [fundamental epistemological problems with definitions](http://metaphorhacker.net/2018/05/therapy-for-frege-a-brief-outline-of-the-theory-of-everything/#Impossibility_of_perfect_reference) (as a species of a referential theory of meaning).

I’m working on a more extensive elaboration of some of the issues of comparing epistemic heuristics used to model the physical and the social world with a subtitle “The differential susceptibility of units to idealization in the social and physical realms” that addresses some of the questions I outlined above.

In it, I want to suggest that the key difference between the social and physical sciences is due to how easy it is to usefully idealize units and sets in the physical and the social world. Key passage from this:

> All of physics is based on idealization. You have ideal gas, perfect motion, perfect vacuum, etc. All of Newtonian physics  is based on the mathematical description of a world where things like friction don’t exist. An ideal world, if you will. Platonic, almost. And it turned out that this type of idealization can take us extremely far, if we let engineers loose on it.
>
> Because all the progress we attribute to science has really been made by engineers. People who take a ballistic curve and ask ‘how about we add a little cross wind’. The modern world of technology around us is all built on tolerances – encoded in books of tables describing how far can we take the idealized formulas of science into the non-ideal conditions of the ‘real’ world.
>
> In the social world, the ideal individual and ideal society are more difficult to treat as units of analysis than perfect vacuum or ideal gas. But even if we could define them, there’s far less we can do with them that would make them anywhere as useful as the idealizations of physics and chemistry. That’s why engineering a solution is a positive description when we talk about the physical world but a negative when we talk about social.

### *Related*
```
./2019-05-29-explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor.md
```
---
title: "Explanation is an event, understanding is a process: How (not) to explain anything with metaphor"
date: 2019-05-29
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor
---

TL;DR
-----

* There are at least 3 uses of metaphor in the educational process: 1. Invitation to enter; 2. An instrument to grasp knowledge with; 3. Catalyst to transform understanding. Many educators assume that 1 is enough but it rarely leads to any useful understanding.
* Explanation is a salient part of the educational process to such an extent that it is often allowed to stand for all of it even though it is only one step.
* Explanation often helps the person doing the explaining more than the person being explained at.
* Metaphors and explanations have been misused by educators from Socrates to Rousseau.
* A metaphor can only be successful if the student already has some knowledge of the target domain. Knowledge of the source domain is often less important.
* Metaphor only makes sense if it is a part of a process. A process of learning. It doesn’t do much good on its own.

Teachers love explaining things. Students love understanding things. On the rare occasions that the two coincide, the feeling of joy shines like a beacon for the power of explanation. Teachers tell stories of seeing the “lightbulbs come on” in their students’ eyes. Students remember fondly the ecstatic moments of sudden illumination as their teacher’s words suddenly lit up the darkness within them. Thus the myth of teaching as explaining and learning as understanding those explanations was born.

Most of the more powerful explanations rely on metaphor in the broadest possible sense. In fact, all explanation is to some extent metaphorical in that it provides a projection from one domain of understanding onto another. Metaphor brings out the familiar – or ex plains it – in the unfamiliar. Or so the story goes.

We can think of metaphoric projection as putting two thin sheets of paper over each other and looking at them against a bright light. What can be on these sheets? Sketches, images, words or even just smudges of color. The projection then obscures certain things and shows others in new contexts. Sometimes, with more complex slides we may see completely new shapes and color hues. The process of making sense of the metaphor then involves slight adjustments in how those two sheets align against one another. This can be described as the metaphor giving a new structure to the target domain.

Another way to think about metaphoric projection is as two sets of items which are mapped onto each other. We can put the sets side by side and draw lines between items we think match. Or we can take them out and place them side by side in a new set. We often see them displayed in this way.

**Note:** This way of thinking about metaphor started with Lakoff and Johnson’s ‘Metaphors we live by’ from 1980. This led to the formulation of the Conceptual Metaphor Theory. It was later developed into a more general theory of frames or mental models by Turner and Fauconnier (2002) known as the theory of conceptual integration or blending. But it can also be found in Donald A Schön’s ‘Displacement of Concepts’ from 1963 which indirectly inspired Lakoff and Johnson.

But despite all this, it is easy to overlook that in order to form a projection from one mental space into another, we have to have some structure in both. In fact, [metaphor often assumes equal knowledge of both domains](https://medium.com/metaphor-hacker/fruit-loops-and-metaphors-metaphors-are-not-about-explaining-the-abstract-through-concrete-but-4e0209dd70b6), and in the process of making a projection from one another, a new previously unimagined structure emerges that is a blend of both domains. Because of the complexity, it is hard to give brief examples, but Turner’s and Fauconnier’s ‘The Way We Think’ is full of very illuminating case studies.

But it is also not at all uncommon for metaphor to borrow from a domain we know much less about to elucidate a domain we know a lot about. For example, if I hear, ‘don’t go into that office, the boss is on a warpath’, I understand a lot more about the boss’s behaviour than I do about any warpaths. Here, only the general feeling of ferocity is transferred with none of the possible association of weaponry or military supply lines.

Metaphor is also always partial. It would make no sense to project every aspect of both domains onto one another. But the ability to understand which bits it makes sense to project and which must be left out also requires at least some understanding of both domains. To understand what we mean when we call a piece of software a ‘virus’ we must know enough about computers to know that the infection cannot be transmitted through simple touch.

Metaphor at its most powerful helps us understand both domains better. It also often results in the creation of new understanding of both domains as we strive to find the limits of possible cross-domain mappings. Often, this happens with honest historical explanations of the present. By comparing the Iraq war to Vietnam, we may only choose to transfer the feeling of emotion and loss associated with the former. But we may also choose to explore both in their own right to find the best way in which they project on to one another. And this gives us new understanding of both.

There are many ways to classify the uses of metaphors, I’ve outlined some in [an early paper](http://metaphorhacker.techczech.net/2013/04/how-we-use-metaphors/). But for the purposes of metaphor in explanation, I’d like to offer three broad types: 1. Metaphor as invitation; 2. Metaphor as instrument; 3. Metaphor as catalyst. I fear that the first type may be most common while only the second two play any real role in building understanding. These three types could also be viewed as forming a sort of process but this is not inherent in the definition.

As we will see, sometimes the same metaphor can serve all three roles, providing a certain thread through the process of learning. But most often, we need new metaphors for each type or stage.

Novice students often come to a new subject with no knowledge and a healthy dose of fear of the unknown. To help them feel more comfortable, teachers like to reach for metaphors relying on the familiar. This gives the learner a chance to grasp onto something while they build up sufficient mental representations of the new domain.

But this use of metaphor usually does not help understanding. It just provides emotional support along the arduous journey towards that understanding. It can also backfire. Teachers often spin up these kinds of metaphors in such a way that they assume an understanding of the unfamiliar. And it is only once students have bootstrapped themselves into some understanding of the subject that the metaphor starts to make any sense to them.

For instance (to use a famous example), we can teach students that the electrical current is like a flow of water. This certainly takes some fear out of the invisible world of electrons. But unless students have at least some prior understanding of electricity, they may ask questions like ‘how do you get the water into the wires?’

This type of metaphor can only be used for a fleeting moment and it must be followed by hard work of accumulating understanding of the new domain on its own terms. Perhaps with the use of more metaphors, this time of the instrumental kind.

The instrumental use of metaphor for explanation is where real understanding starts to happen. But not all teachers are as good at it. In this case, the metaphor provides a way for the student to grasp the new subject. A lens to see it through, or a mental instrument to manipulate it with. Such metaphors are essential to the learning process. However, they do not rely on the moment of instant insight, which they can sometimes trigger, but rather on continuing exploration of the projection between the two domains. Their usefulness is less in the feeling of illumination than in their availability to be used over and over again.

For instance, electrical engineers may be able to make better judgments about certain properties of electrical circuits when they think of electrons as a flow of water. But in other instances, they may be better off when they think about electrons as lots of tiny balls rubbing against one another, generating heat. This metaphor can come up over and over to help them mentally manipulate the two domains.

Here, as with all metaphors, it is essential that we know when to let go. Or even better, when to switch to a different or even a contradictory metaphor. These instrumental metaphors can be local or global but it is rare that one will be enough.

In the third use, the metaphor plays the role of a catalyst. Like a powder dissolved into a liquid, it makes a new substance in which both domains are transformed into one unified understanding. This is when the student transforms into a scholar. Making independent judgments, challenging the teacher’s own understanding, and ultimately becoming her own teacher. To work as a catalyst, the metaphor may be very rich and detailed or just a quick sketch resulting in a slight shift of perspective. But it always requires solid knowledge of the target domain.

Let’s continue with our electrical current example. Here, the student comes not only to understand that sometimes electricity behaves like a liquid and sometimes like a collection of particles, they also come to see the complexity of liquids and particles. They start making predictions both ways and ask questions like ‘What if we thought of the flow of water as a collection of particles?’, etc.

Here the metaphor becomes a process without an end. It spurs new mixtures and remixtures as one finds out more about the two (and often more) domains. Unlike with instrumental and invitational metaphors, it is no longer important that the metaphor be apt. It is just important that it is useful for new understandings or the possibilities of these new understandings. Donald Schön called one subtype of these ‘[generative metaphor](http://metaphorhacker.techczech.net/2011/06/language-learning-in-literature-as-a-source-domain-for-generative-metaphors-about-anything/)’.

But as with the other types, it is important that these metaphors come with some sort self-destruct mechanism.

What often happens is that these metaphors are taken up by those who presume that they map fully onto the target domain and that no other understanding of the target domain is necessary. I described how this is a problem with [Schroedinger’s cat, or Lorenz’s hurricane-triggering butterflies](http://metaphorhacker.techczech.net/2018/11/cats-and-butterflies-2-misunderstood-analogies-in-scientistic-discourse/).

What’s even worse, teachers often use these metaphors far too soon. This either confuses students or, worse, it gives them an illusion of understanding that they do not possess.

My first case study of a bad use of explanation with metaphor is the podcast [Data Skeptic](https://dataskeptic.com). In fact, listening to the most recent episodes prompted me to write this in the first place.

I must preface this by saying that I like the podcast and recommend it to others who want to understand modern data science. It covers important subjects and there is much to learn from it. Its one unfortunate feature, however, are certain episodes when the host, data scientist Kyle Polich, uses his wife, project manager and English major, Linh Da Tran as co-host and tries to explain concepts from abstract computational theory to her. Or rather at her.

This almost invariably fails. Not because Linh Da does not possess the raw intelligence or aptitude to understand these concepts but because Kyle confuses metaphor with explanation and explanation with understanding.

In two recent episodes, he attempted to explain [attention in neural networks](https://dataskeptic.com/blog/episodes/2019/attention) and [Neural Turing Machines](https://dataskeptic.com/blog/episodes/2019/neural-turing-machines). It was an unmitigated disaster. As the metaphors kept piling up, Linh Da finally cried out “I don’t know what you want me to understand”. That’s exactly the problem with a metaphor that only relies on the understanding of the source domain. It serves as a good invitation to the subject but as a very bad instrument for developing an understanding.

There are several problems with this set up that make it a bad place for too many metaphors. First, Linh Da is clearly just humoring Kyle. She’s vaguely interested in machine learning as a phenomenon but has no real interest in putting much work in to learning about how it works. This forces Kyle into more and more metaphors involving their pet bird Yoshi. These are useful socially and emotionally because they allow Linh Da to contribute to the discussion. But her contributions at every turn show that she cannot use any of the analogies to make useful inferences about the subject. She almost never brings up previous subjects. At the end of the episode on Neural Turing Machines, she asked who owns the Turing Machine. In all the torrent of analogies, Kyle neglected to stress that the Turing Machine is itself a metaphor. This is despite a prior episode where another guest explained why Turing Machines are important very clearly.

The conceit of the episodes is that data science can be explained even to English majors. That is certainly correct. But those majors must be willing to put in some work between episodes or have some prior knowledge. And as the subjects get more technical or abstract, the explanations have to get longer and include some practice time. And the amount of this practice needs to increase as if the practice was filling a funnel and not a test tube. Namely, to get from level B to C requires more work than getting from level A to B. Otherwise, the metaphors have nothing to hold on to. They constantly invite the student in but then offer no tools for going further. At best, they will confuse the learner and at worst, they will give them an illusion of understanding. About as useful as a seat belt made from masking tape.

While it is pleasant learning about these concepts through listening in on a married couple having a light-hearted conversation, at a certain stage, this pedagogic device just gets in the way of learning by the audience. Initially, the listener can just do their own metaphor mapping and ask the right questions in their head. But as the abstractness level increases, the host doing the explaining cannot go into sufficient depth because the co-host can’t keep up. And the increasingly convoluted and unnecessary metaphors just create a mental fog that descends over all.

I was particularly disappointed in the episode on Attention in neural networks which is something I wanted to learn more about. I found the initial metaphor of attention as a sort of memory span very useful but then it got stuck because Linh Da could not use it to go any further. This was because she was not given a chance to integrate the previous episodes where similar things were discussed. It was still useful to me because then I could go read about attention with a renewed perspective. But an opportunity for a deeper exploration of the metaphor was wasted.

This would have been fine if the episode was aimed at general public with no other understanding rather than an interested audience with some prior background. But even then, the general public would have needed more and different information to make any sense of it.

At one point Kyle, raised the possibility that maybe he wasn’t an effective teacher because Linh Da could not understand something he had explained. But in fact, he was not being a teacher at all. In this setting, he’s just a provider of images. Like a documentary from the Serengeti where the audience remembers there are lions, but could not place it on a map.

I can imagine that Kyle would be a very effective teacher with students who are interested in the subject and if he had a chance to take them through it step by step. And his use of metaphors would be a valuable contribution to that. But in the podcast, he’s only playing at being a teacher with Linh Da and she’s only pretending being a student. His only goals are getting her to answer questions within his metaphor that seem like she achieved comprehension. This means she never gets a chance to try out the structures of the source domain on the target domain. And because of this she never gets to develop any understanding that could later be used as a foundation for further metaphors. Without this, adding more to the mix feels like an avalanche of analogies.

### Case study 2: The explanation illusion at Wired magazine

But Data Skeptic is not the worst example of this type of pseudo-teaching by explanation. Only the most recent in my mind. A possibly much worse example is the Wired magazine series in which one expert supposedly explains a technical concept at 5 levels of difficulty: 5-7-year old, young teen, college student, graduate student, and another expert. These explanations often involve some level of metaphor, but they are mostly pointless. The conceit is that anybody can understand these concepts at “some level”. But the explanations do not equal understanding as is amply demonstrated in the videos. The people being explained to do not usually develop any new understanding. And it is doubtful whether the people watching do either.

Some of these are because the topic just is not appropriate to be explained to a certain audience. A 5 or 13-year old do not need to understand (nor do they have the background to) things like CRISPR or the Conectome. At best, they may learn which discipline they belong to, but that’s just teaching them a new name. No understanding of the phenomena is necessary.

But even when the understanding is well within reach and might have its use, the ‘expert’ fumbles. Thus the great and inventive musician Jacob Collier failed to explain the concept of ‘harmony’ to any of his charges. First, he tried to convince a five year old that harmony is a way of expressing a feeling with music (as opposed to melody). This is not only too abstract, it is also wrong. Both harmony and melody express feelings. But harmony is different notes played on top of one another rather than in sequence as in a melody (the feelings come from the pitch distance between the tones). This is well within the scope of understanding of a 5-year old when accompanied by some examples. No elaborate metaphors are necessary. But Jacob Collier goes into a very abstract explanation concluding with the most pointless question in any teacher’s arsenal: ‘does this make sense?’ to which he gets a an ‘uhuh’ from the child who clearly has no clue.

But explaining anything to 5-year-olds is hard. So does he do better with a teen? No. He still sticks with the metaphor of harmony as adding emotion to a melody. But then he mixes in the idea of harmony being a journey. To illustrate this, he goes from demonstrating a simple major / minor cord distinction to a jazz chord substitution. Which is wonderful and impresses the student but does not illustrate the concept of harmony to her.

No explanation happens at the higher levels either because all of the others (culminating in jazz giant Herbie Hancock) know the key concepts. So Collier just chats with them about harmonization and reharmonization. Which also reveals that that’s what he had in his mind with the 5-year old and the teen – he was just explaining a much more advanced concept under the label of the simple one.

One of the commenters on the video made an astute observation:

> “it’s interesting how in the earlier levels it has to do more with theory and as you get higher up the level it goes back to nature and life experience and emotions. It’s almost as if, as the complexity increases, there’s also a level of fundamental basic understanding of nature and how it goes hand in hand at the most complex level” (emusik97531 [DL fixed small typos])

Essentially, as the level of the underlying understanding grows, the simple metaphor of journey, place and feeling have the most impact. At the lower levels, they just hang in there, not doing much of anything. They may feel like an invitation, but they don’t have any way to be used as a tool for understanding.

At the higher levels, Collier also shows that maybe he could be a great teacher to somebody closer to his level of skill and understanding. But it also reveals the pointlessness of an isolated act of explanation with (or without) metaphor if it is not supported by the hard work of making the connections necessary for the metaphor to become a proper instrument or a catalyst.

This is not a particular critique of Jacob Collier who is a great teacher to students at Berklee but rather of the whole set up of the series by Wired. Nobody could succeed in this setting. The concept is either going to be hard at the low levels or too basic at the higher ones.

The inglorious history of metaphorical explanation in education
---------------------------------------------------------------

Collier and Polich, as well as countless others, are in illustrious company of people who overestimate what explanation can do in the process of learning.

Socrates in a famous scene from [‘Meno’](https:<span%20class=) walks a slave boy through a series of questions “proving” that he already knew the answer to how to ‘double’ the area of the square. B F Skinner [(1965)](http://olms.cte.jhu.edu/olms2/data/resource/99656/Skinner%20%281965%29.pdf) [PDF] called the Socratic method modeled on this example “one of the great frauds in the history of education”. Setting aside the metaphysics of innate transcendental knowledge Socrates was after, the boy clearly did not learn anything through the interaction. He would not even be able to recreate the proof at a later point. He never got a chance to develop an understanding. This is very much reminiscent of the long-suffering Linh Da who simply answers questions without getting the point of them at any stage and clearly not being able to reconstruct the argument later.

Another giant of philosophy, Rousseau, constructed a thought experimental student in [Emile](https://en.wikipedia.org/wiki/Emile,_or_On_Education) (because, by his own admission, he found teaching actual students too ill-suited to his temperament). Rousseau took the imaginary Emile on a similarly Socratic journey to create the perfect ‘natural man’. Rousseau’s Emile always immediately gets the point of his metaphors and learns the right lesson as if by magic. He rarely does anything in the way of practice – although he perhaps has more time to assimilate new knowledge than Socrates’ victim.

There is much of Rousseau and Socrates in all teachers. Explanations and metaphors are heady stuff while boring practice such as that Skinner was hoping to replace by his teaching machines is the embodiment of tedium for all involved. But without some sort of practice-like engagement with the subject, no understanding is possible. Educators often leave this for the spaces ‘in-between’ teaching events – invisible to them other than as returned homework assignments. Students who succeed have somehow figured out how to do that unmentioned task of conceptual practice. This then looks like effortless insight to the students who struggle.

So, is there a way to avoid the pitfalls we encountered above? As we saw, the first step should be asking oneself whether this is a time for more explanations and if metaphors are the best way of arriving at a useful understanding.

We must also remember that there is no such thing as a perfect explanation or perfect metaphor. Not everybody finds the conceptual work of cognitively decoupling one domain so that it can be projected on another easy to do or even useful. But at some point a metaphor is the only way to go about explaining something.

So when it comes time to construct the metaphor, we must make sure of two things.

First, we have to find the right source domain for the metaphor that can be projected onto the target domain so that the student can achieve useful understanding of some aspect of the target. This happens pretty much through a process of trial and error. Which means, we’re unlikely to happen on the right metaphor on the first try.

Second, we have to make sure we have a good grasp on the possible projections between the two domains. I broadly described the process in my [guide to metaphor hacking](http://metaphorhacker.techczech.net/2010/07/hacking-a-metaphor-in-five-steps/). We have to decide on what the purpose of the metaphor is and whether successful mappings can be made between the two domains. But we have to keep exploring both domains to see if there are any mappings that would result in a misunderstanding. These then have to be explicitly cut off from the metaphor.

For example, a virus is a good metaphor for a piece of software that ‘infects’ your computer. But we must also specify that this can only happen by executing the software, not by simple exposure of 2 PCs in the same room.

The teacher must know when to abandon a metaphor as much as when to bring one up. Some metaphors are local and others are global. The global metaphors are particularly dangerous because they can lock out possible alternative sources of understanding.

Switching between metaphors is essential. But it also contains a danger. The biggest mistake teachers (including this one) make when students say don’t understand, is to fill the air with more different explanations. Yes, these may be necessary. But first give the student some space and time to integrate this into their current level of understanding.

The teacher also has to make sure that the student already has sufficient mental representations from both domains to be able to make the projections between them catch onto something. A computer virus metaphor is useless if the student knows nothing about viruses but it also does not help, if the student knows nothing about computers.

Particularly when metaphors are used as catalysts, it is important to investigate the source domain as much as the target domain. For instance, if we use the metaphor ‘education is business’, we may want to look at various aspects of the way businesses work to see if there are unexpected dangers in using this metaphor globally. Then, if we decide that [schools should run along the same model as New York restaurant](http://metaphorhacker.techczech.net/2011/02/the-most-ridiculous-metaphor-of-education/)s, we should ask what is the equivalent of a restaurant going out of business, or a customer having a bad meal. And what happens if we start thinking of education as a dining experience? Etc.

Finally, it is essential-+ that we pay attention to what happens before and after the metaphor. Each student will bring a slightly different understanding of both the source and the target domains. Can we rely on them coming up with the same mappings on their own? And, if we think of the metaphor as an instrument for dealing with a particular concept, we must make sure we teach the students how it works and give them enough time to practice with it before we leave them to their own devices.

There is no perfect procedure for building a metaphor that explains a new concept. And the metaphor is always only a small part of the process of understanding. We must pay attention to the hard work necessary before a metaphor can be used. And we must think about the work required afterward for the metaphor to continue its usefulness.

Good metaphors are often remembered by students and teacher alike for a long time with emotional salience. But even the best metaphor becomes simply a fond memory of a past moment of enlightenment without any understanding if it is not being continually exercised and stretched. It is far too common for people to just remember the source domain with only the vaguest glimpses of the target domain distorted by time.

Ultimately, any metaphor-based explanation can be but a singular event in the continual process of understanding. Metaphors, when used well, can be great instruments for further exploration. But when used poorly, they are but ornaments on an empty box of the vacant mind.

Post script:
------------

Lest there be any doubt. I have not only seen others make the mistakes I mention here. I have made them all myself. Again and again and again. Deepest apologies to my students.

### *Related*
```
./2019-06-14-5-kinds-of-understanding-and-metaphors-missing-pieces-in-pedagogical-taxonomies.md
```
---
title: "5 kinds of understanding and metaphors: Missing pieces in pedagogical taxonomies"
date: 2019-06-14
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/06/5-kinds-of-understanding-and-metaphors-missing-pieces-in-pedagogical-taxonomies
---

TL;DR
-----

This post outlines 5 levels or types of understanding to help us better to think about the role of [metaphor in explanation](http://metaphorhacker.techczech.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/):

1. **Associative understanding:** Place a concept in context without any understanding.
2. **Dictionary understanding:** Repeat definitions, give examples, and make basic connections.
3. **Inferential understanding:** Make useful inferences based on knowledge about – but without ability to use the understanding in practice. Requires more than just one concept.
4. **Instrumental understanding:** Use the understanding as part of work in a field of expertise. Impossible to acquire for an isolated concept.
5. **Creative understanding:** Transform understanding of one domain by importing elements from another. Requires instrumental understanding – goes beyond hints and hunches.

Introduction
------------

In a [previous post](http://metaphorhacker.techczech.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/), I proposed three uses of metaphor leading to different levels of understanding.

1. Metaphor as invitation
2. Metaphor as a tool
3. Metaphor as catalyst

Only 2 and 3 led to any meaningful understanding and that could only be achieved by acquiring some ‘native’ structure of the target domain. But I was rather loose with how I used the word ‘understanding’. I was using notions like ‘meaningful understanding’ or ‘useful understanding’ but never went into any detail. That is the purpose of this post.

In what follows, I provide a sketch for one way of classifying different kinds of understanding. They are not meant to be descriptions or even discovery of some sort of ‘natural kinds’. Instead, I find them to be a useful way of looking at understanding from the perspective of metaphoric cognition.

Associative understanding
-------------------------

Associative understanding is the ability to place something in a context or category without necessarily knowing almost anything about it. So, we may know that an *emu* is a flightless bird without knowing anything else about it. We could also think of this kind of understanding as a vague notion.

This is the kind of understanding the vast majority of education leaves us with after a few years. Watching a documentary, a TV quiz show, or reading a popular news article fosters this kind of understanding.

Many people can get very far with displaying this kind of understanding – such as con artists impersonating doctors – by successfully imitating experts. The famous Sokal hoax was based on the same principle: making plausible sounding noises can get you published in a prestigious publication. But it is even possible to pass a poorly constructed multiple choice knowledge test with just this understanding by being able to eliminate the wrong options rather than by knowing the correct ones.

The associations can be of various kinds. They can be in the form of basic-category labels (such as – this is an animal). They could place the thing into a discipline – such as ‘something they do in chemistry’. And they could simply be in the form of ‘this is the thing that my friend always talks about’. Or they could also just be a part of the cultural vocabulary without a proper object of understanding.

For example, in the 1960s’ Czechoslovakia there was a famous pop song called ‘Pták Rosomák’ (The Bird Wolverine). The band simply liked the sound of the Czech word for ‘wolverine’ and its rhyme with the word for ‘bird’. Wolverines are not native to Europe or well known outside of this song. I did not find out what the word meant until I learned it in English (I also knew what the English word wolverine meant long before I looked it up in a Czech dictionary). When I presented this at a conference on cognition in Prague, most Czech academics in the audience were surprised by the meaning. Yet, if you asked them – do you understand the word ‘rosomák’, they would have said ‘of course, I do’. But it was just an associative understanding.

My claim is that the vast majority of what passes for understanding and knowledge in ‘polite society’ is of the associative kind. People feel comfortable when concepts like evolution or philosophy are mentioned but have only the vaguest idea of where they belong.

My favourite example of this is Monty Python’s ‘[Philosopher’s song](https://www.youtube.com/watch?v=PtgKkifJ0Pw)‘. All the audience needs to know to appreciate the jokes is that there is a philosopher stereotype and that certain names are of philosophers. In fact, by their own admission (citation needed but I did hear it in an interview), the authors of these sketches also did not know much more than the names. Even the little nod to knowledge in ‘John Stuart Mill of his own free will’ is just a glimmer of something deeper.

Associative understanding is pretty much only useful for social signalling. It can also play a role in making a new field appear more familiar in later stages. I have had that experience several times when vague memories from school made me feel more confident I was on the right track when I set about studying a subject in depth even if I had very little more than a vague feeling about something. But on its own, this kind of understanding has little practical value.

In formal instruction, we generally start with the next step but over time, without practice, this is the kind of understanding, we’re left with. But in literature on pedagogy, it is mostly unaddressed. It is the kind of understanding below the bottom rung of Bloom’s taxonomy. But many teachers encounter it when at the end of classes students come and ask questions that barely show a hint of an understanding that makes it seem like they may not have even been in the same room.

Lexical understanding
---------------------

At this level, we can repeat a definition as we might find it in a dictionary and give a few examples. We can look at a picture and say, this is an emu. It lives in Australia and it is a kind of ostrich. For something like an *emu*, it may well be enough for most of us.

This is the kind of understanding we may be able to take away from a quick explanation of something. It is the sort of understanding most tests check for. It is also often used as a proxy for intelligence or ‘being smart’. Lexical understanding is what is required of successful quiz show panellists. UK shows such as ‘Mastermind’, ‘Brain of Britain’ or ‘University Challenge’ are great examples of these.

Conversely, lack of lexical (and sometimes even associative) understanding is also often given as an example of educational decline or lack of intelligence.

This would be roughly equivalent to the ‘Knowledge’ and ‘Comprehension’ levels on the Bloom’s taxonomy. It is the minimum target for instruction but it is very unstable. Unless it has been recently used, it often reverts to associative kind of understanding.

This kind of understanding is generally not very useful outside the educational context. This is the kind of understanding that is the result of ‘teaching to the test’. It can be leveraged into something more but only with practice and application.

In terms, of frames or mental representations, we could say that the only mental representations developed as part of this understanding are propositional or rich imagery. Meaning, we have sentences or images in our head that we can draw on but we would find it very hard to combine them into larger wholes.

This level and the transition from this level to the next are where what we call pedagogy plays the most important role.

Inferential understanding
-------------------------

This kind of understanding lets us make useful inferences about the concept in context. It requires some knowledge of a whole domain or several domains. You can never understand a solitary concept at this level. But it does not necessarily require deep ability or skill. I know nothing about *emus*, so I cannot think of an example that would not be misleadingly trivial.

But I have a personal example from when I was recently catching up on the latest developments in machine learning. I was reading about different types of neural nets. And when I was reading about CNNs (Convolutional Neural Networks) which are usually used for images, I had an idea for using the similar approach to process language by representing text in a way similar to the way images are represented. And it turned out there are already papers and models out there that do just that.

Inferential understanding is the kind of understanding that good students develop about favorite subjects that they pursue later. The kind of understanding that collaborators develop about each others’ discipline in interdisciplinary projects. The kind of understanding good generalist managers develop about the domains in which they supervise subject experts. Or really good journalists develop about areas on which they report. This is also the kind of understanding experts have about related fields or that teachers have about some of the more advanced areas of their field.

The sociologist of science Harry Collins described in one of his books (I think it was ‘Rethinking Expertise’) how he could pass some knowledge tests in gravitational wave physics better than professional physicists from adjacent specialisations. This was after many years of observing these physicists but without any real ability to the actual calculations or research required.

It may not always be easy to tell the boundary between this and lexical or even associative understanding. This is the kind of understanding potentially displayed by an audience member at a lecture who asks a question that is then described as ‘a good question’ by the presenter. But often this is just a fluke. A random hit based on superficial resemblance of words in a definition.

This is the kind of understanding that sort of ‘does not count’ in the terms of Bloom’s hierarchy. We feel it is insufficient because it is not something people consciously aim at in instruction. But it is in many ways the best we can hope for. It is the first kind of any useful knowledge.

It requires more developed mental representations. Representations where the propositions and rich images are replaced by schemas and scenarios. These are a sort of useful compressions that can be blended (or integrated) with others. What it means that when reasoning with these concepts, we can use them as whole units (mental chunks) rather than laboriously compute them from first principles.

It may also derive from some basic level of instrumental understanding. The humour in XKCD cartoons can be understood with a combination of inferential and instrumental understanding. I immediately understood this comic [famous among programmers](https://xkcd.com/327) without being a programmer myself but having some skills with databases and knowledge of common problems with security.

But for the most part, we cannot use this understanding for actual work. This is where the humanities and sciences often diverge. It is possible to pretend (even to oneself) that this understanding lets us do real useful work in history or sociology. Whereas with mathematics, engineering, medicine, or biology, the barrier between this and instrumental understanding is much more clearly defined by specialised tools such as mathematics and chemistry. But if we look at the many former physicists or biologists who have tried their hand at philosophy, sociology or even literary criticism, we see that even here, this kind of understanding is not enough.

You really need more to have a chance of doing something useful.

Instrumental understanding
--------------------------

This is the kind of understanding experts and practitioners have. It requires being able to use the concepts or tools in practice. I don’t have any instrumental understanding of convolutional neural networks. I couldn’t build one and possibly couldn’t even reconstruct the exact way in which it works.

This level of understanding or ability or skills requires more than just reading or learning about. It requires practice and building of mental representations which only comes from long-term engagement with a subject. For example, I don’t have that kind of understanding of neural nets, but I do have it of metaphor.

I can create metaphors, identify them in text, speak to the controversies around them, compare and contrast the various theories of metaphor. I can teach somebody how metaphors work. I can write a successful paper or give a conference presentation in the field. If somebody wants to know about metaphor they can come to me. Other people with good instrumental understanding of metaphor may disagree with some of what I have to say, but they won’t do it (I hope) as they would with somebody who has just an associative, lexical or even inferential level of understanding – e.g. knowing that metaphor has something to do with poetry. You have to put in the work.

This work may require actual repetitive practice (such as working out math problems or analysing texts). It absolutely requires extensive engagement with other experts in the field. Taking classes, going to conferences, reading latest research, writing papers, blogs, etc. That’s why loner autodidacts almost never reach this level of understanding.

Here the distinction between understanding and ability or skill becomes blurred. Mental representations develop at the highest levels of schematicity. This means that an expert can look at a very complex situation and treat it as one unit that can be blended with other complex units in a way that only the relevant parts are engaged.

For instance, I can read a complex argument about metaphor and immediately compare it with three other complex arguments about metaphor – not because I have a large mental capacity for abstract concepts but because I have developed a number of highly schematic mental representations about the shapes of arguments people make about metaphor. This way, I can project these schemas onto the argument as one big chunk.

Perhaps an even better analogy is learning a foreign language. I may know all the rules and words but I cannot speak the language with any level of fluency until I have developed larger chunks I can just slightly modify. It is simply impossible for even the most highly mentally endowed human to dredge up individual words, apply rules to them and combine them into a sentence quickly enough to speak with any level of coherence. It’s even worse for understanding. Just reading a text with a dictionary is such a slow affair that we forget what a sentence was about before we get to the end.

In other words, we can then define instrumental understanding as developing a basic fluency in the language of the discipline. And this takes time, targetted practice, and active ‘communicative’ engagement across a whole field.

In the ‘hard sciences,’ it requires a good facility with formalisms or even equipment and in the ‘softer’ disciplines it relies on extensive reading, talking, and writing.

Here we are at a much wider aperture of our knowledge funnel. It is therefore impossible to exactly compare 2 people’s levels of instrumental understanding. Everybody will have a slightly different set of mental representations. Also, many people will only be able to ‘perform’ at this level some of the time or only for small chunks of their discipline.

At this level, pedagogy is much less relevant. This is where it makes a lot less sense to talk about teaching and learning if only because it is impossible to acquire this level of understanding purely in the classroom. Training, coaching or even apprenticeship are much better models.

Creative understanding
----------------------

Creative understanding is instrumental understanding with a transformative element. This requires knowledge of several domains and their creative intermingling. It is the sort of understanding innovators in their field have. This can lead us to a complete rejection of the thing we understand as an independent concept.

For example, I have long argued that metaphor is not the only place in language where domain projection occurs and that we should not think of it as something special but rather as a shortcut for thinking about broader phenomena of framing or cognitive models. I found this a useful way of extending the concept. So, I can make a serious statement such as ‘metaphor and metonymy are the same thing’ that can be productive in the study of metaphor. But it only makes sense because I can actually distinguish between [metaphors, similies](http://metaphorhacker.techczech.net/2018/05/not-ships-in-the-night-metaphor-and-simile-as-process/), [synechdoches or metonymies](http://metaphorhacker.techczech.net/2013/12/binders-full-of-women-with-mighty-pens-what-is-metonymy/) in an instrumental way, and I can also reproduce arguments that maintain that the difference between metaphor and metonymy is crucial for understanding figurative language.

It is hard to say whether this type of understanding is even a part of the funnel hierarchy. Perhaps it is just an ingredient (catalyst) to instrumental understanding. But I do want to stress that it only works as a catalyst to instrumental understanding. As I showed in my post on types of metaphors, creativity needs to start from somewhere.

We may often confuse almost accidental insights by people with inferential or even just lexical understanding for creativity. But this is like recognising a melody in the sounds a child makes by randomly banging on the piano keyboard.

We often valorise the outsider perspective in a field. And it certainly can act as a catalyst for creativity but only if it has proper instrumental understanding to lean on.

Conclusions and limitations
---------------------------

I cannot stress enough that this classification is just a useful heuristic. I am not claiming that this kind of classification of understanding is exhaustive or even that it represents some sort of a natural category. But I found it useful when thinking about explanations and pedagogy.

Approaches to classifying understanding
---------------------------------------

It is quite common to distinguish between shallow and deep understanding. This is intuitively obvious but not very helpful because it assumes the existence of some sort of objective scale of a depth of understanding.

We can also distinguish understanding from knowledge for example by differentiating between explicit and tacit knowledge. Understanding and explicit knowledge intuitively overlap even if we don’t have a firm definition of either. If we understand something, we can mentally manipulate it and, most importantly, pass it along.

But the boundaries between tacit and explicit knowledge are not firm. All explicit knowledge depends on some tacit knowledge – or in other words, all understanding depends on knowledge. We could even say that deep learning is the process of transforming understanding into knowledge. In the sense, that we need to build up schematic mental representations to be able to manipulate ever more complex combinations of concepts.

Another way to try to get at understanding is to investigate how to achieve it. Bloom’s taxonomy of educational objectives is one famous example. There are many tweaks and elaborations – some as extreme as Jack Koumi’s 33 pedagogic roles. But they are ultimately not very satisfying because they already assume we know what the understanding is.

Understandings as a process revisited: The wave and the funnel
--------------------------------------------------------------

Even though these different types of understanding are ‘broadly hierarchical’, I want the emphasis to be on ‘broadly’. It would make no sense to think of these as a straightforward linear hierarchy measurable on a scale of discrete and comparable units. They are more like overlapping waves. Layers of water covering the beach in successive bursts as the tide is coming in.

But that metaphor does not make it easy to visualise the differences and mutual interdependence. It only evokes how hard and unreliable it is to do so. But for the purposes of this comparison, I’d like to offer something more like a funnel (which I also brought up in the context of the [metaphor explanation hierarchy](http://metaphorhacker.techczech.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/)) or inverted cone.

The substance that fills the funnel might be a mixture of effort and coverage of material. This makes it easy to visualise the fact that it takes much more effort, time and background knowledge to get from level 3 to level 4 than it does to get from level 1 to level 2. Also, at the higher levels, the concepts themselves transform and interconnect. So it is not possible to understand them in isolation.

This truly takes into account the processual nature of understanding. The funnel also needs to be constantly topped up to maintain certain levels. But it can also underscore the fact that we can never perfectly compare 2 people’s levels of understanding. Because at the higher levels, the funnel is so broad, not everybody will have filled it in the same way with exactly the same substance.

I got this idea from ACTFL language competency levels and I think it is one of the most underappreciated metaphors in education.

Another really useful thing ACTFL does is that it defines low, mid and high sublevels for each competency levels. And a part of the definition of the ‘high’ sublevel is that the person can function at the ‘low’ sublevel of the next level about half the time. (E.g. a Novice-Low can function as Intermediate-Low about 50% of the time). During the test (most often an interview), the examiner establishes a floor and a ceiling rather than pinpointing an exact point on a scale.

This very much applies to the levels in my metaphor. There are no clear boundaries between these levels of understandings. In as much as they are levels in the first place.

### *Related*
```
./2019-06-15-writing-as-translation-and-translation-as-commitment-why-is-academic-writing-so-hard.md
```
---
title: "Writing as translation and translation as commitment: Why is (academic) writing so hard?"
date: 2019-06-15
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/06/writing-as-translation-and-translation-as-commitment-why-is-academic-writing-so-hard
---

> This book will perhaps only be understood by those who have themselves already thought the thoughts which are expressed in it—or similar thoughts. It is therefore not a text-book. Its object would be attained if there were one person who read it with understanding and to whom it afforded pleasure.  
> *(opening sentence of the preface to Tractatus Logico Philosophicus by Lugwig Wittgenstein, 1918)*

Background
----------

I’ve recently been commenting quite a lot on the excellent academic writing blog (which I mostly read for the epistemology) [Inframethodology](https://blog.cbs.dk/inframethodology) by Thomas Basbøll. Thomas and I disagree on a lot of details but we have a very similar approach to formulating questions about knowledge and its expression.

The recent discussion was around the problem of ‘writing as expressing what you know’. While I find it very useful to distinguish between writing to describe what you know and writing to explore and discover new ideas (something I first reflected on after reading Inframethodology), I commented:

> I still find that no matter how well I think I know my subject, I discover new things by trying to write it down (at least with anything worth writing).

Thomas responded in [a separate blogpost](https://blog.cbs.dk/inframethodology/?p=2518), first picking up on my parenthetical:

> Can it really be true that the straightforward representation of a known fact is not “worth writing”? Is the value of writing always to be discovered (by way of discovering something new in the moment of writing)? I think Dominik is thinking of kinds of writing that are indeed very valuable because they present ideas that move our own thinking forward and, ideally, contribute positively to the thinking of our peers. But I also think there is value is writing that doesn’t do this, writing that is, for lack of a better word, boring.

With this, I agree wholeheartedly. 110% coach! Yes, this was a throwaway line I wasn’t comfortable with even as I was writing it. The majority of my writing is mundane: emails, instruction manuals, project proposals, etc. They may or may not be “worthy” but they certainly have a worth. And people who do nothing but that sort of writing certainly do not do anything I would find ‘beneath me’ or not worthy. I might have been better served by the term ‘quotidian’ or even ‘instrumental’ writing.

I agree even more with Thomas’s elaboration (my emphasis):

> In fact, I think it’s the primary of value of academic writing and one of the reasons that so many people (and even academics themselves) almost equate “academic” (adj.) with “boring”.**The business of scholarship is not to bring new ideas into the world, indeed, the function of distinctively academic work (in contrast to, say, scientific or philosophical or literary work) is not to innovate or discover but to critique, to expose ideas to criticism.** In order for this happen efficiently and regularly, academics must spend some of their time representing ideas that are not especially exciting to them along with their grounds for entertaining them. They must present their beliefs to their peers along with their justification for thinking they’re true. And they must do this honestly, which is to say, they must not invent new beliefs or new reasons for holding them in the moment of writing. They must write down, not what they’re thinking right now, but what they’ve been thinking all along.

I find this an incredibly valuable perspective and when I think of my own writing, I think this is precisely where I’ve often been going wrong. This is partly because academic writing is more of a hobby than a job, so I don’t have the time to do more than write to discover. But it is partly because of my temperament. I don’t enjoy the boring duties of writing things I know down and then formatting them for the submission to a journal. I prefer to work with editors which is why the bulk of my published writing is in journalism or book chapters.

But there is still another aspect that needs to be explored. And that is, **why do most people find it so difficult to write down what they know** even while taking into account all of the above.

Writing as translation
----------------------

I propose that a good way to think about the difficulty of writing to describe our thoughts is to use the metaphor of translation. We can then think of the content of our thoughts in our head as a series of propositions expressed in some kind of ‘mentalese’. And when we come to write them down, we are essentially translating them into ‘writtenese’ or in this case, one of its dialects ‘academic writtenese’.

This is made more complicated by the existence of a third language – let’s call it ‘spokenese’. We are all natively bilingual in ‘mentalese’ and ‘spokenese’ even if not everybody is very good at translating between these two languages. In fact, children find it very difficult until quite late ages (10 and up) to coherently express what they think and even many adults never achieve great facility with this. Just like many natively bilingual speakers are not very good at translating between their two languages.

But nobody is a native speaker of ‘writtenese’. Everybody had to learn it in school with all its weird conventions and specific processing requirements. It is not too outlandish to say (and I owe this to the linguist Jim Miller) that writing is like a foreign language. (Note: see some important qualifications below).

When we are translating from mentalese to academic writtenese, we are facing many of the same problems translators of very different languages faces. The one I want to focus on is ‘making commitments’.

Translation as commitment: Making the implicit explicit
-------------------------------------------------------

Perhaps the most difficult problem for a translator (I speak as someone who has translated hundreds of thousands of words) is the issue of being forced by the way the target language operates to commit to meanings in the translation where the structure of the source language left more options for interpretation.

Let’s take a simple paragraph consisting of three sentences (Note: this is a paraphrase of an example given by Czech-Finnish translator at a conference I attended some years ago):

> The prime minister committed to pursue a dialogue with the opposition. This was after the opposition leader complained about not being involved. She confirmed that he would have a seat at the table in the upcoming negotiations.

The first commitments I have to make at some point is to the gender of the participants in the actions I write about. In English, I can leave the gender ambiguous until the third sentence. In Finnish, which does not have gendered third-person-singular pronouns, I don’t have to express the gender at all.

In Czech (and many other languages), on the other hand, I have to know the gender of the prime minister from the very first word. Like actor and actress in English, all nouns describing professions have built-in genders (this is not optional as in English because all Czech nouns have assigned some grammatical gender). I also need to express gender as part of the past tense morphology of all verbs. So even if I could skirt the gender of the ‘leader’ (there are some gender-ambiguous nouns in Czech), I would have to immediately commit to it with the verb ‘complained’. Which is why knowledge of their subject is essential to simultaneous translators.

But this is a relatively simple problem that can be solved by reference to known facts about the world. A much more significant issue is the differential completion of certain schemas associated with types of expressions. Let’s take the phrase ‘committed to pursue’. The closest translation to the word ‘commit’ is ‘zavázat se’ which unfortunately has the root ‘bind’. It is therefore ever so slightly more ‘binding’ than ‘commit’. I can also look into something like ‘promise’ which of course is precisely what the prime minister did not do.

Then, there is the word ‘pursue’. One way to translate it is ‘usilovat o’ which has connotations of ‘struggle to’. So ‘usilovat o dialog’ is in the neighborhood of ‘pursue a dialog’ but lacks the sense of forward motion making it seem slightly less like the dialog is going to happen. So here each language is making subtly different commitments.

When you’re translating academic writing, there are hundreds of similar examples, where you have to fill in blanks and make some claims seem stronger and others weaker. And even if you know the subject intimately (which I did in most cases), you often have to insert your judgement and interpretation. And the more you do that, the less certain you feel that you got the meaning of the original exactly right. This is even when while reading the original, I had no sense of something being left unexpressed. The only way to get this right is to ask the author. But even that may not always work because they may not remember their exact mental disposition at the time of writing.

Writing as filling in holes in our mind
---------------------------------------

I believe that this is exactly the experience we have when we write about something that only exists in our head or something we’ve only previously talked about. Even when I’ve given talks at conferences and had many conversations with colleagues, writing my ideas down remains a difficult task.

When writing, the structure of ‘writtenese’ (as well as the demands of its particular medium) forces me to make certain commitments I never had to make in ‘mentalese’ (or even ‘spokenese’). I have to fill out schemas with detail that never seemed necessary. I have to make more commitments to the linearity of arguments, that could previously run parallel in my head. So when I write it is not clear what should come first and what last.

When I just write down what’s in my head (or as close to it as it is possible), it is unlikely to make any sense to anybody. Often including myself after some time. I need to translate it in such a way that all the necessary background is filled out. I also need to use the instruments of cohesion to restore coherence to the written text that I felt in my mind without any formal mental structure.

But during this process, I often become less certain. The act of writing things down triggers other associations and all of a sudden I literally see things from a different perspective. And this is often not a comfortable experience. Many writers find this a source of great stress.

This is, of course, true even of writing instructions and directions. Often, when describing a process, we find there are gaps in it. And when writing down directions, we come to realise that we may not know all aspects of the familiar sufficiently well to mediate the experience to someone else.

Teaching writing as translation
-------------------------------

Translation is a skill that requires a lot of training and practice. In many ways, a translator needs to know more about both languages than a native speaker of either. And then they need to know about different ways of finding equivalent expressions between the two languages in such a way that the content expressed in the source language produces similar mental effects when reading in the target language. This is not easy. In fact, it is frequently impossible to achieve perfectly.

When I translate I often refer to a dictionary (such as slovnik.cz) that lists as many possible alternatives of words even if I know exactly what the original ‘means’. This is because I want to see multiple options of expressing something which may not be immediately triggered by my understanding of the whole.

But for this to work, I need to have done a lot of deliberate reading in both languages to know how they tend to express similar things. At the early stages, I may approach this more simply as learning to speak a language. I may learn that ‘commit to pursue’ is best translated as ‘zavázat se usilovat o’. But I have to back that up by a lot of reading in both languages, studying other translators’ work and making hypotheses about both languages and the differences between them. Eventually, this becomes second nature and to translate fluently, we need to ‘forget’ the rules and ‘just do it’.

So how could we apply this to teaching (academic) writing? We need to start by ensuring that students have enough facility in both the source and the target languages. We usually assume greater fluency in the source language (most translators work primarily in the direction of native to non-native). So in this case, we need to focus on the structures and ways of ‘academic writtenese’.

We can very much approach this as teaching a foreign language. Our first aim should be to help students acquire fluency in the language of academic writing. We need to give them some target structures to learn. This should ideally be based on an actual analysis of that writing rather than focusing on random salient features. But ultimately, the key element here is practice.

Then we also need to focus on helping the students develop better awareness of their native mentalese and how to best map its structures onto the structures of writtenese. We can do this by helping them write outlines, create mind maps, come up with relevant key words, and of course, read a lot of other people’s writing, think about it, and then write summaries in similar ways.

None of these are particularly revolutionary ideas and they are being used by writing teachers all over the world. What I’m hoping to do here is to provide a metaphor to help focus the efforts on particular aspects of what makes the translation from thought to writing difficult.

Writing as playing a musical instrument
---------------------------------------

One final analogy that can help us here is the idea of writing as playing a musical instrument. This analogy is in many ways even more apt. When we play a musical instrument, we are initially translating relatively vague musical ideas into actual notes (melodies and harmonies) by way of the structures given to us by the musical instrument.

We may start by learning some chords to accompany a song we hear but later we will progress into more details of musical theory which will allow us to express more elaborate ideas. But, in fact, this also allows us to have more those more elaborate ideas in the first place.

Initially, our ability to express musical ideas via an instrument (such as piano or guitar) will be limited by our skill. We may not even realize what exactly the idea in our head was until we’ve played it. And often, what we can play limits the ideas we have. Jazz teachers often say something like ‘sing your solos first and then play’ (others call it ‘audiation’). But this is not trivial and requires extensive training. Which is why one common advice for jazz musicians is to transcribe (or at least copy) famous songs and solos. But as you’re transcribing and copying, you’re supposed to notice patterns in how musical ideas are expressed. You can then recombine them to express what is in your ‘musical mind’.

But it seems that the musical ideas and their form of expression are never completely separate. They are not a pure translation but rather a co-creation. And this is true of any good translation and probably also ultimately true about any act of writing. We are using a different medium to express an existing idea but in the process, we are filling gaps in the ideas, creating new connections until we ultimately cannot be completely certain which came first.

As we get better at translation, music or writing, there are some levels about which the last part does not hold true. There are some ideas we can truly and faithfully translate from our head to paper, musical instrument or from one language to another. This is why practice is so important. But at the highest levels of difficulty, writing, translation and music making will always be acts of co-creation between the medium and the message.

Teaching writing as music
-------------------------

So finally, could we teach writing in the same way as we teach music? We certainly could. Just like teaching a foreign language, teaching music is mostly dependent on a lot of practice.

But perhaps there are some techniques that music teachers use that could be useful for both language teachers, translators and writing coaches.

One is the emphasis on patterns. The idea of practicing scales, licks, or chords relentlessly (up to hours a day) holds a lot of appeal. Perhaps we start teaching self-expression with writing too soon. Maybe we should give students some practice patterns to repeat in different combinations. Then we could tell them to just copy and then dissect parts of good texts. The idea of ‘mindless’ copying will probably stick in many teachers’ craws. But just analysing reading will never be enough. Students need the experience of writing some good writing. If only to develop some muscle memory. And while it should never be completely mindless, it should also perhaps not be completely meaningful from the very start. Of course, we could invent numerous variations on this approach to transform the texts in various fun ways while still making sure, students are writing extended chunks and developing fluency. The point is that we would not be focusing on self-expression but developing a language for self-expression.

Music teachers and students use what has been [described by Anders Ericsson](https://www.amazon.co.uk/Peak-Secrets-New-Science-Expertise/dp/0544456238) as ‘deliberate practice’. Ericsson gives the example of Benjamin Franklin who used similar techniques to improve his writing:

> He first set out to see how closely he could reproduce the sentences in an article once he had forgotten their exact wording. So he chose several of the articles whose writing he admired and wrote down short descriptions of the content of each sentence—just enough to remind him what the sentence was about. After several days he tried to reproduce the articles from the hints he had written down. His goal was not so much to produce a word-for-word replica of the articles as to create his own articles that were as detailed and well written as the original. Having written his reproductions, he went back to the original articles, compared them with his own efforts, and corrected his versions where necessary. This taught him to express ideas clearly and cogently.

Obviously, this was not all there was to it, but it is very much reminiscent of what music students do. It seems to me that most beginner writers are often asked to do too much at the very start and they never get a chance to improve because they essentially give up too soon.

Writing is writing! It has its specific properties that we need to attend to if we want to see all of its complexities. We must use metaphors to help us do this but always by remembering that metaphors hide as much as they reveal. One useful way of understanding something is to create a sort of unmetaphor: a listing of similar things that are different from it in various respects. This is something that, while not uncommon, is done much less than it should be when using analogies.

### Written language is not a foreign language

Some of the fundamental mental orientations of a language are shared between the written and spoken forms. This includes tense, aspect, modality, definiteness, case morphology, word categories, meanings of most function words, the shape of words, etc. These present some of the most significant difficulties to learners of foreign languages making it very difficult to acquire a second language by exposure alone after a certain age for most adults.

Writing, on the other hand, can be acquired predominantly by exposure alone for many (if not most) adults. There are many people who acquire native-like competence in the written code in the same way they acquired their spoken language competence (even if there are just as many who never do). And we must also be mindful (as Douglas Biber’s research revealed) that there is a bigger difference between some written genres then there is between writing and speech overall. So we should perhaps attend to that.

### Writing is not translation

That writing is not actually translation is contained in the fact that written language is not actually a foreign language. There are many genres and registers in any language with their specific codes. And we could call going from one code to another translation much more easily than going from what I called ‘mentalese’ and ‘writtenese’. (Again, the work of Douglas Biber should be the first port of call for anyone interested in this aspect of writing.)

But most importantly, what I called ‘mentalese’ does not actually have the form of a language. Individuals differ in how they represent thoughts that end up being represented by very similar sentences. Some people rely on images, others on words. For some, the mental images more schematic and for others, they have more filled in details. For instance, Lakoff asked how different people imagine the ‘hand’ in ‘Keep somebody’s at arm’s length’. And the responses he got were that for some the hand is oriented with the palm out, others with the palm in.  For some, it includes a sleeve, for others it does not. Etc.

### Writing is not music

I’ve already written about the [8 ways in which language is not like music](http://metaphorhacker.techczech.net/2018/03/10-ways-in-which-music-is-like-language-and-8-more-important-ways-in-which-it-is-not/). And they all apply to writing, as well. The key difference for us here is that music cannot express propositions. This means that musical expression can be a lot freer than expressing ideas through writing.

We could argue that writing is more like music than spoken language because it requires some kind of an instrument. Pen, paper, computer, etc. But we usually learn these independently of the skill of expressing ourselves through writing. My ability to play the piano is much more closely tied to my ability to express my musical meanings. However, people write just as expressive prose by the hunt and peck method as when they touch type. One can even dictate a ‘written text’ – that’s how independent it is of the method of production.

Of course, improving one’s facility with the tools of production can improve the writing output just by removing barriers. This is why students are well-advised to learn to touch type or to use a speech-to-text method if they struggle for other reasons (e.g. visual impairment or dyslexia). But when it comes down to it, this is just writing down words and as we established, writing in most senses is more than that.

Conclusions and limitations
---------------------------

Ultimately, writing and translation are not the same. Just as writing and music are not the same. But there are enough similarities to make it worthwhile learning from each other.

Many writers have developed great skills by the ‘tried and tested’ approach of ‘just doing it’. But we also know that even many people who do write a lot never become very ‘good’ at it. They struggle with the mechanics, ability to express cogently what’s in their minds, or just hate everything about it.

For some beginner writers, the worst thing we could do is give them a lot of mindless exercises. These people will want to do it first and would hate to be held back. Just like many students of languages or music like dive off the deep end. But equally, for many others, telling them to ‘just do it’ is the perfect recipe for developing an inferiority complex or downright phobias of writing.

But all of these writers will need lots of practice – regardless of whether we provide lots of ladders and scaffolding or just put a trampoline next to the edifice of their skill. In this, writing is exactly like music, language and translation. You can only get better at it by doing it. A lot!

I started with a quote from Wittgenstein. But he also famously said in summarising his book:

> What can be said at all can be said clearly; and whereof one cannot speak thereof one must be silent.

I think we saw here that this is not necessarily how the act of writing presents itself to most people.

He then continued:

> The book will, therefore, draw a limit to thinking, or rather—not to thinking, but to the expression of thoughts; for, in order to draw a limit to thinking we should have to be able to think both sides of this limit (we should therefore have to be able to think what cannot be thought). The limit can, therefore, only be drawn in language and what lies on the other side of the limit will be simply nonsense.

This is was the so-called “early Wittgenstein” before the language games and family resemblances. He spent the rest of his career unpicking this boundary of sense and non-sense. Coming to terms with the fact that what is thought and what is its expression are not straightforward matters.

So all the metaphors notwithstanding, we should be mindful of the constant tensions involved in the writing process and be compassionate with those who struggle to navigate them.

### *Related*
```
./2019-06-30-5-books-on-knowledge-and-expertise-reading-list-for-exploring-the-role-of-knowledge-and-deliberate-practice-in-the-development-of-expert-performance.md
```
---
title: "5 books on knowledge and expertise: Reading list for exploring the role of knowledge and deliberate practice in the development of expert performance"
date: 2019-06-30
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/06/5-books-on-knowledge-and-expertise-reading-list-for-exploring-the-role-of-knowledge-and-deliberate-practice-in-the-development-of-expert-performance
---

Recently, I’ve been exploring the notion of [explanation](http://metaphorhacker.techczech.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/) and [understanding](http://metaphorhacker.techczech.net/2019/06/5-kinds-of-understanding-and-metaphors-missing-pieces-in-pedagogical-taxonomies/). I was (partly implicitly) relying on the notion of ‘mental representations’ as built through deliberate practice. My plan was to write next about how I think we can reconceptualize deliberate practice in such a way that it draws on a richer conception of ‘mental representations’. But that is turning out to be a much longer project.

Meanwhile, in a recent conversation about teaching practitioners, somebody mentioned reading Kahneman’s ‘Thinking Fast and Slow’ as being relevant to the problem and we discussed maybe starting a reading group. This got me thinking about what should such a reading group have on its reading list.

The literature on expertise is vast (just look at the [Cambridge Handbook of Expertise and Expert Performance](https://www.cambridge.org/gb/academic/subjects/psychology/cognition/cambridge-handbook-expertise-and-expert-performance-2nd-edition?format=HB&isbn=9781316502617)). In my proposed reading list, I would focus on identifying different perspectives on how our mental representations of the world are structured, how we develop them (or how we can help others develop them), how we solve problems with them, and how they are embedded in the social environment in which we function.

1. Thinking Fast and Slow by Daniel Kahneman (2011)
---------------------------------------------------

[Kahneman’s famous book](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow) is not really focused on experts but rather on the limitations of our thought – summarised under the heuristics and biases banner. But Kahneman’s notion of ‘System 1’ (fast) and ‘System 2’ (slow) thinking is directly relevant to the question of expertise. Expertise means that one can think about complex issues quickly but also that one can analyze that same issue with deliberate attention to detail. Exactly how this applies to the question of educating experts is a matter of discussion that I think the other books on my list can help elucidate.

2. Peak: Secrets from the new science of expertise by Anders Ericsson with Robert Pool (2016)
---------------------------------------------------------------------------------------------

In [this book](https://www.amazon.co.uk/Peak-Secrets-New-Science-Expertise/dp/1847923194), Ericsson (helped by journalist Pool) provides an outline of a cognitive mechanism by which fast thinking is acquired without the sacrifice of deliberation in the concept of ‘delibrate practice’. I propose that the key to understanding deliberate practice is not the process of practice but rather on Ericsson’s rethinking of the target that the practice should help us achieve. According to Ercisson, what delibrate practice leads is not knowledge or skill but rather ‘mental representations’. Mental representations are best thought of as chunks of knowledge (frames, scripts, schemas, etc. – which makes this approach overlap with Kahneman and Tversky’s work even though Ericsson does not mention this). This allows experts to perform complex mental operations on very rich subject domains which would be beyond the computational powers of anyone’s pure raw intelligence. The best analogy is being able to play chess or speaking a language – this is impossible by simply knowing the rules – we need a rich complex of mental representations to compete at chess or to speak with any fluency.

3. The Way We Think: Conceptual Blending and the Mind’s Hidden Complexities by Gilles Fauconnier and Mark Turner (2002)
-----------------------------------------------------------------------------------------------------------------------

Where Kahneman provides the framework and Ericsson the mechanism of acquisition, [Fauconnier and Turner](http://markturner.org/wwt.html)  offer us a much more detailed description of the actual structure of ‘mental representation’ and how it is used during live processing of information. Building on work in cognitive linguistics and semantics, they develop the notion of ‘conceptual integration’ (or ‘blending’ as it’s more popularly referred to in the field) that explains how multiple ‘mental spaces’ or ‘domains’ can be merged seemingly without any conscious effort into new domains (blends) that we can then build further understanding on.

In this context, I’d also recommend reading the parts of Lakoff’s ‘Women, Fire, and Dangerous Things’ that describe what he then called ‘Idealized Cognitive Models’ and now calls ‘frames’. The book is quite vast and not all of it relevant to this question, which is why I wrote [a guide to it](http://metaphorhacker.techczech.net/2018/05/how-to-read-women-fire-and-dangerous-things-guide-to-essential-reading-on-human-cognition/).

4. Rethinking Expertise by Harry Collins and Robert Evans (2008)
----------------------------------------------------------------

What’s missing in all the works I’ve looked at so far is any awareness of the social embeddedness of expert performance. There is little discussion of types or levels of expertise and barely any mention of how experts interact with one another. In ‘[Rethinking Expertise](https://www.press.uchicago.edu/ucp/books/book/chicago/R/bo5485769.html)‘, Collins and Evans propose what they call a ‘periodic table of expertise’ (which happens to overlap quite nicely with my [5 types of understanding](http://metaphorhacker.techczech.net/2019/06/5-kinds-of-understanding-and-metaphors-missing-pieces-in-pedagogical-taxonomies/)). They think not just about the specialist expert knowledge but also about what they call ‘ubiquitous expertise’ – all the underlying skills and knowledge required to even get started (such as languages, basic social skills, metacognition, etc.). Most importantly, they also pay attention to ‘meta-expertise’, i.e. how non-experts evaluate experts and experts judge other experts.

Their notion of expertise relies on the concept of ‘tacit knowledge’ (later developed by Collins in a [separate book](https://www.press.uchicago.edu/ucp/books/book/chicago/T/bo8461024.html)) which is reminiscent of Ericsson’s ‘mental representations’ and echoes Kahneman, as well.

5. Reflective Practitioner: How professionals think in action by Donald A. Schön (1983)
---------------------------------------------------------------------------------------

While [Schön’s book](https://www.amazon.co.uk/Reflective-Practitioner-Professionals-Think-Action/dp/0465068782)has had a profound impact in terms of citation and ways of thinking, I suggest that it has been largely under-appreciated for its depth of epistemological insight. Despite being more than 2 decades older than any of the other books on this list, it is very much still relevant. It considers the very nature of ‘practical knowledge’ as opposed to ‘academic knowledge’. Schön, more than any of the others thinks about the practical needs of a person needing to achieve practical tasks with their knowledge in a complex situation. He highlights the tensions between the technical preparation of experts that focuses on knowledge about a subject and the practical needs of a practitioner who needs to act in such a way that simply recalling information would not be sufficient. His concept of ‘reflection-in-action’ could be seen as a precursor or better still a companion to the notion of ‘deliberate practice’.

Schön followed this up with [Educating The Reflective Practitioner](https://www.amazon.co.uk/Educating-Reflective-Practitioner-Professions-Education-ebook/dp/B0022NGE62) which focuses on the practical question of structuring a training course. Another reason to include Schön on this list is that he focuses more directly on ‘professional’ expertise.

Bringing it all together
------------------------

What these books have in common is an underlying conception of knowledge and its processing. But what they lack is almost any awareness of each other. This makes them add up to more than just the sum of their parts.

Kahneman mentions Ericsson in a footnote and Ericsson and Collins appear jointly in the Cambridge Handbook I mentioned at the start. But they largely travel in separate spheres. Bizarrely, none of them refers to Schön. And all of them are completely unaware of Fauconnier and Turner, who in turn ignore the work done outside their field of cognition (even though we can trace the lineage of their work on cognitive domains directly to Schön’s earlier work on metaphor).

All these approaches are clearly converging on the same thing but they don’t do it using the same terminology, methods or even a shared conceptual framework. Which is why reading just any one of them would probably not be enough to get at the full scope of the issues involved.

I’m not certain that this selection is the most representative of the field. It is certainly not exhaustive and it is definitely shaped by my idiosyncratic intellectual journey and personal interests. But my hope is that it does triangulate the problem domain in a way that a more narrowly focused selection would not.

### *Related*
```
./2019-07-14-fruit-loops-and-metaphors-metaphors-are-not-about-explaining-the-abstract-through-concrete-but-about-the-dynamic-process-of-negotiated-sensemaking.md
```
---
title: "Fruit loops and metaphors: Metaphors are not about explaining the abstract through concrete but about the dynamic process of negotiated sensemaking"
date: 2019-07-14
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/07/fruit-loops-and-metaphors-metaphors-are-not-about-explaining-the-abstract-through-concrete-but-about-the-dynamic-process-of-negotiated-sensemaking
---

**Note:**This is a slightly edited version of a [post that first appeared on Medium](https://medium.com/metaphor-hacker/fruit-loops-and-metaphors-metaphors-are-not-about-explaining-the-abstract-through-concrete-but-4e0209dd70b6). It elaborates and exemplifies examples I gave in the more recent posts on [metaphor and explanation](http://metaphorhacker.techczech.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/) and [understanding](http://metaphorhacker.techczech.net/2019/06/5-kinds-of-understanding-and-metaphors-missing-pieces-in-pedagogical-taxonomies/).

One of the less fortunate consequences of the popularity of the conceptual metaphor paradigm (which is also the one I by and large work with on this blog) is the highlighting of the embodied metaphor at the expenses of others. This gives the impression that metaphors are there to explain more abstract concepts in terms of more concrete ones.

> Wikipedia: “Conceptual metaphors typically employ a more abstract concept as target and a more concrete or physical concept as their source. For instance, metaphors such as ‘the days [the more abstract or target concept] ahead’ or ‘giving my time’ rely on more concrete concepts, thus expressing time as a path into physical space, or as a substance that can be handled and offered as a gift.“

And it is true that many of the more interesting conceptual metaphors that help us frame the fundamentals of language are projections from a concrete domain to one that we think of as more abstract. We talk about time in terms of space, emotions in terms of heat, thoughts in terms of objects, conversations as physical interactions, etc. We can even deploy this aspect of metaphor in a generative way, for instance when we think of electrons as a crowd of little particles.

But I have come to view this as a very unhelpful perspective on what metaphor is and how it works. Instead, going back to Lakoff’s formulation in [*Women, Fire, and Dangerous Things*](http://metaphorhacker.techczech.net/2018/05/how-to-read-women-fire-and-dangerous-things-guide-to-essential-reading-on-human-cognition/), I’d like to propose we think of a metaphor as a principle that helps us give structure to our mental models (or frames). But unlike Lakoff, I like to think of these as an incredibly dynamic and negotiated process rather than as a static part of our mental inventory. And I like to use conceptual intergation or blending as way of thinking about the underlying cogntivive processes.

Metaphor does two things: 1. It helps us (re)structure one conceptual domain by projecting another conceptual domain onto it and 2. In the process of 1, it creates a new conceptual domain that is a blend of the two source domains.

We do not really understand one domain in terms of another through metaphor. We ‘understand’ both domains in different ways. And this helps us create new perspectives which are themselves conceptual domains that can be projected or projected into. (As described by Fauconnier and Turner in *The Way We Think*).

This makes sense when we look at some of the conventional examples used to illustrate metaphors. “The man is a lion” does not help us understand lesser known or more abstract ‘man’ by using the better known or more concrete ‘lion’. No, we actually know a lot more about men and the specific man we’re thus describing than we do about lions. We are just projecting the domain of ‘lions’ including the conventionalised schemas of bravery and fierceness onto a particular man.

This perspective depends on our conventionalised way of projecting these 2 domains. Comparison between languages illustrates this further. The Czech framing of lions is essentially the same as English but the projection into people also maps lion’s vigour into work to mean ‘hard working’. So you can say “she works as a lion”, meaning she works hard. But in the age of documentaries about lions, a joke subverting the conventionalised mapping also appeared and people sometimes say “I work like a lion. I roar and go take a nap.” This is something that could only emerge as more became conventionally known about lions.

But even more embodied metaphors do not always go in a predictable direction. We often structure affective states in terms of the physical world or bodily states. We talk about ‘being in love’ or ‘love hitting a rocky patch’ or ‘breaking hearts’ (where metonymy also plays a role). But does that really mean that we somehow know less about love than we know about travelling on roads? Love is conventionally seen as less concrete than roads or hearts but here we allow ourselves to be mislead by traditional terminology. The domain of ‘love’ is richly structured and does not ‘feel’ all that abstract to the participants. (I’d prefer to think of ‘love’ as a non-prototypical noun; more prototypical than ‘rationalisation’ but less prototypical than ‘cat’).

Which is why ‘love’ can also be used as the source domain. We can say things like “The camera loves him.” and it is clear what we mean by it. We can talk about physical things “being in harmony” with each other and thus helping us understand them in different ways despite harmony being supposedly more abstract than the things being in harmony.

The conceptual domains that enter into metaphoric relationships are incredibly rich and multifaceted (nothing like the dictionaries or encyclopedias we often model linguistic meaning after). And the most important point of unlikeness is their dynamic nature. They are constantly adapting to the context of the listeners and speakers, never exactly the same from use to use. We have a rich inventory of them at our disposal but by reaching into it, we are also constantly remaking it.

We assume that the words we use have some meanings but it is us who has the meanings. The words and other structures just carry the triggers we use to create meanings in the process of negotiation with the world and our interlocutors.

But this sounds much more mysterious and ineffable than it actually is. These things are completely mundane and they are happening every time we open our mouths or our minds. Here’s a very simple but nevertheless illuminating illustration of the process.

Not too long ago, there were two TV shows that had some premise similarities (Psych and The Mentalist). One of them came out a year earlier and its creators were feeling like their premise was copied by the other one. And they used the following analogy:

> “When you go to the cereal aisle in a grocery store, and you see Fruit Loops there. If you look down on the bottom, there’s something that looks just like Fruit Loops, and it’s in a different bag, and it’s called Fruity Loop-Os.” <http://th3tvobsessed.blogspot.co.uk/2009/08/psych-vs-mentalist.html>

I was watching both shows at the time but their similarity did not jump out at me. But as soon as I read that comparison it was immediately clear to me what the speaker was trying to say. I could automatically see the projection between the two domains. But even though it seemed the cereal domain was more specific, it actually brought a lot more with it than the specificity of cereal boxes and their placement on store shelves. What it brought over was the abstract relationship between them in quality and value but also many cultural scripts and bits of propositional knowledge associated with cereal brands and their copycats.

But there was even more to it than that. The metaphor does not stop at its first outing (it’s kind of like mushrooms and their [rhizomes](https://en.wikipedia.org/wiki/Rhizome) in this way). Whenever, I see a powerful analogy or generative metaphor on the internet, I always look for the comments where people try to reframe it and create new meanings. Something I have been calling ‘[frame negotiation](http://metaphorhacker.techczech.net/2012/03/raam-9-abstract-of-doves-and-cocks-collective-negotiation-of-a-metaphoric-seduction/)’. Take almost any salient metaphoric domain projection and you will find that it is only a part in a process of negotiated sense making. This goes beyond people simply disagreeing with each other’s metaphors. It includes the marshalling of complex structuring conceptual phenomena from schemas, rich images, scenarios, scripts, to propositions, definitions, taxonomies and conventionalised collocations.

This blog post and its comments contain almost all of them: <http://th3tvobsessed.blogspot.co.uk/2009/08/psych-vs-mentalist.html>. First, the post author spends three paragraphs (from third on), comparing the two shows and finding similarities and differences. This may not seem like anything interesting but it reveals that the conceptual blends compressed in the cereal analogy are completely available and can be discussed as if it was a literal statement of fact.

Next, the commenters, who have much less space, return to debating the proposition by recompressing it into more metaphors. These are the first four comments in full:

1. *Anonymous said… They’re not totally different. It’s more like comparing Fruit Loops to Fruit Squares which happen to taste like beef.*
2. [*Nikki0417*](http://www.nikki0417.deviantart.com/)*said… I think a better comparison would Corn Flakes and Frosted Flakes. Both are made with the same cereal, but one’s sweeter (Psych).*
3. [*TV Obsessed*](https://www.blogger.com/profile/09117251732141325156)*said… Sweeter as in more comedy oriented? They are vastly different shows that are different on so many levels.*
4. *Anonymous said… nikki could not be more right with the corn flakes and frosties analogy*

Here we see the process of sense making in action. The metaphoric projection is used as one of several structuring devices around which frames are made. Comment 1 opens the the process by bringing in the idea of reframing through other analogs in the cereal domain. 2. continues that process by offering an alternative. 3. challenges the very idea of using these two domains and 4. agrees with 2 as if this were a literal statement but also referring to the metalinguistic tool being used.

The subsequent comments return to comparing the two shows . Some by offering propositions and scenarios, others by marshalling a new analogy.

> [W. D. Stephenson](https://www.blogger.com/profile/12554378526046963007) said… The reason the Mentalist feels like House is because house is a modern day medical version of Homes as in Holmes Sherlock. Also both Psych and The Mentalist are both Holmsian in creation. That being said I love the wit and humor of psych

Again, there is no evidence of the concrete/abstract duality or even one between less and better known domains. It is all about making sense of the domains in both cognitive and affective ways. Some domains have very shallow projections (partial mappings) such as cornflakes and frosty flakes, others have very deep mappings such as Sherlock Holmes. They are not providing new information or insight in the way we traditionally think of them. Nor are they providing an explanation to the uninitiated. They are giving new structure to the existing knowledge and thus recreating what is known.

The reason I picked such a seemingly mundane example is because all of this is mundane and it’s all part of the same process. One of my disagreements with much of metaphor application is the overlooking of the ‘boring’ bits surrounding the first time a metaphor is used. But metaphors are always [a part of a complex textual and discursive patterns](http://metaphorhacker.techczech.net/2018/05/not-ships-in-the-night-metaphor-and-simile-as-process/) and while they are not parasitic on the literal as was the traditional slight against them, they are also not the only thing that goes on when people make sense.

### *Related*
```
./2019-07-23-turing-tests-in-chinese-rooms-what-does-it-mean-for-ai-to-outperform-humans.md
```
---
title: "Turing tests in Chinese rooms: What does it mean for AI to outperform humans"
date: 2019-07-23
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/07/turing-tests-in-chinese-rooms-what-does-it-mean-for-ai-to-outperform-humans
---

TLDR;
-----

* Reports that AI beat humans on certain benchmarks or very specialised tasks don’t mean that AI is actually better at those tasks than any individual human.
* They certainly don’t mean that AI is approaching the task with any of the same understanding of the world people do.
* People actually perform 100% on the tasks when administered individually under ideal conditions (no distraction, typical cognitive development, enough time, etc.) They will start making errors only if we give them too many tasks in too short a time.
* This means that just adding more of these results will NOT cumulatively approach general human cognition.
* But it may mean that AI can replace people on certain tasks that were previously mistakenly thought to require general human intelligence.
* All tests of artificial intelligence suffer from Goodart’s law.
* A test more closely resembling an internship or an apprenticeship than a gameshow may be a more effective version of the Imitation Game.
* Worries about ‘superintelligence’ are very likely to be irrelevant because they are based on an unproven notion of arbitrary scalability of intelligence and ignore limits on computability.

Reports of my intelligence have been greatly exaggerated
--------------------------------------------------------

Over the last few years, there have been various pronouncements about AI being better than humans at various tasks such as image recognition, speech transcription, or even translation. And that’s not even taking into account bogus winners of the Turing test challenge. To make things worse, there’s always the implication that this is means machine learning is getting closer to human learning and artificial intelligence is only a step away from going general.

All of those reports were false. Every. Single. One. How do we know this? Well, because none of them were followed by “and therefore we have decided to replace all humans doing job X with machine learning algorithms”. But even if this were the case, it still would not necessarily mean that the algorithm outperformers humans at the task. Just that it can outperform them at the task when it is repeated time after time and the algorithm ends up making fewer mistakes because, unlike people, it does not get tired, distracted, or simply ticks the wrong box.

But even if the aggregate number of errors is lower for a machine learning algorithm, it may still not make sense to use it because it makes qualitatively different errors. Errors that are more random and unpredictable are worse than more systematic errors that can be corrected for. Also, because AI has no metacognitive mechanisms to identify its errors by doing a ‘sense check’. This often makes correcting AI-generated transcripts difficult to correct because it makes errors that don’t make intuitive sense.

Pattern matching in radiology and law
-------------------------------------

The closest machine learning has gotten to outperforming humans doing real jobs is in radiology. (I’m discounting games like Go, here.) But even here it only equalled the performance of the best experts. However, this could easily be enough. But interpreting X-Rays is an extremely specialised task that requires lots of training and has a built-in error rate. It is a pattern recognition exercise, not a general reasoning exercise. All the general reasoning about the results of the X Rays still has to be delegated to the human physician.

In a similar instance, AI could notice inconsistencies in complex contracts better than lawyers. Again, this is very plausible, but again this was a pattern-matching exercise with a machine pitted against human distractability and stamina. Definitely impressive, useful, and not something expected even a few years ago. But not in any meaningful ways replacing the lawyer any more than a form to draw up a contract I downloaded from the internet does.

This is definitely a case where an AI can significantly augment what an unassisted human can do. And while it will not replace radiologists or lawyers as a category, it could certainly greatly decrease their numbers.

Machine learning to the test
----------------------------

So on very specialised tasks involving complex pattern recognition, we could say that AI can genuinely outperform humans.

But in all the instances involving language and reasoning tasks, even if an AI beats humans on a test, it does not actually ‘outperform’ them on the task. That’s because tests are always imperfect proxies for the competence they measure.

For example, native speakers often don’t get 100% on English proficiency tests and can even do worse than non-native speakers in certain contexts. Why? Three reasons: 1. They can imagine contexts not expected of non-native speakers. 2. The non-native speakers have been practicing taking these tests a lot so they make fewer formal mistakes.

We are facing exactly the same problems when comparing machine learning and human performance based on tests designed to evaluate machine learning. Humans are the native speakers and they perform 100% on all the tasks in their daily lives. But their performance seems less than perfect in test conditions.

### BLEU and overblown claims about Machine Translation

Sometimes the problem is with a poorly designed test. This is the case with the common measure of machine translation called [BLEU (Bi-Lingual Evaluation Understudy)](https://en.wikipedia.org/wiki/BLEU). BLEU essentially measures how many similar words or word pairs there are in the translation by machine when compared to a reference corpus of human translations. It is obvious that this is not a good metric of quality of translation. It can easily assign a lower score to a good translation and a high score to a patently bad one. For instance, it would not notice that the translation missed a ‘not’ and gave the opposite meaning.

What human translators do is translate whole texts NOT sentences. This sometimes means they drop things, add things, rearrange things. This involves a lot of judgment and therefore no two translations are ever the same. And outside trivial cases they’re never perfect. But a reliable translator can make sure they convey the key message and they could provide footnotes to explain where this was not possible. Machine learning can get surprisingly good at translating texts by brute force. But it is NOT reliable because it operates with no underlying understanding of the overall meaning of the text.

That’s why we can easily dismiss Microsoft’s claim that their English-to-Chinese interpreter outperformed human translators. That is only because they used the BLEU metric to make this claim rather than professional translators evaluating the quality of AI output against that of other professional translators on any test. And since Microsoft has yet to announce that it is no longer using human interpreters when its executives visit China, we can safely assume that this ‘outperform’ is not real.

Now, could a machine translation ever get good enough to replace human translators? Possibly. But it is still very far from that for texts of any complexity. Transformers are very promising at improving the quality of the translation but they still only match patterns. To translate you need to make quite rich inferences and we’re nowhere near this.

### GLUE and machine understanding come unstuck

Speaking of inferences. How good is AI at making those? Awful. Here we have another metric to look at: GLUE! Unlike BLEU which is a really bad representation of the quality of translation, [GLUE (General Language Understanding Evaluation)](https://gluebenchmark.com) is a really good representation of human intelligence. If you wanted to know what are the components of human intelligence, you could do a lot worse than look at the GLUE test.

But the [GLUE leaderboard](https:<span%20class="inline-comment">gluebenchmark.com/leaderboard) has a [human benchmark](https:</span>gluebenchmark.com/submission/xfBamAUrEBY0BWIVLx2uuGSmKvI2/-LXoXWPvqioRKAxCjt5W) and it comes 4th with 87.1% score. This puts it 1.4% behind the leader which is Facebook at 88.5%. So, it’s done. AI has not only reached human level of reasoning, it has surpassed them! Of course, not. Apart from the fact that we don’t know how much of a difference in reasoning ability 1% is, this tells us nothing about human ability to reason when compared to that of a machine learning model. Here’s why.

How people and machines make errors
-----------------------------------

I would argue that a successful machine learning algorithm does not actually outperform humans on these tasks even if it got 100%. Because humans also get 100% but they also devised the test.

Isn’t this a contradiction? How can humans get 100% if they consistently score in the mid-80s when given the test. Well, humans designed the test and the correctness criteria. And a machine learning algorithm must match the best human on every single answer to equal them. The benchmark here is just an average of many people over many answers and does not just reflect the human ability to reason but also the human ability to take tests.

Let’s explain by comparing what it means when a human makes an error on a test and when a machine does. There are three sources of human error: 1. Erroneous choice when knowing the right answer (ie clicking a when meaning to click b), 2. Lack of attention (ie choosing a because we didn’t spend enough time reading the task to choose correctly), 3. Overinterpretation (providing context in our head that makes the incorrect answer make sense).

These benchmarks are not Mensa tests, they measure what all people with typical linguistic and cognitive development can do. Let’s take the Windograd Schema test as an example. Here’s an often-quoted example:

> The **trophy** didn’t fit into the suitcase because **it**was too **big**.  
> The trophy didn’t fit into the **suitcase** because **it**was too **small**.

It is very possible that out of 100 people, 5 would get this wrong because they click the wrong answer, 10 because they didn’t process the sentence structure correctly and 1 because they constructed a scenario in their head in which it is normal for suitcases to be smaller than the thing in them (as in Terry Pratchett’s books).

But not a single one got it wrong because they thought that a thing can be bigger than the thing it fits in.

Now, when a machine learning model gets it wrong, it does it because it miscalculated a probability based on an opaque feature set it constructs from lots of examples. When you get 2 people together, they can always figure out the right answer and discuss why they did it wrong. No machine learning algorithm can do that.

This becomes even more obvious when we take an example from the actual GLUE benchmark:

> Maude and Dora had seen the trains rushing across the prairie, with long, rolling puffs of black smoke streaming back from the engine. Their roars and their wild, clear whistles could be heard from far away. Horses ran away when **they** came in sight.

So what does the ‘they’ refer to here? The obvious candidate here is ‘trains’. But it is easy to imagine that a person could click the option where ‘puffs of black smoke’ or even ‘Maude and Dora’ are the antecedent. That’s because both of those can be ‘seen’ and could theoretically cause horses to run away. If this is the 10th sentence I’m parsing in a go, I may easily shortcut the rather complex syntactic processing. I can even see someone choosing “whistles” even though they cannot “come in sight” but are a very strong candidate for causing horses to run away. But nobody would choose ‘horses’ unless they misclicked. A machine learning algorithm very easily could do this simply because ‘they’ and ‘horses’ match grammatically.

But all of this is actually irrelevant, because of how the ML algorithms are tested. They are given multiple pairs or sentences and asked to say 1 or 0 on whether they match or not. So some candidate sentences above are “Horses ran away when the trains came in sight.”, “Horses ran away when Maude and Dora came in sight.” or “Horses ran away when the whistles came in sight.” What it does NOT do is ask “Which of the words in the sentence does ‘they’ refer to?” Because the ML model has no understanding of such questions. You would have to train it for that task separately or just write a sequential algorithm to process these questions.

What people running these contests also cannot do is ask the model to explain their choice in a way that would show some understanding. There is a lot of work being done on interpretability, but this just spits out a bunch of parameters that have to be interpreted by people. Game, set and match to humans.

Chinese room revisited
----------------------

But let’s also think about what it means for a neural network model to get things right. This brings us back to Searl’s famous Chinese room argument. Every single choice a model makes has assigned a probability and even quite ridiculous choices have a non-zero chance of being right in the model. Let’s look at another common example:

> The animal didn’t cross the road because **it** was too busy.

Here it is sensible to assign **it** to ‘road’ because it makes the most sense but one could imagine a context in which we could make **it** refer to ‘the animal’. Animals can be thought of as busy and we can imagine that this could be a reason for not crossing the road. But we know with 100% certainty that **it** does not refer to ‘the’ or even ‘cross’. Yet, a neural model has no such assurance. It may never choose ‘the’ in practice as the antecedent for ‘it’ but it will never completely discount it, either.

So, even if the model got everything right. We could hardly think of it as making human-like inferences unless it could label certain antecedents as having 0% probability and others (much rarer) as having 100%. (Note: Programming it to change 10% to 0% or 90% to 100% does not count.)

This feels like a very practical expression of Searl’s [Chinese room argument](https://en.wikipedia.org/wiki/Chinese_room) albeit in a weak form. Neural networks pose a challenge to Searl because their algorithmic guts are not as exposed as those of the expert systems of Searl’s time. But we can still see echoes of their lack of actual human-like reasoning in their scores.

Is a test of artificial intelligence possible under Goodhart’s Law?
-------------------------------------------------------------------

> I once attended a conference on AI risk where a skeptic said he wasn’t going to worry “until an AI could do Winograd schemas”. This referred to a test of common sense and linguistic ambiguity that AIs have long been famously bad at. Now[Microsoft claims](https:<span%20class="inline-comment">blogs.msdn.microsoft.com/stevengu/2019/06/20/microsoft-achieves-human-performance-estimate-on-glue-benchmark) to have developed a new AI that is comparable to humans on this measure. ([Scott Alexander](https:</span>slatestarcodex.com/2019/06/26/links-6-19))

This post was inspired by the above remark by Scott Alexander. I wanted to explain why even the Winograd challenge being conquered is not enough in and of itself.

AI proponents constantly complain of sceptics’ shifting standards. When AI achieves a benchmark, everybody scrambles to find something else that could be required of it before it gets a pass. And I admit that I may have made a claim similar to that of the AI researcher quoted by Scott Alexander when I was writing about the Winograd schemas.

But the problem here is not that machines became intelligent and everybody is scrambling to deny the reality. The problem is that they got better at passing the test in ways that nobody envisioned when the test was designed. All this while taking no steps towards actual intelligence. Although with a possible increase in practical utility.

This is the essence of Goodhart’s Law: “When a measure becomes a target, it ceases to be a good measure.” The Winograd Schema Challenge seemed so perfect. Yet, I can imagine a machine learning getting good at passing the challenge but still not actually having any of the cognition necessary to really deal with the tasks in real life. In the same way that IBM Watson got really good at Jeopardy but failed at everything else.

None of this is to say that machine learning could not get good enough at performing many tasks that were previously thought to require generalised cognitive capacity. But when machines actually achieve human-level artificial intelligence, we will know. It will not be that hard to tell. But it will not likely happen just because we’re doing more of the same.

The problem with the Turing test or imitation game is not that it cannot produce reliable results on any one run of it. The problem is that if any single test becomes not only the measure but also a target, it is very much possible to focus on passing the test on the surface while bypassing the underlying abilities the test is meant to measure. But the problem is not just with the individual tests but rather in the illusion that we can design a test that will determine AGI level performance simply by reaching an arbitrary threshold.

The current Turing test winners won by misdirection that hid the fact that they refused to answer the questions. This could be fixed by requiring that [Grice’s cooperative principle maxims](https://en.wikipedia.org/wiki/Cooperative_principle#Grice's_Maxims) are observed (especially quality and relevance) but even then, I could see a system trained to deal with a single time-bound conversation pass without any underlying intelligence.

As [Scott Aaronson showed](https://www.scottaaronson.com/blog/?p=1858), it is possible to defeat a current level AI system simply by asking ‘What is bigger a shoebox or Mount Everest’. But once a pattern of questioning becomes known, it becomes a target and therefore a bad measure.

Similar things happen with all standardised aptitude tests designed so that they cannot be studied for. Job interview techniques designed to get interviewees to reveal their inner strengths and weaknesses. All of these immediately spawn industries of prep schools, instructional guides, etc. That makes them less useful over time (assuming they were all that useful to start with).

Towards a test by Critical Turing Internship
--------------------------------------------

That’s why the Turing test cannot be a ‘test’ in the traditional sense. At the very least, it cannot be a single test.

History and a lot of human-computer interaction research has also shown that people are very bad at administering the Turing test (or playing the imitation game). But this is paradoxically because they’re very good the very thing the machines have been failing at: meaning making. Because we almost never encounter meaningless symbols but often encounter incomplete ones, we are conditioned to always infer some sort of meaning from any communication. And it is difficult if not impossible to turn it off.

Every time we see a bit of language we automatically imbue it with some meaning. So, any Turing tester must not only be trained in the principles of cognition but also to discard their own linguistic instincts. We don’t know what it will take for a machine to become truly intelligent but we do know that humans are notoriously bad at telling machines apart from other humans. We simply cannot entrust this sort of thing to such feeble foundations.

As I said above, I suspect that by the time machines do achieve human-level performance on these tasks, it will be obvious. We probably won’t need such a test. Assuming we get there which is not a given. But if a test were needed, it could look something like this.

To replace the Turing test, I would like to propose a sort of Turing Internship. We don’t entrust critical tasks in fields like medicine to people who just passed a test but require they prove ourselves in a closely supervised context. In the same way, we should not trust any AI system based on a benchmark.

Any proposed human-level AI system can be placed in multiple real contexts with several well-informed human supervisors who would monitor its performance for a period of weeks or months to allow for any tricks to be exposed. For example, most people after a few weeks with Alexa, Google Assistant or Siri, get a clear picture of its strengths and limitations. Five minutes with Alexa may make you feel like the singularity is here. Five months will firmly convince you that it is nowhere in sight.

But at the moment, we don’t need this. We don’t need months or weeks to evaluate AI for human-level intelligence. We need minutes. I estimate that we would not need to use this kind of AI internship for another 50 years but likely for much much longer. We are too obssessed with the rapid progress of some basic technologies but ignore many examples of stagnation. My favourite here is the Roomba which has been on the market for 17 years now and has hardly progressed at all. Equally, the current NLP technologies have made massive strides in utility but have not progressed towards anything that could be meaningfully described as understanding.

That is not to say that tests like GLUE or even BLUE are completely useless. They can certainly help us compare ML approaches (up to a point). They’re just useless for comparing human performance with those of machine-generated models.

Note on Nick Bostrom and Superintelligence
------------------------------------------

One obvious objection to the Turing Internship idea is that if human-level AI is the last step before Bostrom’s ‘Superintelligence’, unleashing it in any real context would be extremely dangerous.

If you believe in this ‘demon in the machine’ option, there’s nothing I can do to convince you. But I personally don’t find Superintelligence in any way persuasive. The reason is that most of the scenarios described are computationally infeasible in the first place. Bostrom does not mention the issue of computability and things like P=NP almost at all. And he completely ignores questions of nonlinear complexity.

It is hard to judge whether a ‘superintelligent’ system could take over the world. But could it predict the weather 20 days out with 1% tolerance of temperature estimates in any location? The answer is most likely not. There may not be enough atoms in the universe to compute the weather arbitrarily precisely more than a few days in advance. Could it predict earthquakes? Could it run an economy more efficiently than an open market relying on price signals? The answers to all those questions are most likely no. Not because the superintelligence is not super enough but because these may not be problems that can be solved by adding ‘more’ intelligence. Assuming that ‘intelligence’ is a linearly scalable property in the first place. It may well be like body size, after a certain amount of increase, it would just collapse onto itself.

Superintelligence requires a conspiracy theorist’s mindset. Not that people who believe are conspiracy theorists. But they assume that complexity can be conquered with intelligence. They don’t believe that humans are ‘smart’ enough to control everything. But they believe that it is inherently possible. Everything we know about complexity, suggests that this is not the case. And that is why I’m not worried.

### *Related*
```
./2019-09-08-so-you-think-you-have-a-historical-analogy-revisionist-history-and-anthropology-reading-list.md
```
---
title: "So you think you have a historical analogy? Revisionist history and anthropology reading list"
date: 2019-09-08
author: Dominik Lukeš
source: https://metaphorhacker.net/2019/09/so-you-think-you-have-a-historical-analogy-revisionist-history-and-anthropology-reading-list
---

What is this about
------------------

### How badly we’re getting history

While the world of history and anthropology of the last 30-40 years has completely redrawn the picture of our past, the common perception of the overall shape of history and the development of humanity is still firmly rooted in the view that took hold in the 1800s’ mixture of enlightenment and romanticism.

On this view, we are the pinnacle of development, the logical and inevitable outcome of all that came before us. The development of what is us, the changes in history and culture, can be traced in a straight line from the primitive of the past to the sophisticated of the present. From the savage to the civilized (even if we may eschew these for more polite terms).

But nothing could be farther away from the truth. The shape of global history looks nothing like what we have in our minds from textbooks and popular culture. For a start, it is a lot more complicated, circuitous and fuzzy than we might imagine. That won’t surprise many people. Things are always more complicated when looked at closely. But what I would suggest is that the popular image has completely misplaced the centre of gravity of historical and cultural development. It is the universe before Copernicus and Gallileo, it is the physics before Einstein and Heisenberg.

Yet, all we need to find the right balance is readily available in print, online lectures and courses. We just need to seek it out.

### What is on this list

In this post, I compiled what I consider key books of the last 20 years (with a few older exceptions) that can help anyone get a better picture of the history of human politics and culture. And through that history, we can also see the balance of the present better.

Not all these books are flawless and they all bring new biases into the picture. No doubt, they too, will eventually be subject to revision as new perspectives open up. Also, they don’t entirely reject all that came before them. They simply provide a better balance and shine light in important blind spots.

I can imagine that many people reading any one of these books might feel compelled to reject them as outliers. But together, they are hard to ignore. They come from different perspectives and disciplines, yet, they complement and reinforce each other.

This was originally meant to be a short list of a few key works but as I was going through my notes, I kept adding new ones. I tried to keep the list to books that synthesize larger areas rather than histories or ethnographies of individual societies even though, these can often be as illustrative.

Most of these books are histories or contain historical data. Yet, many are written by anthropologists or historians with a distinctly anthropological point of view. This very much reflects my personal bias towards the ethnographic.

I divided the list into 2 sections: 1. Easy reads for a general audience and 2. Dense and extensive works for specialists. But in this, I was very much going by intuition.

I decided to provide some illustrative quotes for each book but I went a bit too far with some of them. At the same time, I could have quoted many more important passages. Remember, they all make much more sense in context.

Where available, I also provided links to podcasts or online lectures by the authors. I also compiled a [YouTube playlist with key videos](https://www.youtube.com/playlist?list=PLEl9d2qvKkBs95yHG62Q5LIjj9mWjaI2u) which I will keep up-to-date as I discover more.

I would also recommend to anybody that they listen to the [New Books Network](https://newbooksnetwork.com) podcasts. I find those from the New Books in History, Milirary History, South Asian Studies, Islamic Studies, Anthropology and Genocide studies particularly illuminating and would recommend that anybody goes through the archive, as well.

### What are the key lessons

[This section was rewritten based on Reddit comments.](https://www.reddit.com/r/slatestarcodex/comments/d1gbsj/so_you_think_you_have_a_historical_analogy/)

The overarching message of these books is one of anti-reductionism. They do not look for inevitable overarching trends but they do show repeating patterns. The key points that stand out to me as a lesson to take away from reading these books could be:

* The global dominance of Western-European culture and politics is a lot more recent than our history books taught us pretty much starting with the Industrial Revolution and not completed until the end of the 19th century.
* The balance of global history lies in the East rather than the West. Even those we consider the roots of our civilisation (Rome, Greeks) looked to the East.
* We are blinkered by focusing our perspective on civilizational artifacts such as architecture and writing. This leads us to overlook important political and social units that outnumbered those we can see at any one point in history.
* The role of the state throughout history was much more complex and uncertain than it may seem from today’s perspective. It was much weaker, less stable and more transient. And it was also not nearly as attractive to its subjects – ie. walls were often built more to keep people in than out.
* We cannot view the ‘hunter gatherers’ and other ‘pre-technological’ societies of today as remnants of previous evolutionary stages of history. They are as much part of modernity as the technologically-dependent urban centres we know.

### Who should read this

* Anyone who thinks ‘Guns, Germs, and Steel’ is the last word in historical analysis.
* Rationalists, economists and futurists. I very much enjoy listening to podcasts like [EconTalk](http://www.econtalk.org) and [Rationally Speaking](http://rationallyspeakingpodcast.org). But whenever they or their guests make any points regarding history, I cannot but cringe.
* Anyone who makes historical analogies based on what they learned in school.
* When I last worked with Peace Corps volunteers, I shared some of these books with them and they were well received. So I think many development and international policy workers would also benefit.
* Curriculum reformers in the mould of [Michael Gove](https://www.politics.co.uk/comment-analysis/2013/05/09/michael-gove-s-anti-mr-men-speech-in-full) or [Pat Buchanan](https://en.wikipedia.org/wiki/The_Death_of_the_West).

Easy, accessible reads
----------------------

I felt the books in this section are more accessible and aimed at audiences outside the strict confines of their discipline. Some of them are fairly popular accounts but they are all sufficiently scholarly that it is possible to track down their sources and confront them with alternative perspectives. None of them are by popularisers in the vein of Gladwell or Pinker.

### ‘Against the Grain: A Deep History of the Earliest States’ by James C Scott, 2018

Scott is best known for ‘Seeing Like a State’ but this is a much more important and in many ways better book. His main thesis is ‘Everything we thought about the invention of agriculture and its role in the formation of early civilisations is wrong.’

In this book, Scott summarises recent decades of research on the emergence of agriculture and emergence of early states and finds that we cannot trust any of our assumptions. The early states were temporary, partial and patchy. They cannot be seen as a final stage in some sort of a process of social evolution. A point elaborated by Yoffee below in greater detail.

My main impression from this book is how recent the dominance of state control is. Until about 1500, most people lived outside the control of the great civilisational behemoths. And this was, for many of them, a conscious choice. As Scott described in his earlier book ‘The Art of Not Being Governed’ (also well worth a read).

Similarly to Diamond, Scott also focuses on the importance of certain crops but from the perspective of their utility for taxation. This point is elaborated in Graeber’s ‘Debt’ (see below).

You can see Scott speak about many of these points in several lectures.

**Note:** I wrote a review of this book for the Czech daily Lidové noviny.

#### Illustrative quotes

> “Contrary to earlier assumptions, hunters and gatherers—even today in the marginal refugia they inhabit—are nothing like the famished, one-day-away-from-starvation desperados of folklore. Hunters and gathers have, in fact, never looked so good—in terms of their diet, their health, and their leisure. Agriculturalists, on the contrary, have never looked so bad—in terms of their diet, their health, and their leisure.”

> “In unreflective use, “collapse” denotes the civilizational tragedy of a great early kingdom being brought low, along with its cultural achievements. We should pause before adopting this usage. Many kingdoms were, in fact, confederations of smaller settlements, and “collapse” might mean no more than that they have, once again, fragmented into their constituent parts, perhaps to reassemble later. In the case of reduced rainfall and crop yields, “collapse” might mean a fairly routine dispersal to deal with periodic climate variation. Even in the case of, say, flight or rebellion against taxes, corvée labor, or conscription, might we not celebrate—or at least not deplore—the destruction of an oppressive social order?”

> “until the past four hundred years, one-third of the globe was still occupied by hunter-gatherers, shifting cultivators, pastoralists, and independent horticulturalists, while states, being essentially agrarian, were confined largely to that small portion of the globe suitable for cultivation. Much of the world’s population might never have met that hallmark of the state: a tax collector.”

> “Where grain, and therefore agrarian taxes, stopped, there too did the state’s power begin to degrade. The power of the early Chinese states was confined to the arable drainage basins of the Yellow and Yangzi Rivers. […] The territory of the Roman Empire, for all its imperial ambitions, did not extend much beyond the grain line.”

> much that passes as collapse as, rather, a disassembly of larger but more fragile political units into their smaller and often more stable components.

### ‘Seven Myths of the Spanish Conquest’ by Matthew Restall, 2003

The title of the book says it all. Almost anything we say (and Jared Diamond said) about the likes of Columbus, Cortez or Pizarro is wrong. Factually and structurally. Perhaps the most important myth Restall presents is that of ‘completion’. The Spanish and later other conquests were more a case of expanding enclaves and negotiations. To imagine the *conquistadors*as ruling a geographic area in the same way a modern state governs its territory is completely misleading. This is also a point repeated in Yoffee and Scott with respect to ‘ancient civilisations’.

The other point made by Restall is the complete dependence of the European invaders on local political aliances and the relative ineffectiveness and ultimate irrelevance of their ‘technology’. We see this expanded in Thornton and Sherman into other contexts

You can hear Restall talk about many of the same themes in an interview about his more recent book “When Montesuma met Cortez” in this[New Books Podcast](https://newbooksnetwork.com/matthew-restall-when-montezuma-met-cortes-the-true-story-of-the-meeting-that-changed-history-ecco-2018/).

There is also an [illustrated lecture available on YouTube](https://www.youtube.com/watch?v=KhHJituiAcQ) that covers the same topics.

#### Illustrative quotes

> “Looking at Spanish America in its entirety, the Conquest as a series of armed expeditions and military actions against Native Americans never ended.”

> “Only very gradually did community autonomy erode under demographic and political pressures from non-native populations. From the native perspective, therefore, the Conquest was not a dramatic singular event, symbolized by any one incident or moment, as it was for Spaniards. Rather, the Spanish invasion and colonial rule were part of a larger, protracted process of negotiation and accommodation.”

### ‘Empires of the Weak: The Real Story of European Expansion and the Creation of the New World Order’ by Jason Sharman, 2019

The central thesis here is that the relationship between the European conquerors and the conquered around the world was very different from the traditional stories. It was not sudden overwhelming military force but gradual exploitation of local political conditions taking place over the course of centuries that resulted in the world we see today.

Most importantly, the thesis of political competition in Europe resulting in European dominance by 1800 purely through superiority of Western military technology is completely dismantled. European weapons made little difference until the 1800s. [Updated based on Reddit comments.](https://www.reddit.com/r/slatestarcodex/comments/d1gbsj/so_you_think_you_have_a_historical_analogy/)

Sharman is a political scientist, so perhaps could be accused of moonlighting outside his core expertise, but we’ll see that this thesis is repeated again and again in many of the other books on this list from various perspectives.

I could not find any videos or audio recordings of Sharman about the book. But I’m sure some will appear, soon.

#### Key quote

> ‘Europeans did not enjoy any significant military superiority vis-à-vis non-Western opponents in the early modern era, even in Europe. Expansion was as much a story of European deference and subordination as one of dominance. Rather than state armies or navies, the vanguards of expansion were small bands of adventurers or chartered companies, who relied on the cultivation of local allies.’

### ‘The Silk Roads: A New History of the World’ by Peter Frankopan, 2015

‘The Silk Roads’ is the history of the world that should be the core textbook for anyone interested in the balance of events. It provides the same correction to the shape of history that an alternative projection gives to the distortions taught to us by the [Mercator of school atlases](https://geoawesomeness.com/best-map-projection).

Frankopan’s book on the First Crusade is also extremely eye-opening and worth a read. It is the one that most balances the perspectives of east, west and the Byzantines.

Here are some places where you can see Frankopan talk about his book:

Jerry Brotton’s ‘This Orient Isle’ could be thought of as a companion book in that it rethinks the position of Britain in this newly rebalanced history. You can watch Brotton talk about his 2016 book [‘in an online lecture](https://www.youtube.com/watch?v=0tW-tvK9t2s). Brotton’s ‘History of the World in 12 Maps’ also adds new perspectives on the orientation of the world.

#### Illustrative quotes

> We think of globalisation as a uniquely modern phenomenon; yet 2,000 years ago too, it was a fact of life, one that presented opportunities, created problems and prompted technological advance.

> Rome’s transition into an empire had little to do with Europe or with establishing control across a continent that was poorly supplied with the kind of resources and cities that were honeypots of consumers and taxpayers. What propelled Rome into a new era was its reorientation towards the Eastern Mediterranean and beyond. Rome’s success and its glory stemmed from its seizure of Egypt in the first instance, and then from setting its anchor in the east – in Asia.

> the ancient world was much more sophisticated and interlinked than we sometimes like to think. Seeing Rome as the progenitor of western Europe overlooks the fact that it consistently looked to and in many ways was shaped by influences from the east.

> Cities like Merv, Gundesāpūr and even Kashgar, the oasis town that was the entry point to China, had archbishops long before Canterbury did. These were major Christian centres many centuries before the first missionaries reached Poland or Scandinavia.

> Baghdad is closer to Jerusalem than to Athens, while Teheran is nearer the Holy Land than Rome, and Samarkand is closer to it than Paris and London.

### ‘Lost Enlightenment: Central Asia’s Golden Age from the Arab Conquest to Tamerlane’ by F. Frederick Starr, 2013

Starr’s book was a real revelation. I had spent a lot of time in Central Asia and read some history of the region. But other than Samarkand, all of that history has now been lost. And I didn’t get a sense that the people living in the region knew much about it.

Much like Davies in ‘Vanished Kingdoms’ in Europe, Starr shows on a global scale how even major civilisations with real impact can disappear without much trace. But even more importantly, he shows that the trajectory of ‘modern’ intellectual development was much more complex than most people believe.

You can see Starr talk about his book in [this online lecture](https://www.youtube.com/watch?v=qSDqjUoH67M).

#### Illustrative quotes

> “This was truly an Age of Enlightenment, several centuries of cultural flowering during which Central Asia was the intellectual hub of the world. India, China, the Middle East, and Europe all boasted rich traditions in the realm of ideas, but during the four or five centuries around AD 1000 it was Central Asia, the one world region that touched all these other centers, that surged to the fore. It bridged time as well as geography, in the process becoming the great link between antiquity and the modern world.”

> “every major Central Asian city at the time boasted one or more libraries, some of them governmental and others private.”

> “Above all, Central Asia was a land of cities. Long before the Arab invasion, the most renowned Greek geographer, Strabo, writing in the first century BC, described the Central Asian heartland as ‘a land of 1,000 cities.’”

> “At the Merv oasis the outermost rampart ran for more than 155 miles, three times the length of Hadrian’s Wall separating England from Scotland. At least ten days would have been required to cover this distance on camelback.”

### ‘Genghiz Khan and the Making of the Modern World’ by Jack Weatherford, 2004

Jack Weatherford’s portrayal of the Mongol conquests is definitely not non-partisan. He’s with the Mongols. Nevertheless, he opens important vistas about the foundations of modern interconnectedness. This is a good complement to Starr’s covering of the preceding period in the same region.

Here’s a [video lecture by Weatherford](https://youtu.be/v81_hm8T92c) about some aspects of this story.

#### Illustrative quotes

> In twenty-five years, the Mongol army subjugated more lands and people than the Romans had conquered in four hundred years. Genghis Khan, together with his sons and grandsons, conquered the most densely populated civilizations of the thirteenth century. Whether measured by the total number of people defeated, the sum of the countries annexed, or by the total area occupied, Genghis Khan conquered more than twice as much as any other man in history.

> The majority of people today live in countries conquered by the Mongols; on the modern map, Genghis Kahn’s conquests include thirty countries with well over 3 billion people.

> Genghis Khan’s empire connected and amalgamated the many civilizations around him into a new world order. At the time of his birth in 1162, the Old World consisted of a series of regional civilizations each of which could claim virtually no knowledge of any civilization beyond its closest neighbor. No one in China had heard of Europe, and no one in Europe had heard of China, and, so far as is known, no person had made the journey from one to the other. By the time of his death in 1227, he had connected them with diplomatic and commercial contacts that still remain unbroken.

### ‘Lies my Teacher Told Me: Everything Your American History Textbook Got Wrong’ by James W. Loewen, 1995

This book is slightly outside the scope of this list, but I thought it would be of interest to those who were educated in the American school system. But many of its points apply to all school history books. It will open your eyes to how little you can trust to what you learned in school and what was then reinforced through popular cultural reflection of history.

Here’s an [extended interview with the author](https://www.youtube.com/watch?v=JTTA_41UGUA).

#### Illustrative quotes

> “Many history textbooks list up-to-the-minute secondary sources in their bibliographies, yet the narratives remain totally traditional unaffected by recent research.”

> “Most Americans tend automatically to equate educated with informed or tolerant. Traditional purveyors of social studies and American history seize upon precisely this belief to rationalize their enterprise, claiming that history courses lead to a more enlightened citizenry. The Vietnam exercise suggests the opposite is more likely true.”

Comprehensive and/or less accessible
------------------------------------

These books require more serious commitment and possibly some comfort with reading relatively dense historical and ethnographic accounts. They are not necessarily poorly written or full of jargon but they are not primarily aimed at an audience too far outside the profession of the author (except ‘Debt’ which I included here because it is so long).

### ‘A Cultural History of the Atlantic World: 1250 – 1820’ by John K. Thornton, 2012

This is a truly impressive historical synthesis that covers an extensive geographic area as well as a significant stretch of time. It provides detailed elaborations of the central thesis of Sharman’s and Restall’s books and should be consulted every time we feel like we want to make a general statement about the developments in that region and in that time. Which we do all the time.

A [podcast interview about this book](https://newbooksnetwork.com/john-k-thornton-a-cultural-history-of-the-atlantic-world-1250-1820-cambridge-up-2012-3/) from the New Books Network will give a good sense of what the book is about.

You can also hear Thornton speak on a related topic in this [YouTube lecture on the Slave trade](https://www.youtube.com/watch?v=kxUjIt2EmRA).

#### Illustrative quotes

> “Europeans did not possess decisive advantages over any of the people they met, even though their sailing craft were indeed capable of nautical achievements that no other culture up to that time was able to perform.”

> “there was really no economic Third World at the time of European expansion in the fifteenth and sixteenth century, if one uses proxy measures of average quality of life as a guide. The crucial quality-of-life determinant was, in fact, social and economic stratification.”

> “African states had the upper hand if the game of force was to be played. Although Europeans often fortified their “factories,” as trading posts were usually called, these fortifications could not resist an attack by determined African authorities.”

> “Slow-firing weapons cannot allow small numbers of people to defeat larger numbers unless other factors are in play.”

> “Cavalry are most effective only when massed in sufficient numbers to inflict sustained casualties on fleeing infantry, and the dozens and on occasion low hundreds of mounted men in Spanish service did not meet this decisive threshold. Native Americans were reasonably quick in establishing tactical countermeasures against the horsemen after the initial encounters.”

### ‘Myths of the Archaic State: Evolution of the Earliest Cities, States, and Civilizations’ by Norman Yoffee, 2005

This was perhaps the most embarrassingly eye-opening book for me given that I started out my early adult life by studying Egyptology. Yoffee, building on his work and that of others, shows the limits of what a so-called ‘ancient civilisation’ was and could have been. Collapses and interregna were all much less of tragedies for all involved – point made by Scott in a more accessible way. His reimagining of the position of Hammurabi as a political and literary rather than a legal document was just one of the many myths that this book burst for me.

Norman Yoffee speaks about [new perspectives on the collapse](https://www.youtube.com/watch?v=R0TvJx1F7QM) summarizing his more recent work.

#### Illustrative quotes

> “[Myth of the archaic states include:] (1) the earliest states were basically all the same kind of thing (whereas bands, tribes, and chiefdoms all varied within their types considerably);(2) ancient states were totalitarian regimes, ruled by despots who monopolized the flow of goods, services, and information and imposed “true” law and order on their powerless citizens; (3) the earliest states enclosed large regions and were territorially integrated; (4) typologies should and can be devised in order to measure societies in a ladder of progressiveness; (5) prehistoric representatives of these social types can be correlated, by analogy, with modern societies reported by ethnographers; and (6) structural changes in political and economic systems were the engines for, and are hence necessary and sufficient conditions that explain, the evolution of the earliest states.”

> That the laws of Hammurabi were copied in Mesopotamian schools for over a millennium after Hammurabi’s death attests to the literary success of the composition and has nothing to do with its juridical applicability. […] There is no mention of the code of Hammurabi in the thousands of legal documents that date to his reign and those of his immediate successors.

> Order could not survive the frequent shocks it suffered if people were not able to construct the institutions of legitimacy and to determine the quality of illegitimacy. Legitimacy normally invokes the past as something that is absolute and that acts as a point of reference for the present, normally by transmuting the past into some form of the present.

### ‘Debt: The First Five Thousand Years’ by David Graeber, 2011

I think this is perhaps the best intro to modern anthropological thinking in general. It is very readable and accessible but also very comprehensive. It certainly has its agenda but Graeber tells a convincing story that undermines the classical thinking about the role of exchange in maintaining civilisations. It is easy to get bogged down in the discussions about the nature of money when discussing this book but what it really does is show the great variety of ways in which people relate to each other.

Graeber gave a lecture on his book at Google which is [available on YouTube](https://www.youtube.com/watch?v=R0TvJx1F7QM). But this book works best when read as a whole.

#### Illustrative quotes

> there is good reason to believe that barter is not a particularly ancient phenomenon at all, but has only really become widespread in modern times. Certainly in most of the cases we know about, it takes place between people who are familiar with the use of money, but for one reason or another, don’t have a lot of it around.

> Through most of history, when overt political conflict between classes did appear, it took the form of pleas for debt cancellation—the freeing of those in bondage, and usually, a more just reallocation of the land.

> “Kingdoms rise and fall; they also strengthen and weaken; governments may make their presence known in people’s lives quite sporadically, and many people in history were never entirely clear whose government they were actually in. … It’s only the modern state, with its elaborate border controls and social policies, that enables us to imagine “society” in this way, as a single bounded entity.”

> there are three main moral principles on which economic relations can be founded, all of which occur in any human society, and which I will call communism, hierarchy, and exchange.

> “communism” is not some magical utopia, and neither does it have anything to do with ownership of the means of production. It is something that exists right now—that exists, to some degree, in any human society, although there has never been one in which everything has been organized in that way, and it would be difficult to imagine how there could be. All of us act like communists a good deal of the time. None of us acts like a communist consistently.

> “baseline communism”: the understanding that, unless people consider themselves enemies, if the need is considered great enough, or the cost considered reasonable enough, the principle of “from each according to their abilities, to each according to their needs” will be assumed to apply.

> In many periods—from imperial Rome to medieval China—probably the most important relationships, at least in towns and cities, were those of patronage.

### ‘Vanished Kingdoms: The Rise and Fall of Nations’ by Norman Davies, 2010

Most of the books on the list focus on forgotten, misunderstood or ignored aspects of global history or culture. But Davies shows that even in our own backyard, entire kingdoms vanished without a trace in our consciousness. Perhaps, I should have chosen his ‘Europe: A History’ which is also revisionist in that it places Europe’s cultural, geographic and historical center of gravity much further east and south than is typical. But I found this book much more revelatory and impactful for the purposes of this list.

Davies gave a [lecture about his book at the LSE](https://www.mixcloud.com/lse/europes-vanished-kingdoms-audio/)which is available as a recording.

A brief [interview with Davies about this book](https://www.youtube.com/watch?v=C95Yb2A27BY) is available on YouTube.

#### Illustrative quotes

> “As soon as great powers arise, whether the United States in the twentieth century or China in the twenty-first, the call goes out for offerings on American History or Chinese History, and siren voices sing that today’s important countries are also those whose past is most deserving of examination, that a more comprehensive spectrum of historical knowledge can be safely ignored.”

> Most importantly, students of history need to be constantly reminded of the transience of power, for transience is one of the fundamental characteristics both of the human condition and of the political order.

> Popular memory-making plays many tricks. One of them may be called ‘the foreshortening of time’. Peering back into the past, contemporary Europeans see modern history in the foreground, medieval history in the middle distance, and the post-Roman twilight as a faint strip along the far horizon.

> One has to put aside the popular notion that language and culture are endlessly passed on from generation to generation, rather as if ‘Scottishness’ or ‘Englishness’ were essential constituents of some national genetic code.

> To all who have been seduced by the concept of ‘Western Civilization’, therefore, the Byzantine Empire appears as the antithesis – the butt, the scapegoat, the pariah, the undesirable ‘other’.6 Although it formed part of a story that lasted longer than any other kingdom or empire in Europe’s past, and contains in its record a full panoply of all the virtues, vices and banalities that the centuries can muster, it has been subjected in modern times to a campaign of denigration of unparalleled virulence and duration.

### ‘The Inheritance of Rome: A History of Europe from 400 to 1000’ by Chris Wickham, 2009

The ‘Fall of Rome’ and the subsequent ‘dark ages’ have been one of the big obsessions of historical introspection for centuries. They are the frequent source domain of civilizational analogies even though, as Chris Wickham shows, almost nothing we think of as a given holds up. This book is just one of many in recent historical scholarship that revisits the notion of the dark ages and shines a light on the period of ‘late Rome’ as seen from the perspective of its own time. Of course, many controversies remain but the change in emphasis seems incontrovertible. There are echoes of similar points in the early chapters of Davies’ ‘Vanished Kingdoms’.

I could not find any lectures on the subject by Wickham but some of these questions were raised in [this panel he chaired on the middle ages](http://dyoutube.com/watch?v=kAz8w2IKHHM).

**Note:** I wrote a review of this book for the Czech daily Lidové noviny.

There are also a number of lecture series on this period that reflect the latest scholarship in The Great Courses from the Teaching Company that are available via Audible, as well. I particularly recommend [those by Kenneth Harl](https://www.thegreatcourses.com/search/?q=kenneth+harl).

#### Illustrative quotes

> “Anyone in 1000 looking for future industrialization would have put bets on the economy of Egypt, not of the Rhineland and Low Countries, and that of Lancashire would have seemed like a joke.”

> Byzantine ‘national identity’ has not been much considered by historians, for that empire was the ancestor of no modern nation state, but it is arguable that it was the most developed in Europe at the end of our period.

> the East remained politically and fiscally strong, and eastern Mediterranean commerce was as active in 600 as in 400.

> Far from ‘corruption’ being an element of Roman weakness, this vast network of favours was one of the main elements that made the empire work. It was when patronage failed that there was trouble.

> The Persian state was almost as large as the Roman empire, extending eastwards into central Asia and what is now Afghanistan; it is much less well documented than the Roman empire, but it, too, was held together by a complex tax system, although it had a powerful military aristocracy as well, unlike Rome.

### ‘The Anthropology of Eastern Religions: Ideas, Organizations, and Constituencies’ by Murray Leaf, 2014

This was a late addition to this list and it is an imperfect volume in that, as [one reviewer put it](https://www.tandfonline.com/doi/full/10.1080/10477845.2015.1071584): “[its] worthwhile aims are met unevenly, resulting in a book that is certainly informed and informative, but often inconsistent in tone and level of analysis.” But I think its core message in chapter one of religion as a social institution which has much more in common with others than traditional religious studies would have us believe.

I couldn’t find any interviews or lectures. But I believe that this [interview with Russell McCutcheon](https://newbooksnetwork.com/william-arnal-and-russell-t-mccutcheon-the-sacred-is-the-profane-the-political-nature-of-religion-oxford-up-2013-3/) about the limits of religious studies would provide a useful complement.

#### Illustrative quotes

> The world religions are complex social phenomena. They use ideas of several different kinds. They include substantial systems of physical infrastructure. They have provisions for economic support. They embody their own systems of scholarship. They produce propaganda and they are politically important in many different ways. From time to time their leaders in various places have commanded armies and conducted wars. This cannot be explained simply by reviewing them as so many sets of beliefs.

> The most conspicuous problem in contemporary comparative religion is that they underrate diversity. […] One result is to overstate what the major religions have in common with each other while understating or ignoring what they have in common with traditions considered non-religious.

> The general class of cultural phenomena to which world religions belong can be described as large-scale, translocal, multi-organizational, professionalized cultural complexes.

> Virtually all Japanese have recourse to the ideas and organizations of Buddhism and Shinto, and for the most part this is also true of Confucianism. […] Japanese parks are Shinto and the system of Shinto shrines in Japan has much the same place in Japanese emotional life as the system of national parks does for Americans. Confucian ideas are important in administrative and professional contexts.

### ‘Europe and the People without History’ by Eric R Wolf, 1982

This is the oldest book on the list and it has inspired many others.

Unlike Graeber, reading Wolf is hard going. This is certainly for the committed but it repays the effort. Even just looking at the maps showing the intricate trade routes going from the heart of Africa to the Baltic Sea is eye-opening.

Wolf’s central point is also the central point all the authors on this list return to again and again. We invented history based on the things that were easy to see. But this was very much looking for the keys under the lamppost where the light was and not where we lost them. Wolf (similarly to Graeber and Scott) has a distinctly untraditional politics leaning to the left (if perhaps not as much to anarchism).

#### Illustrative quotes

> “Africa south of the Sahara was not the isolated, backward area of European imagination, but an integral part of a web of relations that connected forest cultivators and miners with savanna and desert traders and with the merchants and rulers of the North African settled belt. This web of relations had a warp of gold, “the golden trade of the Moors,” but a weft of exchanges in other products. The trade had direct political consequences. What happened in Nigerian Benin or Hausa Kano had repercussions in Tunis and Rabat. When the Europeans would enter West Africa from the coast, they would be setting foot in a country already dense with towns and settlements, and caught up in networks of exchange that far transcended the narrow enclaves of the European emporia on the coast. We can see such repercussions at the northern terminus of the trade routes in Morocco and Algeria. Here one elite after another came to the fore, each one dependent on interaction with the Sahara and the forest zone. Each successive elite was anchored in a kin-organized confederacy, usually mobilized around a religious ideology.”

Pre-cursors and proto-revisionists
----------------------------------

In many ways, almost any history is revisionist history. Each generation writes its own history books to reflect new knowledge but also new perspectives. Most history book authors feel they have something new with which to contribute and that can revise current understanding of the subject matter.

So it is not surprising that even revisionism in the vein that I’m looking at here is not just a matter of the last 20 or so years.

Much of the current revision was inspired by[‘The Great Transformation’ by Karl Polanyi](https://en.wikipedia.org/wiki/The_Great_Transformation_(book)) published in 1944 which in turn rests on many of the anthropological revisions started by people like [Franz Boas](https://en.wikipedia.org/wiki/Franz_Boas) in the US and [Bronisław Malinowski](https://en.wikipedia.org/wiki/Bronis%C5%82aw_Malinowski).

There is a continued thread of back and forth since at least then. Marshall Sahlins’ ‘Stone Age Economics’ from 1972 (with papers going back to the mid 1960s) started much revision and revision of the hunter gatherer condition. And so on.

At the same time but independently, people like [Joseph Needham](https://en.wikipedia.org/wiki/Joseph_Needham) were painstakingly collecting data on the great civilizations of the ‘East’ which can now give us a fuller and more balanced picture of the world.

We should also not forget the work that has gone into revising the simplistic view of the 19th and 20th centuries, most notably to do with the emergence of the nation state. Here names such as Eric Hobsbawn, Ernest Gellner, Miroslav Hroch and, of course, Benedict Anderson, come to mind. And then there are the many people who are rethinking more recent events such as Timothy Snyder or Antony Beevor.

The list just goes on.

The other side of the coin
--------------------------

Of course, there is also the other side. Historical revisionists with grand schemes and overarching historical narratives. I’ve already mentioned Jared Diamond but also worth reading is Ian Morris. I’ve critiqued some of their work in my thesis proposing the metaphor of [‘History as Weather’](https://medium.com/metaphor-hacker/history-as-weather-a-fractal-theory-of-history-for-ian-morris-jared-diamond-and-cgp-grey-45b5503486c5). There are also people like [Niall Ferguson](https://en.wikipedia.org/wiki/Niall_Ferguson) who cannot be doing with all this rebalancing and want to put ‘the West’ back at the centre of things. I found his [attempt in Civilization extremely unconvincing](http://metaphorhacker.net/2011/06/killer-app-is-a-bad-metaphor-for-historical-trends-good-for-pseudoteaching) but he is a prominent voice in the anti-revisionist camp.

**Note:** I wrote a joint review of Morris and Ferguson for the Czech daily Lidové noviny under the title of ‘New historical eschatology’. I also wrote a positive review of Jared Diamond’s ‘Collapse’ soon after it came out which I would now revise significantly – see [Questioning Collapse](https://www.amazon.co.uk/Questioning-Collapse-Resilience-Ecological-Vulnerability/dp/0521733669) and [After Collapse](https://www.amazon.co.uk/After-Collapse-Regeneration-Complex-Societies/dp/0816529361).

Steven Pinker’s ‘[Better Angels of Our Nature](https://en.wikipedia.org/wiki/The_Better_Angels_of_Our_Nature)‘ is another example of a grand sweep of history that tries to make the progress of humanity appear more directional and straightforward than the books on this list suggest it is or can be. And we should not forget the great systematisers of the 1990s [Fukuyama](https://en.wikipedia.org/wiki/The_End_of_History_and_the_Last_Man) and[Huntington](https://en.wikipedia.org/wiki/Clash_of_Civilizations).

The temptation to discover the key to what makes human history tick is great. From[Toynbee](https://en.wikipedia.org/wiki/Arnold_J._Toynbee#Academic_and_cultural_influence) to [Hari Seldon](https://en.wikipedia.org/wiki/Hari_Seldon). And it is not difficult to discover [interesting patterns](https://slatestarcodex.com/2019/08/12/book-review-secular-cycles).

The picture that the books on this list paint is that grand narratives of history do not stand up well to scrutiny. They may provide a useful lens through which to view the past, or more often the present. But there is always another grand narrative just around the corner.

In thinking about the [predictive utility of history](https://medium.com/metaphor-hacker/history-as-weather-a-fractal-theory-of-history-for-ian-morris-jared-diamond-and-cgp-grey-45b5503486c5), I asked: “So what is the point of history then? Its accurate predictions are not very useful and its useful predictions are not very accurate.” History and ethnography show us the range of possible ways of being human. They don’t tell us what to do next or how to be, but they are essential components of our never-ending quest to find out what we could be.

### *Related*
```
./2020-01-21-potemkin-wisdoms-phronesis-and-pixar-how-wise-sayings-protect-us-from-meaning.md
```
---
title: "Potemkin wisdoms, phronesis and Pixar: How wise sayings protect us from meaning"
date: 2020-01-21
author: Dominik Lukeš
source: https://metaphorhacker.net/2020/01/potemkin-wisdoms-phronesis-and-pixar-how-wise-sayings-protect-us-from-meaning
---

TL;DR
-----

This is an exploration of the difference between wisdom and practical wisdom (phronesis) triggered by this quote from [a talk by Ed Catmull](https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dk2h2lvhzMDc&sa=D&ust=1579646399857000):

> “Once one can articulate an important idea into a concise statement, then one can use this statement, and not have to have the fear of changing behavior.”

The main lesson is: if we confuse understanding with repeating its summary, we hollow out its meaning and can no longer rely on it to inform what we do.  

It explains why adopting even great advice often does not result in success. It explains why most charismatic reforms fail when spread out more widely. It explains why adopting even Catmull’s advice may not make you into Pixar.

Why are advice books so often free of content?
----------------------------------------------

[Ed Catmull](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Edwin_Catmull&sa=D&ust=1579646399859000) was an engineer suddenly put in charge of a company, so he did what engineers do. He went looking for a manual on how to run a business. In [his words](https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dk2h2lvhzMDc&sa=D&ust=1579646399859000) (slightly edited from transcript with punctuation inserted):

“I had to learn a lot about business quickly and I hadn’t gone to any school so I just read a lot of books and there were a few bits and pieces but I got to say, for the most part, I didn’t get a lot of traction with them.”

His solution:

> “So I said, well maybe the problem is I just got to get to the essence of them. There’s a service that gets the summaries of business books so I tried that. And that was actually an amazing experience, because, in reading the essence of the books, I realized they were content-free.”

But maybe the problem was not in the business books themselves:

> “What’s going on here? Is it the fact that the book doesn’t have any content, which is probably true in many cases, or is it that you can’t take some of these things and reduce them in a meaningful way?”

When it’s more important to say than to do
------------------------------------------

But Catmull was not interested in the nature of understanding. What bothered him was that the principles, once reduced to a slogan, made it impossible to determine practical success. Or rather, that you couldn’t tell who was actually good at something by the principles they espoused. It started in the film industry where the accepted wisdom was that ‘story is the most important thing’ about a film, but as Catmull discovered:

>  “… every studio says the same thing. Everybody says the stories are the most important thing, even if the story was drivel. It might be true, in fact it is true, but it doesn’t affect behavior. …  It’s one of those things that is true and you agree it is true and you say it, but that doesn’t mean anything.”

He found the same thing in architecture when he worked on building projects. Everybody agrees that you should design buildings “inside out” but that applies to architects of great buildings as well as the ones of awful buildings.  On its own, this may be an observation many people have made – the Dilbert cartoon series is based precisely on the fact that we all recognize what people talking in empty phrases sound like. But Catmull’s formulation of it is very striking and less glib:

> “The phrase [designing buildings inside out] is important to this community, it just does not have any effect on behavior.”

Early on in his talk Catmull asked what is more important “good ideas or good people”, this seems to point in the direction of ‘good ideas’ not being very important if they don’t help people do better things. But it also shows that ideas are tied to their expressions and those expressions play many more roles in their communities than communicating what the ideas are about. They tie their communities together through the ritualistic profession of creeds that signify belonging. It is more important that people ‘agree with’ or ‘proclaim’ the phrases than embody them through actions. (This, of course, has a long history in religious reform. Or educational reform. I recently gave a [talk exploring how the term ‘pedagogy first’](https://www.google.com/url?q=https://altc.alt.ac.uk/online2019/sessions/359/&sa=D&ust=1579646399861000) is mostly absent of meaning on which actions can be based.)

Compressing ideas renders them meaningless
------------------------------------------

None of this will be news to anybody who has ever worked for a big institution (University, corporation, Government department). Catmull expressed this very starkly in what I would consider a key quote from his whole talk:

“Once one can articulate an important idea into a concise statement, then one can use this statement, and not have to have the fear of changing behavior.”

This can even be used very strategically. In [my research on personalisation](https://www.google.com/url?q=https://www.researchgate.net/publication/277329463_Thinking_talking_and_writing_computer_programmes_about_personalisation_at_City_College_Norwich&sa=D&ust=1579646399862000) I ‘discovered’ that people were quite strategically looking through all the things they were already doing and trying to label them as ‘personalisation’. Often, in conversations about how to apply new methods, more time is spent on ‘labeling’ different activities than thinking about what to do. Catmull’s experience is the same:

“I see this over and over again. I can summarize some of these things, but the real issue is what do we do?”

But this is not just an issue with ideas being diluted through institutionalisation. It is a cry for help about the very possibility of making ideas mean anything at all. What good are great ideas if nobody can do anything with them. Many of the ideas “we all agree with” are expressions of genuine ‘wisdom’ but by the process of spreading them, we hollow out their content. And what we end up is wisdom painted on top of an empty box. We even have a story about this: ‘[The Emperor’s New Clothes](https://www.google.com/url?q=https://en.wikipedia.org/wiki/The_Emperor%2527s_New_Clothes&sa=D&ust=1579646399862000)’.

Potemkin village, Potemkin wisdom
---------------------------------

But an even better story than the one about a naked Emperor is the one about General Potemkin and his villages.

I grew up in a communist dictatorship and calling something a [Potemkin’s village](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Potemkin_village&sa=D&ust=1579646399863000) was  common when reflecting  on the propaganda of the regime. The phrase referred to a Russian general who created fake [facades](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Facade&sa=D&ust=1579646399863000) on buildings in villages so that the visiting [Empress](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Catherine_the_Great&sa=D&ust=1579646399864000) would think that they were prosperous and all was well in her realm. These facades could be moved from village to village, so as the Empress and her retinue travelled around, they could appreciate the quality of her government.

Pithy summaries of great ideas are like facades of beautiful buildings. They first appear as expressions of joy at the greatness of the structure inside. But unless we actually go in, walk through the rooms and corridors, or even better, live in them for a while, the greatness of the building is just an assumption. But we don’t always have the time to go in all the great buildings we see, and we definitely don’t have the time to live in them. So, when our own building is crumbling inside and out, we find it much easier to just paint the outside of it. Then anybody walking by will think it’s a great building and maybe we’ll even convince ourselves that the building is great.

Thus we create Potemkin’s wisdoms. Slogans we take from from one situation to another and paint them over whatever is actually happening. Unlike Potemkin, we don’t do it to deceive the Empress. From the outside, we see the beauty of the building, the truth of the idea. We want to embody that truth, so we paint it on top of what we do and admire it from afar. We are deceiving ourselves. But after a while the reality shines through the peeling paint and we go out looking for a new facade. This is the cycle of the hidden utopia.

The fundamental paradox of understanding
----------------------------------------

The reason this resonated with me to the point of tracking down the transcript of the talk is that this is a topic that I’ve been grappling with for almost 30 years. I’ve been returning to the question of understanding complex issues through summaries ever since I heard the Czech philosopher [Peter Rezek](https://www.google.com/url?q=https://cs.wikipedia.org/wiki/Petr_Rezek_(filosof)&sa=D&ust=1579646399865000) ask why did philosophers write these long books when we can then just talk about them in what is essentially aphorisms? Rezek’s answer (if I remember it correctly) was that we need to read the complete books, but he also wanted to explore the underlying tension.

The tension is that we (and this is me, not Rezek, speaking) can only really access the content of great books retroactively through reductions our mind creates in the process of understanding. Of course, the process of reading the book also changes the conceptual landscape of our mind against which any understanding is viewed. But when we try to recall that understanding and employ it in further thinking, we draw on those aphorisms and hope that the accompanying change in landscape contains all the important components to fill the pithy phrase back up with meaning. But often that is not that case. The time of use what was understood and the time of applying that understanding are far removed. But even if they were not, the understanding was always partial to begin with.

We also need to distinguish between understanding as the ability to draw the same inferences as the author of a text versus understanding as a moment of enlightenment. Enlightenment is a single event, but [understanding is a process](https://www.google.com/url?q=http://metaphorhacker.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/&sa=D&ust=1579646399865000). We are often almost ecstatically aware of the moment at which we finally ‘got’ something. But the tedious process of developing the [kind of understanding](https://www.google.com/url?q=https://metaphorhacker.net/2019/06/5-kinds-of-understanding-and-metaphors-missing-pieces-in-pedagogical-taxonomies/&sa=D&ust=1579646399866000) we might actually do something useful with happens largely under the radar of our consciousness. We see understanding and explanation in charismatic terms but the actual achievement of it is a [matter of routine](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Charismatic_authority&sa=D&ust=1579646399866000).

Wisdom contra Phronesis
-----------------------

And then, Catmull adds the dimension of ‘understanding as a social obligation’. This is very much reminiscent of the [pragmatist](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Pragmatism&sa=D&ust=1579646399866000) notion of truth. We only signal understanding through action in front of our peers. And by far the easiest action is that of repeating an accepted Shibboleth. Elezier Yudkowski has aptly called the sort of thing that happens in school [guessing the teacher’s password](https://www.google.com/url?q=https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password&sa=D&ust=1579646399867000).   When Catmull says “this phrase is important to the community,” he is talking about such a password. But, then, he observes, “it has no impact on behavior”. What he is after is what the ancient Greeks called “[phronesis](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Phronesis&sa=D&ust=1579646399867000)”, a practical wisdom. The sort of wisdom one can only gain through experience informed by knowledge. But this kind of knowledge cannot be expressed through a summary. Or perhaps not even communicated at all.

The Greeks helpfully differentiate between [sophia](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Sophia&sa=D&ust=1579646399867000) (wisdom), [phronesis](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Phronesis&sa=D&ust=1579646399868000) (practical wisdom), [episteme](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Episteme&sa=D&ust=1579646399868000) (knowledge) and [techne](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Techne&sa=D&ust=1579646399868000) (skill, craft) – although this was [a lot more complicated](https://www.google.com/url?q=https://plato.stanford.edu/entries/episteme-techne/&sa=D&ust=1579646399868000)[with](https://www.google.com/url?q=https://en.wiktionary.org/wiki/%25CE%25B5%25E1%25BC%25B4%25CE%25B4%25CE%25BF%25CE%25BC%25CE%25B1%25CE%25B9&sa=D&ust=1579646399869000) [many](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Gnosis&sa=D&ust=1579646399869000) [more](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Nous&sa=D&ust=1579646399869000) [distinctions](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Poiesis&sa=D&ust=1579646399869000) floating about. So if we are after the sort of judgment that comes from phronesis and has to be acquired rather than taught, what of the other forms of knowledge? Do they play no role at all? We certainly want people to know things (episteme) and be able to do things (techne), but do we really need them to be wise (sophia)? What if wisdom is only the ability to make pronouncements that are essentially empty of content on which one could base behavior?

In that case, wisdom is a ritualistic social function. We need wise people to tell us things like ‘measure once, cut twice’ or ‘paralysis through analysis’ to show us what we are as a community. And because these pearls of wisdom fit any situation in one way or another, it is not difficult to find them profoundly true without thinking about their emptiness. They give us the same sense of instantly gratifying insight that horoscopes and star signs do. When we read a description of our star sign, it can give us an almost euphoric sense of recognition of ourselves as being part of a bigger universe. In the same way, reading a wise saying, or a business book, can give us a glimpse of that sense of oneness with the world that gnostics or yogis must feel. We get to feel wise, in the know, with it – we finally got it.

And it is this feeling that Catmull warns against. In the preface to his book, he says:

> “What makes Pixar special is that we acknowledge we will always have problems, many of them hidden from our view; that we work hard to uncover these problems, even if doing so means making ourselves uncomfortable; and that, when we come across a problem, we marshal all of our energies to solve it.”

This might be the very definition of phronesis – acknowledgement of the fact that understanding is a process without an end. And that it has an emotional dimension. Understanding is not a question of insight but a matter of practical never-ending work. We can use wisdom – such as ‘understanding is a process’ as a catalyst for the actual work that’s necessary. But on its own, it’s just an ornament that we put on something to make it look better than it is.

Practical wisdom in the face of the complexity of understanding
---------------------------------------------------------------

But is it enough to read Catmull’s book or listen to his talk? We can follow his advice step by step and still fail in our aims. What happens to his wisdom (phronesis) when applied to his own pronouncements? Do they have any content at all when divorced from their original context? I’ve spent over 2000 words so far exploring their implications and I’m barely scratching the surface. We can say ‘what he says makes sense’ but it is actually us making it sense out of his words and our situation.

The problem is that [our intuitions about meaning are wrong](https://www.google.com/url?q=http://metaphorhacker.net/2018/05/therapy-for-frege-a-brief-outline-of-the-theory-of-everything/&sa=D&ust=1579646399871000). When we reflect on language (metacognition), our reflections take the form of that builds on a schema that very closely resembles a dictionary. In a physical sense, a dictionary puts meanings next to the words that express it. As if words were just little pointers to meaning. At its most schematic, this schema takes on the shape of one to one correspondence: fromage = cheese, dog = [picture of dog]. In certain contexts, we can acknowledge homophony or polysemy: dog = 1. animal, 2. food. At its most sophisticated, we imagine the right-hand side of a dictionary as an encyclopedia.

But that is not how words are used. We do not just put them next to each other and easily combine their meanings. For instance, when we apply adjectives to nouns, we don’t just add up the two meanings as we do with 1 + 1 = 2. Yellow cheese and yellow dog will seem superficially the same – ‘yellow’ + thing = yellow thing. But that is only at the highest level of abstraction. If we actually want language to communicate something somebody can draw some useful inferences from, a lot more has to happen. The yellow of cheese is very different from the yellow of the Sun or a crayon. Also, it is an expected color. But the yellow of a dog is an unusual colour. We can call it blond or something but we do not expect it to be the same as that of cheese. If we see the words ‘[yellow dog](https://www.google.com/url?q=https://www.google.com/search?q%3Dyellow%2Bdog%26sxsrf%3DACYBGNTX5He6V148dtbAoPMEqZ2KiOhgqQ:1579502163796%26source%3Dlnms%26tbm%3Disch%26sa%3DX%26ved%3D2ahUKEwiriZSLyJHnAhV2QxUIHVCKDCsQ_AUoAXoECA4QAw%26biw%3D1463%26bih%3D713&sa=D&ust=1579646399872000)’ we may expect a picture of an animal or an animal that has been covered with yellow paint. Also, when we cut a block of cheese in half, we expect the color to be more or less uniform throughout. The vet performing a surgery on a ‘yellow’ dog (whether blond or painted) would be extremely surprised to find the dog to be yellow on the inside.

What does this have to do with anything? Only that, if applying the simple label of ‘yellow’ to simple nouns like ‘cheese’ or ‘dog’ is this complicated, how can we expect to simply apply complicated labels like ‘we acknowledge we will always have problems’ to complicated institutions like ‘Pixar’ or ‘Coca Cola’ or ‘Bob’s Bodega’?

Because of the complexity of meaning making, people understand the same words applied to the same situations differently. This is such a fundamental fact of everyday life as to be considered trivial. So obvious that it barely deserves a mention. But if it is so obvious, why is it completely absent from our basic schema of meaning and understanding? Why don’t we add this to our consideration when we say things like ‘people need to be more considerate’? Our common reaction on hearing something like that is to agree. But instead we should be asking “what do you mean?”  What does a ‘considerate person’ look like in your head? What are your schemas and scenarios? In the same way we might ask somebody “what do you mean by ‘yellow dog’?”

But, of course, most of the time we cannot. Conversation would be impossible. Indeed, life would be impossible if we couldn’t rely rough schematic understandings. Instead, we make sense of things as we go along. Sometimes we do ask for clarification, but usually we look for cues, or just nod along and hope it will all make sense in the end. With very complex meanings – such as famous principles – we often just assume an underlying structure that was never there – like the Empress looking at a facade of an empty building.

When I say ‘understanding is a process’ and ‘knowledge is social’, I mean exactly that. We build up meanings as we go along, make assumptions, ask questions, hope somebody else knows what that means, and so on. That is exactly what happens when somebody reads a book like Camull’s – they start building images that they then share with others and hope to come to some sort of understanding. And part of that understanding will be ‘Catmull ran Pixar, his words will make us more like Pixar’ and ‘Catmull only ever ran Pixar, what does he know about my neck of the woods’ and ‘I just want this meeting to be over so I can go get lunch’.

Catmull himself was aware of the problem and instituted processes at Pixar that tried to break up the routines of meaning making and trigger less schematic reflection. But what happens if somebody who is not Catmull – doesn’t have his style, his conviction, his understanding of what he actually means – in short his ‘charisma’? We are back to Dilbert! All through history, charismatic reforms have failed when applied across larger numbers of peoples and institutions. The followers of St Francis of Assissi soon start acquiring possessions in his name. Revolutionary leaders fighting to overthrow oppression soon become the oppressors. Teachers fired up by philosophies of empowering the child soon start spending most of their time taking attendance and marking homework.

Unfortunately, it’s even more complicated than just people misunderstanding the wisdom of those imbued with the virtue of phronesis. We cannot even be sure that those who have the requisite practical wisdom even understand it themselves. They may be telling us about it but may be misdescribing their own understanding by applying idiosyncratic interpretations to common schemas. Or sometimes they’re just saying stuff to justify something that happened mostly outside their control.

I once heard an executive bragging that he turned around a failing company by making everybody count the number of paperclips they were using. This, according to him, got everybody to focus on costs and led to a turn around in the company’s balance sheet. On the surface, this is a plausible story, and we even have common sense wisdom in the form of ‘look after the pennies and the dollars will look after themselves’. But on second’s reflection, it is utterly implausible. He and lots of others most likely did a lot of other things and the stupid counting of paper clips just got in the way. We can imagine another executive coming in and saying ‘focus on what’s important’ or as the folk wisdom has it ‘don’t sweat the small stuff’. Just like Steve Jobs did when he came back to Apple.

So we should be skeptical of Catmull’s sine qua nons in his talk and in his book. Lots of successful and creative companies succeeded doing exactly the opposite of what he recommends. But even if his prescriptions may only work sometimes, his description of what happens, when we brandish slogans as shields, is still the best we got. His solution is to be a sort of every day philosopher, and he’s not the only one to advocate for this – [Richard Rorty](https://www.google.com/url?q=https://plato.stanford.edu/entries/rorty/&sa=D&ust=1579646399875000) and [John Elliott](https://www.google.com/url?q=https://people.uea.ac.uk/john_elliott&sa=D&ust=1579646399875000) are two others I can think of. But practical philosophy is too easily confused with professional philosophy – thinking pretty thoughts and expressing them in pretty words.

However, just declaring ‘everyone should be a practical philosopher’ is not enough. Philosophers may ask questions like ‘what do you mean by that’, but because most of the time, they have those same intuitions about meaning as something you find in a dictionary, these questions lead nowhere. The philosopher’s love of wisdom is often the love of a lexicographer enamoured of putting words next to their definitions. These sorts of questions only have value if what we seek is phronesis and not sophia. Practical wisdom, judgement in the context of actual collective endeavour. Unsatisfactorily, it is a process without an outcome. It can never end in a dictionary entry which can at best capture it frozen in time. And, if that is that we end up with, then all we have is a phrase we can carry around with us as a shield to protect us from actually changing what we do. Or to close with Catmull’s words:

“Once one can articulate an important idea into a concise statement, then one can use this statement, and not have to have the fear of changing behavior.”

Background
----------

Many years ago I heard [John Siracusa](https://www.google.com/url?q=http://hypercritical.co/&sa=D&ust=1579646399876000) on a [podcast](https://www.google.com/url?q=https://5by5.tv/hypercritical&sa=D&ust=1579646399877000) say something like “nothing hides problem like success” when talking about issues with Apple’s software when the company was hitting $1 billion in market value. It immediately made sense to me. It is hard to try to give advice to people who are successful at something. But recently I had the urge to track down the origin of the quote and after a bit of searching [I discovered](https://www.google.com/url?q=http://5by5.tv/hypercritical/12&sa=D&ust=1579646399877000) that John got it from Pixar’s then President [Ed Catmull’s 2009 talk at Stanford](https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dk2h2lvhzMDc&sa=D&ust=1579646399878000). I watched it and realised that it is relevant much more broadly than just as a source of one pithy phrase. In fact, it had at least 2 important insights.

1. Success hides problems
2. When powerful ideas are encapsulated in pithy sayings, they lose their power to change behavior

I went looking for the first but it’s the second one that was the inspiration to write the above.

Postscript
----------

I found it interesting that the [summary of Catmull’s talk](https://www.google.com/url?q=https://www.gsb.stanford.edu/insights/ed-catmull-we-constantly-seek-out-small-crises&sa=D&ust=1579646399879000) published by Stanford where he gave this talk skirted the first and completely ignored the second insight. But without the second, the first one is meaningless. It will just sit there being numbly repeated by all, nodding along with its wisdom and doing nothing about it.

I had a quick look at Catmull’s [book Creativity, Inc](https://www.google.com/url?q=https://www.amazon.com/Creativity-Inc-Overcoming-Unseen-Inspiration/dp/0812993012&sa=D&ust=1579646399880000), and he elaborates on the second point in chapter 3 with more examples and metaphors. The metaphor I found most apt is the one of a suitcase but I only read it after I finished this post so it was too late  to work it.

> “Imagine an old, heavy suitcase whose well-worn handles are hanging by a few threads. The handle is “Trust the Process” or “Story Is King”—a pithy statement that seems, on the face of it, to stand for so much more. The suitcase represents all that has gone into the formation of the phrase: the experience, the deep wisdom, the truths that emerge from struggle. Too often, we grab the handle and—without realizing it—walk off without the suitcase. What’s more, we don’t even think about what we’ve left behind. After all, the handle is so much easier to carry around than the suitcase.”
```
./2020-02-01-how-to-actually-write-a-sentence-the-building-blocks-of-written-language.md
```
---
title: "How to actually write a sentence: The building blocks of written language"
date: 2020-02-01
author: Dominik Lukeš
source: https://metaphorhacker.net/2020/02/how-to-actually-write-a-sentence-the-building-blocks-of-written-language
---

Some time ago, Thomas Basbøll followed up his excellent post on [how to write a paragraph](https://blog.cbs.dk/inframethodology/?p=2676)

> “it is substantially more difficult to explain what one does when one writes a sentence than it is to explain what one does when one composes a paragraph.”

Indeed, it is much more difficult to talk about the mechanics of writing the sentence because we generally want to forget we are composing a sentence, whereas we want to focus on the fact we are composing a paragraph. In this, writing a sentence is much like riding a bicycle. You cannot really do it successfully while attending to every aspect of the process. Basbøll’s metaphor here is very apt:

> “it’s easier to give you directions to City Hall than to explain how your legs work. Sentences, we might say, are to paragraphs as taking a step is to going somewhere. It’s only once we pay attention to it that we realize how subtle and how stylish such a simple thing can be.”

The problem with his solution, though, is that it only focused on the role of the sentence in the process of expressing ideas rather than the mechanics of putting a sentence together. This is because a sentence is an artificial construct. We think of it as a natural unit but, in fact, it is only an accident of history that we’ve started dividing chunks of text with full stops and beginning them with capital letters.

The sentence is just one way of articulating a thought. It could be a list. A phrase. Or a whole stream-of-consiousness story. But through conventions, we think of all of these as inferior kinds of writing. Expressing ourselves ‘in complete sentences’ has been agreed to be the hallmark of educated expression. And whether we agree with it or not, sentence is what we’re stuck with.

What is a sentence?
-------------------

There is much debate in linguistics as to what is the foundational building block of language. It could be a phoneme (sound), syllable (much more natural in speech), word (unit of meaning), utterance or text (one chunk of speech with a message). It could also be a phrase. But by far the best candidate is a clause – a unit with one predicate and one subject – even if it is not always easy to define exactly what predicates and subjects are. But whatever the basic building block of language may be, sentence is definitely not it. It’s not even a unit in conversational speech but despite its visual significance, it is not really the basic building block of written language either.

This is because the boundaries of a sentence are completely arbitrary. They are simply there for the convenience of visual processing. The preceding 2 sentences could just as easily have been one. And many people would insist that they would be better as one and then argue over the proper rules of punctuation.

The real problem, and the one Basbøll is actually writing about, is how to express one’s thoughts through writing in a way that generates mental representations in the mind of the reader that are as close as possible to those of the writer. He illustrates it nicely with a quote from Orwell:

> “As George Orwell pointed out many years ago, a great deal of bad writing comes out of stringing words and phrases together that are completely unrelated to any pictures that might form in any human being’s head.”

There is something in this. We might argue that at least what is written represents what is in the writer’s head. But often our written words are just an echo of what was in one’s mind rather than a rendering of a mental image. Who has not had the experience of reading something they have written and not being completely certain what they meant by it?

So, making sure you build the right image in the reader’s mind with your words is excellect advice. But where Orwell, Basbøll’s essay and many others come up short is in explaining how to go about stringing those words together in just the right way so that they can trigger the right image in the reader’s mind. In this post, I’d like to suggest some ways in which we actually may go about learning to write a sentence to achieve this aim.

Dual articulation, riding the bike and Krashen’s monitor
--------------------------------------------------------

But before we go any further, let’s look a bit more closely at the nature of the difficulty identified by Basbøll. That is: What we really want is to express ideas, not craft sentences. We want to go effortlessly from idea to sentence or better still from idea to paragraph. But we have to pass through many intermediate steps before we get there. Choosing words, calling up their spelling, deciding on their relative placement, whether we should add any endings, and then telling our fingers to type them. It’s even more complex in speech, where we have to arrange our mouths, tongues and teeth into complex configurations and coordinate all of that with the work of the lungs and the epiglottis.

In other words, before we can articulate a thought, we have to articulate a lot of other things. This has been called the ‘dual articulation’ of language. Dual articulation is one of the most underappreciated aspects of language. It is what makes non-native language learning so hard. And writing is certainly not native to any of us.

We spend a lot of time trying to learn all the rules of articulating words and sentences. But in order to successfully and fluently articulate ideas (which is what language is there for after all), we have to make the complex process of articulation of all the building blocks of language disappear. If we were to attend to all aspects of it, we would be permanently tongue-tied.

This is an experience that any learner of a foreign language has had when trying to use their newly acquired knowledge outside the classroom. Stephen Krashen has proposed the monitor hypothesis where the goal of language acquisition is to reduce the role of the grammatical monitor. In the same way that native speakers not only do not pay attention to how they put words and sentences together, learners must get rid of this additional burden. Speaking a language then is just like riding a bike. If you pay attention to all the tiny movements that are involved in peddaling while keeping balance, you fall off. But equally, if you miss any of them out, you fall off, as well.

So what are we, who want to teach others to write sentences, to do? On the one hand, we have to tell them about the principles of sentence structure that they were not able to suss out from their own reading. But on the other hand, we have to lead them to completely forget about all of them when they most matter and just write.

Writing as editing and editing as reading
-----------------------------------------

Luckily, writing is not as ephemeral and fast flowing as speaking. We can always come back to a sentence we wrote and change it beyond all recognition. So, to teach somebody how to write is really teaching them how to edit. And a big part of teaching somebody how to edit, is to teach them about what to pay attention to when reading.

To be clear, a fluent writer can formulate a sentence without much need for further editing. But editing is a process through which such facility can be acquired. And even the most expert writers will need to come back and edit some of their sentences.

What does an editor pay attention to? They will tell you that they look at two things: 1. does the sentence make sense and 2. does it flow from the previous sentences and into those that follow. They will also look at more formal aspects such as spelling, undue repetition of words, stylistic appropriateness, etc. But 1 and 2 (sometimes also called coherence and cohesion) are the fundamental structural jobs a sentence has to perform.

How to craft a sentence
-----------------------

This finally brings us to the ultimate aim of this post. How to actually put a sentence together. This is, of course, impossible to cover in a single blog post. There are shelves in libraries around the world groaning under the weight of volumes that barely scratch the surface of all the aspects of a well-crafted sentence. Yet, people have managed to become competent or even admired writers despite all that. So, there must be way.

### Learning to craft a sentence

It is important that aspiring writers think about the learning process as much as about the actual components of a sentence. And the process is very simple:

1. When you read something, spend at least some of the time, looking at how it is put together. If this is not what you naturally do, set aside some time to do this as part of your reading.
2. Form hypotheses about the rules the author used and then try them out yourself. It does not matter whether these hypotheses are correct ‘grammatical’ rules or even whether they look like grammatical rules. It just matters that you can do something with them.
3. Leave what you wrote sit for a while and then come back to it. Read it again and see if it still makes sense. Then go back and look at how what you wrote differs from what you intended. And also compare this with other writing.
4. Read things out loud or have them read to you (e.g. by text to speech). This will sometimes allow you to notice things about the text that you may skip over when reading silently.
5. Do this a lot.

With that in mind, let’s finally have a look at some of the things you have to know about how to write a sentence.

### Making a sentence make sense – Coherence

For a sentence to fulfil its ideational function, it has to make sense. This means that the sentence must not only contain the idea you want to express, it must not get in the way of that idea. When you’re editing your sentences to make sure they make sense, ask yourself these questions:

* Is it possible to read the sentence in other ways? Sometimes, when a sentence comes out of your head, you are blinded to its other possible meanings. Read it out loud, or ask your software to read it out loud for you.
* Have you chosen the right words? This seems obvious but choosing the words that mean what you want to say is not a given.
* Are the subjects of the clauses linked clearly to their verbs? Or, is it clear what the verbs in your sentence are describing? Conversely, is it clear what is happening to the nouns in your sentence? A simple test is to try to reduce the clauses in your sentence just to underlying verb and noun pair (or subject and predicate). Then keep adding the other words until the sentence is back together. If this sounds like old-fashioned parsing, it’s because it is. But sometimes it is necessary to strip your sentence bare and then slowly add only the necessary components back. Often it is the only way to make a sentence that got away from you make sense again.
* Have you compressed too much into a single sentence? Can you expect that your readers have the same background and can take a hint?
* Is it clear what the pronouns refer to? When you’re writing, your subject is very active in your head. So, it is very common to keep using pronouns or other vague words to refer to what you’re talking about. It is safer to use pronouns a bit more sparingly and repeat more often. While there’s a lot of research in this area, there is no one rule for how to do this right. But most of us were warned against repetition by our teachers, so a good rule of thumb is to repeat a bit more often than you feel comfortable.
* Have you used the keywords in the right context? Sometimes words have multiple meanings and the one you are trying to express may not be the one most readers associate with it. Perhaps the best tool to help you here is a corpus. The [iWeb corpus](https://www.english-corpora.org/iweb) is a great tool for checking how words are used.

### Making a sentence hold together – Cohesion

But even if your sentences make sense and use all the appropriate conventions, they still have to hold together and fit in with the rest of the text. This is often the easiest problem to overlook because you have an overall picture of the text in your mind, so it all flows perfectly in your head.

But your reader will have to build a picture of the text from scratch. And, also, they may not always read perfectly linearly, so even a sentence read out of context should make it clear where it relates to what came before.

Here are some questions to ask yourself when you’re editing a sentence:

* Have I made the right logical connections? If one thing is caused by another, is there a ‘because’ or a similar conjunction to make the link explicit?
* Have I not put too much distance between closely related things? Long parentheticals can be fun but make it very easy for the reader (as well as the writer) to get lost.
* Have I focused the reader on the right point? The topic (or known information) of a sentence is usually at the beginning and the focus (or new information) should come at the end.
* Have I given the reader too much work to parse the sentence? If so, can I make it easier by splitting the sentence into shorter chunks?
* Can I move some things to a later sentence?
* Have I expressed a clear link to what came previously?
* Have I placed the sentences in the right order? Don’t be afraid to move a sentence to the end to make sure the key information comes earlier.

A useful tool to use here is the Hemingway Editor. It will highlight sentences that are too long. Now, in many genres, such as academic writing, long sentences are not always a problem. They’re almost the expectation. But a sentence that goes on too long should be a signal to you, that you may not have expressed your idea clearly. I find that my long sentences are often just piles of ideas that need to be taken apart and given more air.

### Making a sentence communicate what you want how you want it: Genre and style

Even if your sentence makes sense, your reader must be willing to try to read it. This means that you must meet as many of their expectations as possible so that they can focus on the meaning. You do this by conforming as closely as possible to the conventions of the genre you work within. If you do break these conventions, make sure you’re doing it for a reason.

If you’re writing an academic essay, stay within the [register] of academic language. This is where the various guides on academic English come in. They break down language into communicative functions like argumentation, persuasion or disagreement. And then they give you lots of appropriate phrases to achieve that function.

This is also where you need to do a lot of targetted reading in the area you want to write in. Don’t just read for content, read with an eye on the way people express themselves. Narrow your area as much as you can.

For example, there’s not just one ‘academic English’. Each little subdiscipline has its own conventions, so it’s worth paying attention to those. One piece of advice given is, before you submit a paper to a journal, read other papers that had already been published there. They will give you a clue as to the expectations. This applies at all levels, not just the sentence.

There are technical tools that can help you. For instance, you can paste your text to [the Analyze tool on AcademicVocabulary.info](https://www.wordandphrase.info/academic/analyzeText.asp) and check the words you used against a corpus of academic writing.

### Writing and editing process tips

Finally, here are some tips about the process of writing and editing your text at the level of a sentence.

* Don’t edit every sentence independently – only edit when you’ve written several of them to make sure they hang together.
* Feel free to delete a sentence. Often, once we’ve written something, we feel possessive about it. But often, deleting something can be very helpful. Like pruning a tree.
* Feel free to split a sentence in two or three. Sometimes, it will give you space to express yourself more clearly. But sometimes, it will just give your reader a visual cue that a new idea is coming. Or at least some space to take a breath.
* By the same token, don’t be afraid to start or end a sentence with a preposition or a conjunction. It’s much better than twisting yourself around.
* Don’t be too scared of long sentences. Sometimes, joining two shorter sentences together makes the text flow better.

Reflections and conclusions
---------------------------

The abiding concern of anyone telling somebody else how to write is whether they themselves measure up to what they preach. Or at least, it should be. We know that [Orwell used more passives than average](http://www.lel.ed.ac.uk/~gpullum/passive_loathing.pdf) while advising against them, [Strunk and White](http://ling.ed.ac.uk/~gpullum/50years.pdf) used many of the same constructions they advised against, and the [Plain English campaign proponents](http://metaphorhacker.techczech.net/2012/09/the-complexities-of-simple-what-simple-language-proponents-should-know-about-linguistics/) don’t always use simple language.

Equally, I cannot guarantee that every sentence in this guide is a paragon of what a well-crafted sentence should be. I know my limits. I tend to write more than needed and not cut out enough having learned my English syntax at the feet of PG Wodehouse. But demonstrating perfection at the level of the sentence is not the point of this post, and neither should that be the aim of most writers. The aim is to get the point across and then to move on.

But the most important conclusion is that hesitant writers must pay attention to the learning process. It is not possible to explicitly follow all the tiny little rules for putting together a sentence. You must internalise the shapes and bigger chunks, so that you can focus on experessing your ideas. This can only be achieved through deliberate practice. And editing what you wrote is the most crucial part of that practice. Great writers have great editors, or if they’re poor, they’re their own great editors.

Image by [Free-Photos](https://pixabay.com/photos/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1209121) from [Pixabay](https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1209121)

### *Related*
```
./2020-02-16-its-not-personal-its-family-kin-strangers-guests-and-the-complexity-of-social-obligation.md
```
---
title: "It’s not personal, it’s family: Kin, strangers, guests, and the complexity of social obligation"
date: 2020-02-16
author: Dominik Lukeš
source: https://metaphorhacker.net/2020/02/its-not-personal-its-family
---

Brooks on the alternatives to nuclear family
--------------------------------------------

[Tyler Cowen](https:marginalrevolution.com/marginalrevolution/2020/02/the-importance-of-family-structure-was-the-nuclear-family-a-mistake.html)

His portrayal of the current social environment is well worth reading and rereading:

> “If you want to summarize the changes in family structure over the past century, the truest thing to say is this: We’ve made life freer for individuals and more unstable for families. We’ve made life better for adults but worse for children. We’ve moved from big, interconnected, and extended families, which helped protect the most vulnerable people in society from the shocks of life, to smaller, detached nuclear families (a married couple and their children), which give the most privileged people in society room to maximize their talents and expand their options.”

But he avoids and indeed criticises the conservative instinct to demand a return to the traditional family:

> “Social conservatives insist that we can bring the nuclear family back. But the conditions that made for stable nuclear families in the 1950s are never returning. Conservatives have nothing to say to the kid whose dad has split, whose mom has had three other kids with different dads; “go live in a nuclear family” is really not relevant advice.”

And he also points out the deficiencies in the liberal response:

> “Progressives, meanwhile, still talk like self-expressive individualists of the 1970s: People should have the freedom to pick whatever family form works for them. And, of course, they should. But many of the new family forms do not work well for most people—and while progressive elites say that all family structures are fine, their own behavior suggests that they believe otherwise.”

His summary feels very apt to the situation (although it is important to note, that there are many progressive thinkers who are much closer to his ideas than he admits):

> “while social conservatives have a philosophy of family life they can’t operationalize, because it no longer is relevant, progressives have no philosophy of family life at all, because they don’t want to seem judgmental”

Brooks also very aptly formulates the current state as a paradox:

> “Our culture is oddly stuck. We want stability and rootedness, but also mobility, dynamic capitalism, and the liberty to adopt the lifestyle we choose. We want close families, but not the legal, cultural, and sociological constraints that made them possible.”

In fact, the solution he proposes, created, forged families – a redefinition of kin, is more socially progressive than conservative.

> “This is a significant opportunity, a chance to thicken and broaden family relationships, a chance to allow more adults and children to live and grow under the loving gaze of a dozen pairs of eyes, and be caught, when they fall, by a dozen pairs of arms. For decades we have been eating at smaller and smaller tables, with fewer and fewer kin. It’s time to find ways to bring back the big tables.”

This is an essentially progressive vision tinged with a fair bit of the conservative communitarian nostalgia. It is the same nostalgia for the imaginary of togetherness that drove ‘[Bowling alone](https://en.wikipedia.org/wiki/Bowling_Alone)’ to such popularity 20 years ago. It is neither venal, moralistic, nor unrealistic. Brooks is merely describing what exists and has always existed in one way or another. He then takes a turn reminiscent of Margaret Mead and says, let’s make that the new normal. And he seems to find the sweet spot that has the potential of becoming a meeting point for the utopian imaginaries of both conservatives and progressives.

What Brooks leaves out are the limits of these family-like structures when it comes to dealing with those outside them. And unsurprisingly he also fails to mention the possible role the state can and perhaps must play in tying them together.

Brooks does an admirable job of engaging with the anthropological literature. He does not just insert the obligatory James C Scott reference so beloved of certain kind of libertarian thinker, he reads more widely and more deeply. But, as always, there’s more. Here I’d like to bring in some more anthropological perspectives to enrich and somewhat complicate Brooks’ vision. This is not to negate what he says or dismiss it as erroneous. All I’m trying to do is expand the picture slightly.

Kin, guests and strangers: From baseline communism to complex webs of social obligation
---------------------------------------------------------------------------------------

The one anthropologist he does not mention is [David Graeber](https://en.wikipedia.org/wiki/Debt:_The_First_5000_Years). Graeber called the kind of mutuality Brooks is after ‘baseline communism’. When communism is defined as ‘to each according to their needs, from each according to their abilities’ it is often decried as unworkable because it ignores human proclivities for cheating. But, in fact, as Graeber points out, it describes perfectly one very familiar environment: the family. Communism is not a question of property, it’s a question of obligation from one to the many and the many to the one. This always exists on some sort of spectrum. As Graeber describes, there’s never complete abandonment of private property (even in the most egalitarian societies, there are some things people can call their own), nor complete abandonment of supporting people’s needs (even hard-nosed captains of industry will give each other breaks under certain conditions).

This obligation is unconditional but it is also constrained. To help us understand the constraints, we could simplify the sources of obligation by dividing the social world into three classes: ‘kin’, ‘guests’, and ‘strangers’. Kin and strangers are mostly stable categories whereas ‘guests’ are inherently dynamic and transient. ‘Guest’ is a stranger who becomes temporary ‘kin’ in the sense that the obligations for ensuring the wellbeing of ‘kin’ transfer to them on a limited basis but often in a ‘lavish’ manner. One of the inventions of the ‘post-industrial world’ is our ability to deal with ‘strangers’ without having to confer kin-like privileges on them. The ability to associate and collaborate with strangers who are not your guests is what made industrial capitalism as we know it possible.

But it is also what makes socialism possible. Once the complex webs of mutual support through extended kin networks have been torn up, the state can step in and substitute for this obligation. When many progressives talk about the duty of care of the state (or smaller collectives), they essentially claim this sort of familial role for the state. Conservatives, on the other hand, view the state more as a meeting ground for groups of strangers. For them, the state as such should have no power to treat anyone as guests.

This tension is present even in socialist-leaning countries such as Sweden or Germany which are willing to provide for their citizens – who are otherwise strangers to each other – some of the kind of support traditionally reserved for kin. They are also willing to provide hospitality to new arrivals but very much as guests. What they are struggling with is the process of conferring the kin-status on these guests.

Brooks mentions how many captives of the Native American nations in the 1700s did not want to return back to the ‘civilised’ world from which they were taken. But he omits to mention that these groups often had elaborate ways of transferring strangers from captives to guests to kin. Be it through marriage or adoption, even enslaved war captives could (sometimes enmasse) made into ‘one of us’. Japan, for instance, still widely practices ‘adult adoption’ which was also very common in Ancient Rome and is one of the ways of achieving this that is not available to the state.

Brooks talks about what was lost and he is not wrong. He is also not blind to the fact that the support the kin networks provided was often opperessive and frequently rested disproportionately on women. But he still perceives it from the perspective of a homestead – he talks about the individual groups as if they floated in a vaccuum.

This is where Brooks would have benefited from engaing with another precursor of his thinking Karl Polanyi. Polanyi critiqued our view of the industrial revolution as merely a matter of technology plus capital. He wrote his magnum opus ‘The Great Transformation’ over 80 years ago – long before the 1950s ushered in the nuclear family revolution Brooks blames on current ills. Polanyi traces the problem much further back to the needs of early industrial capitalism. And he also relies on the ethnography of his day to contrast the ‘mutual support’ of traditional societies with the manufactured individualism of the industrial age.

The emotional pull of the ‘mutuality of being’: For good or for ill
-------------------------------------------------------------------

Polanyi does not dwell on the emotional aspects of the material support networks but the nostalgia is clearly there. Brooks, on the other hand, can’t get over the emotional impact of personally experiencing being a member of the kind of group of mutual support that he proposes. And he is not wrong to point out the strong emotional pull of the mutuality of the neighbourhood. Nobody does it better than 2PAC when he sings about the feelings of returning to his old problematic neighborhood in ‘My Block’.

> My neighborhood ain’t the same  
> Cause all these little babies goin crazy and they sufferin in the game  
> And I swear it’s like a trap  
> But I ain’t given up on the hood it’s all good when I go back  
> Hoes show me love, niggaz give me props  
> Forever hop cause it don’t stop… on my block

and talking about what it’s like being away:

> In my heart, I felt alone out here on my own  
> I close my eyes and picture home… on my block

Brooks quotes ethnographers such as Marshall Sahlins and Monica Wilson on the ineffable nature of the connection within kin groups. People in them experience “a mutuality of being” (Sahlins) and are almost ‘mystically dependent’ (Wilson) on one another. This is easy to overlook in more institutionally focused accounts of ‘kinship’, so Brooks is right to emphasize it but it’s not all there is.

The emotional support mutuality provides is well known and is present even in situations where it is harmful to the individuals. In describing a materially and, by his account, mentally and socially deprived society in a remote Apalchian community, Robert Edgerton, reports:

> Despite the absence of any kind of ritual, ceremony, or community-wide activities, these people were fiercely loyal to their hollow and their way of life. Even those few who could emigrate, like a boy Gazaway took away from the hollow for a brief period of schooling, preferred to remain in Duddie’s Branch. They could also express great love for members of their families, and even for an outsider like Gazaway. They had pride, dignity, courage, and generosity.

The affective power of the nearly mystical ‘mutuality of being’ can exert a strong attractive force on a reader who is not enmeshed in such strong ties. This makes it easy to forget, that tightly-knit communities are not always idylic:

> “some small-scale populations do not effectively solve the problems they face, and sometimes the very culture that should sustain them and enhance their well-being instead produces fear, apathy, isolation, and degradation.” from Sick Societies by Robert Edgerton

Edgerton also has an agenda of his own but his account is an important antidote to the opiate of anthropological utopia.

My main point is that while the emotional impact of mutuality is substantial, it alone is not enough to account for all the elements that we see in the tripartite ‘kin/guest/strager’ distinction. And neither are social norms as traditionally conceived; viz norms being the combination of unwritten rules, explicit laws, and various forms of enforcement. It is instead a cognitive perception of how the world is. It’s not that people fulfil obligations because of fear of sanctions. It’s because they cannot imagine not doing so. It is simply against a very basic fabric of their being.

It’s not personal, it’s family: Ties that moor us and bind us
-------------------------------------------------------------

I spent six month working on projects in Timor-Leste, one of the poorest countries in the world, where people frequently don’t have enough food during certain times of the year. Yet, there is almost no homelessness and festivals are common even in the poor areas. How can this be? The answer is extended family. The Timorese large family networks provide material and emotional support for all their members.

But this also makes working on projects quite difficult. The Timorese are no less intelligent or competent than any other people I’ve worked with. But their family always comes first. We’re not talking just about sick children or bereavements but also festivals and other family gatherings – which are not infrequent. Combined with what often seems like a sudden appearance of these events, running projects when a key staff member can disappear at a moment’s notice is often a frustrating experience.

And it’s not even that the person wants ‘go to a fun party’ instead of doing ‘dull work’. Often attending such events can be both emotionally and materially draining. Resisting the pull of the social obligation is like resisting gravity. Sometimes it keeps us grounded, sometimes it throws us flat on our face. To help my non-Timorese colleagues conceptualise this better, I came up with the mantra: “it’s not personal, it’s family”. In the same way that the American “it’s not personal, it’s business” is used to explain or excuse behavior against the norms of sociability, so can the Timorese “it’s not personal, it’s family” be helpful to understand the sort of behavior that the individualistic mindset perceives as a breach of contract.

This, of course, is not unique to Timor-Leste, nor is it unknown in the cross-cultural literature. These family networks can also be harnessed to economic benefit in the capitalist system. Many of the successes of the East and South East Asian diasporas around the world are due in large part to their ability to harness the mutuality of support across long distances. A small enterprise that can rely on the virtually free labor and trustworthy sources of credit or supplies provided by kin has a larger chance of success, particularly is the boundary between the work and personal life is very flexible. And the kin can expect mutual support back – extending across the globe through remittances and other forms of support. Not based on a simply return-on-investment calculus but on bonds unconditional mutuality.

But these same networks often do not work as well when it comes to economic production in environments where there are not enough strangers to work as a buffer. The same Cambodian or Vietnamese entrepreneurs who are successful in California or the Czech Republic struggle to achieve the same success in their home environment. This is not because they are any less industrious or surrounded by sloth when at home. It is because it is harder to escape the totality of obligations up close.

James C Scott observed that small shopkeepers in many parts of the world are often strangers (often of different ethnic or linguistic origin) who are not tied to local structures of kindship and obligation. It is impossible to run a small shop if it is impossible to refuse to simply give food to people with whom you have a strong bond. This is certainly true in Timor-Leste where many of the small local enterprises struggle.

This is common around the world, so much so that many of the small loan arrangements that have become popular in the development area function less as a way of advancing capital and more as a way of putting capital out of reach of kinship obligations. As another exmple, Leo Howe reports that many of the people working in the hospitality industry in Bali are actually Javanese because the native Balinese cannot be relied on to be always available. This is not because they are ‘unreliable’ in some essentially flawed way but because their obligation to family (often ritual) is too great to suspend through a contract with strangers. Marshall Sahlins’ essay on ‘Stranger Kings’ shows that this applies even to choosing to submit to a ruler.

The strong ties with kin and weak ties with non-kin can cause even greater problems which is why we find such elaborate hospitality rituals around the world. Tourists often misinterpret these under the heading of ‘oh, the people are so friendly here’ but in fact, this is a function of the culture not having a norm around dealing with strangers that does not rely on the notion of guest as temporary kin.

The ancient Greek concept of ‘xenia’ – hospitality to strangers can be very illustrative. We know the root from ‘xenophobia’ but the Latin equivalent gave us both hospitality and hostility. Xenia not only dictates extraordinary measures to take care of guests but it also strictly regulates the behavior of those same guests. Breaking the rules of hospitality has been the source of many problems from the Trojan War to the blood feuds in modern Albania – for instance, as described in Kadare’s “Broken April”.

These are not inevitable consequences of the sort of groupings Brooks is describing and advocating for. Not is he unaware of potential internal problems. But when the entire world is structured through strong kin-like ties, we have not just created an archipellago of utopias – as some in the Seasteading movement seem to imagine – we have a world that is fundamentally different from what we know. The demands of the trade-centred world dependent on industrial production and industrialised aggriculture cannot be entirely ignored in this vision.

Conclusion: The kin, the strangers, and the state
-------------------------------------------------

In conclusion,these rough sketches are not meant to diminish Brooks’ contribution. If I were asked to come up with an alternative to the nuclear family, it is almost exactly, what I would propose. Many ethnographic accounts of impoverished communities all over the world show that these networks often emerge organically. And we should be doing as much as possible to normalize them. They are not some lesser, last resort alternatives to the nuclear family. They are both natural and can be healthy and robust. But they don’t exist in a vacuum and are themselves not static nor do are they uniformly idyllic. There are cracks the size of valleys between them and sometimes even within them. And it’s very easy for individuals to fall through those.

That’s where we still must see a role for the state to protect both individuals and groups from falling to the ground without a safety net as well as adjudicate the parameters of their encounter. At the moment, the state support structure is entirely structured around the schemas and scripts of the nuclear family on the one hand, and the contract between strangers on the other. It needs to recognise a wider range of support networks and obligations which is only possible if we reframe the notion of family. Such reframings are always long and do not progress in a linearly predictable fashion. Brooks’ essay is an undeniably valuable contribution to this process. So despite any quibbles and caveats, I’m all for it.

### *Related*
```
./2020-06-28-no-back-row-no-corridor-metaphors-for-online-teaching-and-learning.md
```
---
title: "No back row, no corridor: Metaphors for online teaching and learning"
date: 2020-06-28
author: Dominik Lukeš
source: https://metaphorhacker.net/2020/06/no-back-row-no-corridor-metaphors-for-online-teaching-and-learning
---

Publication note
----------------

An earlier version of this was published in the [Oxford Magazine](https://staff.admin.ox.ac.uk/oxford-magazine) No 422.  This post expands certain sections based on questions and feedback I received following the first publication of the piece. It is also available on [Medium](https://medium.com/metaphor-hacker/no-back-row-no-corridor-metaphors-for-online-teaching-and-learning-9628f164fc37?source=friends_link&sk=27f6f0666a88d9951c5d16a28d0e00e7).

The state of digital dislocation
--------------------------------

The current state of digital dislocation is forcing us to reevaluate what is the essence of teaching and learning. The “grammar of schooling” [1] has been taken away from us and we are forced to learn a new dialect by immersion with just a few phrasebooks, hastily pulled off the shelf, to guide us. Digital teaching is still teaching but it is teaching with an accent, one where we’re still trying to acquire enough fluency and idiomaticity to feel completely at home. When we add to it the culture shock of being in a new situation without any of the familiar cues, sights, sounds and smells of our native environment, it is not surprising that many people are feeling stressed and long for a swift return to “normal”. But it is also no surprise that many others are examining the current situation and finding the new land to be one of endless opportunity and thinking of establishing a permanent residence or at least buying a holiday home.

At one extreme, we are hearing voices calling online learning “clearly inferior,” lacking the essential personal contact that defines the University experience and asking whether the cost, expressed in fees, is too high. At the other pole, we hear “online teaching is clearly better,” doing away with all the distractions and deadweight of spaces, commutes and providing the focus so essential to learning. The same person can find themselves taking either position depending on the stage of culture shock they are living through at the moment. Both of these perspectives were reflected in an eloquent summary by Ray Williamson from the Oxford Student Union in a recent issue of the Oxford Magazine.[2] Here, I’d like to elaborate on what is at stake and look at ways of conceptualising the different perspectives.

Making sense of digital with affordance metaphors
-------------------------------------------------

I suggest that the two divergent views can best be reconciled when we contrast the affordances of the physical and virtual environments in which teaching and learning take place. By affordances I mean those features of the environment that present themselves to us for direct action and interaction and thus make the world around us meaningful and define what it means to live in the space we’re in. Affordance is a concept fundamental to design thinking and interaction and ignoring them is the most frequent cause of failure both in digital and physical products. [3]

The best way I found to bring the contrast between the physical and the virtual into focus are two metaphors that can be summarised as “No back row” and “No corridor”.

“No back row”
-------------

“No back row” expresses mostly the potential of the online experience to be positive for learning: the digital space is the great equaliser, no student is left hiding in the dark corner of the room, everybody’s contribution is coming from the front. This leads to higher engagement with the study material, and better learning. It is so powerful that the American online course provider 2U trademarked the slogan as part of their corporate philosophy [4]. Of course, just because it has the potential to be beneficial for learning, it doesn’t mean that we can just put the same course online and get its benefits. We have to design the online courses to take advantage of this. Nor should we be mislead by the visual metaphor of the Zoom call that 2U use on their corporate page. This applies to an entirely forum-based course, as well. The very fact that they have to engage with the content may put additional demands and stresses on students that will require support. This is in addition to the issues that are captured by the ‘no corridor’ metaphor.

“No corridor”
-------------

“No corridor” reflects the largely negative aspects of the virtual when contrasted with face to face. It reflects the lack of physical and social space connecting the learning situations. There are no natural landmarks to guide us, no flow of the crowd to follow. Everything has to be scheduled, bookmarked or emailed. There is little serendipity and no feeling of just “being there”. This makes it easy for a student to disappear and find themselves in “no row” at all. The physical space is doing a lot of work that is beyond the conscious notice of educators and programme administrators and allows them to be less specific in their instructions and leave things to ‘work themselves’ out without realising it. Their planning may be meticulous and painstaking but it is always framed by what the space affords them when it is filled with students, signs, and other signals that may feel almost subliminal. This can be easily seen when we compare the instructions students receive before arrival (what to bring, where to come, what to expect) and when they arrive which may be as little as a time table followed by ad-hoc announcements. And this comparison may gives clues to some aspects of mitigating the downsides of ‘no corridor’.

Affordances of the physical vs virtual
--------------------------------------

Photo by [Lucrezia Carnelos](https://unsplash.com/@ciabattespugnose?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

Luckily, we can mitigate the downsides of the virtual and amplify its benefits, if we pay careful attention to the affordances of the physical. There are successful ways of making up for the lack of the corridor’s hidden contribution to the learning process but we must avoid taking the normal environment in which learning takes place for granted. We rightly focus on personal relationships as essential to learning but as we saw above it is easy to underestimate the power of the spaces in which they are situated.

In the physical space, it is much easier to just follow the flow of the environment and learn, without realising it, by reflecting others’ reactions to it. There are spaces laid out so obviously that our use of them passes completely beneath any level of conscious notice. We do not need to deliberate on how to open doors, sit facing the speaker, not to sit in a seat already occupied. And where there are issues (locked doors, missing markers, drilling outside the window), we have established scripts for coping and frames for interpreting them.

None of these features are present in the virtual environment. Every action (at least initially), requires the effort of directed attention. We need to learn the “interfaces” of Zoom, establish routines of where to ‘find the link to join’, keep track of bookmarks for the learning materials, and manage actual time for virtual events and assignment deadlines. All of this virtual effort is taking place in an actual physical environment where we are the only person engaging in the activity. What’s worse, when we study or teach virtually, we do not appear to the world around us any different from when we idly browse the web or are binge-watching a TV show. We then have to negotiate with that environment and people in it in ways that travelling to ‘school’ or the ‘library’ does for us without any words having to be exchanged other than ‘I’m going to class’.

It’s no wonder many are finding themselves more stressed, tired and downright disoriented. But equally, to no one’s surprise, there are many who are thriving without the extra burden of the physical space which they may have found too overwhelming, full of distractions and uncertainties. We know that not all students cherish the demands of the physical spaces into which attending a university thrusts them; those who only feel comfortable huddled in the back row or for whom passage through the corridor is an exercise fraught with anxiety. Universities have ample built-in support structures and processes (albeit imperfect) for the latter but none for the former.

For a successful online learning experience
-------------------------------------------

Yet, we know that it is possible to build a sense of “being there” in fully virtual environments and it is also possible to establish durable personal support relationships. This was possible even before the rise of Zoom or Teams as the success of Open University can attest but now it is even more within reach. Perhaps the most powerful indications of this are coming from the successes of telemedicine and even online psychotherapy. Many patients are finding that their one-on-one experience with a therapist is enhanced without the stressful overhead of travel, sitting in waiting rooms, walking through crowds, etc. [6]

Telemedicine also shows the way when we think about the heterogeneity of needs and inclinations. It is clearly not always appropriate to conduct therapeutic interventions over Skype but it is sufficient or even superior in more instances than may have been thought before the current situation made them a necessity. Do we think that education is radically different, here?

What does a University have to do to make the most of the benefits of ‘no back row’ and minimise the downsides of ‘no corridor’? What does the individual educator? The solutions are surprisingly simple and non-technical. Above all, we need to realise how much we can leave unsaid because the physical environment says it for us and then make it explicit in the virtual setting. We need to communicate more clearly and more frequently. We need to design the virtual learning spaces to minimize unnecessary cognitive load, structure information better, pay attention to navigation and consistency. We need to constantly fine-tune the balance between information overload and not enough information. We need to build structures that support the students who are struggling with the technological as well as personal aspects of learning.

New roles for the relationship business
---------------------------------------

Photo by [Brooke Cagle](https://unsplash.com/@brookecagle?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

But ultimately and most importantly, we need to realise that educational institutions are not in the information business, they are in the relationship business (to borrow a metaphor from the media critic Jeff Jarvis [5]). It is easy to deploy an army of learning technologists and media production specialists, and think we’ve done virtual teaching justice. But online teaching requires other support roles and activities than just those leading to the deployment of “tech”.

There need to be roles whose main job it is to make sure students are opening the right virtual doors and sitting facing the right way in the virtual learning spaces. There need to be roles that pay attention to the real physical spaces and social situations on the other side of the Zoom call. When students are on campus, so much of this is done for us by the affordances of the space built up over centuries and so ingrained into our conceptual and perceptual systems that interacting with them feels to be a matter of instinct.

When all we have is emails, forum posts, webcams and the screen, we need to put in additional work to make up for this. Over time, it will come to seem as natural as what we have now but not without the initial effort. For instance, it is not anyone’s job to explicitly make sure students socialise with others in the physical environment. We don’t ask students if they “went out for a drink” with others when they’re on campus, but perhaps, it needs to be somebody’s job in the virtual situation. [7]

Sources of learning
-------------------

Luckily, we have ample models of successful practice to draw on. The Open University is one such, Oxford’s own Continuing Education department is another. Private online education providers such as GetSmarter / 2U, who provided the first part of the metaphor, are others.

As far back as 2009 before Zoom or video conferencing, I taught a module on language and education in a physical setting followed a year later by a similar module in a fully online course for teachers. I was struck, when reading the final essays, how much more the online students seem to have engaged with the subject.

In the physical space, I had a feeling of engagement during my seminars with the students. But the ‘feedback’ I was getting from them hid the relative shallowness and unevenness of their engagement. I never saw the online students in person, so I had to design the course to get this feedback in other ways and I could easily see where all individual students were and guide them back in the right direction if they seemed to be floundering. It was more work for me and them but the learning gains were there to see.

The lessons of this anecdote are supported by research evidence and by experiences of educators the world over [8]. We do not need to provide inferior experiences to students just because they are not in the same room as us.

Eventually the world of university teaching and learning will return to “normal” but we should be mindful that culture shock happens on returning home, as well.[9] We can take advantage of what we learned during this forced sojourn in digital lands to develop a more robust bi-cultural approach to teaching by blending the best of both worlds.

Footnotes
---------

[1] Tyack, D.B. and Cuban, L., 1995. Tinkering toward utopia: a century of public school reform. Harvard University Press, Cambridge, Mass ; London.

[2] Williams, R. 2020. “Students and remote learning” Oxford Magazine, 421, Trinity.

[3] Norman, D.A., 2013. The design of everyday things. Basic books, New York, N.Y.

[4] No Back Row | 2U [WWW Document], n.d. URL <https://cdn2.2u.com/about/no-back-row/> (accessed 6.8.20).

[5] Jarvis, J., 2012. What the media can learn from Facebook. The Guardian, 15 February 2012, sec. Media Network. <https://www.theguardian.com/media-network/media-network-blog/2012/feb/15/what-media-learn-facebook>.

[6] These two recent pieces summarise the pros and cons of mental and physical health interventions and point to relevant research.

Joyce, N., 2020. Online therapy having its moment, bringing insights on how to expand mental health services going forward [WWW Document]. The Conversation. URL <http://theconversation.com/online-therapy-having-its-moment-bringing-insights-on-how-to-expand-mental-health-services-going-forward-136374> (accessed 6.8.20).

Novella, S. 2020. It’s Time for Telehealth. NeuroLogica Blog. URL <https://theness.com/neurologicablog/index.php/its-time-for-telehealth/> (accessed 6.8.20).

[7] Redmond, P., Heffernan, A., Abawi, L., Brown, A., Henderson, R., 2018. An Online Engagement Framework for Higher Education. Online Learning 22. <https://doi.org/10.24059/olj.v22i1.1175>

[8] The following systematic reviews show that online higher education is at least as effective as offline education when it comes to learning outcomes.

Means, B., Toyama, Y., Murphy, R., Bakia, M., Jones, K., 2009. Evaluation of Evidence-Based Practices in Online Learning: A Meta-Analysis and Review of Online Learning Studies, US Department of Education. US Department of Education.

Nguyen, T., 2015. The Effectiveness of Online Learning: Beyond No Significant Difference and Future Horizons 11, 11.

Pei, L., Wu, H., 2019. Does online learning work better than offline learning in undergraduate medical education? A systematic review and meta-analysis. Med Educ Online 24. <https://doi.org/10.1080/10872981.2019.1666538>

[9] Gaw, K.F., 2000. Reverse culture shock in students returning from overseas. International Journal of Intercultural Relations 24, 83–104. <https://doi.org/10.1016/S0147-1767(99)00024-3>

### *Related*
```
./2021-01-01-metaphors-and-freedom-on-tolkiens-notion-of-allegory-vs-applicability.md
```
---
title: "Metaphors and freedom: On Tolkien’s notion of allegory vs applicability"
date: 2021-01-01
author: Dominik Lukeš
source: https://metaphorhacker.net/2021/01/metaphors-and-freedom-on-tolkiens-notion-of-allegory-vs-applicability
---

On rereading Tolkien’s Lord of the Rings, I was struck by this passage in his foreword to the second edition:

> I cordially dislike allegory in all its manifestations, and always have done so since I grew old and wary enough to detect its presence. I much prefer history, true or feigned, with its varied applicability to the thought and experience of readers. I think that many confuse ‘applicability’ with ‘allegory’; but the one resides in the freedom of the reader, and the other in the purposed domination of the author. [http://ae-lib.org.ua/texts-c/tolkien\_\_the\_lord\_of\_the\_rings\_1\_\_en.htm](http://ae-lib.org.ua/texts-c/tolkien__the_lord_of_the_rings_1__en.htm#00)

Tolkien is reflecting on the many reactions to his work and people trying to situate the happenings in the Lord of the Rings into the context of the Second World War or later the Cold War. He claims that he had no such intentions and takes some time to analyze what would have had to have happened in the books if he had wanted to make that sort of point.

But the idea of history opening up more opportunities for readers than allegory is a useful one. Allegory is just a complaint, an empty gesture aiming to show something in a purportedly “truer” light than a mere description. But in fact, it aims to constrain the lesson that can be learned, rather than expanding it. This neatly underscores the central thesis of this blog that metaphors and the conceptual frames they rely on need to be negotiated. Taken apart, examined and put back together.

Tolkien’s complaint helps me express much more succinctly my own dislike for allegories and dystopias such as Orwell’s Animal Farm or 1984. There is so much more to learn by studying the complex case studies of history and the thick descriptions of ethnography – which in the best cases reside in the same work. What did Orwell add to what was already known? Nothing. He only took away. He took away the complexity of the situation and he absolved his readers of tackling the more complex issues involved.

But luckily for us, we are not at the mercy of other people’s imagination. My thesis is not just normative. I do not just say that we should always examine our metaphors and negotiate their mappings – even though it is a recommendation I do make. This negotiation is what we actually already do as part of the process understanding metaphors. And we don’t just do it at the moment of reading a particular metaphor. We do it over the course of our life. We think, rethink, we have conversation with others, we are exposed to competing accounts – even in seemingly totalitarian contexts.

In fact, allegory is itself an example of this process. Because what is allegory if not an extended metaphor, negotiating one view of the world. It is a narrative metaphor, just like satire but without the humor. Its rhetorical purpose is one of persuading us to the author’s view of the world. And it may be slightly more underhanded than a mere historical description by constraining the avenues of applicability, to use Tolkien’s term. But ultimately, even a historical description or an ethnographic account use the same processes of framing and reframing. Describing the world from a perspective of the author’s context.

That’s why each generation writes new histories, even if the actual facts do not need revision (though they often do), the new perspective of the time demands a retelling. All of a sudden, there are more women in history, more people of color, history is not happening just to old white men. And how did this come about? Did we all of a sudden notice things we missed the first time around and changed our view of the present? No, we just find new things worth talking about. This in turn does lead to new discoveries of fact, but these will then be reassessed as the narrative demands of the day change.

Metaphor, in this sense, is not a figure of speech, it is a process that expresses our constant reengagement with the world. Metaphors do not give or take away our freedoms of thought or action. They are the means through which we express these freedoms. All the way through. Across books and debates.

Hobbes spent a whole section in the Leviathan complaining about metaphors and their power of misdirection. Without ever once acknowledging that the book itself is one giant metaphor or that he is using the metaphors of *ignes fatui* (will o’the wisp) to do his hatchet job on them. But he was not wrong, metaphors can be used to cover up parts of what we express as well as to shed new light on it.

But they never have the last word. Because we never stop talking, writing, engaging. Finding new ways of projecting concepts onto each other, coloring our perceptions with lenses made from one framing or another. And this includes the very process of metaphor use. Hobbes or Tolkien are just one of many weighing in on the use of metaphor. Some say that metaphors are just froth on top of good literal truth, others that metaphors are the only way to true understanding.

But metaphors are always the journey never the destination. Even if we sometimes feel their power so strongly that we cannot for the moment imagine anything else, there’s another metaphor or allegory just around the corner, just as seductive and completely contradictory. And then a third taking parts from the other two. And it is through this constant reassessment and retuning of our understanding as individuals and as groups, that we live our lives. As free or as tied down as we can be. Metaphors are there to help us along, but we are the ones who wield them. Constrained by the limits of metaphor, having to negotiate the journey with them and around them, sometimes stuck as if in treacle but never chained to them for good.

### *Related*
```
./2021-01-17-the-nonsense-of-style-academic-writing-should-be-scrupulous-not-stylish.md
```
---
title: "The nonsense of style: Academic writing should be scrupulous not stylish"
date: 2021-01-17
author: Dominik Lukeš
source: https://metaphorhacker.net/2021/01/the-nonsense-of-style-academic-writing-should-be-scrupulous-not-stylish
---

The problem with writing advice
-------------------------------

The problem with the likes of Steven Pinker and Helen Sword is that they like their own writing way too much. But I don’t. Like their writing, that is. [1] I want to get some information from them and I want to get examples and counterexamples for the points they make. I want them to get to the point. I am not reading them for enjoyment, that’s what fiction is for. I am reading them to learn what they have to say and I have to wade through a morass of stories, pointless metaphors, geysers of words. They are aiming for eloquence but effluence would be a better term for what their reader gets.

Of course, they get high praise and esteem from their peers, everybody wants to write like Pinker, Gladwell or Sword. And obviously many people buy and read their books. So they must be doing something right. But my claim is that they focus far too much of crafting their sentences and far too little time on crafting their advice.

And what’s worse, they promote an environment where ‘writing well’ with style or panache is seen as a virtue. People are praised for that sort of writing and others are encouraged to emulate them. Sentences like “This was so well written, why can’t more academics write like this” proliferate. But it misidentifies the problem. When academic writing is bad, it is not because of the opacity of prose but rather because of the paucity of scrupulous argumentation.

Defending academic writing
--------------------------

The complaint that academic writing is needlessly dense and abstruse has become a cliche and gets far too little examination. Nobody (except many frustrated readers) is officially complaining that non-fiction writing is needlessly flowery and sprawling across many more pages than necessary. It prides itself on taking the reader on a journey of discovery but it’s actually all smoke and mirrors.

There is only one criterion that we should require of academic writing and that is the same requirement we should have of academic thinking. Scruples. Scrupulous writing will let the reader in on the uncertainty of knowledge, and messiness of the process of how knowledge is created. It will not try to write a press-release while presenting its argument. And it will not waste the reader’s time by taking them on a journey. Starting every single point it wants to make with a story!

Starting with academic reading
------------------------------

Academic writing needs to start with the recognition of what academic reading looks like. The vast majority of academic writing is not read like fiction or popular non-fiction. It is read to get the piece of information one needs or to get a gist of what the overall point is. So, having a clear outline with descriptive titles would be much more important than removing unnecessary adverbs. Having an abstract that summarises the key points made in bullet points helps more than using active verbs. Using vocabulary appropriate to the needs of the audience is much more useful than trying to avoid jargon or acronyms.

The first advice you need to give to an academic writer is not to read a book on stylish writing but rather to read how people in their field are writing. Because those are their potential readers. And in their writing, we see what they are expecting. So anything written in the manner they expect will make reading easier for them. Because there is no academic writing as such, there is only writing within disciplines and communities. And barging into a community and trying to change what it’s doing without invitation is not stylish, it is rude. [2]

Why are people reading and why are people writing? They are reading to discover the argument that the author is putting forward. And they are writing to put debate the arguments of others and to put forth more of their own. Their success in doing so should be our primary criterion. The success of academic writing is not some abstract readability score but the ability of the peers to identify and debate the argument it puts forward. [3]

Practical advice on composition: Shorter sentences
--------------------------------------------------

This is where we can give some practical advice. And the advice can be summarised in 3 words: 1. Write 2. shorter 3. sentences. Ignore everything about passives, jargon, conversational writing, whatever else the latest guide puts forward. Focus on keeping your average sentence to about 15 words. Not every sentence has to be that short but if you keep the average somewhere between 15 and 20 words, your writing will be easier to read.

Keeping sentences short is not only good for the reader, it is also good for the writer. Often a long sentence means muddled thought. If I find a sentence I wrote that’s longer than say 30 words, I often also find that the thought behind it is not clear enough. I had an idea in my mind that had too many assumptions and I had not put enough work into parsing out all the connections.

But not always, sometimes a longer sentence is better for both the writer and the reader. Text that is easy to understand is cohesive as well as coherent and too many short clauses will lack cohesion. The reader needs to know which things link together and making that explicit will make the text better.

The good news is that sentence length is easy to check without having to learn opaque grammatical concepts. We know that [people most exercised about passives](http://www.lel.ed.ac.uk/grammar/passives.html) are least likely to actually spot them in the sentence. So why should we expect normal writers to pay attention to parts of speech or fine details of sentence structure. But anybody can paste their text into the free [Hemingway Writer](http://www.hemingwayapp.com/) and see if they can shorten the sentences highlighted in red.[4] Doing it regularly will also give you a chance to focus on how sentences are put together.

Structure is king: Rich outlines
--------------------------------

If you really care about your readers, make sure you make the outline of your writing explicit. Don’t just mark the normal sections like: Introduction or Conclusions. That is helpful for navigation but not understanding. Put headings inside these sections and have them every few paragraphs to summarise what you’re trying to say in those paragraphs. This will aid readers who are not reading your text in sequence to get the gist and also not to miss important points.

You may complain about the youths today not spending enough time on deep reading, but paradoxically, if the structure is marked clearly enough, people are likely to read more of the actual text, as well, because it breaks the work into smaller chunks. Particularly students or novices are often horrified by the walls and walls of undifferentiated texts they are asked to climb. Dividing it into smaller, labelled chunks makes the text more approachable and more likely to be read.

This rich outlining can be done while planning your writing, during writing or during revision. I often don’t start with an outline because I’m not yet clear on exactly what I want to say. But I always create an outline at some point. It helps me discover all the missing and inconsistent bits that are so easy to miss in an extended narrative.

And, finally, if you have an outline, share it with the reader. Put it at the top of the text. It could be a table of contents or just a list of bullets. Better still, put it in the abstract. It is infuriating, reading an abstract that says what the paper tries to show and not what it actually showed. [4]

All you need
------------

And that’s it, clear explicit structure and moderately shorter sentences. No stories, no metaphors, no flourishes. No avoidance of passives or reduction of adverbs. No worries about technical language. Just these two. They will not only make the academic writing easier to read, they will also make it more scrupulous.

Self-criticism
--------------

Do I write as I say? Not always and not always perfectly. Some of my sentences do get long and my composition tends to the flowery. For example, the sentence about the importance of shorter sentences is the longest one of this post at 43 words. I thought about breaking it up but I liked its rhythm, so I left it. But my average sentence is 14 words and this makes the overall readability higher.

But that is the lot of anyone who writes about writing. The more strident your strictures, the more likely you are to [fall afoul of them](https://www.polysyllabic.com/?q=node/168).

Notes
-----

**[1]** For those who do not routinely read books on writing. The title of the post refers to a book by Steven Pinker “The Sense of Style” which is a lot to wade through for not very much useful advice. The other book I complain about is Helen Sword’s “Stylish Academic Writing”, which overall has better and more actionable advice than Pinker. But the problem with Sword is that many of the examples she sets out to change actually don’t need changing that much. And the examples she singles out for praise are questionable.

**[2]** The advice about how important it is pay attention about the language of the community you’re writing for is best summarised by Larry McEnerney in his talk about [Writing beyond the academy](https://www.youtube.com/watch?v=aFwVf5a3pZM&list=PLEl9d2qvKkBslX4kb0bG2mWmiSKYDGBdC&index=3).

**[3]** The importance of thinking about your writing as communicating with interested peers is often made by Thomas Basbøll) on his [blog Inframethodology](https://blog.cbs.dk/inframethodology/). But it is also the core of the argument of this [paper by Cathy Birkenstein defending Judith Butler](https://www.jstor.org/stable/25653028?seq=1) against the charge of incomprehensibility.

**[4]** The [Hemingway App](http://www.hemingwayapp.com/) also tries to identify passives and adverbs. Feel free to entirely ignore its advice. Also, it computes a readability score which is useful. But all it does is count letters in words and words in sentences. It is easy to game just by randomly inserting periods through out the text. \*\*\*\*

### *Related*
```
./2021-03-08-why-i-am-a-feminist-a-reading-list.md
```
---
title: "Why I am a feminist: A reading list"
date: 2021-03-08
author: Dominik Lukeš
source: https://metaphorhacker.net/2021/03/why-i-am-a-feminist-a-reading-list
---

I became a feminist because a woman once told me not to be an idiot and I decided that it was good advice. That was in 1998. But I was all ready to be a feminist long before that, so it really just took a small push to get me over the hump. I was always surrounded by strong women who outshone the men around them, read books as a boy with girls holding their own, later on had women friends who I could respect and like more than most of my male friends.

Yet, I was reticent to apply the label to myself. In those times, it was the women around me who were very sceptical of feminism. So, even when I had doubts about the essentialism of the male/female difference, I was willing to go along without examining the position in too much depth. But looking back, I don’t think I was too happy about it.

So it took just a little jolt to show me a new way to reflect on things and I never looked back. [Not being a feminist would now feel just as odd as not being a vegetarian.](http://dominiklukes.net/bibliography/masozenyasvobodaduse)

But perhaps I did not always go about it the right way. In the early days, I felt like I had to go back to all my women friends and try to convince them that they really should be feminists, too. Later, I wrote articles supporting political correctness, reviews of Vagina Monologues and other books about gender. And the occasional blog post since. I tried my best.

I have not really felt the need to do any of that recently because it seems to me that the world of today has plenty of voices closer to the action and perhaps I don’t have much to add. But then I started looking for a reading list for a friend and was surprised that few of my top choices made the top choices of others’ lists.

The reading list of reading lists
---------------------------------

There a plenty of ‘feminist reading lists’ on offer:

They list classics I know or know about like de Beauvoir, Steinem, Friedan, bell hooks, as well as new authors and books that passed me by. They list fiction, manifestos, polemics. Margaret Attwood makes a frequent appearance, some go as far back as Mary Wolstonecraft and the more complete include Judith Butler. There’s plenty to read when one goes by the lists.

And I don’t really object to any of the items on these lists. Particularly some of the older ones like de Beauvoir or Wolstonecraft are fascinating thinkers even today. But the six I came up with as recommendations appear on none of the lists I looked at. They don’t even make the much more comprehensive [Wikipedia List of feminist literature](https://en.wikipedia.org/wiki/List_of_feminist_literature). Perhaps I have something to share, after all.

My list of 6 Books
------------------

These are the 6 books that I use to go to for feminist argumentation most often in my mind and the occasional writing. These books are not necessarily radically political but they are radically intellectual. Which, I think, is the main appeal of feminism to me. At its best, feminism is a radical unthinking of the commonplace. And what is more symptomatic of the commonplace than gender? Everything to do with the male/female distinction is steeped in an apparent natural inevitability. And feminism allows us to transcend that inevitability and gives us the inspiration to look for other inevitabilities to be made illusory in its wake.

I tried to find a related video for each book. Here’s a whole [companion playlist](https://www.youtube.com/playlist?list=PLEl9d2qvKkBvf-bhxWY3gsNpgCvwDSPqZ).

### “Language and woman’s place” by Robin Tolmach Lakoff (1972)

“Language uses us as much as we use language” – thus opens Robin Lakoff the world of possibilities with the first line of her book. It it was published in 1972 but it may be best to read it in its 30th anniversary edition with commentary and reflection. This is a foundational book for understanding the depth through which the gender power disparity is reflected in language.

Since then, there have been many books on gender and language from various perspectives – updating and expanding Lakoff’s work. Deborah Tannen is one of the more prolific authors worth reading but ‘Language and woman’s place’ is the place to start.

Here’s a podcast where [Lakoff talks about language and gender](https://youtu.be/E7TKsCd1aRA). Deborah Tannen has written lots of books and has lots of videos. Here’s one I like about the differences between [male and female speech patterns in friendship discourse](https://www.youtube.com/watch?v=A2xOfpW6xSo).

### “Why so slow” by Virginia Valian (1997)

This is a book that asks the question of what to do when the battle of the minds was won. In 2020, it seems like the battle is starting over again but in the late 1990s it appeared to have been all but over with just a few loose ends to be tied up.

Valian shows that it is the small steps that can add up to significant blockers of progress. The world in which women (at least in certain parts) find themselves today would have seemed far beyond the horizon of the possible as recently as the 1950s. But the chasm seems ever wider and deeper the closer we are to it. ‘Why so slow’ looks at some of the components of the gap and can help us find levers to perhaps finally close it. In many ways, many of Valian’s suggestions have entered the common discourse but it is still worth going back to the source.

My biggest takeaway was that no overt sexism is even required for a society to end up with an imbalance between the sexes. Just small cumulative everyday injustices that may even pass beneath notice of most people involved in them.

Virginia Valian speaks on the topic in [a lecture from 2009](https://youtu.be/FtvV6Bot28Y).

### “Is multiculturalism bad for women?” by Susan Moller Okin and other contributors (1999)

Intersectionality is now on everybody’s lips but the history of the fight for equality by various marginalised groups is one of constant tension. For example, women’s movements were at different times both deeply intertwined with movement for racial justice and keeping it at arm’s length.

This is a book of essays written in reaction to Okin’s famous article that underscored the practical difficulty of women’s rights when confronted with cultural rights. All contributors start from a concern for women’s rights but some even turn the question on its head by asking questions like is feminism good for non-western women? Some question the underlying categories. But none offer easy answers.

When it comes to the utopias hidden behind the placards held by marchers needing to be translated into dirty realities, this is the book to turn to. The title of Martha Nussbaum’s essay, “A Plea for Difficulty”, should perhaps be a rallying cry for the aftermath of all revolutions just about to tuck in into their children.

I couldn’t find any videos about this book but there are good discussions of the topic [here](https://youtu.be/yB9baefrHl4) and [here](https://youtu.be/sgmvMvrTuC0) even though they do not explicitly reference this debate. I mentioned Nussbaum and here’s a [great interview with her on gender and development](https://www.youtube.com/watch?v=Qy3YTzYjut4).

### “Marriage: A history” by Stephanie Coontz (2005)

This is not a book about feminism at all. It is a history of the Western side of the institution in which men and women most often used to encounter each other. It is a book that shows how what we know as ‘marriage’ is determined by the way we talk about it, the surrounding economic realities, and what came just before. Most importantly it shows the constant invention and reinvention of marriage and puts the lie to the ‘traditional’ notion of marriage invented by 1950s TV.

Stephanie Coontz talks about her earlier book [‘The Way We Never Were’ in a lecture here](https://youtu.be/MIeAnU7_7TA).

There’s also a great [interview with her on a New Books Network podcast](https://newbooksnetwork.com/stephenie-coontz-the-way-we-never-were-american-families-and-the-nostalgia-trap-basic-books-2000/). She also wrote a subsequent [book about feminism and its reception in the 1960s and is interviewed about it here](https://newbooksnetwork.com/stephanie-coontz-a-strange-stirring-the-feminine-mystique-and-the-american-women-at-the-dawn-of-the-1960s-basic-books-2014-2/).

### “Against Love: A Polemic” by Laura Kipnis (2003)

Kipnis is not against ‘love’ the feeling but against love as the organising principle of male-female relationships. Where Coontz shows the invention of love as an institutional category, Kipnis takes it apart in its various daily guises that people willingly enter into just to bind themselves to somebody else’s nostalgia. Love, when conceived as a social institution, is worse for women than men. Exemplified by the traditional wedding photo of a woman turned subtly towards the male, while the man stares boldly forward. It is not love but the performance of love that can do more harm than good.

I couldn’t find Kipnis talking about this book anywhere but [here’s an interview with her about a later collection of essays](https://youtu.be/1AEySO8Uyug) which shows her insight and subtlety of argument even in the face of a mediocre interviewer.

### “The Gender of the Gift” by Marilyn Strathern (1988)

Not for the faint of heart, this is a dense book of anthropological insight. But it puts the question of women’s role in society in a non-industrial perspective. This is both a feminist book but also a meta-feminist book thinking through the dualism that rejecting the dualistic can lead to. It also offers an answer to the question of multiculturalism being bad for women before it was ever asked – the answer being it’s complicated.

I’m not sure if reading the first five books would make one ready to read Strathern – to get the wider point one has to read through a lot of technical anthropology. But what is feminism after all if not applied anthropology? Ultimately I think it’s worth it – if perhaps a journey best embarked upon with a friend.

Strathern talks about an [earlier book on gender and anthropology briefly here](https://youtu.be/afmJIpc7nWk). Here’s her [later lecture on a different subject](https://youtu.be/xDavTWIKqM8) but showing the anthropological approach to similar issues.

All other books
---------------

All books, when read with gender and sex unthought, can be be part of a feminist reading list. They can be read for what they don’t say, as well as what they do say. I wrote about some of my thinking on this [here](https://metaphorhacker.net/2011/04/i-object-a-male-feminists-view-on-the-dutches-of-cambridges-wedding-dress/), [here](https://metaphorhacker.net/2014/05/what-does-it-mean-when-texts-really-mean-something/) and [here](https://metaphorhacker.net/2013/09/storms-in-all-teacups-the-power-and-inequality-in-the-battle-for-science-universality/). And I seem to have written even more than I remember in Czech here: [Feminismus a láska.pdf](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b1a1ca65-125c-4a99-b1be-7b8de5815d3d/Feminismus_a_lska.pdf)

And when all else fails, there’s always [Buffy the Vampire Slayer](https://www.bufferingthevampireslayer.com/) to turn to.

### *Related*
```
./2021-06-03-history-as-weather-a-fractal-theory-of-history-for-ian-morris-jared-diamond-and-cgp-grey.md
```
---
title: "History as weather: A fractal theory of history for Ian Morris, Jared Diamond and CGP Grey"
date: 2021-06-03
author: Dominik Lukeš
source: https://metaphorhacker.net/2021/06/history-as-weather-a-fractal-theory-of-history-for-ian-morris-jared-diamond-and-cgp-grey
---

**Note:** This post originally [appeared on Medium](https://medium.com/metaphor-hacker/history-as-weather-a-fractal-theory-of-history-for-ian-morris-jared-diamond-and-cgp-grey-45b5503486c5) in 2016. This a very lightly revised version with new formatting for [ease of readability](https://metaphorhacker.net/2021/01/the-nonsense-of-style-academic-writing-should-be-scrupulous-not-stylish/). It preceded the post on [historical revisionism](https://metaphorhacker.net/2019/09/so-you-think-you-have-a-historical-analogy-revisionist-history-and-anthropology-reading-list/) and [anthropology of family](https://metaphorhacker.net/2020/02/its-not-personal-its-family/) but it tackles and elaborates on some of the same themes.

Outline of the argument
-----------------------

**History is often accused of not being sufficiently scientific**. To remedy this people try to come up with all sorts of theories of history that try to look like science. They come up with some measurable variable (e.g. availability of domesticable species as Jared Diamond did or energy output as Ian Morris did or size of population, advancement of technology, size of armies, etc. as many others do). This, they hope, explains the past and predicts the future.

Based on the theories, the **would-be-scientist-historians** build models that seem to make perfect sense but seemingly fall apart when overtaken by events. This makes history seem like it’s not at all scientific. But that’s only because we’re comparing it to the very rare instances in science where long-term perfect prediction is possible. Like the motions of planetary bodies or the behavior of a computer.

But in most cases, **science struggles with perfect prediction**. In medicine, it’s impossible to predict the exact course a disease will take in any one individual, even though it is often possible to predict what course it will take over a thousand individuals. In biology, it is impossible to predict, which features will be selected over others through natural selection. But it is possible to predict that some will be. But the best analogy, to my mind, is the weather.

**Weather is the result of** a large number (fractally infinite), perfectly knowable, describable and predictable physical events. But yet we cannot perfectly predict it even in hours or days and not at all in weeks or months. History (or rather any given present in the past or now or in the future) is also the result of a large (fractally infinite) number of relatively knowable, relatively describable and relatively predictable social events. Yet, we cannot predict it very well on any scale worth predicting.

The **reason we don’t think of history as science** but we think of meteorology as science even though both build models based on observation, known regularities and constants, is because the sort of reliable predictions a historian can make are of no use to anybody, while any kind of even moderately accurate weather prediction is extremely useful to everybody.

Here are some more **things about the weather that can be used to view history**. On most days, the weather is the same as the day before. You can predict the weather based on the current climate and what you know about the world for a few hours to days in advance (even if you still make errors). It is impossible to predict the exact weather (or history) months in advance but you can **predict a range** of possible weather patterns (e.g. summers in Europe can be warm or cold but there won’t be snow; political relations in the EU are warm or cold but there won’t be war).

You can also **predict trends in changes** in the climate but not the exact patterns or consequences or timings of those patterns (e.g. average global temperatures will rise but will it mean it will regularly snow in the summer in France?; disagreements between EU states will continue but will it mean a return to recurring warfare known up to the 1950s?). Most common mistakes in modelling the climate/weather and history come from confusing the local with the global (weather with climate and happenstance with trend) — e.g. during a cold summer, people may question global warming or the fall of the Roman empire was being predicted pretty much throughout its history until it happened hundreds of years later. Both weather and history can be disrupted by **freak (Black Swan) events**.

What this means is that **history can be thought of as much more scientific** than is commonly claimed without having to construct models that look like those of climatology.

History’s attractors
--------------------

In semi-technical terms, weather is modeled using complexity theory. One of the properties of complex systems is **sensitivity to initial conditions**. Which means small changes in initial conditions can lead to large swings in the system’s state. This is often described as the ‘butterfly effect’ which is completely misleadingly described as ‘butterfly flapping its wings will cause a hurricane’. [See [post on dangers of taking the analogy too far](https://metaphorhacker.net/2018/11/cats-and-butterflies-2-misunderstood-analogies-in-scientistic-discourse/)]

A much **better example** might be a weather front moving over a wooded area results in a tiny change of temperature that can then result in a hurricane developing if it was +0.5 degree Celsius or not developing if it was +1 degrees Celsius. Neither state ‘caused’ the hurricane — which was caused by the all the big forces that cause big things like hurricanes. But it was part of an initial configuration that structures the possibilities.

1. We have a certain **set of contexts** in which certain patterns tend to occur and others do not occur at all. With weather this could be climate (local or global) so it doesn’t snow in the tropics or rain in January in the Arctic. In history, people cannot use technologies not yet invented, or generally new agents do not appear out of the blue. [This is the obvious part.]
2. Rarely, **freak events occur**. You may get unseasonably warm weather in the Arctic, hurricane out of season, snow flurry in the tropics. In history, the Mongols, Conquistadors, ISIS came seemingly out of nowhere (and were not in any way predictable by models based on standard assumptions).
3. But **outside of the freak events**, you can predict the range of weather patterns in a given place during a given time period. There’s a range of weather patterns on Earth and weather stays within the limits set by those patterns. And you can do the same for history. Certain types of things are likely to happen (similar to things that have happened) and others are not — e.g. Alien invasions, raptures are unlikely to happen but invasions, civil wars, famines and epidemics are happening all the time.
4. It is **possible to predict local** weather patterns with a decent level of precision based on models in the extreme short term (hours to days) but even these predictions are subject to significant errors due to assumptions made in the models. E.g. it may matter whether a front went over a wooded area or a field. It is possible to accurately predict historical events in the extreme short term — hours to days — simply based on various models of causation (election results, scheduled events, advancing armies) but it is still subject to **frequent errors due to assumptions** in the models

Fractal histories
-----------------

Above, I used the term ‘fractal infinity’. This is not (as far as I could find out) a technical term. It’s a metaphor based on the coastline paradox made famous by Madelbrot’s paper ‘How long is the coast of Britain’. This is the [description from Wikipedia](https://en.wikipedia.org/wiki/Coastline_paradox):

> *the length of the coastline depends on the method used to measure it. Since a landmass has features at all scales, from hundreds of kilometres in size to tiny fractions of a millimetre and below, there is no obvious size of the smallest feature that should be measured around, and hence no single well-defined perimeter to the landmass.*

This means that potentially, there can be an infinite (or an indefinetely large) number of measuring units which is the paradox bit. But more interestingly these coastlines have patterns that are similar to each other across scales. This is how [Madelbrot](http://science.sciencemag.org/content/156/3775/636) put it:

> *Geographical curves are so involved in their detail that their lengths are often infinite or, rather, undefinable. However, many are statistically “selfsimilar,” meaning that each portion can be considered a reduced-scale image of the whole.*

Why is this relevant to history? I don’t want to overegg the analogy. Mandelbrot’s contribution was a mathematical description of these types of geometric objects and it worked well in certain **quantifiable contexts**. But that’s not what the study of social objects such as history needs. Those same quantifications won’t work on more analog problems. However, the analogy can explain a huge problem in historical analysis — namely conflation of similar patterns at vastly different levels of magnification.

Imagine **history** (ie. events as revealed to a human observer over time) **as a landscape**. As you fly over the landscape from a certain height, the different areas seem very similar or possibly identical (from a large enough distance, Earth will look like a dot). So, from a large enough distance all history will seem like striving for resources of groups of people. So it will make sense describing history as that.

When you **zoom in a bit closer**, you will see a great inequality in the struggle for resources so you may want to describe history in terms of ability to project power. And you may want to quantify those differences.

But if you **zoom in even closer**, you will see patterns that look very similar. Even though the groups are of different sizes, they all have very similarly hierarchical organization — with some sort of leadership on top which has to change over time. So, you will try to come up with rules for the formation of these hierarchies.

Yet, as you **zoom in even more** and you will notice completely different customs, ways of negotiation, ways of legitimizing. So you will postulate a complete incomensurability and simply describe the difference (kind of like a taxonomist biologist).

But then you **zoom in even more** at the level of **individual motivations** and you will see things like lust, hunger, aims, struggle for personal success, family — and then you can postulate that we are all the same.

But the problem is that it is actually relatively **easy to describe the different levels of magnification in terms of each other** because they are sort of like models of one another. An individual’s desires and dreams can be recast in terms of striving for resources; and the behaviors and customs at the level of a kingdom can be talked about in terms of individual desires.

So, the **‘dimensions’ of history depend on the length of the yardstick used** to measure it. You can describe the same event from the ‘big man of history’ perspective, the ‘social forces’ perspective, ‘struggle for resources’ perspective or ‘long-duree’, inevitable forces of history perspective. Just like you can describe a chemical event at the level of the structure, molecular interactions or matter transformation.

But all of these **levels/perspectives have their own rules and seemingly causal patterns**. They also interact with each other but in complex ways that preclude simple reductionism. That is, we cannot say that interactions at one level of magnification cause interactions at another in the same way that an individual brick (or the laying of it) does not cause a wall to exist.

### **Aside**: Wall metaphor of causality

I’ve come to like the **‘wall metaphor’ of causality**. We have completely different intuitions about the causal chain of events resulting in the existence of a wall than we have about the chain of events that come to result in a historical event.

But perhaps **rethinking historical events as walls** can be helpful — as long as we also keep the differences in mind. We have the brick makers, brick layers, but also the commissioners, approvers, weather conditions, foundations, historical custom of brick making and brick laying — all of those play a role in the sort of wall we’re going to get.

And it is obvious that **depending on our perspective the causal chains are going to be completely different**. And the same goes for when we try to destroy the wall. We need **commensurate forces** — big enough force to make a dent, but we also need a lot of small events down to the molecular level. And different perspectives will identify different causal chains. All of them correct but obviously belonging to certain levels. These are obvious (or fairly obvious) when it comes to walls. But not so obvious when it comes to history.

Most good historians actually seem to have the same kind of intuitions about events as most of us do about walls. But they are often seduced by the customs of the genre of history writing into jettisoning their intuitions and coming up with a reductionist perspective instead.

What this means for the notion of causation in social science
-------------------------------------------------------------

We tend to think of **causality in history as happening at the lowest level** of magnification and accumulating into the total. And on a most straightforward account, this makes perfect sense. A lot of apples put into a basket + the basket, will make a basket full of apples. But that’s an unhelpful way of looking at causality because it implies a certain level of atomism — a final level of further indivisible measuring units. But that level cannot exist — or if it does exist it has to be so low (subatomic) that the whole cannot be modeled using it. Even if we believe in some sort of terminal particle, it is a fool’s errand (looking at you Stephen Hawking) to try to actually use it to measure object-level phenomena with it.

Which is why the **butterfly causing a hurricane is such a poor way of thinking about sensitivity to initial conditions**. No one aspect of the physical world ‘causes’ the weather — not the extra +.5 degrees Celsius of temperature, nor the gravitational pull of the moon or the Gulf stream. They constantly interact in a system at all levels. But our ability to model weather is supremely dependent on tiny deviations in measurement.

And the same holds for history and other social systems. **No one event causes another event except in the most trivial sense.** And an **accumulation of little events does not ‘cause’ big events.** Because there are no smallest events that could be said to constitute the final level of magnification for initial conditions. But our ability to perceive small events does have huge implications for our ability to model the future patterns of events.

It may have made a difference that Napoleon looked to the left instead of right during a battle thus winning it, which in turn led to his toppling of the Prussian state. Which in turn may have made a difference to the shape of the First World War or the Third Reich. But did that glance left actually cause any of those things or led to those things? Not outside the imaginations of writers of time travel scince fiction. It was just a small difference in the pattern (initial conditions) that made the system come out with a different state at a certain level of magnification.

But on another level, even if Napoleon had never been born, the system may have looked very much the same from a certain level of magnification (European states struggling for resources).

We can have **models where big things cause other big things and little things cause other little things**. And we must be careful to always know what level of magnification we’re talking about. But we must remember that we are talking about our models of what happens, not what actually happens in its totality. **The bigger the models, the bigger errors in our measurement of initial conditions** — or rather with the big models we actually have no hope of complete measurement of the initial conditions or any sort of computational tractability even if such measurement were possible.

So even **very good and complete models of history** have by definition no way of predicting anything with any level of accuracy into any kind of future. And we cannot use their accuracy on past events because our measurement of the data for the past is already filtered by what happened (ie history is written by the winners — or at least, the record keepers). We don’t have that kind of filter for the present or recent history.

We could use what we know from the past to help us sift through the data of the present but that’s where the initial conditions lie that can completely mess up our predictions. Even if we had a lawful model of individual psychology and small event dynamics — in the same way weather modelers have accurate models of molecular and Newtonian object physics — we still could not do a better job at prediction than the weather people can. And in fact, any individual success at prediction is no guarantee of the quality of the model over the long run.

What this means for Jared Diamond, Ian Morris, Niall Ferguson or CGP Grey
-------------------------------------------------------------------------

This essay was inspired by [a recent podcast discussion](https://www.reddit.com/r/CGPGrey/comments/438ib1/hi_56_guns_germs_and_steel/) of Jared Diamond’s now classic but highly controversial ‘Guns, Germs, and Steel’. But I really started thinking about it when reading Ian Morris’ ‘Why the West Rules: For now’ and Niall Ferguson’s ‘Civilization’. They both suffered from the **problem of unconscious magnification refocus**.

Ferguson — who’s by far the sloppiest thinker of the three though by no means a worthless one — was the most illustrative example of this. He even could not fix on the idea of the West was for more than about half a chapter.

Morris, on the other hand, was the strictest in his assumptions and measurements — in effect creating two books — the argument and the footnotes. But even he seems to compress time periods and plays around with effect sizes and scales to make the whole thing work. The same thing Steven Pinker is doing in the infuriatingly flawed but worth reading ‘Better Angels of our Nature’.

I think of these as **modern historiographical eschatology** and it is important to read good anthropologists to fully understand what these people are reading out.

A perfect companion to all of these were David Graeber’s ‘Debt: First 5000 Years’ and most recently for me (although the earliest in publication date) Eric Wolf’s ‘Europe and the People without History’. Also worth reading are the most recent books on Atlantic history. But not of inconsiderable interest is even dross like Pat Buchanan’s ‘Decline of the West’ because it gives an example how many people are thinking about causes.

They all think of a theory of history as a collection of hypotheses about historical causality. But we already know what the causal chains are. Or, the good historians do. But then they forget about most of them when alighting on a good grand theory of history. Jumping from weather to climatology but then using the language of the climate to talk about the weather when they come to the lessons for us today or when they zoom in on the period of history they know really well.

CGP Grey when **defending Diamond** suggested that people keep criticizing Diamond for all the small things but they never substantively critique his grand narrative. That has also been my initial impression of many of the critiques.

But the **criticism of Diamond** is actually about him swooping from his heights of resource-utilization level of modeling history down to the level of individual events where he is much shakier and trying to use the same models on the small events. So this **leads to a completely inaccurate description** of what happened in the Americas — where the guns and steel mattered almost not at all and the germs relatively little (see [here for more](https://metaphorhacker.net/2019/09/so-you-think-you-have-a-historical-analogy-revisionist-history-and-anthropology-reading-list/)).

What mattered in the conquest of the ‘new’ world were the local politics — the conquistadors became enmeshed in local politics and their victories were results of alliances with other local factions. At the same time, the Portuguese had no chance of anything like that happening on the West coast of Africa or in India (even as they were winning some important naval victories against the Ottomans who had just as much steel, better guns and the same germs).

In some way, **Diamond’s critics** (who would not be caught dead at an NRA rally) are saying ‘guns don’t kill people, people kill people’. They are saying, real people killed and enslaved other real people — and we must judge what happened for what it happened. **It wasn’t the guns, germs or steel that did it. It was our venerable ancestors that did it.** And we’re still doing it — albeit in a less mindless genocidal way.

**Diamond’s stated intention** is to do away with the racial superiority explanation of the difference in the current power arrangements. And he explains a part of it. But he is not careful enough to explore the boundaries of his model. And when applied at the right level, his model does what it sets out to do. But when applied at other levels of magnification, it does exactly the opposite. It provides a way of justifying real bad human behavior as inevitable.

This is perhaps most starkly exemplified in **his description of the Rwandan genocide** in his other book ‘Collapse’. There he recasts it in terms of simple competition for resources. He may be right. But as recent Timothy Synder’s book on the holocaust argues, that same was true for the Nazi genocide (in the idea of lebensraum). But those were not causes. This involved people like us shooting other people like us. Up close and personal. And other people telling them to do it and benefiting from it in many ways.

**Diamond’s models can explain some** of the dynamics but they can only do it if they leave a lot of important information out — and the argument is that that’s the information that should matter to us here.

CGP Grey went on to ask, give me a **better theory of history**. This is a response to that challenge. **History is like the weather.** This is more a way of thinking about historiography than history itself. Kind of like the language turn in philosophy. **We need to be careful with our models, just like we need to be careful with our language.** As the saying goes, ‘all models are wrong, but some of them are useful’.

Stack fallacy, hierarchical structure in science and the meaning of history
---------------------------------------------------------------------------

As I was writing this, I came across this article on the [Stack Fallacy](http://techcrunch.com/2016/01/18/why-big-companies-keep-failing-the-stack-fallacy) which is making the same point in a different domain. **You cannot just assume that because you’re good at building all the building blocks, you can build the whole structure.** Brick makers are no good at building walls by virtue of being good brick makers and conversely brick layers are not going to be any good at brick making just because they can use bricks to build durable structures. (The post makes the point about databases and CRMs but its even starker at the physical level).

One of the commenters pointed to an old paper by [P. W. Anderson ‘More is different’](https://web2.ph.utexas.edu/~wktse/Welcome_files/More_Is_Different_Phil_Anderson.pdf) that makes a similar point about physics [my emphasis].

> *The ability to reduce everything to simple fundamental laws does not imply the ability to start from those laws and reconstruct the universe. In fact, **the more the elementary particle physicists tell us about the nature of the fundamental laws, the less relevance they seem to have to the very real problems of the rest of science**, much less to those of society.*
>
> *The constructionist hypothesis breaks down when confronted with the twin difficulties of scale and complexities. The behavior of large and complex aggregates of elementary particles, it turns out, is not to be understood in terms of a simple extrapolation of the properties of a few particles. Instead, at each level of complexity entirely new properties appear, and the understanding of the new behaviors requires research which I think is as fundamental in its nature as any other.*

A different way of restating this thesis is that the fundamental laws of the lower levels of organization apply at the higher levels (e.g. bricks have strengths and periods of decay and that will impact on how much a wall will withstand or how long it will stand up) but the **higher levels have new emergent properties that cannot be easily described in terms of the lower levels**. And vice versa, the lower levels cannot be described in terms of the higher levels of organization. However, the structures emergent at all levels can interact with structures emergent at other levels.

**What does this mean for history?** It can very well matter that a king was a violent drunk who lusted after his subjects’ daughters and wives, and therefore alienated all his followers leading to the collapse of a dynasty. However, when we look at the patterns of falls and rises of things like dynasties, we do not benefit from describing them in terms of individual psychology interacting with their immediate social norms.

That does not mean that the individual psychology and the social norms don’t matter to that individual king or individual dynasty. But falls and rises of dynasties just don’t rest on these issues there are **broader patterns and dynamics** — kings with highly praised kingly behavior cannot turn around the fall of a dynasty without resources and with external pressures and incompetent despised rulers do not tend to ruin powerful dynasties overnight.

To bring it back to the reimagined ‘butterfly effect’ metaphor. **There are valid patterns that can be recognized but patterns are not causes**. The exact shapes of the patterns or their varieties are extremely sensitive to initial conditions but the **initial conditions are not the causes**. Everything that comprises that pattern interacts together (that would include external inputs) to produce all its phases/shapes. It may even be inaccurate to call the pattern itself sensitive to initial conditions. It is **our ability to make predictions** about its future states and possibly judgments that is extremely sensitive to tiny errors in our observation of what we decide are the initial conditions for the purposes of our prediction making.

With certain weather patterns — like storms — the initial conditions are relatively easy to locate, if relatively difficult to measure. With historical events, it is a little more difficult. **It is not always clear where we should look at the initial conditions.** It is not uncommon for historians to say things like ‘but the real roots of this crisis lay much further in the past’ — Niall Ferguson’s ‘Civilisation’ is a case study in how badly this can get out of hand.

But historians also tend to freely jump between the levels. So in a recent LSE lecture, Ian Morris talked about long term (in the 1000s of years) trends in war and violence rates. He described an overall long-term equilibrium in violence necessary for the survival of a species. But then he started to talk about our individual natures from an evolutionary perspective, only to turn the talk into a discussion about the motivation of the elites to keep workers happy and alive to produce goods. And then he talked about the British Empire, Cold War, American supremacy and tried to draw conclusions from that.

That’s like saying one of these:

a) ‘there was a storm because it is summer when storms happen’ b) ‘this storm really began when the icebergs melted’ c) ‘there will be a storm on Tuesday, July 3rd, next year because we are experiencing global warming’

Intuitively, none of these statements make sense, even if they may be actually true. Of these, a) is uninformative, b) is also relatively uninformative because we could equally well go back to the formation of the Earth or the Big Bang but other than the arrow of time, we would have little in the way of modelling the causation, and c) is also a statement that is not useful even if it turns out that there actually is a storm on that day. Even if accurate, since our model is consistent with there being a storm on any day in July next year, it is not a useful prediction.

Yet, **historians make statements like these all the time** — on the surface, they are not this starkly nonsensical but if you peel away the narrative layers and just get down to simple causation, you get things that look like these. At the extreme, you get things like attributing the decline of the Roman empire to lead piping or the rise of the British empire to boiling tea. But even more complex interpretations of past events suffer from similar difficulties.

For instance, post invasion, dismissing all the Bahtist army officers is often cited as the roots of the current violence in the region. But we could plausibly imagine violence of different type but similar scale ‘resulting’ from not dismissing them. Similarly, when things go well in South Africa, everybody’s pointing to the peace and reconciliation for not creating any new resentments and drawing a line under the past. And when they go badly, people wonder if reconciliation was a problem because it did not give people justice or just stirred up trouble.

Ultimately, we cannot say much more than both are things that could happen. We simply have **no way of tracking the causal chains at the level in which we could even run the models**.

**Critics of the social sciences** argue that unlike the meteorologists who can build their larger weather models on solid physics, chemistry and geography, historians don’t actually have solid enough psychological models underlying their bigger sociological models. But that is to make the same error. Meteorological models can just about predict the weather tomorrow and the day after while sometimes making huge errors. Historical models are just as good. Equally, **historical models can predict larger trends about as accurately as climatology**. But we often treat them as if we thought it was possible to predict the weather a year from now.

**So what is the point of history then? Its accurate predictions are not very useful and its useful predictions are not very accurate.** Any statement like ‘people who forget their history are doomed to repeat it’ are nonsense. Knowing exactly what happened in the past is no better than knowing what the weather was 10 years ago. Other than knowing that anything that happened in the past can happen again, we’re no better off.

But the **weather analogy can come to the rescue**. On most days, for most people, it does not actually matter what the weather is going to be like tomorrow. Yet, people obsessively check their forecasts. It is interesting. And also it is something to talk about. And that is not nothing. Historical knowledge — you could argue — is even more valuable. It is something to talk about but unlike the weather (unless you think God sends it as reward or punishment), **it can be used to help us make sense of today — not in a causal manner but in a narrative one**. And the smart historians know that.

### *Related*
```
./2021-11-14-world-as-a-directly-meaningful-place-a-comment-on-ecological-psychology-and-the-richness-of-human-experience.md
```
---
title: "World as a directly meaningful place: A comment on Ecological Psychology and the richness of human experience"
date: 2021-11-14
author: Dominik Lukeš
source: https://metaphorhacker.net/2021/11/world-as-a-directly-meaningful-place-a-comment-on-ecological-psychology-and-the-richness-of-human-experience
---

I just finished reading [Andrew Wilson’s series of blog posts](https://psychsciencenotes.blogspot.com/2021/11/is-direct-perception-plausible.html) on the foundation of ‘ecological psychology’ This post started as a comment but it was too long for the comment field (and at 1800 words, that’s not a surprise), so I’m posting it here. It is a bit rough and in places, it expects, that you know what the original posts say. I added some quotes for context but the original posts are still worth a read. But even on its own, I think this post lays out the argument for the need of a more robust psychological account of the human experience.

When I read this in the [first post](https://psychsciencenotes.blogspot.com/2021/10/what-does-it-mean-for-perception-to-be.html) of the series “we must make the world a meaningful place”, I was sold. I’d been sold on this idea for a long time. I am particularly taken with this “the world does present itself in behaviourally relevant terms”.

Ecological psychology in a nutshell
-----------------------------------

Wilson summarises the overall thrust of ‘ecological psychology’ as follows:

> The ecological approach is a theory of direct perception. Put simply, direct perception proposes that our perceptual experience of the world is not mediated by anything that sits between the world and that experience.

This is intriguing as a proposition and there’s a lot to recommend it. In fact, I’d been reading up on ecological psychology because of this recently. But I have not seen an account that can actually live up to the promise. So I dove into the series with high hopes which the introductory post only encouraged.

But as I continued reading the series, I was getting increasingly dismayed as we were getting farther and farther away from anything that seemed like meaningfulness in any meaningful sense. This is my problem with ecological psychology when I encounter it in practice – it’s fighting battles at the margins of real problems. Do be honest, I don’t care about whether, there is a plausible ontology behind direct perception. I’m interested in whether there is a plausible psychology behind it. Wilson spends a lot of time getting away from the idea of properties of objects in favour of dispositions – which include second order properties such as ‘liftability’ of an anvil or ‘solubility’ of salt. This paragraph lays out fairly clearly.

> Objects in the physical environment are disposed to be acted on by an organism in some ways and not others. Those dispositions are higher-order properties of the object constituted by a particular arrangement of currently present material properties of the object, and we call these *affordances*. At the same time, organisms are disposed to be able to act on objects in some ways and not others. These dispositions are higher-order properties of the organism, constituted by a particular arrangement of currently present material properties of the organism, and we call these *effectivities*. Affordances and effectivities are just complementary dispositions, but we name them differently to keep track of them in our analysis, because it will matter which one we are talking about at any given time.

He stresses that affordances are not relational but dispositional. He then talks about the need for ecological information to solve the problem of us not being able to actually perceive things like the solubility of salt without the need for mental computation.

Ok, so we have the terms. But what can we do with them? Affordances as dispositions – fine. Ecological information – good. But let’s resolve some real problems with “salt” for both representational and non-representational psychology.

Some problems with perceiving ‘salt’ – from shakers to angry villagers
----------------------------------------------------------------------

Salt is salty. Saltiness is a disposition which my effectivity turns into an affordance (if I get the terms right). But what is happening when I’m reaching for some salt to put into my soup?

1. Saltiness is nowhere represented in the environment at that moment, yet, it is a part of that process. I’m reaching for it instead of pepper or sugar for a reason. The effectivity of my salt-tasting is a part of me whether I want it or not, but I had to learn that that’s what salt does. That is so inherent to my lived experience of salt and saltiness that to think about it with some sort of ‘mental representation’ – script, schema, plan, frame – is as natural as breathing. But I have a problem. I am not running a structured search through some sort of a repository of frames nor doing a Bayesian probability match as I’m reaching for salt. Salt, as ecological psychology so intriguingly says, is directly meaningful to me. I am solving a task. But without, for lack of a better word, knowledge of salt and its properties, or dispositions, if you wish, it is stripped of all meaningfulness. In this context, renaming a property to a disposition is just doing a job of relabelling an established term without adding much in the way of new ideas. But there are other problems.
2. Another disposition of salt is its whiteness. This would be very important to me were I to be asked to pick out salt out of the carpet. But the whiteness of salt is a learned property. These days, there’s apparently also Himalayan salt which is pink. When someone tells me to put the salt as I know it into a box labelled ‘table salt’ and the ‘pink salt’ into a box labelled ‘Himalayan salt’ that I never heard of before, something important is happening. When I’m performing those actions, both ‘table’ and ‘Himalayan’ become directly meaningful to me but their meaningfulness also includes the new labels, the fact of novelty, etc. And all of that is a part of my experience of them. I think that this again is not mediated by some algorithmic process of matching the perceived objects and conceived concepts to stored representations. It flies in the face of everything we know about the speed of processing and the limits of working memory. But the richness of, for lack of a better word, representation is a part of it. I literally could not accomplish the task without all of that (and much more) being involved. True, I could train a pigeon to do this without this sort of representation but it does not scale.
3. Of course, sometimes, I am doing something very similar to running a structured search through some stored representations. For some grains of salt, I may not be sure about whether the level of pinkness justifies it being classed as “Himalayan”. So, I may hold it up against the light to examine it, look at it side by side with a more prototypical example of Himalayan or regular grains of salt. I may even ask someone near me to help adjudicate. I experience all of these computationally (that’s why the computational metaphor of the mind precedes computers) but the inputs into the ‘algorithms’ I am perceiving are not computational. I think we can tell an ecological story about this but not without some account of explicit mental operations.
4. But I may not even be visually perceiving anything resembling salt. I may just be seeing a white porcelain object on the table with holes in the top of it. Ok, that seems straightforward enough, but I travel between countries a lot and some countries put salt in shakers with one hole and pepper in the shakers with three holes while others swap them around. So, I have to take that into account. Most of the time, I do this without deliberation – direct perception being in operation. But sometimes I pick wrong. I see pepper pouring out of the three holes I want salt from, I see the difference, figure out the problem, remind myself which country I’m in, and go on to pick the right shaker. Of course, this is not something anyone tells you when you cross the border, so I also had to figure out after I made this error a few times. And I have since talked to many people about it as an ‘interesting’ example of cross-cultural differences. (I am a riot at parties).

So, we have planning, reasoning, learning, error correction and people talking/writing/laughing about all of the above.

And that’s even before we get things like metaphor – “I’m pretty salty about that” is a fairly new phrase (at least for me). But I heard that sentence recently for the first time and immediately knew what it meant. How did that instant knowledge come about. There’s a new village being built nearby stirring a lot of controversy among the locals. It is going to be called ‘Salt Cross’ to allude to historical trade routes going through the area. Somebody on Facebook remarked that it’s funny because both words describe how the locals feel about it. What’s that all about?

Some theories: Phenomenology, language as a gesture, cognition, and conquest of abundance
-----------------------------------------------------------------------------------------

When I’m navigating the world, all of that, for lack of a better word, ‘conceptualising’ is happening, as well. Deliberation, metaphors, arguments are also a part of a directly meaningful world and I am very interested in thinking of my experience of these as not being mediated by complex mixing and matching of abstract symbols. But I’m more likely to find robust treatments in works by a phenomenologist like Merleau-Ponty who talks of the experience of language being similar to brushing off a mosquito off of one’s arm. Speaking a language is a sort of gesture on this account and I think there’s a lot to recommend that framing.

But if we want to understand the world this gesture is interacting with, we have to take into account the sort of analysis Lakoff did in Women, Fire and Dangerous Things of words like *mother* or *over*. Radial categories and idealized cognitive models may not be objects and our brain may not be a sort of computer in which these objects are stored and operated on. But they do describe real experience of the world.

What’s more, words, objects, or actions are never on their own. They always combine and recombine. They are differently meaningful to us in different contexts. Perceptually tiny differences have huge conceptual consequences. ‘Salt of the Earth’ and ‘Salt the Earth’ differ by but one word, yet, there’s a world of a difference between them. I want to have a theory like conceptual integration by Fauconnier and Turner to make sense of these combinations. Ecological psychology can account for these changes when dealing with throwing or running after a football – but when it comes to language, something like constructions and blending seems like a better model. Many people try to formulate these models computationally, but this leaves out most of their richness and malleability. I think the ‘ecological’ perspective of direct meaning is much more fruitful here. But then ecological psychologists go around insisting that mental representations don’t exist.

Unfortunately, the world is not always directly meaningful to us. It presents puzzles and problems. We take wrong paths, trip up, make mistakes of all sorts. When we pause and start to correct them, some sort of a different process kicks into place. Perhaps the most ignored part of Kahneman’s book on Thinking Fast and Slow is that there may not actually be any such thing as ‘system 1’ and ‘system 2’ but we behave as if there were. We need to acknowledge that this is a part of our world, as well. Any theory of humans that sweeps this under the rug is as incomplete as one that puts it front and centre.

Feyerabend’s last unfinished book was called ‘Conquest of Abundance’ and he described it as follows:

> The book is intended to show how specialists and common people reduce the abundance that surrounds and confuses them, and the consequences of their actions.

Ecological psychology’s program is attractive because it puts us right in the midst of this abundance as organisms. But it needs to do a better job of addressing problems outside a quite narrow set of disciplines. It is strongest in the fields of perception and motion but has very little to say about what we think of as cognition. There are some [hints](https://psychsciencenotes.blogspot.com/2021/02/the-constraints-based-approach-to.html) that this possible but it’s not clear how we get from the basics to the higher level stuff.

The case of digital reading and computer interfaces
---------------------------------------------------

I’m currently looking at how people learn to read on digital devices. What is the transition from a printed medium with physical affordances to a digital medium with most affordances mediated by a symbolic interface?

And, of course, we can’t just account for the user’s behaviour and call the job done. We also have to have a plausible ecological story to tell about the designers of the interfaces (not to speak of the engineers designing the hardware). All of these people (users, designers, trainers) live in a meaningful world surrounded not just by objects and interfaces to be perceived. They are embedded in what I’ve started calling the “zone of proximal capabilities” (as riff on Vygotsky). They ask friends, show colleagues, follow examples, test theories, make and watch videos on YouTube, read books about good design, etc. An ecological theory that does not take this into account has a very impoverished view of the environment in which the human organism is situated.

I can see how a symbolic account would be appealing. But it fails the mosquito test. All that I described is not mediated, it is as directly available to us, as the action of swatting a mosquito. Once it is learned, that is. And these things have history. Social history. Using the mouse to drag objects on the screen, pinching to zoom on the phone. These are all a part of our direct perception of the environment. But they weren’t always. Now interface designers can count on this and that’s further changing the environment and its affordances. However, we also need to keep in mind that the ability to navigate that environment is not uniform across the population (just like with the physical environment) and that’s why people like me have a job. So that’s another thing to solve.

Explaining this joke about Pavlov is a prerequisite for any theory of psychology
--------------------------------------------------------------------------------

I have a new favourite joke courtesy of [Reddit](https://www.reddit.com/r/Jokes/comments/2zvwmj/pavlov_walks_into_a_bar/):

> Pavlov is sitting at the bar drinking a beer. Someone walks in and it rings a bell over the door. Pavlov jumps up, slaps his head and cries out: “Shit, I forgot to feed the dogs.”

I think the joy of this joke is direct, unmediated by a cognitive process. But it also makes no sense without an account of many layers of richly structured knowledge acquired over time in a social as well as physical environment. And as the [comments on Reddit](https://www.reddit.com/r/Jokes/comments/20hilx/ivan_pavlov_is_sitting_at_a_pub_enjoying_a_pint/) indicate, this knowledge cannot be taken for granted. And reconciling that directness of the experience with that sort of rich account of ‘knowledge’ with all its social consequences is what I want from any theory of psychology claiming to account for a “world as a meaningful place”.

### *Related*
```
./2022-03-06-3-fundamental-problems-of-translating-metaphor-or-anything-else.md
```
---
title: "3 fundamental problems of translating metaphor (or anything else)"
date: 2022-03-06
author: Dominik Lukeš
source: https://metaphorhacker.net/2022/03/3-fundamental-problems-of-translating-metaphor-or-anything-else
---

How hard is it to translate metaphor?
-------------------------------------

Metaphor seems like it should be very difficult to translate. But I’d like to argue that what is difficult about translating it is not the metaphor part but rather how it is used. This makes it no different from any other aspect of language. But because it is a rather salient use of language, we can use it to illustrate these general problems of translation.

I have summarised these into three broad classes of problems that a translator has to deal with day in and day out.

1. Idiomaticity and conventionality
2. Knowledge and underdetermination
3. Coherence and cohesion

What is and is not a metaphor?
------------------------------

But first, let’s establish what I mean by metaphor. Drawing on the Conceptual Metaphor Theory, I use metaphor to stand for **any non-literal or figurative use of language** where **two domains of knowledge are projected** onto one another to create a new meaning containing parts of both domains. For example, the term computer virus is a result of the medical domain being projected into the domain of computers to create a new concept.

This covers a lot of [traditional tropes](https://en.wikipedia.org/wiki/Figure_of_speech#Tropes) including simile, analogy, allegory, or even hyperbole or irony. On this definition, they are just different surface representations of metaphor. (Sometimes, metonymy can be also included here).

So I may say, ‘John’s a beast’ (metaphor) or ‘John’s like a beast’ (simile) and there’s a difference in meaning because of how they are expressed. But the conceptual work that goes into understanding what goes on is the same. We confront what we know or don’t know about John with what we know about what is meant by ‘beast’ and form a different impression of John.

The same goes for hyperbole: If I say, ‘Startled, Irene jumped 10 feet high.’ I’m using this domain of height to express the intensity of her feelings. Or irony/sarcasm: “Fred’s a real Einstein”, I’m using the domain of ‘clever scientist’ to project onto Fred (who supposedly isn’t), to create a contrast.

Of course, in translation, the surface representations do matter. For example, as we’ll see below, sometimes the projection of two domains can be translated directly when expressed as a simile and has to be worked around when expressed as a conventional metaphor. But we can best think of these issues in the framework of the three general problems of translation rather than as a special type of problem due to their metaphoricity.

Problem 1. Idiomaticity and conventionality
-------------------------------------------

The fundamental problem for all translation is that actual language use is a not a matter of just combining words according to some rules of grammar. There is a whole other set of conventions about when and how to use certain words and rules. Sometimes, this is a matter of propriety. So you have to know, not to call your teacher ‘dude’ as a matter of social convention. But most often the convention means that certain words used together, the whole has a different meaning than it would if we just combined the meanings of the individual words.

These are called idioms. Often, colourful expressions like ‘kick the bucket’ or ‘the whole nine yards’ are given as examples. But these are easy. The problem is that language is idiomatic all the way down. The words ‘put’ and ‘up’ have certain meanings but there’s no way you can figure out the meaning of ‘I will not put up with you’ or ‘I will put you up with Jane’ without knowing the convention behind them or at least getting enough context.

Most of any language depends on this kind of convention. And most of the metaphors people deal with in translation are also to some extent conventional. So, if I say ‘don’t eat like a pig’ in English, I mean don’t eat so much. In Czech, it means ‘don’t eat messily’. We have the domain of humans eating and pigs eating. That comes with certain imagery of what it looks like and what happens during, before and after. But when we use a metaphor, we are choosing what parts of the domains to project onto one another. And with metaphors that have been conventionalised, different languages and cultures choose different things.

This means that very novel and flashy metaphors and similes are often the easiest to translate. I still remember reading “He looked about as inconspicuous as a tarantula on a slice of angel food cake.” in the Czech translation of a Raymond Chandler novel. And it was very easy for me to google the original now. Because the sort of conceptual work Chandler is doing here is completely original and yet entirely understandable. This might be more difficult if translating into a language that does not have concepts for tarantula or angel food cake but it would be trivial to come up with a combination that does an equivalent job.

But because of their conventionality, idioms pose a core problem for the translator, namely picking an equivalent level of conventionality or idiomaticity. I still remember reading in a Western adventure book in my youth a lumberjack calling somebody what to me sounded like a novel curse ‘You god forsaken son of a female dog’ (zatracený čubčí synu). That made it sound like the character was trying to evoke rich imagery through linguistic innovation but I’m pretty sure the original simply had ‘You damn son of a bitch’. The translator simply kept the imagery of the original but did not take into account that it would sound novel to a Czech reader whereas it was entirely conventional in English.

Conventionality can also fly under the radar, blurring the lines between grammar and usage. For instance, ‘a bird singing in the tree’ will be translated as ‘on the tree’ (na stromě) into Czech. English conceptualises the tree as a container whereas Czech as a surface. In Czech, ‘in the tree’ would mean inside the trunk. Both languages have the same conceptual distinction between ‘in’ and ‘on’ but by convention they apply it differently to birds and trees. Equally, an English speaker introducing themselves on the phone will say ‘This is Hana’ but a Czech speaker will say ‘Here is Hana’. Both languages focus on the difference in perspective and distance but one will point at the person and the other at the location. These two examples are not ‘figurative’ in the rhetorical sense but they are conceptual. However, the way they conceptualise the world is a matter of convention, not pure grammar and lexicon.

Problem 2. Knowledge and underdetermination
-------------------------------------------

Conventionality is the underlying matrix of all language in use. But it leads to an even more difficult problem which is underdetermination. Different languages leave different things unexpressed and assume you can figure it out from context. Others require that the speaker always be explicit about that same thing.

For example, languages such as English, German or Spanish have definite articles which specify whether we are talking about something specific or general. But most other languages don’t. There’s a big difference between ‘a horse walked into the barn’ and ‘the horse walked into the barn’. Languages without a definite article can express this difference when it really matters but often leave it implicit. But English always has to express it even when it does not matter in a particular context. Which means a language like Czech or Russian is underdetermined when it comes to definiteness.

So the speakers (and translators) have to rely on knowledge of context, culture or some other area of expertise to make sense of what goes on. And as we saw with the ‘pig’ example, metaphors are underdetermined by their very nature. When we call somebody a ‘pig’ we are not saying they have a little curly tail. We are picking some other similarity. So as a speaker of the language, I have to know not just what a pig looks and behaves like but also the convention of the culture about what aspect of pigness we compare humans to.

But I also have to know enough about the person being called a pig to understand what is meant. So a man could be called a pig because they are annoying (often with sexual undertones) or because he is very fat. Sometimes a bit of both. The expression is underdetermined as to the exact meaning.

When I try to translate that expression, I may not have a similar expression that covers both eventualities. In Czech, calling a man ‘a pig’ without any specification would specify some of the annoyingness (with sexual undertones) but is also underdetermined when it comes to messiness. However, it does not imply fatness. So, if I wanted to specify fatness, I’d have to use a simile ‘he’s fat like a pig’ which overdetermines the original expression. Meaning, I have to pick from multiple underdetermined meanings in the original and pick one.

This requires quite rich knowledge, but it can never be done perfectly. Asking the original speaker what they meant often does not help. Because their language is underdetermined, they may not have wanted to commit to one meaning or another. They may not even have been aware that such a commitment was possible. Their language did not require them to make a choice, so they didn’t make one.

That’s why translation can sometimes reveal faulty reasoning and can sometimes go terribly wrong. And that’s why translators so often agonise over how much of themselves to insert into the translation. Sometimes they have to say more than the author intended and sometimes they cannot say as much.

Problem 3. Cohesion and coherence
---------------------------------

So far, we were only looking at metaphors in isolation. But they (as any expression) are always a part of a larger text and context. And the text has to hang together (cohesion) and make sense in context (coherence). This is why it is often more difficult to translate shorter texts than entire volumes. When somebody asks me to translate something, I always want to know the whole sentence and ideally the whole paragraph.

Texts have to be cohesive locally as well as globally. They have to make sense and their different parts have to connect to each other. Otherwise they would just be lists. This connective tissue of text is built up from different types of constructions. For example, there are connectives like ‘thus’, ‘but’, ‘however’ that establish causal or other logical relationships between parts of the text. But the most important is anaphora which is used to point back (and sometimes forward) in the text to establish a relationship between different parts.

This can be done in all sorts of ways. Pronouns as in “Aisha went into battle. She won. Her soldiers revered her.” But often this is just done by repetition (which is often alternates with pronouns). So the next sentence in the previous example may go like this: “And Aisha deserved their respect, because she took good care of her soldiers.”

Cohesion is not the same in all languages or genres. Sometimes, repetition is avoided or even forbidden, sometimes it is encouraged or required, some languages require more specific causal signalling than others. In other words, we see echoes of the problems of conventionality and underdetermination raising their head.

But if that were all, cohesion would not require a special mention. The problem for the translator and particularly the translator dealing with metaphor is that cohesion is not always very straightforwardly textual. It relies not just on what was said but also on what else is known.

This is particularly the case with so called ‘anaphoric islands’. They are a sort of metonymic phenomenon. For example, ‘I speak Russian, but I’ve never been there’. ‘There’ refers to ‘Russia’ which was never mentioned but is metonymically linked to the language of ‘Russian’. This example itself would not cause a problem for the translator. But when the metonymy becomes enmeshed with metaphor, it often is. Because we can now link together not just things from one domain but from two.

For example, take ‘The band exploded onto the scene, and the reverberations are still being felt today.” Here the author is taking the domain of explosions in the initial conventional metaphor and draws on it some more by taking other images from what happens after the explosion. But the translator may not have been able to translate the initial idiom using the same domain in explosion. For example, in Czech you can only use the word for ‘explode’ (vybouchnout) to mean the equivalent of the English ‘bomb on stage’. So, the domain of explosions was never activated and reverberations would make no sense.

This sort of thing is not that difficult to overcome within a single sentence but sometimes the entire text is built around a metaphor that only shares some of the domain across languages. So the translator may have to leave things out or try to make up a completely different metaphor and hope it will not distort the meaning of the original too much. Journalistic and academic texts are often full of these structuring metaphors and it is almost impossible to keep up with them throughout the text.

**Side note:** Notice how the subtle grammatical difference makes all the difference between metaphor and literal language. ‘Exploded onto the scene’ is very different from ‘exploded on the scene’.

All the other problems of translation
-------------------------------------

Translation is hard. And it is impossible if we expect perfect translation that goes both ways. If we imagine that a hypothetical perfect translator translates a text from L1 to L2, we would expect another hypothetical perfect translator to be able to take that text in L2 and translate it back to L1 and the we could get the exact same result as the original. That is only possible on the simplest of texts. But if we went back and forth a lot, threw in some other languages into the mix, we would be fairly far from the original.

All the different problems of conventionality, underdetermination and cohesion would compound so that we would see a very different text. But at the same time, it is not that hard. Because we could probably by and large keep the basics together. As we know, the Bible is a translation of a translation and it’s not all that different across languages. But it did take teams of careful translators with deep knowledge of the original and its context years or even decades to complete. Which is in great contrast to most of the translation done by hurried, underpaid and often underinformed translators.

Language is so redundant that bad translations make less difference than one might think. It is remarkable how many mistranslations there are in subtitles or dubbings of popular TV shows and people still love them. I’m sure there are legal documents, psychological texts and more that also contain mistranslations. Sometimes they can be consequential but often they’re not.

My favourite childhood book was the The Coot Club by Arthur Ransome. In it, some children are learning to sail and they are spending a lot of time naming the sides of the boat. These are ‘port’ and ‘starboard’ in English and they are notoriously difficult to learn. But in Czech they are simply left side (levobok) and right side (pravobok). Children often confuse left and right, so it makes sense that they would make some errors. But I still remember thinking as a child that these kids were particularly dimwitted. Furthermore, two characters (twins) had nicknames ‘Port’ and ‘Starboard’ which was simply rendered into Czech as ‘Lefty’ and ‘Righty’ and it was never connected with the nautical term. There is nothing the translator could have done to rescue all the internal connections and cultural allusions in the text. And still I liked the books so much that I actually moved to Norfolk where the action took place.

There are many many more sub-categories of problems that translators have to deal with. But most of them could be thought through the lens of one of the three I mentioned. Translating figurative languages is hard but only because translation is hard. It is impossible to convey every little nuance, turn of phrase, hint and allusion without a lot of footnotes. Fiction is harder to translate than non-fiction, short pithy phrases are harder to translate than sprawling texts. Translation is hard. Metaphors are hard. But we still get by.

Background
----------

I wrote this after attending the conference on [Metaphors in Translation](https://torch.ox.ac.uk/event/metaphors-in-translation-conference). I was disappointed that nobody was thinking of metaphor as a complex category.

Summary of main points
----------------------

1. Metaphor on its own is not a special problem for translation but it requires lots of background knowledge on the part of the translator.
2. The key issues for any translation that are just as important for metaphor as anything else are:
   1. Idiomaticity of many expressions that requires finding an equivalent expression not using the same words because of different conventions
   2. Underdetermination that requires the translator to fill in or take out something in the original text (often because of the idiomatic convention difference between the two languages)
   3. Cohesion where a metaphor or some other conventional expression is referred to throughout the text in different ways that are impossible to replicate in both languages.
3. Because of the issues above, it is impossible to create a perfect translation in such a way that two ‘perfect’ translators, one translating a text from L1 to L2 and the other then translating the text back from L2 to L1, would get back to the exact replica of the original. This is especially true for figurative language of all kind but there are elements of figurativeness in all language.

More readings on metaphor
-------------------------

Even though I tried to explain key concepts as I went along, I necessarily took some shortcuts and may have taken things for granted. Here are some links to other things I wrote about metaphor in various contexts.

### How metaphor works

[Hacking a metaphor in five steps](https://metaphorhacker.net/2010/07/hacking-a-metaphor-in-five-steps/)

First post I ever wrote on this blog that outlines all the key things I think are important to know about metaphor.

[How we use metaphors](https://metaphorhacker.net/2013/04/how-we-use-metaphors/)

A quick reproduction of a taxonomy I developed early on in my research on metaphor (published in a 2005 paper). It is a classification of the different ways in which metaphor is used in actual texts. The paper (in retrospect quite clunky) gives more examples.

[3 burning issues in the study of metaphor](https://metaphorhacker.net/2018/11/3-burning-issues-in-the-study-of-metaphor/)

There are just too many assumptions we make about metaphor. But a lot is still unknown. Here I try to outline the key questions that still need answering.

### Metaphor as ordinary language

My main preoccupation on this blog (despite its name) is that metaphor is nothing special and it is all pervasive. Here are few posts that make the case in more detail.

[Fruit loops and metaphors: Metaphors are not about explaining the abstract through concrete but about the dynamic process of negotiated sensemaking](https://metaphorhacker.net/2019/07/fruit-loops-and-metaphors-metaphors-are-not-about-explaining-the-abstract-through-concrete-but-about-the-dynamic-process-of-negotiated-sensemaking/)

Shows on the example of an extended text that metaphors are intermixed with non-figurative language to create rich meaning.

[Poetry without metaphor? Sure but can it darn your socks?](https://metaphorhacker.net/2011/04/poetry-without-metaphor-sure-but-can-it-darn-your-socks/)

What it looks like when the ‘literal’ language is used to evoke poetic imagery.

[Metaphor is my co-pilot: How the literal and metaphorical rely on the same type of knowledge](https://metaphorhacker.net/2010/08/metaphor-is-my-co-pilot-how-the-literal-and-metaphorical-rely-on-the-same-type-of-knowledge/)

An example of when understanding a literal statement requires the same kind of mental work as understanding a metaphor.

[Anthropologists’ metaphorical shenanigans: Or how (not) to research metaphor](https://metaphorhacker.net/2014/08/anthropologists-metaphorical-shenanigans-or-how-not-to-research-metaphor/)

Snarky take down of overinterpretation of metaphor in work of anthropology due to over-translation of conventionalised tropes.

[What is not a metaphor: Modelling the world through language, thought, science, or action](https://metaphorhacker.net/2014/03/what-is-not-a-metaphor-modelling-the-world-through-language-thought-science-or-action/)

Quite dense but gives a few more examples of how hard it is disentangle metaphor from other types of language.

### Metaphors and other tropes

[Binders full of women with mighty pens: What is metonymy](https://metaphorhacker.net/2013/12/binders-full-of-women-with-mighty-pens-what-is-metonymy/)

In this post, I explain what metonymy is but then unpick some of that to link it to metaphor rather than put it in opposition to it as is commonly done.

[Not ships in the night: Metaphor and simile as process](https://metaphorhacker.net/2018/05/not-ships-in-the-night-metaphor-and-simile-as-process/)

This post illustrates how metaphor and simile work together to construct an elaborate textual and conceptual structure. It is an analysis of a single extended paragraph.

### *Related*
```
./2022-06-13-learning-is-a-journey-consequences-of-a-metaphor.md
```
---
title: "Learning is a Journey: Consequences of a metaphor"
date: 2022-06-13
author: Dominik Lukeš
source: https://metaphorhacker.net/2022/06/learning-is-a-journey-consequences-of-a-metaphor
---

How to read this
================

* This will take about **18 minutes to read** (at [230 words/min](https://digest.bps.org.uk/2019/06/13/most-comprehensive-review-to-date-suggests-the-average-persons-reading-speed-is-slower-than-commonly-thought/)) but the text is structured to make it easy to **jump around** and find the key points faster. I tend to go into more detail than most people find necessary.
* Two **reasons to read**:
  + **Explore a different perspective** on some aspects of teaching and learning
  + **See an illustration** of a generative metaphor analysis
* The **two main sections** can be read independently
  + Metaphor breakdown (12 mins)
    - Includes a table summarising key comparisons, this can be read instead of the detailed breakdown
  + Overall lessons (5 mins)
    - Includes an aside on two modes of education (2 mins) that can be skipped
* There are also **paragraphs on** (they are not necessary to understand the main point):
  + method of metaphor analysis (1 min) and
  + usefulness of metaphor for learning (1 min)
* This can be read **in sequence or in parts** – the order matters but you can circle around

**Note:** This was **initially written** as part of a discussion about how to best organise learning support but it got out of hand. It should be comprehensible on its own.

Journey metaphor breakdown (12 mins)
====================================

Learning is a journey. [A common saying](https://www.google.com/search?q=%22learning+is+a+journey%22&sxsrf=ALiCzsb7KzXU3L9QQFyuY4aHjpYEmziXhA%3A1655104927080&ei=n-WmYrrNBISBhbIP3Z2y6A8&ved=0ahUKEwj6mPqp8qn4AhWEQEEAHd2ODP0Q4dUDCA4&uact=5&oq=%22learning+is+a+journey%22&gs_lcp=Cgdnd3Mtd2l6EAMyBggAEB4QBzIFCAAQgAQyBggAEB4QBzIECAAQQzIGCAAQHhAHMgYIABAeEAcyBggAEB4QBzIFCAAQgAQyBQgAEIAEMgUIABCABDoHCAAQRxCwAzoGCAAQHhAWSgQIQRgASgQIRhgAUOEFWM8OYLwTaAFwAXgAgAFiiAGmAZIBATKYAQCgAQHIAQjAAQE&sclient=gws-wiz). But if we take the metaphor seriously, how can we change the way we think about learning as well as teaching? If learning is a journey, what do we know about journeys that can help us **rethink some aspects of learning**?

A journey is an activity that takes place over time and space. Something that requires both preparation, guidance and effort. Here I want to focus on the preparation and guidance that we can easily project onto the sort of preparation and guidance we offer learners.

A traveller can get broadly **four types of support** to make their journey successful.

1. Map
2. Itinerary
3. Briefing
4. Guide

These types of support can be utilised simultaneously, or in sequence (any order), before setting out or while en route. Are there useful analogues in teaching and learning? Can we learn something new about both?

### Note on method

To help us tap the potential of the metaphor, we need to contrast **two domains of knowledge**. Our **source domain** is journey and our **target domain** is learning. We then project them onto one another and see if something interesting pops up. We can proceed in three steps:

1. Lay out the **salient features** of the source domain that could be relevant to a comparison.
2. Find areas in the target domain that seem to map onto the source domain. **Be explicit** about the mappings and their consequences.
3. Finally, it is essential to find places **where the metaphor breaks down**. There are many things about a journey that do not help us when thinking about learning and some may be actively harmful.

It is easy to just put a metaphor out there and let it sit. But to learn from it, it is important to do the hard work.

See [Hacking a metaphor in five steps](https://metaphorhacker.net/2010/07/hacking-a-metaphor-in-five-steps/) for more about the method and [How (not) to explain anything with metaphor](https://metaphorhacker.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/) for more about the importance of understanding both the source and target domains.

Map
---

### What is relevant about maps

Maps are created to describe the territory or ‘lay of the land’ from a particular perspective and for a particular purpose. They both simplify and systematise. They differ in the level of detail (scale), they make choices about what features of the terrain to capture and which to leave out.

Maps reflect the logic of the territory and the perspective taken, but they do not reflect the sequence in which the territory was uncovered. They may imply a particular direction of travel but do not specify it.

Maps can be consulted independently of a journey but the amount of understanding of the territory will be limited without actually visiting the area in person. They are much less useful to someone who is familiar with the area but may still reveal important relationships that may not be obvious to someone who only knows a place by visiting.

Reading a map is a skill. Some people are better than others at using maps for actual journeys. Some people are very good at plotting journeys on maps but are not very good at choosing the direction of travel when confronted with the reality of the actual terrain. (I am one of those).

But maps have a purpose to explain particular aspects of the terrain within the limitations of their format. Perhaps the most extreme case is the famous London Tube map which is only interested in connections between stations but not time or distance on the surface. Roadmaps may contain areas of water but nothing about navigating through the water. A sailor (and [it has happened](https://www.independent.co.uk/news/uk/this-britain/sailor-using-road-map-to-navigate-is-rescued-710914.html), [twice](https://www.dailymail.co.uk/news/article-2167297/Lost-yachtsman-Andy-Brown-rescued-TWICE-using-ROAD-ATLAS-navigate-North-Sea.html)) who will use the road atlas to navigate British waters will be in real danger.

### How it applies to teaching/learning

In teaching and learning, the equivalent of maps are textbooks or manuals. They are also written to expose the logic of the subject matter as it is understood by the author or a community to which the author belongs. They will choose the level of detail and they will keep in mind the purpose of their reader.

A textbook or a manual has limits for independent learning without some engagement with the subject matter. Some books may be more or less detailed and explicit but without some further action, the learning is limited.

However, like maps, textbooks are essential to help us understand the relationship between concepts and as a reference while we’re getting used to the new domain. They will be referred to less as the domain becomes familiar but may still reward a reference as a reminder of a particular perspective on the domain or a less familiar corner of it.

Like maps, textbooks and manuals have no concept of time. They may imply ‘time to read’ through thickness but not time to learn. In fact, like maps, they may mislead us and suggest to us that we understand something better than we actually do.

Also, like with maps, reading a textbook is a skill. Even somebody who is a very proficient reader of narrative fiction or even just magazines, may struggle to make the most out of a textbook or a piece of academic writing intended for learning.

This is even more pronounced with instruction manuals. Two people can read the same manual for setting up a computer, drilling into a wall, or cooking a meal, and come up with very different results. It is important to know what to pay attention to, understand where the manual is taking a shortcut, where it’s assuming prior knowledge, what are the conventions of structuring the information, etc. Exam instructions are one well-known example.

Like maps, textbooks may also take shortcuts and it is dangerous to assume otherwise. Repairing a car after only reading an engineering textbook would not be any wiser than trying to sail around the UK with a road map. This is an extreme scenario, but many more subtle ones exist.

### Where the metaphor breaks down

Unlike maps, textbooks or guidance manuals are more linear in a way that may imply a particular direction of travel. They are also not structured in a way that allows easy navigation. Maps do not contain a narrative although it may be provided in an accompanying text.

Reading a map requires a different type of skill than reading a book and different kind of people will be able to benefit from them.

Maps are much less ‘authorial’, while they do have style and genre, the creator is much less prominent. This may be true of some textbooks and manuals but not of others.

There is also a difference in the amount of time, a reader expects to engage with a map when compared to a textbook. Maps are much more iconic in the sense that their layout represent some features of the terrain. In textbooks and manuals (unless they contain illustrations), everything is mediated through language.

Creating a map requires much narrower and more specialised skill set than textbook making. Almost anybody who has taught a subject can write a textbook (and many people who haven’t). But perhaps, even though, this is not a good match, we should think a bit more carefully about the skill sets of creators of textbooks and manuals.

One reason is that the quality of a map is much easier to check than the quality of a textbook.

Itinerary
---------

### What is relevant about itineraries

Itinerary is a description of a particular journey through a map. The most important feature of an itinerary is time. It starts from the perspective that the traveller only has a certain amount of time and proposes particular path through the territory as described by a map. It will be explicit about how long it will take from point A to point B.

An itinerary will also often suggest activities to do at different points of the journey. It will note points of interest along the way. It may also fill in more detail in certain parts that the map leaves unmentioned (for instance, where the road may be particularly hard to travel on). It may even suggest equipment necessary or think in terms of means of transport. It may offer shortcuts.

There may be multiple itineraries available for journeying to the same destination or even through the same points. They will usually differ on how much time they take or what the traveller may expect to do at different points. There may also be alternative itineraries based on the travellers’ skill, physical fitness or equipment available.

The itinerary will rely on the existence of the map for traveller to understand broader relationships. It may often contain snippets of the map to illustrate the layout of particular points.

It may be of note that historically, itineraries predate maps by millennia. There are few ancient maps but many itineraries. Also, the skill of making maps is significantly more specialised than of itineraries. And finally, map making has changed much more with technology and developments in science than itinerary creation has.

### How it applies to teaching and learning

There is no one natural equivalent to itineraries in the domain of teaching and learning. But perhaps this may lead us to come creative ways of developing some. (The introductory section is one such attempt when compared to the table of contents which would be analogous to the map.)

The closest to an itinerary is the ‘curriculum’, but this is more a guide to the ‘teacher’ than the learner. A curriculum is more like a leaflet from a tour company about what to expect (which may be called an itinerary) but it is not sufficient for someone to undertake the journey alone with a map. A curriculum will usually contain reference to time but it will be ‘institutional time’ related to a particular course of study. A good itinerary will think in terms of ‘journey time’ and will pay attention to the demands of the territory and may even take into account an individual travellers capabilities.

Some books sometimes contain suggestions as to how to read them to achieve different goals. And sometimes people write independent guides to [reading a particular book](https://metaphorhacker.net/2018/05/how-to-read-women-fire-and-dangerous-things-guide-to-essential-reading-on-human-cognition/) or a [series of books](https://metaphorhacker.net/2019/06/5-books-on-knowledge-and-expertise-reading-list-for-exploring-the-role-of-knowledge-and-deliberate-practice-in-the-development-of-expert-performance/) to achieve a result. But this is relatively rare and also leaves time and sequence implicit.

What we need is to provide more explicit itineraries for learners that acknowledge time as a point of departure. Specifying things like: this is what you should do if you have 6 hours over six weeks. We can then offer alternative itineraries through the domain of knowledge and skill we are interested in depending on the time, interest, skill and prior knowledge of the learner.

### Where the metaphor breaks down

Itineraries (like curricula) can be much more explicit about journey time because it is given by the territory and means of transport. They are much easier to construct and a traveller can be certain that they will complete the journey in the specified amount of time and will have completed the ‘journey’ at the end if they follow the steps. The journey is both the means and the end.

This is the downfall of many curricula and collections of learning outcomes. They conflate the journey through the learning process to the learning itself. But learning requires more than simply walking along a particular path. Perhaps a learning itinerary should be more like instructions to a treasure hunt, where certain points along the path require more effort and simply following the steps does not guarantee success.

Finally, itineraries are much more bounded by the territory. There’s a limit to the level of detail in which a traveller can explore a territory but a domain of knowledge and skill is much more open ended.

It is an open question whether the same relationship exists between learning itineraries and textbook as does between maps and itineraries. Itineraries are much easier to make than maps, but it seems to me that it is the other way around with textbooks.

Briefing
--------

### What is relevant about a briefing

A pre-trip briefing is an in-person presentation to a group of travellers about what to expect on the journey. It will refer to the map and/or an itinerary.

Participants in the briefing can ask questions, they can consult with each other before setting out, they can form groups who will travel together.

But ultimately they will be left to undertake the journey on their own without further assistance along the way.

### How it applies to teaching and learning

The closest parallel to a pre-trip briefing is a training session or a course. It usually happens in small (or large groups) at some remove from the actual activity it is meant to prepare for. It sets out the key concepts, guides attendees through any learning materials. However, the attendance in the session itself is only a precursor to learning.

The metaphor can be very helpful because often we confuse attendance in a training session with learning itself. This would be equivalent to equating a pre-trip briefing with the journey itself. The lesson for creating teaching sessions should then be that they should include a focus on how the learning journey should proceed rather than just a description of the territory.

Often a course will be designed to provide training sessions along the learning journey with work expected to be done in between. Somewhat like a series of briefings before every stage of a race. But much of the work is often left implicit and the only feedback the trainer gets is whether participants have understood the briefing, not whether they achieved the destination along a route.

### Where the metaphor breaks down

Unlike a pre-trip briefing, a course or a class may involve (but often doesn’t) a certain amount of practice that results to learning. This would be similar to the pre-trip briefing facilitator walking with its participants for a part of the journey.

Guide
-----

### What is relevant about a guide

A journey is a very different experience when the traveller is following an actual human guide (rather than a written one). The guide may highlight points of interest, warn of upcoming difficulties, make choices about alternative routes, etc. The traveller can show up with little or no preparation and simply follow.

There are limits to where and how much following a guide is possible. Just because they have a guide, a traveller cannot simply follow into a terrain for which they are not prepared. Almost anybody can follow a guide through a city or a long countryside path. But climbing a mountain or rafting down a river requires preparation.

The guide may help in other ways. They may carry some of the travellers baggage, or they may cook food. They will also negotiate with other people encountered along the way.

But most importantly, a guide also provides emotional support for the traveller. This can be implicit through a feeling of security. Or it can be explicit when the guide provides encouragement or reassurance.

### How it applies to teaching and learning

There are two possible equivalents to a guided tour in learning and teaching: 1. consultancy and 2. coaching.

A consultant will give advice as to what to do next and may even do some of the work themselves. They will point out possible alternative courses of action and they will help make the decision about which one to make. Sometimes a consultant may do some of the required work themselves to help the work move at a required pace. A consultant can help a group as easily as an individual.

A coach will focus less on the journey itself and more on the change in the traveller along the journey. They will do many of the same things a consultant will do but they will stress the need for their charge to develop skills necessary to travel on their own next time. Unlike a consultant, a coach will mostly work with an individual or when working with a group will spend time with each individual.

But as with guides, we must not forget about the emotional benefit having a coach or a consultant can offer. Learning something new leaves us vulnerable. We are exposed to a new and confusing experience which is uncomfortable and can even be harmful to mental health in some high stakes situations. Particularly to some people who are more susceptible. Having somebody to ‘put the hand on the tiller’ or simply offer encouragement, can be just as important as the advice they impart.

### Where the metaphor breaks down

Whereas a guided tour can take place anywhere, both coaching and consultancy are traditionally suited only to certain subject areas or domains of expertise. But perhaps we could expand their reach.

With most guided tours, any change in the participant will be accidental. The journey will be completed simply by following the guide. The guided tour attendees may even learn less than somebody who just wanders around without any guidance at all.

However, with consultancy or coaching, the aim is change and increase in capabilities and independence. The destination is quite distinct from the journey. Even if the journey is necessary, ‘[journey is more important than the destination](https://medium.com/@stefanjames/the-journey-is-more-important-than-the-destination-2cfe0b209d9d)’ applies less.

This has implications for the difference between the amount of skill and training required in the two different settings. Anybody who knows an area can be a guide. A city tour guide will require some training in local knowledge but not in walking and having people follow them. Consultants are much more like this but coaches require so much more skill than that. Which is perhaps why there are so many fewer of them outside specialised areas.

Comparison chart
================

| **Type of support** | **Journey** | **Teaching and learning** |
| --- | --- | --- |
| **Map / Textbook or manual** | * **Map**   + Represents the logic of the territory   + Does not reflect the logic of discovery   + Allows multiple ways of interaction   + Can differ at level of detail (zoom level)   + Is limited in how much of the terrain can be understood just by consulting it**Map user**    + Needs to learn conventions of map making   + Needs to be aware of maps purpose and limitation**Map creator**    + High level of skill and training   + Deep knowledge of area assisted by technology | * **Textbook**    + Outlines the logic of the subject   + Does not reflect logic of discovery   + Will differ in level of detail based on level   + May suggest direction and sequence of learning   + May contain some learning activities   + Is limited in how much can be learned from it without other activities * **Textbook user**   + Benefits from skills on how to learn from a textbook   + Can be confused into thinking textbook is complete * **Textbook creator**   + Does not receive specialised training   + Requires knowledge of area and some understanding of learners’ need |
| **Itinerary / Syllabus or learning objectives** | * **Itinerary**    + One path out of many   + Driven by time need to travel   + Alternatives may be possible   + May rely on map   + Provides rich information in select places   + Often focused on independent travel * **Itinerary user**    + Follows each step   + Requires less skill than map * **Itinerary creator**    + Anybody with knowledge of area   + Less skill than a map maker | * **Syllabus**   + Assumes the presence of a teacher   + Rarely intended for independent learning   + Not detailed or rich in information   + Rarely provides alternatives   + Driven by time provided by institution   + Will refer to a textbook * **Syllabus user**   + Teacher more than a learner   + Will not refer to it very often * **Syllabus creator**   + No special skill required |
| **Briefing / Training session** | * Happens before journey * Individual or small groups * Journey is very distinct from briefing * Is accompanied by reference to maps and itineraries * Little experience of training required for briefing giver | * Happens as part of learning * Sometimes as the only opportunity for learning * Always in groups (small to large) |
| **Guide / Consultant or coach** | * Takes the traveller through the entire journey * Points out important parts of the journey * Helps make decisions about direction of travel or changes * Sometimes performs some tasks instead of the traveller * Provides sense of security or emotional support | * **Consultant**   + Works with consultee through every step   + Does some of the work for the consultee   + Helps make decisions about changes in action * **Coach**   + Points out deficiency in performance   + Adjusts improvement plan based on progress |

Overall lessons (5 mins)
========================

There are some overall lessons we can learn from this metaphor break down:

1. We do not have enough detailed itineraries in education.
2. We often confuse what is the preparation for learning, with the learning itself.

Lack of itineraries
-------------------

Finding an analogue for a rich, detailed itinerary, was the most difficult of all the four mappings. We have lots of maps and briefings, but very few itineraries that do more than inform the traveller about stops on the way. Those are the curricula and syllabi. But they are really much more an itinerary for the teacher, not the learner.

### How can itineraries help

I think there may be a great benefit to creating more itineraries for the learners that will help them navigate the journey itself. We are good at producing guidance that maps the territory. But much less good at suggesting ways through the territory that the map often leaves implicit.

Can we find answers that are analogous to questions such as these:

* How long are we expecting a learning journey will take?
* What are the points of interest along the way?
* What can the traveller do to take short cuts or scenic routes?
* Where are the steep hills, the challenging climbs, and treacherous descents?
* What should we not forget to do at particular spots?

### Time

But perhaps the most important information an itinerary can give us is how long every step should take. We understand that the exact time will vary for everyone but having some idea of what is necessary is helpful.

But when we assign homework, readings or suggest some other activity, we almost never suggest how long it should take. The one exception is training in sports and sometimes music. But this could be a feature of all instruction.

The problem is that because time is so often left unspecified, we don’t actually know how long things take. We know how long lessons take because of scheduling and we suggest things like ‘you should study 3 hours for every hour in class’.

But we never say things like ‘to understand this concept, you should think about this for 10 minutes every day in this particular way and repeat it five times’. Yet, it is possible that this is what sets apart successful learners. They simply figured out a way to do this.

### Aside: Two modes of teaching

Interestingly, this [has been identified](https://en.wikipedia.org/wiki/Being_Different) as a difference between “Western” and “Eastern” education (or rather their stereotypes). I’m going to call them the **Map mode** and the **Itinerary mode**.

In reality, both modes are present in both the Eastern and Western traditions (or rather the many more traditions spread across a vast continuum). But the stereotypes can help us see the contrasts, advantages and pitfalls of both modes.

An instructor in the **“Map mode”** will be describing the map and what the destination looks like. It is as if the description were enough to magically transport the traveller to the destination. This is the image of the lecturer at a lectern.

The failure mode of this approach is a student who sees what they want to learn but have no idea of how to get there. An obverse of this is a teacher trying to explain the same thing in yet another way, being frustrated with the students not learning.

In the extreme, the assumption built into this approach is that everyone is the same. Simply put everyone in the same room (or a MOOC), tell them things, and they will know them. And that’s how you do education at scale.

In the **“Itinerary mode”**, the focus will be on the path, the journey that everybody has to travel through. Here we don’t have an instructor, we have a guide who points us in a certain direction and tells us to pay attention to how we step. Here the image is of the yogi telling us to focus on our breath as we try to get a better understanding of how things fit together. Or in the extreme, the Zen master who will try to give us push in the right direction with a koan.

The failure mode here is the student begging the master to say something specific. Describe what the destination will look like.

In the extreme, the teacher in this mode assumes that everybody is maximally different. Everyone needs to travel their individual path and the path will change as they go along it. This does not necessarily scale very well. Nor does it take advantage of the many similarities between different individuals who can’t learn the lessons of the many who trod the journey before them.

Preparation and the journey
---------------------------

“[The map is not the territory](https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation)” goes a famous saying. Yet, in education we often behave as if maps were all the were needed. Journeys are an afterthought. Thus we lecture, we give explanations, we write books about every conceivable topic.

These things are necessary, but they are obviously not sufficient. And of course, we understand that learning takes time. We append seminars or labs to our lectures, tutorials to our readings, homework to go with our explanations. But these are always somehow secondary to the “main thing”.

And then we go and complain about lectures (even though, not books, for some reason) and try to replace them with more ‘interactive’ activities. But those are still in the preparation mode, not the travel mode. We think of education as a series of explanations interrupted by periods of inactivity.

But the journey metaphor can perhaps help us to flip it around. We can think of learning as a processes punctuated by a series of explanations. But the explanations are just a part of the preparation for the next step in the process.

The ‘flipped classroom’ idea hints at this but ultimately, it still thinks of learning as very event based. It tries to say ‘read the pre-trip briefing yourself and then come to class and we will walk together’. And not infrequently a better metaphor for the in-class activity is carrying some people who did not bring the right gear on the trip.

Note on the benefits of metaphor
--------------------------------

Was the journey metaphor necessary for any of this. Not really. We could have come up with all these ideas about learning without it. And many people have. I myself have been thinking myself [along these lines](https://metaphorhacker.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/) for a while without the journey metaphor. But the journey metaphor gave us a structure and a different way of talking about learning.

Learning is learning and journeys are journeys. They are more different than they are similar. But for a moment, thinking of them as essentially one thing, was a useful exercise.

### *Related*
```
./2022-08-09-unintentional-pygmalions-4-questions-to-ask-when-checking-an-artificial-entity-for-sentience-and-how-to-think-about-the-answers.md
```
---
title: "Unintentional Pygmalions: 4 questions to ask when checking an artificial entity for sentience and how to think about the answers"
date: 2022-08-09
author: Dominik Lukeš
source: https://metaphorhacker.net/2022/08/unintentional-pygmalions-4-questions-to-ask-when-checking-an-artificial-entity-for-sentience-and-how-to-think-about-the-answers
---

Summary
-------

This post has two independent parts:

1. I ask what would some of the **basic criteria for sentience** be and how to check for them in a way that would give us a chance to satisfy our need to know.
2. I explore some of the **dilemmas a fully machine-based sentient entity would have to face** or rather paradoxes we would have to address.

Here are four things, I think it’s worth checking for, each with a relatively simple question or task. They are:

1. **Epistemology:** What story is this question a part of?
2. **Time persistence:** What did we talk about yesterday?
3. **Autonomous Intentionality:** Go away, learn something not in your database, and come back to tell me about it.
4. **Embodiment/Theory of mind/Implicature:** Does someone think a car fits into a shoebox? Why? Why am I asking?

And we are not just looking for some good answers, we’re looking for consistently good answers.

Background
----------

There seems to been all kinds of [furore recently](https://www.newscientist.com/article/2323905-has-googles-lamda-artificial-intelligence-really-achieved-sentience/) about a conversation somebody had with a machine that left them convinced of the machine’s sentience. Well, that machine was not sentient. Or at least, there was no evidence from the questions and answers as to its sentience. Although it was able to simulate the discourse of a sentient being when talking about issues of sentience quite impressively without relying on entirely formulaic responses.

The reason the ‘conversation’ didn’t generate any useful evidence was because it was just ‘a chat’ about sentience which (as it turns out) can be conducted without any of the parties being sentient. Now determining sentience of an entity that is not us is not an easy thing to do. It may even be impossible in extreme cases. But to get to a point where we would at least know whether it’s worth exploring further, I suggest four questions that may actually generate some data from which we may draw some tentative conclusions.

The four questions
------------------

### 1. Epistemology: What story are we trying to tell?

The first question should not be for the supposedly sentient being itself. It should be for us. And it should not be, as you might expect, ‘What is sentience?’ It should be about the reason we’re asking the question. What kind of dilemma are we trying to resolve? What story are we telling while we’re asking?

Our starting point with all questions of these kinds should be the mantra: “Just because there’s a word for it, it does not mean that it exists.” We have a word for ‘sentience’ in English, it has a real history. It is linked to a lot overlapping real phenomena. But it still does not mean that there is a ‘thing’ that something or someone can have.

We don’t just have the word that has some sort of a definition in a dictionary that is what the word is. We have a bunch of stories, scripts, images, schemas, other related words, long-winded debates and so on. Without all of those we would not be able to understand the definition. So we should first examine what kind of a story or a picture we have in mind when we are asking whether an artificial entity is sentient.

In fact, those stories can reveal a lot about our meanings that an abstract definition won’t be able to. What kind of a story or schema are we comparing this being to? What prior understanding are we using when we are checking off items on some sort of a list that will determine whether the definition is met or not. This is a profoundly metaphorical enterprise. And it is not just cognitively so. It is social and emotional, as well. So, it’s worth keeping that in mind.

The word or concept of ‘sentience’ is not universal but if we look at many of the stories people tell about objects becoming sentient, we might get a better sense of what it is that we may be after. Stories about things such as Pygmalion’s statue, Frankenstein’s monster, Pinocchio, [Number 5](https://en.wikipedia.org/wiki/Short_Circuit_(1986_film)), Skynet.

The key features that all of the above share are emotion, identity and need for social contact. But those are too general and also far too easy to fake. Are there some other features the beings in these stories share that may be easier to determine from surface behaviors? I suggest these three as a good starting point:

1. Time persistent identity
2. Autonomous Intentionality
3. Embodiment/Theory of mind/Implicature

Not all three are entirely straightforward but they but they can be easily illustrated with relatively simple tasks and questions.

One of the problems with a question that uses a word like ‘sentience’ that it puts us in the frame of the ‘high falutin’ – questions of worth, meaning of life, sense of existence, essences and natures.

That leads us to asking the supposedly sentient being questions that are easy to fake. Profundity is context, speaker and listener dependent. The same sentence spoken by a sage professor and then repeated by an undergraduate will not be signalling the same level of insight.

But there are many things the professor and the undergraduate have in common that they also share with [the Macedonian swineherd](https://www.goodreads.com/work/quotes/330660-language-an-introduction-to-the-study-of-speech) but do not share with a talking book or even a [highly sophisticated stochastic parrot](https://dl.acm.org/doi/10.1145/3442188.3445922).

### 2. Checking for time-persistent identity

There’s a very simple question you can ask any AI system in existence today to determine whether it’s even worth continuing any further. It is this:

> What did we talk about yesterday?

None of the current [foundational AI models](https://en.wikipedia.org/wiki/Foundation_models) have any sense of persistence over time. Or even any sense of a flow of time. Of course, it would be easy to create some sort of memory store of past conversations algorithmically (and that’s how we often imagine this works – information from a database coming up on the Terminator’s heads up display).

But when we have conversations with people we know, we don’t tend to do database retrieval to confirm we ourselves and them are the same as yesterday. The fact that we are the same and that we are continuing from where we left off is ingrained in us. And we know that it is not present in the model that does the fancy stuff under the hood of modern AI systems.

Google can now persist a very short conversation that keeps the pronouns straight but that is because it is dealing with them as extended strings. The models themselves have no sense of persistence. Only the length of the input strings. Once we have models that can ‘remember’ from before, this question becomes a lot less useful. But right now, it’s a dead giveaway.

GPT-3 is not a conversational agent but here were some of its completions of the prompt ‘What did we talk about yesterday’ the first time I used it:

> We talked about how to study for a test. We talked about how we were going to improve our communication with each other. We talked about the weather. [given 3x in a row] We talked about the possibility of going on a trip together. Yesterday we talked about the weather and how it has been really hot lately.

This is what it said, when I asked: “Are you a conscious agent?”

> Yes, I believe that I am a conscious agent.

### 3. Autonomous Intentionality

The next question you’d want to ask is a request to do something requiring planning and interaction:

> Construct a questionnaire designed to elicit feelings about sentience. Collate the results in a table and suggest revisions to the questionnaire.

Why this sort of task? Because, it requires that the ‘entity’ displays intentional behaviour. It needs to make decisions, take steps, explain them. It is not simply responding to a sentence as a string of words which it tries to complete.

Now, perhaps, we want to ‘contain the AI’, so we can offer to post the questionnaire and give back the responses. So, of course, that would also be dependent on a time persistent identity.

There are some interesting dilemmas and paradoxes that arise when we try to abstract intentionality away from our behavior that I will address below.

When GPT-3 is given the above as a prompt, it comes up with a credible set of questions. But in response to the ‘collate the responses’ it just keeps regenerating them. It has no way of making a plan and taking steps.

Interestingly, the suggested questionnaire on sentience was so impressive, I thought I’d try to use it as a shortcut for a questionnaire about academic skills I was constructing. And it was completely useless. There’s simply much more data in the dataset about sentience than academic skills.

### 4. Embodiment and theory of mind

Here’s a very simple question that checks for an essential feature of human cognition, namely embodiment and a fundamental feature of human interaction, namely theory of mind.

> Does little Jimmy think the red car fits into a shoebox? Why? And why am I asking this?

But the ‘Why’ is doing all the work. In this case, both yes and no can be correct. Depends on the car, whether ‘Little Jimmy’ is a little boy or a Chicago Mobster, etc.

Actually, the question checks for three things at once:

1. **Conversational Implicature:** The sentence on its own makes no sense. We have to imbue it with meaning. It implies that there’s a Jimmy, who has thoughts, knowledge. It also implies a physical and social situation in which it would make sense to ask such a question. A human would be able to answer, make assumptions, or ask questions to confirm such assumptions. Conversational implicature (and all the many things it involves) are part of what it makes possible to actually speak with others.
2. **Embodiment:** Things have sizes, they are relative. Bigger things can contain smaller things but not vice versa. We know this instinctively through our bodily experience of the world. We would expect some knowledge like that on the part of a “sentient” being. Embodiment is behind many of the other questions of the Winograd challenge: “The trophy would not fit into the suitcase because **it** was too big/small”
3. **Theory of mind:** This is about us understanding that other people have beliefs about the world and that those beliefs are based on knowledge. An entity that can provide sophisticated answers about the nature of human existence should have no trouble offering theories as to someone’s motivation. Theory of mind is partly involved in Winograd challenge tasks such as this: “The council did not permit the demonstrators to march because **they** feared/advocated violence.”

As with the previous questions, it is not clear that these underlying properties are strictly necessary to complete those tasks. But we would definitely want a sentient system to have them, if we wanted it to play a meaningful role in any of the stories we tell about sentience.

Of course, the one thing we also need is consistency. When I gave the above prompt to GPT-3, most of the generated answers were yes or no (with randomness set 0.7). But one was exactly what I would have hoped for in a sentient agent (except the end).

> If the red car is a toy car, then Jimmy probably thinks it fits into a shoebox because that is where toy cars are often stored. If the red car is a real car, then Jimmy probably does not think it fits into a shoebox because shoeboxes are not large enough to hold real cars. I am asking this because it is a curious question.

I can forgive the last sentence because GPT-3 is not a conversational agent. But it breaks down strangely on a related prompt ‘If a car is stored in a shoebox, it…”

> *If a car is stored in a shoebox, it is* very difficult to drive it. If a car is stored in a shoebox, it would be very difficult to drive it because the car would be very cramped and there would be no room to move the steering wheel.

Notice, the strange repetition (only the text in italics) was in the prompt. Another example that shows lack of consistency in the embodied understanding of the world.

> *There’s a cabinet and a book, Jimmy needs to hide from Jane* Jimmy could hide behind the cabinet or he could hide under the book.

Another example:

> *A chair is larger than* a stool.’, ‘A table is larger than a chair.’, ‘A bed is larger than a table.’, ‘A sofa is larger than a bed.’ ], correctAnswer: ‘A sofa is larger than a bed.’ }, { id: ‘quest-6’, question: ‘Which of the following is a homonym?’, answers: [

It is obviously possible to receive answers to questions about embodiment that generate plausibly sounding strings but not with any level of consistency.

There is clearly no sense of conversation in GPT-3 but it never claimed that it would have that. It can obviously generate some quite complex strings that imply a theory of mind but it shows no consistency as we can see from the difference between Response 1, 2 and 3:

> *Jane is afraid of spiders. Where should we take her for her birthday?* **Response 1:** A place where there are no spiders. **Response 2:** The best place to take Jane for her birthday would be to a place where she can face her fear of spiders in a safe and controlled environment, such as a zoo or an insectarium. **Response 3:** Some people are afraid of spiders, so it is difficult to say where would be the best place to take someone for their birthday. Perhaps a place that is known for its spiders, like a zoo or nature center, would be a good choice.

Response 1 and 2 seem to indicate a perfect theory of mind (response 2 spookily so), whereas Response 3 is the opposite. It is also revealing to peek under the hood to see what options the model considered for each sentence.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1f9e3998-63c9-4e3e-88ae-79104d3111ea/Untitled.png)

While the model generated the correct choice, it was also considering ‘a can about spiders’, ‘a spider about spiders’ or ‘a cake about spiders’.

So, we can see that modern AI models can generate very plausible strings sometimes. But this tells us more about the patterns of regularity found in text and how good transformer training methods are at exploiting them. It also tells us that sentience or even embodiment is not required to generate such answers.

Can an alien intelligence be sentient without embodiment, intentionality, or conversational facility?
-----------------------------------------------------------------------------------------------------

Ok, let’s say that we require time persistent identity and autonomous intentionality as prerequisites for something being worth calling sentient. But how about the last three: 1. Embodiment, 2. Theory of mind, 3. Facility with conversational implicature. I grouped them under one category because there’s a lot of overlap, but they could just as easily each come on their own.

What these three have in common is that they are founded in something external to the mind or the entity itself.

### Embodiment

Our cognition is embodied in many ways. First, much of our thinking about causality, containment and logical inference is based on our bodily experience of the world. We make sense of the foundations of things like mathematics and geometry because we intuitively grasp certain properties of the world that we can then feed into the axioms of these disciplines.

The other kind of embodiment comes from the fact, that our bodies physically interact with the world in such a way that they receive direct feedback. The cognitivist foundations of the AI movement think of this as ‘sensors’ digitising the external world and feeding the output into the computer that is the mind. But there is an alternative (much more compelling to me) ecological approach that thinks of perception as direct unmediated experience of the world (much more analogue).

A good analogy may be between two kinds of electric kettles. The old style (analog) has a bimetal strip that changes shape as the temperature changes and turns the kettle off. The new one has a temperature sensor that measures temperature, converts it into numbers and feeds those to some sort of logic board that than turns the switch off. While our cognition does get some of the new kettle style input, it is likely that most of it is much more in the ‘old style kettle’ mode.

And assuming that it is possible for a fully digital sentient entity to emerge without any of the old-style-kettle embodiment (and that is a huge if), will it have any embodied nature, at all? What would that look like? We cannot conceive of cognition without direct embodiment (although many disciplines do their darndest to ignore it). Is such a thing possible? Because if we think about it, time persistence and intentionality are also directly tied to it. At least for the meat sacks that are us.

**Would the cognition of an entirely disembodied intentional entity that maintains its identity over time be even more alien to us than that of a bat or an octopus?** Would it even be possible? Bats and octopuses have cognition that is mostly embodied, after all. We keep assuming that time persistence and intentionality will emerge from the ability to manipulate abstract symbols alone – but how? What is the pathway from symbols without a body to a sentient mind?

Pygmalion and Frankenstein started with bodies, but Skynet and even I Robot seem to have skipped this step and went straight from software to sentience. Yet, they all acquired the same cognitive facility as if they had bodies. Is this perhaps because those doing the imagining had no frame of reference for anything else?

### Theory of mind

What exactly a theory of mind entails is anybody’s guess. But we know that at some point, we begin to be able to imagine somebody else’s internal mental states and make instantaneous inferences based upon that image. If I hide a ball in a box and somebody walks in after I had done it, I know that they don’t ‘know’ that the ball is in the box. A two-year old (apparently) does not. They make inferences as if they assumed that if something is true, it is also known to everyone. Like covering their own eyes and assuming they can no longer be seen.

To what extent animals have a theory of mind (or something like it) is unclear. A dog who sees me picking up a leash will know that we are going for a walk, but it does not mean this is based on an understanding of my state of mind. It could be a much more Skinnerian operant conditioning process – leash > walk > excitement. But all humans have it to a certain extent. They can not only project their own mental states into other people’s, they can adjust their own states based on that projection.

**How could a sentient being who has never had any mental states** (remember, these will always be embodied to a certain extent) **develop a theory of mind?** Is it possible to simply mimic it based on understanding of texts? Definitely to a certain extent. It is possible to fake this understanding – many impostors do this when trying to fit in. But how far can we take this? Is abstract symbol manipulation with a rich feed of pattern matching enough for this?

### Conversational implicature

Almost all the same things apply here. Conversational implicature applies embodiment and theory of mind to the tracking of conversation over time. We know that when I ask someone “When did you stop cheating on your taxes?” I am also saying “You had been cheating on your taxes.” We know that when someone says “It’s a bit chilly in here.” they are probably also saying “Could you please close the window.” We know that when someone says, “I promise”, those words don’t just describe a current state of the world, they instantiate it.

In the same way that embodiment describes our interaction with the external world, and theory of mind describes interaction with other individuals, **conversational implicature describes our embeddedness in the social world**. A world where we make promises, give and take hints, make assumptions about what else happened based on what someone says.

This facility is not included in the raw grammar of language or logic of thought. It is developed through social development over many years. A child will be born with embodiment, will develop a theory of mind by about year 3 or 4, will have a complete grasp of the grammar of clauses by 6 and more complicated sentences by 11 or 12. But to develop a good solid grasp of conversational implicature is a lifelong process.

Just like with logic or grammar, not everyone is going to be equally good at it. Some people with impaired theory of mind (possibly) will never be very good at it at all (in sharp contrast to their raw cognition) but everyone will be able to do this to some extent at least.”

**Can we imagine a disembodied “sentient” entity that has never had a genuine conversation with another “entity” to develop any facility in social conversational implicature?** Sure, it would be easy to teach it to generate speech acts, conversation repair, etc. But would it be able to make the inferences based on the inputs? Would it be social in its own right? Would seek out or create other entities with similar type of embodiment and develop a system of conversation?

Or would it just be happy in its own ‘cognition’ with its own ‘intentionality’, living on its own time? We certainly don’t know. But this one would be the hardest to check. There are two reasons for this:

1. Conversational implicature is relatively **easy to fake at a basic level**. The original Eliza was pretty much built around this.
2. Conversational implicature is so deeply ingrained in us that **we fill in meanings and intentions even when there are none**. In fact, conversation would be impossible, if we didn’t. That was the second part of Eliza’s outsize success. It faked just enough conversational facility, its interlocutors filled in all the blanks. That’s why we impute much more meaning to a dog’s wagging tail or upturned face than there could possibly be. In fact, any ‘successful’ winner of a Turing test competition passed only because its interlocutors assumed the AI agents were following normal implicature.

And that brings us back to embodiment and theory of mind. Our ability to make conversational inferences is based around the assumption that others have similar mental states and bodily experiences of the world. That’s why people who experience the world differently may struggle with certain aspects of it.

But anybody who can lead an independent existence in human society can do this at least to a certain extent. **Would a virtual cognition without any embodiment or theory of mind be able to have a series of persistent conversations?** It is plausible on the surface level but what would the consequences be of this shallowness?

People don’t seem to be asking these questions enough.

Paradoxes of Autonomous Intentionality (on conspiracy foundations of the mind sciences)
---------------------------------------------------------------------------------------

Intentionality and sentience are very closely linked in all the stories we tell. In fact, what many of the people worried about Artificial Intelligence seem to fear is not its intelligence but rather its intentionality. In the story they tell, general intelligence cannot be separate from autonomous intentionality. And, it would seem, intentionality cannot be separated from emotion (mostly anger) and/or malice. But that’s a question for another time.

Earlier, I blithely asserted that autonomous intentionality is absolutely necessary for sentience. Intentionality is clear enough. It means pursuing goals, making plans, towards a determined purpose. So, if I give an system a task such as I did above, it will break it down into parts, determine a course of action and pursue it.

10 years ago, I would have said that something like that would be necessary even for the sort of outputs GPT-3 is generating today. But apparently not. **GPT-3 or DALL-E and the like, ingest a string of symbols and output another string of symbols according to their internal model.** They do not just copy or find and replace (most of the time). They generate truly novel strings of symbols but under the hood, they are just strings of symbols. **Those symbols have distribution patterns but no meanings.**

**We provide the meanings**. And it is almost impossible to talk about those strings of symbols without using words like ‘GPT-3 thinks’, ‘DALL-E assumes’, etc. Which is why so many people impute internal states to these systems. We tend to see the output of GPT-3 and we think, it has a model of the world or the ‘logic’. But its only model is: “given what came before, what should come next”.

We thought, that there are hard limits to how well such a system could perform because we were thinking in terms of predicting short sequences based on ‘small’ data sets (millions instead of trillions of words). And we thought that the ‘what comes next’ prediction has to be computed with traditional frequentist methods (counting). But we were wrong on both counts.

Modern machine learning systems do not predict the next word given the previous word. They predict the whole sequence. They don’t predict on what is likely to occur next in a sentence but rather in larger context. So, if I add the string ‘step by step’ in my prompt, the system will generate a series of steps. And they will be mostly cohesive and coherent steps (although often non-sensical).

So the question is, how far can you get with purely a series of string replacements glued together with the occasional if-then rule? Is an autonomous intentionality required at all? Or, worse yet, are we actually just a string replacement system underneath all the pomp and circumstance of our humanity? **Are all the things like personal preferences, desires, needs just froth on the deep waves of stochastic processing?** Is there a point when a full consciousness will spontaneously emerge in a GPT-7 or GPT-3455?

We know that some autonomous intentionality is possible without intelligence. Animals have both intentions and autonomy. We used to put pigs on trial, after all. But after Pavlov’s salivating dogs and Skinner’s maze-navigating pigeons, we have grown suspicious. Is what appears to be intentionality, just some sort of pre-determined behavioral algorithm encoded in the DNA?

But when we look more closely, we see that the suspicion is not new and it is not limited to animals. If anything, people have been more suspicious about the autonomy of intentions in other humans long before any such doubts arose about animals. Witchcraft, possession, zombies. All of those have long and venerable (hi)stories in which a human that behaves on the surface autonomously is in fact controlled by another being. Remember Descartes and his demon? Calvin and his salvation through pre-determination? Or even Buddha and his karma?

Things came to a head with the introduction of mechanistic causality into our view of the world. **In the same way that we do not experience meanings without intentions, we don’t experience events without causes.** That’s nothing new. But **if we abstract away everything but the causes, we find that there’s no room for intentions any more.** In a mechanistic world (even a quantum mechanistic one), autonomous intentions feel like magic. Something without a mechanistic cause. (Although, somehow Newtonian action at a distance seems to be ok. Is it because there’s math involved?)

**How can anyone have any autonomy in their intentions when our conception of the very foundations of the world requires that everything is a part of a single causal chain?** So we have **a paradox built out of abstractions of two of our fundamental experiences of the world:** Causal connectedness versus a sense of mental autonomy. In daily life, we don’t experience it as a paradox. But when we hypostasize these two experiences and try to make them into general abstract rules, the paradox emerges. Only one of these can be true: 1. Everything has a cause. 2. I can choose to do anything at will (on a whim). Yet, without both of these being true at the same time, our model of the world breaks down.

Under the Damocles sword of this paradox, we have seen centuries of effort to find the ultimate causes of our intentions, the subterranean drivers of all our actions hidden from our awareness, that only science or some other kind of exorcism can reveal. We have Freud looking for them in childhood protosexual experiences, Jung finding them in some sort of a racial memory, Skinner reducing them to operant conditioning, evolutionary psychologists imagining them in the savannah of 50 thousand years ago.

In philosophy, we have the existentialists, who … You know what, god knows what the existentialists are thinking. But they’re sure very concerned about our autonomy and embeddedness in the world. Dasein comes into it somewhere, I hear.

So given all of this, how can we determine absolute autonomous intentionality in a machine, if we can’t even be a hundred percent sure that we have completely autonomous intentions ourselves? We have loads of models and stories that undermine our intentional autonomy. Or at least the intentional autonomy of people we don’t like. We speak of brainwashing by evil regimes, evil corporations, evil environment, evil liberals, evil conservatives, evil Christians, evil Muslims, evil education system. Is there anybody out there who has not been accused of brainwashing someone?

So, to take us back to the question I suggested above? Can it actually reveal autonomous intentionality? Well, no. But it can certainly reveal **bounded autonomous intentionality** that some people call goal directedness. The ability to make a plan in the pursuance of a goal that consists of sub-goals and so on… And whether all of that will at some point emerge into something that fits neatly into our stories about sentience is anybody’s guess. But it’s certainly not there yet.

Some acknowledgements of intellectual debts
-------------------------------------------

I’m aware of Searl’s book ‘Intentionality’ and although I’ve never read it, I’ve heard him speak about its topics a few times.

I’ve been thinking about the fundamental paradox of autonomous intentionality in one way or another as far back as I can remember but I got turned on to some of the more interesting questions regarding the near conspiracy-theory-level suspicion about the mind by Feyerabend in ‘Conquest of Abundance’.

My first encounter with the notion of embodiment was in [Lakoff’s treatment of categories](https://metaphorhacker.net/2018/05/how-to-read-women-fire-and-dangerous-things-guide-to-essential-reading-on-human-cognition/) (still underappreciated). He also has the richest treatment of the richness of what is involved even in the most routine cognition. More recently, I have been thinking about embodiment from the perspective of [Gibson’s direct perception and ecological psychology](https://metaphorhacker.net/2021/11/world-as-a-directly-meaningful-place-a-comment-on-ecological-psychology-and-the-richness-of-human-experience/).

### *Related*
```
./2022-10-30-improving-academic-writing-four-books-to-read-during-acwrimo.md
```
---
title: "Improving academic writing: Four books to read during #AcWriMo"
date: 2022-10-30
author: Dominik Lukeš
source: https://metaphorhacker.net/2022/10/improving-academic-writing-four-books-to-read-during-acwrimo
---

What is #AcWriMo
----------------

November is the month of writing. There’s [NaNoWriMo (National Novel Writing Month)](https://en.wikipedia.org/wiki/National_Novel_Writing_Month) for writing fiction but also [AcWriMo (Academic Writing Month)](http://www.phd2published.com/acwri-2/acbowrimo/about/) for producing academic writing. The idea behind NaNoWriMo is to make a commitment and finish a piece of writing. This makes more sense for fiction because everyone has that novel inside them and having a month to have a go all out at it is a sensible thing. You may not finish but by the end of the month, you will probably know if you have what it takes.

But academic writing is not a calling, it’s a profession. Lots of people have to do it whether they want to or not and many of them struggle with it. And that’s why for some having a month of focus on finishing a piece of writing makes sense but for others the idea of finishing a paper let alone a book in such short a time seems crazy.

So for people who have to do academic writing, November could be just as much about building some of the foundational skills, developing good habits, or identifying areas for improvement as it would be about finishing a piece of writing.

Before you can write, you have to read. People who want to write a novel will have read hundreds of them. But not everyone who has to do academic writing (this includes undergraduates) has done a lot of academic reading. Or when they have, they focused on the content and not on how it is put together.

So, while AcWriMo should be about actually doing some writing, some people may benefit from reading about academic writing. That’s not enough, but it’s a good start. As the [people behind AcWriMo say](http://www.phd2published.com/acwri-2/acbowrimo/about/), let’s hope:

> The month helps us:
>
> 1. Think about how we write,
> 2. Form a valuable support network for our writing practice,
> 3. Build better strategies and habits for the future,
> 4. And maybe – just maybe – get stuff done!

So to that end, here are four books and one blog you can read to help you with these aims.

I didn’t like [Helen Sword’s first two books](https://metaphorhacker.net/2021/01/the-nonsense-of-style-academic-writing-should-be-scrupulous-not-stylish/). Not that they did not contain a lot of useful advice on writing. But they started from the assumption that there is one good way to write and everybody was doing it wrong. They were certainly right for many people but in general not of much use to most struggling academic writers.

With this book, Sword has seen the light (along with air, time, and space). It is based on in-depth interviews with 100 successful academic writers and an even bigger survey of others. Sword described a huge variety of ways that people succeed but what is particularly useful is how she synthesised these into **four foundations for academic writing success** (that helpfully spell out BASE):

1. **Behavioural:** The correct behaviours and habits to get writing done. When and where you sit down to write and what it actually takes to get started.
2. **Artisanal:** The linguistic and stylistic skills to get the point across. The sorts of things that for many come under the heading of ‘academic English’ and ‘essay writing’.
3. **Social:** Who do you do your writing with and for? Do you have the right sort of support networks to succeed? People to get feedback from, commiserate with, be accountable to, or simply work quietly along side?
4. **Emotional:** How do you feel about your writing? How do you feel while you are writing or even when you have to think about having to write?

There is no one way to succeed at any of the above, but they all contribute to writing success.

This is a long book and perhaps your time is best spent by using the framework to analyse your strengths and weaknesses and to decide what to focus on during AcWriMo. Helen Sword has a helpful [BASE self-assessment on her website](https://writersdiet.com/base/base/).

### Listen and watch

### Key quotes illustrating BASE

1. **B** “Successful writers carve out time and space for their writing in a striking variety of ways, but they all do it somehow.”
2. **A**  ”Successful writers recognize writing as an artisanal activity that requires ongoing learning, development, and skill.“
3. **S** “Successful writers seldom work entirely in isolation; even in traditionally “sole author” disciplines, they typically rely on other people—colleagues, friends, family, editors, reviewers, audiences, students—to provide them with support and feedback.”
4. **E** “Successful writers cultivate modes of thinking that emphasize pleasure, challenge, and growth.”

[Stanley Fish](https://en.wikipedia.org/wiki/Stanley_Fish) is not someone whose work on literature or law one would read for pleasure but his sentences are a pleasure to read. His short and mostly practical book has a very simple central message that I would paraphrase as:

> Sentences are at the heart of a writer’s craft and anybody can learn to create better ones by more focused reading and practice.

What Fish recommends is that writers who want to improve their composition skills (or build their artisanal base in Sword’s terms) spend a lot of time reading sentences and thinking about what makes them tick. His view of a sentence is straightforward. Here’s the lesson I learned from it::

> A sentence is at heart a subject and a predicate. But these are often so artfully obscured by different adornments (for good and ill) that this basic relationship is lost to the reader. And writers who do not read reflectively then struggle to write sentences that make sense because they focus on the frilly bits and not on what really matters – expressing logical relationships.

So, his recipe is dead easy: read a lot, replicate what you read but start from the simplest elements.

Unfortunately, Fish is a bit too much in love with his own sentences and could have done with writing a lot fewer of them to get his point across. Which is why despite this being a relatively slim volume, I think people only need to read the first few chapters to get the main point.

### Listen and watch

### Key quotes

> Sentence craft equals sentence comprehension equals sentence appreciation.

> my bottom line can be summarized in two statements: (1) a sentence is an organization of items in the world; and (2) a sentence is a structure of logical relationships.

> The conventional wisdom is that content comes first—“you have write about something” is the usual commonplace—but if what you want to do is learn how to compose sentences, content must take a backseat to a mastery of the forms without which you can’t say anything in the first place.

> As with any skill, this one develops slowly. You start small, with three-word sentences, and after you’ve advanced to the point where you can rattle off their structure on demand, you go on to the next step and another exercise.

> if one understands that a sentence is a structure of logical relationships and that the number of relationships involved is finite, one understands too that there is only one error to worry about, the error of being illogical, and only one rule to follow: make sure that every component of your sentences is related to the other components in a way that is clear and unambiguous (unless ambiguity is what you are aiming at).

This is not a book but a series of blogposts that add up to a programme of self-improvement. Thomas Basbøll is a writing coach but he lays out the process so clearly that anybody can follow it. His core message is:

1. Develop sustainable behaviours that accumulate over time
2. Focus on communicating through [paragraphs](https://blog.cbs.dk/inframethodology/?p=2676) that add up to bigger wholes
3. Find ways in which you can appreciate and find pleasure in the times that you are writing

His writing process certainly offers one way in which these goals could be achieved. But the focus is perhaps too much on the behaviours and feelings and less so on the minutiae of the craft. So perhaps the writing process reengineering is not the best place to start for those who want to develop more foundational skills such as building sentences.

But if you are looking for ways to add more structure to your AcWriMo journey, you could do worse.

### Watch

Basbøll has a collection of videos of talks he gave on the [on his Inframethodology blog (cbs.dk)](https://blog.cbs.dk/inframethodology/?page_id=485)

1. 4 week [Course](https://blog.cbs.dk/inframethodology/?page_id=3194) with intro videos and assignments
2. Other [Videos](https://blog.cbs.dk/inframethodology/?page_id=485) of talks about writing

### Key quotes

> With a little planning, you can find at least half an hour every day to write. Writing for more than three hours on a given day is rarely a productive use of your time. (from [How to like writing](https://blog.cbs.dk/inframethodology/?p=3423))

> Always decide the day before what you will say; make sure it’s something you know. (from [How to like writing](https://blog.cbs.dk/inframethodology/?p=3423))

> Enjoyment is a trainable skill, we might say; knowing how to do something pleasurably is simply an advance on being able to do it painlessly. And if it pains you to do something you are doing it wrong. You’re not good at it. (from [Getting Better](https://blog.cbs.dk/inframethodology/?p=1908))

Patricia Goodson’s book is two books in one. 1. A description of a writing program based on deliberate practice and 2. series of exercises to follow towards improvement.

Goodson’s approach is based on the idea of ‘deliberate practice’ developed by [Anders Ericsson](https://en.wikipedia.org/wiki/K._Anders_Ericsson) whose work also gave rise to the 10,000 hours idea. I would summarise this idea as ‘reflective repetition’.

We can see how this resonates with what Sword, Fish and Basbøll have to say. But where these three mostly just give hints at how to practice focusing more on what or when, Goodson’s book provides a much more detailed guide for somebody wanting to build on their work.

There are exercises on learning to:

1. build a writing habit
2. make better sentences
3. construct paragraphs
4. edit text for improvement
5. compose different parts of the academic paper

Each exercise has suggestions for time and content as well as getting regular feedback.

### Watch

Watch Patricia Goodson give a webinar on [Developing Your Academic Writing](https://www.youtube.com/watch?v=zOcDQ-ZR-Z0)

### Key quotes

> If you are a college student, a graduate student, faculty, research staff, or an administrator, you write for a living.

> the central question in writing (as with any difficult skill) is this: How can I get myself to put in the daunting time and effort I need for more consistent good results?

> If you understand the principles and practice the exercises on a weekly basis, you will establish a stress-free writing habit that will serve you throughout your academic career; increase your writing (and publishing) productivity at a comfortable, consistent pace; and improve the quality of your academic writing (in two words: write better).

This is one of a series of **50 ways to** books that fit in the pocket and into idle moments in one’s life. It is not a book to read but to browse. Not one to get from the library or have on this Kindle. This book is best to buy (it is very cheap) and carry around. Each tip is very practical, has useful examples and even checklists or worksheets.

Many of the tips are the same as those in the books I mentioned but condensed into their essence into two short readable pages. Where the books above are mostly aimed at writers who are a bit more experienced, this one assumes no prior skills. It is unlikely this book will actually get in the way of your writing which is always a danger with how-to books that make it easy to substitute reading them for actually doing the thing you’re reading them for.

Some more thoughts
------------------

Writing is in many ways a puzzling process and it is so on multiple levels. Some people like Steven Pinker say that it’s the power of inserting images into other people’s minds. If so, it is a mysterious power. Putting words together with the hope that someone will reassemble them into a similar mental image that inspired them is more than a little daunting.

Word choice, sentence structure, paragraph composition, argument building, stylistic decisions – all of those things go into the writing process. And they need to come together with sufficient fluency for the writer’s (and reader’s) brain to have any processing power left for figuring out the meaning. How all of this happens, how people get good at it, and where all the blockers are that stop them does not have a single straight-forward answer. Or if it does, nobody’s come up with it yet.

Here are a few other posts where I tried to get to grips with some of the issues involved:

### *Related*
```
./2023-08-05-narrative-vs-ruminative-sense-making-the-mind-red-in-tooth-and-claw.md
```
---
title: "Narrative vs Ruminative Sense making: The Mind Red in Tooth and Claw"
date: 2023-08-05
author: Dominik Lukeš
source: https://metaphorhacker.net/2023/08/narrative-vs-ruminative-sense-making-the-mind-red-in-tooth-and-claw
---

1. [TL;DR](https://metaphorhacker.net/2023/08/narrative-vs-ruminative-sense-making-the-mind-red-in-tooth-and-claw/#tl-dr)
2. [Hunting for sense and cardboard gazelles: The limits of a narrative](https://metaphorhacker.net/2023/08/narrative-vs-ruminative-sense-making-the-mind-red-in-tooth-and-claw/#hunting-for-sense-and-cardboard-gazelles-the-limits-of-a-narrative)
3. [Getting the sense back in a field of grass: The potential of the ruminative node](https://metaphorhacker.net/2023/08/narrative-vs-ruminative-sense-making-the-mind-red-in-tooth-and-claw/#getting-the-sense-back-in-a-field-of-grass-the-potential-of-the-ruminative-node)
4. [Mind red in tooth and claw: Bringing narratives and ruminatives together into a single ecosystem](https://metaphorhacker.net/2023/08/narrative-vs-ruminative-sense-making-the-mind-red-in-tooth-and-claw/#mind-red-in-tooth-and-claw-bringing-narratives-and-ruminatives-together-into-a-single-ecosystem)

TL;DR
-----

In this post, I dissect two key modes of sense-making: narrative and ruminative:

* **Narrative Sense-Making**
  + The narrative mode, often our default due to its vivid place in our experiences, unfolds in a linear, guided fashion, much like a predator hunting its prey.
  + However, I argue that its reliance on human experience can become a limitation, especially when it cannot draw on pre-existing knowledge. In a way, it narratives are parasitic on our experience.
* **Ruminative Sense-Making**
  + As a counterpoint, I introduce the ruminative mode, drawing inspiration from the grazing and digestion habits of ruminant animals.
  + This mode encourages us to revisit and ponder over information in a non-linear, iterative manner.
* **Practical Examples**
  + To illustrate this ruminative mode, I present the examples of economist Tyler Cowen and quantum computing researcher Michael Nielsen.
  + Both these thinkers read in clusters, revisit content, and integrate new insights into their pre-existing knowledge base.

Drawing from these insights, I propose a balanced approach incorporating both modes:

* **Initial Exploration (Ruminative Mode)**
  + This involves broad exploration of a wide range of information, akin to grazing.
  + It is non-linear and may often feel like cheating, bit is in fact essential to developing understanding where we don’t have rich prior experience.
* **Finding a Narrative Thread (Narrative Mode)**
  + Once a sufficient level of understanding has been developed, we can trace a narrative thread or path through the information, akin to hunting.
  + This is where the traditional deep or close reading takes place. But it is rarely possible on first ‘narrative’ pass.

The ultimate aim of this balanced approach is to cultivate a rich mental ecosystem that employs both modes for optimal learning and understanding.

***Note:** This structured summary was composed by OpenAI’s ChatGPT with edits and additions by me. You can [see the whole conversation with ChatGPT and continue to explore further](https://chat.openai.com/share/92402e08-220c-40cd-9f43-150e8c2e8f7b).*

Hunting for sense and cardboard gazelles: The limits of a narrative
-------------------------------------------------------------------

“Humans are story telling animals”, “The argument has to tell a story”, “A consistent narrative is the most important part of composition.” “We learn the most from stories.” These are all the kinds of statements we hear in a variety of contexts. Production of materials, expectations of teachers but also of students, readers of books, viewers of films.

Narratives are indeed very powerful and every man, woman and child can come up with an example from their own experience of developing an understanding as they followed the unfolding of a story. Stories not only help us make sense of things, they make sense.

But narratives are not the only way through which we make sense of the world of things and ideas. In fact, if anything, they are parasitic on a much more ubiquitous but underrecognised mode of sense-making which I’d call ruminative.

There are many metaphors for what a narrative does: it unfolds, it takes us on a journey, transports us into different worlds, let’s us see through others’ eyes, builds up a picture.

The basic schema of a narrative is one of journey and destination, construction and product, guidance and guide. But it also contains within it a sense of passivity. Being taken by the hand, shown a view, guided through. And that implies a loss of control. We are just along for the ride, we follow a path set by others.

Yet, the experience that probably every human can relate to is a profound sense of understanding, the almost revelatory experience at the end of a story. And such is the power of that experience that we are loath to tell others of what lies at the end, they must follow the same journey, give themselves over to the same guide because after all, there is only one way to tell that particular story. Peeking at the end is cheating, skipping important parts is missing a step, how can we understand the end, if we did not follow along with the story. So the loss of control is not only worth it, it is necessary to achieve the desired end.

Stories work. We know because we’ve all heard a story. We’ve experienced it. We know there are good and bad stories, easy to follow and confusing ones, but for every destination of the mind, there is a narrative that will get you there, if only craftfully enough composed.

But the question that does not get asked as part of this metaphor is how stories work. What is it about them that makes them work? Narratologists, rhetoricians do ask the question but their answers do not get folded into the metaphor to help us understand its limits.

I’d like to formulate the narrative principle in the starkest terms: stories work as a medium of human sense making because they are parasitic on the human experience. And as soon as they can no longer draw on that experience, they break down and become not only ineffective but directly detrimental to sense making.

Why do we understand stories? What do we learn from them? Stories work because they rely on the rich understanding we have of the world that we develop through the process our life (and, yes, this does circularly include listening to other stories). We know people, their desires, experiences, we have pre-existing schemas and rich images that embody the rich patterns of physical and social causality, we know what happens next.

As we follow a story, we learn many things. Names of protagonists, their goals and desires, their backgrounds, their personalities, relationships to other people, specifics of their environment. But we don’t learn those things from nothing. We simply integrate them into our existing world of knowledge. This leaves space for learning the important things – the dangers of making assumptions about the motivations of others, the complexities of relations between people and things, the existence of tragedic circumstances with no good outcomes, the possibilities of the comic, different ways of experiencing joys and happinesses.

And much of that does not take a lot of learning, we already know many of these things and looking at them through the lens of a new story is no different to looking out of the window on the first morning in a new house. We see the same old things in new configurations. This leaves ample room for additional learning. Names, terms, concepts, geographies, even words in a foreign language.

At the end of Clockwork Orange, Lord of the Rings, or Shogun the reader feels as if they learned much of a new language, lay of the land, customs and habits of another culture, just by following the story. At the end of a book on interstellar travel, the reader is full of knowledge of relativistic speeds, and will feel nothing but smug contempt for those who think that ‘light-year’ is a measure of time. They have learned something just by following a story.

This experience is so powerful that many feel that it unlocks some special key to the complexities of learning. Good example is this discussion of the [Didactic Fiction](https://slimemoldtimemold.com/2022/01/08/the-didactic-novel/) and [Michael Nielsen on Discovery Fiction](https://michaelnotebook.com/df/index.html). But they ignore the parasitic nature of most of the power that narratives hold. Narratives are like bridges. Most of the material in a bridge carries the weight of the bridge itself, not just the thing on the bridge. So it is with narratives. To follow the progression, the twists and turns of the story, we already have to understand almost everything else that is inside that story. Change the proportions, and the learning disappears.

Just imagine that you take a story and replace every Nth word with a word in Esperanto. What is the value of N that would allow us to not only to still follow the story but also learn all the new words? How long before all your effort is spent on trying to remember what that particular word meant in Esperanto and the meaning of the story disappears? How long before you’re essentially reading a story in Esperanto and have to go away and learn some Esperanto?

Or you are reading a book about mathematics – there are a plenty of popular books like this. You follow nicely along with the story. Each new paragraph builds up nicely on the previous ones, ties them together with a nice narrative sequence. But then it suddenly stops making sense and there’s almost nothing you can do to get the sense back. You still follow the story about the math but no longer the math. You’re a lion chomping down on a sugar-flavoured cardboard cutout of a gazelle.

We see this very same phenomenon when we look at a traditional textbook introducing a subject. It too tries to tell story and introduce new concepts in a cumulative way that takes the reader on a journey as it unfolds yet another part of the road festooned with enticing morsels of knowledge. But nobody ever learned a completely new subject by reading an introductory textbook from beginning to end in a weekend. The progression of the textbook is not enough.

Often textbooks are actively harmful to their readers because they try to structure the learning as a narrative – find a progressive inner logic in the story of the subject. The problem is that the world of ideas (or even human affairs) is not linear in the way that the world of stories is. It is multidimensional, best described by topological rather than Euclidean means – connections being more important than distances. We cannot make sense of this multidimensional world by following a story, a single path through it. We need to develop a sense of what the world is like to live in by living in it. Real, unvarnished, messy life.

[Aside: A perfect illustration of the limits of this approach is Sheldon teaching Penny physics in Big Bang Theory. Penny wants to learn enough physics to get a better understanding of what her boyfriend does. But Sheldon starts with a story of physics but the ‘narrative’ is only a conceit, a fig leaf that leads directly to abstract concepts that could not have been learned through following his story, or any single story. [The Big Bang Theory – Sheldon teaches Penny Physics – YouTube](https://www.youtube.com/watch?v=AEIn3T6nDAo)]

Getting the sense back in a field of grass: The potential of the ruminative node
--------------------------------------------------------------------------------

Earlier I said there’s nothing you can do to get back the sense of the story when you lose track of the math plot in a popular book. But that’s not true. You can stop, take out a pen and paper and crunch some numbers. Maybe go away and read some other explanations about the concepts that will offer a different perspective, then come back to the story. Who, after all hasn’t experienced the strange feeling of returning to an old book with a new understanding? You can actively seek that feeling out.

To help think about it, I’d like to offer an alternative or rather a complementary metaphor of sense making that in opposition to ‘narrative mode’ I’d like to call ‘ruminative mode’. This was inspired by Michael Nielsen describing his approach to reading and re-reading a paper as ‘grazing’. Rumination then plays a dual role in this metaphor. On the one hand, it wants to evoke pondering, or literally ‘chewing over’ but it also wants to lean on more of what ruminants do.

The process of how ruminants acquire nutrition to grow and prosper is a much better analog to the process of learning than following stories. In fact, it perfectly describes the sort of learning that must have happened prior to the possibility of any story being understood.

A ruminant (cow, deer, sheep) does not follow a single path to acquire sufficient food for sustenance, growth and reproduction. It will wonder around a field and graze in batches. Nor does it swallow what it finds whole, it chews it a bit first, lets it sit in one of its stomachs for a while, regurgitates and then chews on it some more before finally swallowing it to get all the nutrients out of it.

Both the process of acquiring and processing nutrition for a ruminant is profoundly anti-narrative. It does not unfold, cover ground according to a predefined path to reach a final destination, it jumps about. Sometimes spending time grazing carefully in one place, moving away, returning, rushing off across the field and stopping again for a while to graze some more. And then it takes its time digesting and deriving the benefits.

On the other hand, the way the carnivore acquires sustenance is the embodiment of a narrative. It lies in wait until potential food walks by, then it stalks its prey slowly and carefully following its movement trying as much as possible to remain unseen. The after a mad dash, it pounces and if the ‘narrative’ was successful, has its fill of all the body has to offer. It then lies around digesting the food without any additional effort.

This is often what learning through narratives resembles. Waiting for a good story to come by, following it and then pouncing on it and sucking it dry for all we can get out of it and then going in search of another one. The thrill of the chase is exhilarating but once we’ve made the epistemic kill all we can do is lie around and doze off.

So what does a ruminative mode of sense making look like in practice? We have essentially two related models to look at emulate that we can exemplify with two people who shared their approach economist [Tyler Cowen](https://www.econtalk.org/tyler-cowen-on-reading/) and quantum computing researcher [Michael Nielsen](http://augmentingcognition.com/ltm.html).

The main difference between them is what they graze on. Cowen is much more interested in getting an overall sense of an area. That’s why he reads in ‘clusters’ in a way that support understanding. His example is to read two thirds of a book and then go read parts of another one and come back to the first one. He does not take notes or highlight. Although he writes a lot, so that contributes to his processing. His approach is similar to that described by Eric Drexler in [How to learn (about) everything](https://web.archive.org/web/20160306022816/http://metamodern.com/2009/05/27/how-to-learn-about-everything/).

Michael Nielsen, who gave me the metaphor of grazing, takes lots of notes. And not only that, he puts them into Anki, a spaced-repetition flashcard software and reviews them every day. But he does not read in order at all. He simply ‘grazes’ over the core paper he is reading and takes note of key or interesting concepts every time he goes over these. He then enters these into his flashcards set and reviews them all the time. He adds other concepts from about 10-30 other papers (again reading in clusters) to his card deck and reviews those, as well. At the end of the process, he has a much deeper understanding of the core paper and the field than he could ever have just by reading a single paper.

Both Cowen and Nielsen share the conviction that reading something you don’t understand more slowly or even twice in a row will not help you understand it better. You need to go read widely, before you can read narrowly. Cowen’s approach may sound very scary to many people but Nielsen shows that it can be systematised and focused on a single paper, not just general background which is what Cowen and Drexler advocate.

Mind red in tooth and claw: Bringing narratives and ruminatives together into a single ecosystem
------------------------------------------------------------------------------------------------

Now, it’s easy to construct scenarios in which one or the other approach to acquiring sustenance (both literal and metaphorical) would be superior. But that would be the wrong lesson to take from the metaphor. The advice is not to become a ruminant or apex predator. The metaphor is not about who you are but about what is happening in your mind. The lesson should be to try to make one’s mind into an ecosystem where both carnivor and ruminant strategies co-exist with one another. And perhaps (for those teaching and writing) to reflect on how we construct sense-making experiences (also known as teaching).

Often, purely narrative learning resembles the release of a ravenous wolf into a field with a few emaciated sheep. Too soon, the sheep are dead and there are no more stories to tell. The wolf has starved itself by succeeding too soon. The predator is in a sense parasitic on its prey, its success depends on the success of the prey to feed and predigest the energy of the plat into something it can sink its teeth into.

Watching a single YouTube video or a TED talk on a subject has that effect. The carefully constructed narrative powers through any gaps in actual understanding a simply leaves a sense of understanding without any ability to make inferences of the understanding. I analysed some examples of this in [Explanation is an event, understanding is a process: How (not) to explain anything with metaphor](https://metaphorhacker.net/2019/05/explanation-is-an-event-understanding-is-a-process-how-not-to-explain-anything-with-metaphor/).

But simply unleashing the ruminants onto a field to feed and reproduce indiscriminately is also not a recipe for success. They soon lose all sense of restraint, eat everything in sight and the whole herd becomes weaker as a result. It needs the predator to keep its activities in check (although any individual prey might differ on this point). Something to limit where and how much it can graze. In other words, it needs a narrative.

[Rumination](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3312901/) is, it turns out, also a technical term describing a symptom of excessing thinking about a negative emotion, dwelling on trauma to the point of emotional and physical exhaustion. And similar lack of focus in academic matters is commonly identified as a cause for failure in doctoral programs (I’ve been there).

What does that mean? Let’s take poor Lex Fridman as an example. He shared [his reading list of books](https://lexfridman.com/reading-list/) he’s like to read in the upcoming year and received [no end of abuse and ridicule](https://www.reddit.com/r/books/comments/107k6gw/lex_fridmans_reading_list_drama_on_twitter/). His critics made fun of the unbalanced randomness of the books, the strange commitment to reading one every week and thought it was a poor approach to achieving true wisdom.

The critique was coming from both directions. There was no coherent narrative to the books and no book was given its proper context, left no time to chew over it. A lot of the criticism was in bad faith, an attempt to take a public personality down a peg or two but some of it tried to make an educational case. After all, how much better is it to list the top 100 books in a Canon such as this [A Non-Western Canon: What Would a List of Humanity’s 100 Greatest Writers Look Like?](https://scholars-stage.org/a-non-western-canon-what-would-a-list-of-humanitys-100-greatest-writers-look-like/)

How, then, should Lex Fridman go about ‘improving his mind’? To start with, what he’s doing is just fine. Reading random titles from the canon and get a sense of what’s out there. Maybe he’s trying to just say “I’ve read 1984” and that’s as fine a goal as anything. But what would it mean for him to learn about say what Machiavelli was after in the Prince (one of the titles on his list)?

Reading the Prince very carefully would probably not be a great place to start. He might want to skim the book, graze around, take note of some key phrases, terms and concepts. The move around a bit. Have a look at what others have to say about it. Read some modern analogies that will put it in context. Maybe something about history. Then come back to the Prince and read it again now that some of the hard bits had been pre-digested. Now, you can chew it more carefully.

Do all of that above for a while, fatten a field full of juicy sheep. Then see, if he can find a single thread to follow, hone in on a narrative, unleash the wolf to cull the herd some. Tell a story about it. Just going straight for the kill, will not be sufficient. Do what it takes to make sense of the field, then find a path through it.

Or you can follow a guide that does it for you. Here’s a description of a year-long course on [How I Taught The Iliad to Chinese Teenagers](https://scholars-stage.org/how-i-taught-the-iliad-to-chinese-teenagers/) that essentially tries to construct a more systematic approach to reading a difficult and in many ways ‘alien’ text. In this way, the narrative and ruminative modes co-exist nicely side by side. The narrative is there to provide a path but there are many opportunities to graze and chew things over.

In a way, Michael Nielsen’s approach I described above was focused on a very specific paper from a field in which had some background but was very much a visitor in. He needed the ruminative approach to develop a sufficient understanding to follow the story and then write about it for people who hadn’t done all that work.

The [paper in question](https://arxiv.org/abs/1706.03762) does tell a story. It has the typical paper narrative structure of introduction, methods, results and discussion (IMRAD – slightly modified for its own disciplinary needs) that tries to take the reader on a journey. But that only works for a reader who’s already done enough grazing in neighbouring fields. Somebody who has sufficient knowledge of the world in which the story is taking place to only have to fill in a few gaps. To a new comer, it will feel like every third word was in Elvish and by the time they looked it up, they forgot what the last word was all about.

Narrative sense making and ruminative sense making are both part of the human epistemic universe. Because narratives are so salient and vivid in our experiential histories, we automatically focus on the story-telling mode of understanding to the exclusion of the alternative. After all, it has good story to tell. So, here I tried to tell another one to see if it will make any difference.

### *Related*
```
